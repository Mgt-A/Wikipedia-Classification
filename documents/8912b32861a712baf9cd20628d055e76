<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
		<meta http-equiv="Content-Style-Type" content="text/css" />
		<meta name="generator" content="MediaWiki 1.15alpha" />
		<meta name="keywords" content="Human extinction,Articles needing additional references from March 2008,Articles with unsourced statements since March 2009,Articles with unsourced statements since December 2007,Articles with unsourced statements since February 2009,Articles with unsourced statements since February 2007,Articles with minor POV problems from September 2008,Fact,Doomsday,1993,A.I. (movie)" />
		<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Human_extinction&amp;action=edit" />
		<link rel="edit" title="Edit this page" href="/w/index.php?title=Human_extinction&amp;action=edit" />
		<link rel="apple-touch-icon" href="http://en.wikipedia.org/apple-touch-icon.png" />
		<link rel="shortcut icon" href="/favicon.ico" />
		<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)" />
		<link rel="copyright" href="http://www.gnu.org/copyleft/fdl.html" />
		<link rel="alternate" type="application/rss+xml" title="Wikipedia RSS Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=rss" />
		<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=atom" />
		<title>Human extinction - Wikipedia, the free encyclopedia</title>
		<link rel="stylesheet" href="/skins-1.5/common/shared.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/common/commonPrint.css?207xx" type="text/css" media="print" />
		<link rel="stylesheet" href="/skins-1.5/monobook/main.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/chick/main.css?207xx" type="text/css" media="handheld" />
		<!--[if lt IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE50Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE55Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 6]><link rel="stylesheet" href="/skins-1.5/monobook/IE60Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 7]><link rel="stylesheet" href="/skins-1.5/monobook/IE70Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Common.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Print.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="print" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Handheld.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="handheld" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Monobook.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=-&amp;action=raw&amp;maxage=2678400&amp;gen=css" type="text/css" />
		<!--[if lt IE 7]><script type="text/javascript" src="/skins-1.5/common/IEFixes.js?207xx"></script>
		<meta http-equiv="imagetoolbar" content="no" /><![endif]-->

		<script type= "text/javascript">/*<![CDATA[*/
		var skin = "monobook";
		var stylepath = "/skins-1.5";
		var wgArticlePath = "/wiki/$1";
		var wgScriptPath = "/w";
		var wgScript = "/w/index.php";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = "http://en.wikipedia.org";
		var wgCanonicalNamespace = "";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = "Human_extinction";
		var wgTitle = "Human extinction";
		var wgAction = "view";
		var wgArticleId = "1528711";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = "en";
		var wgContentLanguage = "en";
		var wgBreakFrames = false;
		var wgCurRevisionId = 285988239;
		var wgVersion = "1.15alpha";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = ["", ""];
		var wgDigitTransformTable = ["", ""];
		var wgMWSuggestTemplate = "http://en.wikipedia.org/w/api.php?action=opensearch\x26search={searchTerms}\x26namespace={namespaces}\x26suggest";
		var wgDBname = "enwiki";
		var wgSearchNamespaces = [0];
		var wgMWSuggestMessages = ["with suggestions", "no suggestions"];
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		/*]]>*/</script>

		<script type="text/javascript" src="/skins-1.5/common/wikibits.js?207xx"><!-- wikibits js --></script>
		<!-- Head Scripts -->
		<script type="text/javascript" src="/skins-1.5/common/ajax.js?207xx"></script>
		<script type="text/javascript" src="/skins-1.5/common/mwsuggest.js?207xx"></script>
<script type="text/javascript">/*<![CDATA[*/
var wgNotice='';var wgNoticeLocal='';
/*]]>*/</script>		<script type="text/javascript" src="http://upload.wikimedia.org/centralnotice/wikipedia/en/centralnotice.js?207xx"></script>
		<script type="text/javascript" src="/w/index.php?title=-&amp;action=raw&amp;gen=js&amp;useskin=monobook"><!-- site js --></script>
	</head>
<body class="mediawiki ltr ns-0 ns-subject page-Human_extinction skin-monobook">
	<div id="globalWrapper">
		<div id="column-content">
	<div id="content">
		<a name="top" id="top"></a>
		<div id="siteNotice"><script type='text/javascript'>if (wgNotice != '') document.writeln(wgNotice);</script></div>		<h1 id="firstHeading" class="firstHeading">Human extinction</h1>
		<div id="bodyContent">
			<h3 id="siteSub">From Wikipedia, the free encyclopedia</h3>
			<div id="contentSub"></div>
									<div id="jump-to-nav">Jump to: <a href="#column-one">navigation</a>, <a href="#searchInput">search</a></div>			<!-- start content -->
			<table class="metadata plainlinks ambox ambox-content" style="">
<tr>
<td class="mbox-image">
<div style="width: 52px;"><a href="/wiki/File:Question_book-new.svg" class="image" title="Question book-new.svg"><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/50px-Question_book-new.svg.png" width="50" height="39" border="0" /></a></div>
</td>
<td class="mbox-text" style="">This article <b>needs additional <a href="/wiki/Wikipedia:Citing_sources" title="Wikipedia:Citing sources">citations</a> for <a href="/wiki/Wikipedia:Verifiability" title="Wikipedia:Verifiability">verification</a>.</b> Please help <a href="http://en.wikipedia.org/w/index.php?title=Human_extinction&amp;action=edit" class="external text" title="http://en.wikipedia.org/w/index.php?title=Human_extinction&amp;action=edit" rel="nofollow">improve this article</a> by adding <a href="/wiki/Wikipedia:Reliable_sources" title="Wikipedia:Reliable sources">reliable references</a> (ideally, using <i><a href="/wiki/Wikipedia:Footnotes" title="Wikipedia:Footnotes">inline citations</a></i>). Unsourced material may be <a href="/wiki/Template:Fact" title="Template:Fact">challenged</a> and <a href="/wiki/Wikipedia:BURDEN" title="Wikipedia:BURDEN" class="mw-redirect">removed</a>. <small><i>(March 2008)</i></small></td>
</tr>
</table>
<p><b>Human extinction</b> is the assured end of the <a href="/wiki/Human" title="Human">human</a> <a href="/wiki/Species" title="Species">species</a>. Various scenarios have been discussed in <a href="/wiki/Science" title="Science">science</a>, <a href="/wiki/Popular_culture" title="Popular culture">popular culture</a>, and <a href="/wiki/Religion" title="Religion">religion</a> (see <a href="/wiki/End_time" title="End time">End time</a>). The breadth of this article is on <a href="/wiki/Existential_risks" title="Existential risks" class="mw-redirect">existential risks</a>.</p>
<p>Humans are very widespread on the Earth, and live in communities which (whilst interconnected) are capable of some kind of basic survival in isolation. Therefore, <a href="/wiki/Pandemics" title="Pandemics" class="mw-redirect">pandemic</a> and deliberate killing aside, to achieve human extinction, the entire planet would have to be rendered uninhabitable. This would typically be during a <a href="/wiki/Mass_extinction" title="Mass extinction" class="mw-redirect">mass extinction</a> event, a precedent of which exists in the <a href="/wiki/Permian%E2%80%93Triassic_extinction_event" title="Permian–Triassic extinction event">Permian–Triassic extinction event</a> among other examples.</p>
<p>In the near future, two anthropogenic scenarios exist: <a href="/wiki/Catastrophic_climate_change" title="Catastrophic climate change">catastrophic climate change</a>, which seems increasingly likely, and all-out <a href="/wiki/Nuclear_war" title="Nuclear war" class="mw-redirect">nuclear war</a> which may well result from catastrophic climate change as nation states become increasingly desperate, and two possible natural ones: <a href="/wiki/Bolide_impact" title="Bolide impact" class="mw-redirect">bolide impact</a> and large-scale <a href="/wiki/Volcanism" title="Volcanism" class="mw-redirect">volcanism</a>. Both of these have occurred repeatedly in the geologic past and there is no reason to consider them unlikely in the future. As technology develops, there is a possibility that humans may be deliberately destroyed by the actions of a rogue state or individual in a form of global <a href="/wiki/Suicide_attack" title="Suicide attack">suicide attack</a>. A more likely scenario is the emergence of a pandemic of such virulence and infectiousness that very few humans survive the disease. While not actually a human extinction event, this may leave only very small, very scattered human populations that would then evolve in isolation.</p>
<p>It is important to differentiate between human extinction and the extinction of life on Earth. Of possible extinction events, only pandemic is selective enough to eliminate humanity while leaving the rest of life on earth relatively unscathed.</p>
<table id="toc" class="toc" summary="Contents">
<tr>
<td>
<div id="toctitle">
<h2>Contents</h2>
</div>
<ul>
<li class="toclevel-1"><a href="#Possible_scenarios"><span class="tocnumber">1</span> <span class="toctext">Possible scenarios</span></a></li>
<li class="toclevel-1"><a href="#Attitudes_to_human_extinction"><span class="tocnumber">2</span> <span class="toctext">Attitudes to human extinction</span></a></li>
<li class="toclevel-1"><a href="#Perception_of_human_extinction_risk"><span class="tocnumber">3</span> <span class="toctext">Perception of human extinction risk</span></a></li>
<li class="toclevel-1"><a href="#Observations_about_human_extinction"><span class="tocnumber">4</span> <span class="toctext">Observations about human extinction</span></a>
<ul>
<li class="toclevel-2"><a href="#Omnicide"><span class="tocnumber">4.1</span> <span class="toctext">Omnicide</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Scenarios_of_the_world_without_humans"><span class="tocnumber">5</span> <span class="toctext">Scenarios of the world without humans</span></a></li>
<li class="toclevel-1"><a href="#See_also"><span class="tocnumber">6</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1"><a href="#Further_reading"><span class="tocnumber">7</span> <span class="toctext">Further reading</span></a></li>
<li class="toclevel-1"><a href="#References"><span class="tocnumber">8</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1"><a href="#Notes"><span class="tocnumber">9</span> <span class="toctext">Notes</span></a></li>
</ul>
</td>
</tr>
</table>
<script type="text/javascript">
//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>
</script>
<p><a name="Possible_scenarios" id="Possible_scenarios"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Human_extinction&amp;action=edit&amp;section=1" title="Edit section: Possible scenarios">edit</a>]</span> <span class="mw-headline">Possible scenarios</span></h2>
<div class="rellink boilerplate seealso">See also: <a href="/wiki/Risks_to_civilization,_humans_and_planet_Earth" title="Risks to civilization, humans and planet Earth">Risks to civilization, humans and planet Earth</a></div>
<ul>
<li>Severe forms of known or recorded disasters
<ul>
<li><a href="/wiki/War" title="War">Warfare</a>, whether <a href="/wiki/Nuclear_warfare" title="Nuclear warfare">nuclear</a> or <a href="/wiki/Biological_warfare" title="Biological warfare">biological</a>, or conventional (although nuclear weapons and biological agents are likely to be used); see <a href="/wiki/World_War_III" title="World War III">World War III</a>.</li>
<li><a href="/wiki/Pandemic" title="Pandemic">Pandemic</a> involving an <a href="/wiki/Antibiotic" title="Antibiotic">antibiotic</a>-resistant <a href="/wiki/Bacteria" title="Bacteria">bacterium</a>, <a href="/wiki/Antifungal" title="Antifungal" class="mw-redirect">antifungal</a>-resistant <a href="/wiki/Fungus" title="Fungus">fungus</a>, <a href="/wiki/Gene" title="Gene">genetic</a> disease, <a href="/wiki/Prion" title="Prion">prion</a>, or <a href="/wiki/Antiviral" title="Antiviral">antiviral</a>-resistant <a href="/wiki/Virus" title="Virus">virus</a>. In practical terms this is unlikely as not all individuals and communities are likely to be exposed to a disease, and not all individuals die when exposed to infections.</li>
<li>Scientists such as <a href="/wiki/Richard_C._Duncan" title="Richard C. Duncan">Richard C. Duncan</a> have stated that a <a href="/wiki/Famine" title="Famine">famine</a> resulting from a combination of <a href="/wiki/Overpopulation" title="Overpopulation">overpopulation</a> and a <a href="/wiki/Resource_depletion" title="Resource depletion">depletion of key non-renewable resources</a> <a href="/wiki/Peak_oil" title="Peak oil">especially petroleum</a> is highly likely in the near future, as suggested by the <a href="/wiki/Malthusian_catastrophe" title="Malthusian catastrophe">Malthusian catastrophe</a> and <a href="/wiki/Olduvai_theory" title="Olduvai theory">Olduvai theory</a>. While most forecasters of such a famine predict only a severe reduction in human population as opposed to outright extinction, others have postulated that combined with probable related events (such as wars and pandemics) the human species might not survive.</li>
</ul>
</li>
<li>Environmental collapses
<ul>
<li>Catastrophic <a href="/wiki/Climate_change" title="Climate change">climate change</a> as a result of <a href="/wiki/Global_warming" title="Global warming">global warming</a> or the effects of extensive <a href="/wiki/Deforestation" title="Deforestation">deforestation</a> and <a href="/wiki/Pollution" title="Pollution">pollution</a>. (E.g. the warnings of <a href="/wiki/James_Lovelock#Mass_human_extinction" title="James Lovelock">James Lovelock</a>)</li>
<li>Loss of a breathable <a href="/wiki/Earth%27s_atmosphere" title="Earth's atmosphere">atmosphere</a>, for example due to an <a href="/wiki/Anoxic_event" title="Anoxic event">anoxic event</a>.</li>
<li>Occurrence of a <a href="/wiki/Supervolcano" title="Supervolcano">supervolcano</a>.</li>
<li>Extreme <a href="/wiki/Ice_age" title="Ice age">ice age</a> leading to <a href="/wiki/Snowball_Earth" title="Snowball Earth">Snowball Earth</a></li>
<li>The destruction of the <a href="/wiki/Ozone_layer" title="Ozone layer">ozone layer</a> causing higher <a href="/wiki/Ultraviolet_radiation" title="Ultraviolet radiation" class="mw-redirect">ultraviolet radiation</a>.</li>
</ul>
</li>
<li>Long term habitat threats
<ul>
<li>There is a 1% chance that during the life of our solar system the gravitational force from <a href="/wiki/Jupiter" title="Jupiter">Jupiter</a> may have exerted enough work on <a href="/wiki/Mercury_(planet)" title="Mercury (planet)">Mercury</a> to perturb its orbit enough to cross the orbital path of <a href="/wiki/Venus" title="Venus">Venus</a>.<sup class="noprint Template-Fact"><span title="This claim needs references to reliable sources&#160;since March 2009" style="white-space: nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed">citation needed</a></i>]</span></sup> Were this to happen, Mercury could be sent off its orbit when it gets critically close to Venus (see <a href="/wiki/Gravitational_slingshot" title="Gravitational slingshot" class="mw-redirect">gravitational slingshot</a>). Then, the planet may collide with Earth (though more likely colliding with Venus or the Sun, or simply leaving the solar system), wiping out any forms of life, including <a href="/wiki/Humans" title="Humans" class="mw-redirect">humans</a>.</li>
<li>Within a million years, the <a href="/wiki/Hypergiant" title="Hypergiant">hypergiant</a> <a href="/wiki/Eta_Carinae" title="Eta Carinae">Eta Carinae</a>, which is 7500 light years from the Sun, may go <a href="/wiki/Eta_Carinae#Future_prospects" title="Eta Carinae">hypernova</a>.</li>
<li>In 1.4 million years <a href="/wiki/Gliese_710" title="Gliese 710">Gliese 710</a> will be only 1.1 <a href="/wiki/Light_year" title="Light year" class="mw-redirect">light years</a> from Earth and might catastrophically perturb the <a href="/wiki/Oort_cloud" title="Oort cloud">Oort cloud</a>, possibly resulting in a comet shower.</li>
<li>In about 3 billion years, our <a href="/wiki/Milky_Way_galaxy" title="Milky Way galaxy" class="mw-redirect">Milky Way galaxy</a> is expected to <a href="/wiki/Andromeda-Milky_Way_collision" title="Andromeda-Milky Way collision" class="mw-redirect">collide with the Andromeda galaxy</a>. Collisions of individual bodies will likely be scarce; however, the consequences for orbits of stars and planets are unclear, and impossible to predict for individual stellar systems.</li>
<li>In 5 billion years hence the <a href="/wiki/Sun" title="Sun">Sun</a>'s <a href="/wiki/Stellar_evolution" title="Stellar evolution">stellar evolution</a> will reach the <a href="/wiki/Red_giant" title="Red giant">red giant</a> stage, in which it will expand and engulf Earth. But before this happens it will already have changed Earth's climate and its radiated spectrum may alter in ways Earth-bound humans could not survive.<a href="http://www.space.com/scienceastronomy/080226-vaporized-earth.html" class="external autonumber" title="http://www.space.com/scienceastronomy/080226-vaporized-earth.html" rel="nofollow">[1]</a></li>
<li>In the far future the main risks to human survival could be <a href="/wiki/Heat_death" title="Heat death" class="mw-redirect">heat death</a> and cooling with the <a href="/wiki/Expansion_of_the_universe" title="Expansion of the universe" class="mw-redirect">expansion of the universe</a>.</li>
</ul>
</li>
<li><a href="/wiki/Evolution" title="Evolution">Evolution</a> of humanity into a <a href="/wiki/Posthuman_(Human_evolution)" title="Posthuman (Human evolution)" class="mw-redirect">posthuman</a> life-form or <a href="/wiki/Existence" title="Existence">existence</a> by means of <a href="/wiki/Technology" title="Technology">technology</a>, leaving no trace of original humans
<ul>
<li>Commentators such as <a href="/wiki/Hans_Moravec" title="Hans Moravec">Hans Moravec</a> argue that humanity will eventually be supplanted and replaced by <a href="/wiki/Artificial_intelligence" title="Artificial intelligence">artificial intelligence</a> or other forms of <a href="/wiki/Artificial_life" title="Artificial life">artificial life</a>; others such as <a href="/wiki/Kevin_Warwick" title="Kevin Warwick">Kevin Warwick</a> point to the possibility of humans evolving by linking with technology<sup id="cite_ref-0" class="reference"><a href="#cite_note-0" title=""><span>[</span>1<span>]</span></a></sup>; while others have argued that humanity will inevitably experience a <a href="/wiki/Technological_singularity" title="Technological singularity">technological singularity</a>, and furthermore that this outcome is desirable (see <a href="/wiki/Singularitarianism" title="Singularitarianism">singularitarianism</a>).</li>
<li><a href="/wiki/Transhumanism" title="Transhumanism">Transhumanist</a> <a href="/wiki/Genetic_engineering" title="Genetic engineering">genetic engineering</a> could lead to a species unable to inter-procreate, accidentally resulting in actual (rather than <a href="/wiki/Pseudoextinction" title="Pseudoextinction">pseudo</a>) extinction.</li>
<li><a href="/wiki/Isaac_Asimov" title="Isaac Asimov">Isaac Asimov</a>'s <i><a href="/wiki/The_Last_Question" title="The Last Question">The Last Question</a></i>, <a href="/wiki/Greg_Bear" title="Greg Bear">Greg Bear</a>'s <i><a href="/wiki/Blood_Music" title="Blood Music">Blood Music</a></i>, and <a href="/wiki/Arthur_C._Clarke" title="Arthur C. Clarke">Arthur C. Clarke</a>'s <i><a href="/wiki/Childhood%27s_End" title="Childhood's End">Childhood's End</a></i> provide diversions on this theme.</li>
</ul>
</li>
<li><a href="/wiki/Evolution" title="Evolution">Evolution</a> of humanity into another hominid species. Humans will continue to evolve via traditional natural selection over a period of millions of years, and homo sapiens will gradually transition into one or more new species. This mechanism for the extinction of <a href="/wiki/Homo_sapiens" title="Homo sapiens" class="mw-redirect">Homo sapiens</a> would, however, require that regional interbreeding ceases for tens of thousands of years.</li>
<li><a href="/wiki/Dysgenics" title="Dysgenics">Dysgenics</a> among humanity resulting in a less intelligent species. (See <i><a href="/wiki/Idiocracy" title="Idiocracy">Idiocracy</a></i>.)</li>
<li><a href="/wiki/Population_decline" title="Population decline">Population decline</a>
<ul>
<li>Preference for fewer children; if <a href="/wiki/Developed_world" title="Developed world" class="mw-redirect">developed world</a> <a href="/wiki/Demographics" title="Demographics">demographics</a> are extrapolated they mathematically lead to 'soft' extinction before 3000 AD. (<a href="http://lifeboat.com/ex/bios.john.leslie" class="external text" title="http://lifeboat.com/ex/bios.john.leslie" rel="nofollow">John Leslie</a> estimates that if the reproduction rate drops to the <a href="/wiki/Germany" title="Germany">German</a> level the extinction date will be 2400<span class="reference plainlinksneverexpand" id="ref_2400"><sup><a href="http://en.wikipedia.org/wiki/Human_extinction#endnote_2400" class="external autonumber" title="http://en.wikipedia.org/wiki/Human_extinction#endnote_2400" rel="nofollow">[2]</a></sup></span>).</li>
<li><i>Political intervention in reproduction</i> has failed to raise the birth rate above the <a href="/wiki/Demographics_of_Russia#Figures_and_age_structure" title="Demographics of Russia">replacement level</a> in the rich world, but has dramatically succeeded in lowering it below the replacement level in <a href="/wiki/China" title="China">China</a><sup class="noprint Template-Fact"><span title="This claim needs references to reliable sources&#160;since December 2007" style="white-space: nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed">citation needed</a></i>]</span></sup> (see <a href="/wiki/One_child_policy" title="One child policy" class="mw-redirect">One child policy</a>). A <a href="/wiki/World_government" title="World government">World government</a> with a <a href="/wiki/Eugenic" title="Eugenic" class="mw-redirect">eugenic</a> or small population policy could send humanity into 'voluntary' extinction.</li>
<li><a href="/wiki/Infertility" title="Infertility">Infertility</a>: Caused by <a href="/wiki/Hormone" title="Hormone">hormonal</a> disruption from the chemical/<a href="/wiki/Pharmaceutical" title="Pharmaceutical" class="mw-redirect">pharmaceutical</a> industries, or <a href="/wiki/Biological_process" title="Biological process">biological</a> changes, such as the (<a href="/wiki/Controversial" title="Controversial" class="mw-redirect">controversial</a>) findings of falling <a href="/wiki/Spermatozoon" title="Spermatozoon">sperm cell</a> count in human males. (See <i><a href="/wiki/The_Children_of_Men" title="The Children of Men">The Children of Men</a></i> (novel) or <i><a href="/wiki/Children_of_Men" title="Children of Men">Children of Men</a></i> (film).)</li>
<li>A disruption, chemical, biological, or otherwise, in humans' ability to reproduce properly or at all</li>
<li>Disease: The 'weak-gened' and birth-defected are kept alive by medicines. This is the opposite of nature, where the weak are less likely to survive and successfully reproduce, leaving the species genetically 'strong'. Eventually everyone has weak/flawed genes, and these defects become increasingly severe, until the human body is unable to fight diseases, even with the help of advanced medicine. In the end, disease ends the human species<sup class="noprint Template-Fact"><span title="This claim needs references to reliable sources&#160;since February 2009" style="white-space: nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed">citation needed</a></i>]</span></sup>. Arguably however if this point was reached natural selection would again become a factor, potentially reversing this 'decline'.</li>
<li><a href="/wiki/Voluntary_human_extinction_movement" title="Voluntary human extinction movement" class="mw-redirect">Voluntary extinction</a></li>
</ul>
</li>
<li>Scientific accidents
<ul>
<li>In his book <i><a href="/wiki/Our_Final_Hour" title="Our Final Hour">Our Final Hour</a></i>, Sir <a href="/wiki/Martin_Rees" title="Martin Rees" class="mw-redirect">Martin Rees</a> claims that without the appropriate regulation, scientific advancement increases the risk of human extinction as a result of the effects or use of new technology. Some examples are provided below.
<ul>
<li>Uncontrolled nanotechnology (<a href="/wiki/Grey_goo" title="Grey goo">grey goo</a>) incidents resulting in the destruction of the Earth's ecosystem (<a href="/wiki/Ecophagy" title="Ecophagy">ecophagy</a>).</li>
<li>Creation of a <a href="/wiki/Naked_singularity" title="Naked singularity">naked singularity</a> (such as a "<a href="/wiki/Micro_black_hole" title="Micro black hole">micro black hole</a>") on Earth during the course of a scientific experiment, or other foreseeable scientific accidents in <a href="/wiki/High-energy_physics" title="High-energy physics" class="mw-redirect">high-energy physics</a> research, such as <a href="/wiki/Vacuum_metastability_disaster" title="Vacuum metastability disaster" class="mw-redirect">vacuum phase transition</a> or <a href="/wiki/Strangelet" title="Strangelet">strangelet</a> incidents. There were worries concerning the <a href="/wiki/Large_Hadron_Collider" title="Large Hadron Collider">Large Hadron Collider</a> at <a href="/wiki/CERN" title="CERN">CERN</a> as it is feared that collision of protons at a speed near the speed of light will result in the creation of a black hole, but it has been pointed out that much more energetic collisions take place currently in Earth's atmosphere.</li>
<li>The world's food supply being threatened and extinguished as a result of scientific tampering, due to genetic engineering encouraging more prevalent plant diseases, or the interference of pesticides contributing to the destruction of crops due to the effect on bees (See <a href="/wiki/Colony_collapse_disorder" title="Colony collapse disorder">colony collapse disorder</a>.)</li>
</ul>
</li>
<li>Accidental contact of an <a href="/wiki/Extraterrestrial_life" title="Extraterrestrial life">alien civilization</a> by Earth's radio and TV signals, radar, Internet tech dependent on radio, TV signals, other signals.</li>
<li>Biotech disaster such as <a href="/wiki/Green_goo" title="Green goo" class="mw-redirect">green goo</a>. (e.g. the warnings of <a href="/wiki/Jeremy_Rifkin" title="Jeremy Rifkin">Jeremy Rifkin</a>)</li>
</ul>
</li>
<li>Scenarios of extraterrestrial origin
<ul>
<li>Major <a href="/wiki/Impact_event" title="Impact event">impact events</a>.</li>
<li>If a rogue <a href="/wiki/Black_hole" title="Black hole">black hole</a> passed near the Sun, it could disrupt Earth's orbit.</li>
<li><a href="/wiki/Gamma-ray_burst" title="Gamma-ray burst">Gamma-ray burst</a> in <a href="/wiki/Gamma_ray_burst#Mass_extinction_on_Earth" title="Gamma ray burst" class="mw-redirect">our part</a> of the <a href="/wiki/Milky_Way" title="Milky Way">Milky Way</a> (Bursts observable in other galaxies are calculated to act as a "sterilizer", and have been used by some <a href="/wiki/Astronomer" title="Astronomer">astronomers</a> to explain the <a href="/wiki/Fermi_paradox" title="Fermi paradox">Fermi paradox</a>). The lack of fossil record interruptions, and relative distance of the nearest <a href="/wiki/Hypernova" title="Hypernova">Hypernova</a> candidate make this a long term (rather than imminent) threat.
<ul>
<li><a href="/wiki/Wolf-Rayet_star" title="Wolf-Rayet star">Wolf-Rayet star</a> <a href="/wiki/WR_104" title="WR 104">WR 104</a>, which is 8000 light years from the Sun, may produce a gamma ray burst aimed at the Sun when it goes supernova.</li>
</ul>
</li>
<li><a href="/wiki/Invasion" title="Invasion">Invasion</a> by militarily superior aliens (see <a href="/wiki/Alien_invasion" title="Alien invasion">alien invasion</a>) — often considered to be a scenario purely from the realms of <a href="/wiki/Science_fiction" title="Science fiction">science fiction</a>, professional <a href="/wiki/SETI" title="SETI">SETI researchers</a> have given serious consideration to this possibility, but conclude that it is unlikely. <span class="reference plainlinksneverexpand" id="ref_AlienConquestUnlikely"><sup><a href="http://en.wikipedia.org/wiki/Human_extinction#endnote_AlienConquestUnlikely" class="external autonumber" title="http://en.wikipedia.org/wiki/Human_extinction#endnote_AlienConquestUnlikely" rel="nofollow">[3]</a></sup></span></li>
<li><a href="/wiki/Gerard_O%27Neill" title="Gerard O'Neill" class="mw-redirect">Gerard O'Neill</a> has cautioned that <a href="/wiki/First_contact_(anthropology)" title="First contact (anthropology)">first contact</a> with alien intelligence may follow the precedent set by historical examples of contact between human civilizations, where the less technologically-advanced civilization has inevitably succumbed to the other civilization, regardless of its intentions.</li>
<li><a href="/wiki/Solar_flare" title="Solar flare">Solar flares</a> may suddenly heat the earth, or the light from the sun may be blocked by dust, slowly freezing it (eg. the dust and vapour may come from a <a href="/wiki/Kuiper_belt" title="Kuiper belt">Kuiper belt</a> disturbance).</li>
<li>A <a href="/wiki/False_vacuum" title="False vacuum">vacuum phase transition</a> could destroy the universe.</li>
<li>It is possible that the space of our universe, the <a href="/wiki/Big_Bang" title="Big Bang">Big Bang</a>, and all its consequences are events taking place within a computer or other device on another cosmological plane, if this process were to end then everything within the universe would summarily vanish (see <a href="/wiki/Simulated_Reality" title="Simulated Reality" class="mw-redirect">Simulated Reality</a>).</li>
</ul>
</li>
<li>Philosophical scenarios
<ul>
<li><i>See <a href="/wiki/End_of_the_world_(disambiguation)" title="End of the world (disambiguation)" class="mw-redirect">End of the world</a></i></li>
</ul>
</li>
</ul>
<p><a name="Attitudes_to_human_extinction" id="Attitudes_to_human_extinction"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Human_extinction&amp;action=edit&amp;section=2" title="Edit section: Attitudes to human extinction">edit</a>]</span> <span class="mw-headline">Attitudes to human extinction</span></h2>
<p>Attitudes to human extinction vary widely depending on beliefs concerning <a href="/wiki/Spirituality" title="Spirituality">spiritual</a> <a href="http://en.wiktionary.org/wiki/survival" class="extiw" title="wiktionary:survival">survival</a> (souls, heaven, <a href="/wiki/Reincarnation" title="Reincarnation">reincarnation</a>, and so forth), the value of the human species, whether the human species evolves individually or collectively, and many other factors. Many <a href="/wiki/Religions" title="Religions" class="mw-redirect">religions</a> <a href="/wiki/Prophesy" title="Prophesy" class="mw-redirect">prophesy</a> an "<a href="/wiki/End_times" title="End times" class="mw-redirect">end times</a>" to the <a href="/wiki/Universe" title="Universe">universe</a>. Human extinction is therefore a part of the <a href="/wiki/Faith" title="Faith">faith</a> of many humans to the extent that the end time means the absolute end of their physical humanity but perhaps not an internal soul.</p>
<p>However not all faiths connect human extinction to the end times, since some believe in cyclical regeneration, or that end times actually means the beginning of a new kind of existence (see <a href="/wiki/Eschatology" title="Eschatology">eschatology</a> and <a href="/wiki/Utopianism" title="Utopianism" class="mw-redirect">utopianism</a>).</p>
<p><a name="Perception_of_human_extinction_risk" id="Perception_of_human_extinction_risk"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Human_extinction&amp;action=edit&amp;section=3" title="Edit section: Perception of human extinction risk">edit</a>]</span> <span class="mw-headline">Perception of human extinction risk</span></h2>
<p>The general level of fear about human extinction, in the near term, is very low, despite the pronouncements of some fringe groups. It is not an outcome considered by many as a credible risk. Suggested reasons for human extinction's low public visibility:</p>
<ol>
<li>There have been countless prophesies of extinction throughout history; in all cases the predicted date of doom has passed without much notice, making future warnings <a href="/wiki/Cry_wolf" title="Cry wolf" class="mw-redirect">less frightening</a>. However, a <a href="/wiki/Survivor_bias" title="Survivor bias" class="mw-redirect">survivor bias</a> would undercut the credibility of accurate extinction warnings. <a href="/wiki/John_von_Neumann" title="John von Neumann">John von Neumann</a> was probably wrong in having “a certainty”<span class="reference plainlinksneverexpand" id="ref_Putnam"><sup><a href="http://en.wikipedia.org/wiki/Human_extinction#endnote_Putnam" class="external autonumber" title="http://en.wikipedia.org/wiki/Human_extinction#endnote_Putnam" rel="nofollow">[4]</a></sup></span> that nuclear war would occur; but our survival is not proof that the chance of a fatal nuclear exchange was low (or indeed that such an event could not occur in the future).</li>
<li>Extinction scenarios (see below) are speculative, and hard to quantify. A <a href="/wiki/Frequentist" title="Frequentist" class="mw-redirect">frequentist</a> approach to probability cannot be used to assess the danger of an event that has never been observed by humans.</li>
<li><a href="/wiki/Nick_Bostrom" title="Nick Bostrom">Nick Bostrom</a>, head of the James Martin 21st Century School <a href="/wiki/Future_of_Humanity_Institute" title="Future of Humanity Institute">Future of Humanity Institute</a>, has suggested that extinction risk-analysis may be an overlooked field because it is both too psychologically troublesome a subject area to be attractive to potential researchers and because the lack of previous human species extinction events leads a depressed view of the likelihood of it happening under changing future circumstances (an 'inverse <a href="/wiki/Survivorship_bias" title="Survivorship bias">survivorship bias</a>').</li>
<li>There are thousands of <a href="/wiki/Public_safety" title="Public safety">public safety</a> jobs dedicated to analyzing and reducing the risks of individual death. There are no full-time <i>existential safety commissioners</i> partly because there is no way to tell if they are doing a good job, and no way to punish them for failure. The inability to judge performance might also explain the comparative governmental apathy on preventing human extinction (as compared to <a href="/wiki/Panda" title="Panda" class="mw-redirect">panda</a> extinction, say).</li>
<li>Some <a href="/wiki/Anthropology" title="Anthropology">anthropologists</a> believe that risk perception is biased by social structure; in the "<a href="/wiki/Cultural_Theory_of_risk" title="Cultural Theory of risk">Cultural Theory of risk</a>" typography "<a href="/wiki/Cultural_Theory_of_risk#Individualist" title="Cultural Theory of risk">individualist</a>" societies predispose members to the belief that nature operates as a self-correcting system, which will return to its stable state after a disturbance. People in such cultures feel comfortable with a "trial-and-error" approach to risk, even to unsuitably rare dangers (such as extinction events).</li>
<li>It is possible to do something about dietary or motor-vehicle health threats. Since it is much harder to know how existential threats should be minimized<span class="reference plainlinksneverexpand" id="ref_Minimize"><sup><a href="http://en.wikipedia.org/wiki/Human_extinction#endnote_Minimize" class="external autonumber" title="http://en.wikipedia.org/wiki/Human_extinction#endnote_Minimize" rel="nofollow">[5]</a></sup></span>, they tend to be ignored. High technology societies tend to become "<a href="/wiki/Cultural_Theory_of_risk#Hierarchist" title="Cultural Theory of risk">hierarchist</a>" or "<a href="/wiki/Cultural_Theory_of_risk#Fatalist" title="Cultural Theory of risk">fatalist</a>" in their attitudes to the ever-multiplying risks threatening them. In either case, the average member of society adopts a passive attitude to risk minimization, culturally, and <a href="/wiki/Psychology" title="Psychology">psychologically</a>.</li>
<li>The bias in popular culture is to relate extinction scenario stories with non-extinction outcomes. (None of the 16 'most notable' <a href="/wiki/World_War_III_in_popular_culture#Film_and_television" title="World War III in popular culture">WW3 scenarios in film</a> are resolved by human extinction, for example.<span class="reference plainlinksneverexpand" id="ref_JournalOfReligionAndFilm"><sup><a href="http://en.wikipedia.org/wiki/Human_extinction#endnote_JournalOfReligionAndFilm" class="external autonumber" title="http://en.wikipedia.org/wiki/Human_extinction#endnote_JournalOfReligionAndFilm" rel="nofollow">[6]</a></sup></span>)</li>
<li>The threat of nuclear annihilation actually was a daily concern in the lives of many people in the 1960s and 1970s. Since then the principal fear has been of localized <a href="/wiki/Terrorism" title="Terrorism">terrorist</a> attack, rather than a global war of extinction; contemplating human extinction may be out of fashion.</li>
<li>Many people believe that if human extinction did occur, the amount of research done prior to the event would be irrelevant (as humanity would no longer exist).</li>
<li>Some people have philosophical reasons for doubting the possibility of human extinction, for instance the <a href="/wiki/Final_anthropic_principle" title="Final anthropic principle">final anthropic principle</a>, <a href="/wiki/Plenitude_principle" title="Plenitude principle">plenitude principle</a> or <a href="/wiki/Intrinsic_finality" title="Intrinsic finality">intrinsic finality</a>.</li>
<li><a href="/wiki/Amos_Tversky" title="Amos Tversky">Tversky</a> and <a href="/wiki/Daniel_Kahneman" title="Daniel Kahneman">Kahneman</a> have <a href="/wiki/Experimental_economics" title="Experimental economics">produced evidence</a> that humans suffer <a href="/wiki/Cognitive_bias" title="Cognitive bias">cognitive biases</a> which would tend to minimize the perception of this unprecedented event:
<ol>
<li><i>Denial</i> is a negative "<a href="/wiki/Availability_heuristic" title="Availability heuristic">availability heuristic</a>" shown to occur when an outcome is so upsetting that the very act of thinking about it leads to an increased refusal to believe it might occur. In this case, <a href="/wiki/Imagination" title="Imagination">imagining</a> <i>human extinction</i> probably makes it seem less likely.</li>
<li>In cultures where human extinction is not expected the proposition must overcome the "<a href="/wiki/Disconfirmation_bias" title="Disconfirmation bias" class="mw-redirect">disconfirmation bias</a>" against heterodox theories.</li>
<li>Another reliable <a href="/wiki/Psychology" title="Psychology">psychological</a> effect relevant here is the "<a href="/wiki/Positive_outcome_bias_(prediction)" title="Positive outcome bias (prediction)" class="mw-redirect">positive outcome bias</a>".</li>
<li><a href="/wiki/Behavioural_finance" title="Behavioural finance" class="mw-redirect">Behavioural finance</a> has strong evidence that <a href="/wiki/Recency_effect" title="Recency effect" class="mw-redirect">recent</a> evidence is given undue significance in <a href="/wiki/Risk_analysis" title="Risk analysis">risk analysis</a>. Roughly speaking, "100 year storms" tend to occur every twenty years in the <a href="/wiki/Stock_market" title="Stock market">stock market</a> as traders become convinced that the current good times <a href="/wiki/Dot-com_bubble#Free_spending" title="Dot-com bubble">will last forever</a>. Doomsayers who hypothesize rare <a href="/wiki/Stock_market_crash" title="Stock market crash">crisis-scenarios</a> are dismissed even when they have statistical evidence behind them. An extreme form of this bias can diminish the <a href="/wiki/Bayesian_probability#Varieties_of_Bayesian_probability" title="Bayesian probability">subjective probability</a> of the unprecedented<span class="reference plainlinksneverexpand" id="ref_unprecedented"><sup><a href="http://en.wikipedia.org/wiki/Human_extinction#endnote_unprecedented" class="external autonumber" title="http://en.wikipedia.org/wiki/Human_extinction#endnote_unprecedented" rel="nofollow">[7]</a></sup></span>.</li>
</ol>
</li>
</ol>
<p>In general, humanity's sense of <a href="/wiki/Self_preservation" title="Self preservation">self preservation</a>, and <a href="/wiki/Intelligence_(trait)" title="Intelligence (trait)" class="mw-redirect">intelligence</a> are considered to offer safe-guards against extinction. It is felt that people will find <a href="/wiki/Creative" title="Creative">creative</a> ways to overcome potential threats, and will take care of the <a href="/wiki/Precautionary_principle" title="Precautionary principle">precautionary principle</a> in attempting dangerous <a href="/wiki/Innovations" title="Innovations" class="mw-redirect">innovations</a>. The arguments against this are; firstly, that the management of destructive technology is becoming difficult, and secondly, that the precautionary principle is often abandoned whenever the reward appears to outweigh the risk. At least one instance where the principle may have been overruled was when prior to the <a href="/wiki/Trinity_test" title="Trinity test" class="mw-redirect">Trinity</a> nuclear test, one of the project's scientists (<a href="/wiki/Edward_Teller" title="Edward Teller">Teller</a>) speculated that the <a href="/wiki/Nuclear_fission" title="Nuclear fission">fission</a> explosion might destroy New Mexico and possibly the world, by causing a reaction in the nitrogen of the atmosphere. A calculation by <a href="/wiki/Hans_Bethe" title="Hans Bethe">Hans Bethe</a> proved such a possibility theoretically impossible, but the fear of the possibility remained among some until the test took place. (See <i>Ignition of the atmosphere with nuclear bombs</i>, LA-602, <a href="http://www.fas.org/sgp/othergov/doe/lanl/docs1/00329010.pdf" class="external text" title="http://www.fas.org/sgp/othergov/doe/lanl/docs1/00329010.pdf" rel="nofollow">online</a> and <a href="/wiki/Manhattan_Project" title="Manhattan Project">Manhattan Project</a>).</p>
<p><a name="Observations_about_human_extinction" id="Observations_about_human_extinction"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Human_extinction&amp;action=edit&amp;section=4" title="Edit section: Observations about human extinction">edit</a>]</span> <span class="mw-headline">Observations about human extinction</span></h2>
<p>The fact the vast majority of species that have existed on Earth have become extinct, has led to the suggestion that all species have a finite lifespan and thus human extinction would be inevitable. Dave Raup and Jack Sepkoski found for example a twenty six million year periodicity in elevated extinction rates, caused by factors unknown (See <a href="/wiki/David_M._Raup" title="David M. Raup">David M. Raup</a>. "Extinction: Bad Genes or Bad Luck" (1992, Norton). Based upon evidence of past extinction rates Raup and others have suggested that the average longevity of an invertebrate species is between 4-6 million years, while that of vertebrates seems to be 2-4 million years. The shorter period of survival for mammals lies in their position further up the food chain than many invertebrates, and therefore an increased liability to suffer the effects of environmental change. A counter-argument to this is that humans are unique in their adaptive and technological capabilities, so it is not possible to draw reliable inferences about the probability of human extinction based on the past extinctions of other species. Certainly, the evidence collected by Raup and others suggested that generalist, geographically dispersed species, like humans, generally have a lower rate of extinction than those species that require a particular habitat. In addition, the human species is probably the only species with a conscious prior knowledge of their own demise, and therefore would be likely to take steps to avoid it.</p>
<p>Another characteristic of the human that may be unique is its religious belief, which in most situations encourages respect for life. On the other hand, it may also create conditions for warfare and genocide. As a result, thinkers as <a href="/wiki/Albert_Einstein" title="Albert Einstein">Albert Einstein</a> believed that "We shall require a substantially new manner of thinking if mankind is to survive."<sup id="cite_ref-1" class="reference"><a href="#cite_note-1" title=""><span>[</span>2<span>]</span></a></sup></p>
<p>Humans are very similar to other <a href="/wiki/Primate" title="Primate">primates</a> in their propensity towards intra-species <a href="/wiki/Violence" title="Violence">violence</a>; <a href="/wiki/Jared_Diamond" title="Jared Diamond">Jared Diamond</a>'s <a href="/wiki/The_Third_Chimpanzee" title="The Third Chimpanzee">The Third Chimpanzee</a> (<a href="/wiki/Special:BookSources/0099801809" class="internal">ISBN 0-09-980180-9</a>) estimates that 64% of hunter-gather societies engage in warfare every two years. Although it has been argued (e.g. in the <a href="/wiki/UNESCO" title="UNESCO">UNESCO</a> <a href="/wiki/Seville_Statement" title="Seville Statement" class="mw-redirect">Seville Statement</a>) that warfare is a cultural artifact, many <a href="/wiki/Anthropology" title="Anthropology">anthropologists</a><sup class="noprint Template-Fact"><span title="This claim needs references to reliable sources&#160;since February 2007" style="white-space: nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed">citation needed</a></i>]</span></sup> dispute this, noting that small human tribes exhibit similar patterns of violence to <a href="/wiki/Chimpanzee" title="Chimpanzee">chimpanzee</a> groups, the most murderous of the primates, and our nearest living <a href="/wiki/Genetics" title="Genetics">genetic</a> relatives. The '<a href="/wiki/Neopallium" title="Neopallium" class="mw-redirect">higher</a>' functions of reason and speech are more developed in the brain of <i><a href="/wiki/Human" title="Human">Homo sapiens</a></i> than other primates, but the relative size of the <a href="/wiki/Limbic_system" title="Limbic system">limbic system</a> is a constant in <a href="/wiki/Ape" title="Ape">apes</a>, <a href="/wiki/Monkey" title="Monkey">monkeys</a> and <a href="/wiki/Human" title="Human">humans</a>; as human rational faculties have expanded, so has the <a href="/wiki/Wetware" title="Wetware">wetware</a> of <a href="/wiki/Emotion" title="Emotion">emotion</a>. The combination of inventiveness and urge to violence in humans has been <a href="/wiki/Citation" title="Citation">cited</a> as evidence against its long term survival<span class="reference plainlinksneverexpand" id="ref_HumanSelfDestructionCitation"><sup><a href="http://en.wikipedia.org/wiki/Human_extinction#endnote_HumanSelfDestructionCitation" class="external autonumber" title="http://en.wikipedia.org/wiki/Human_extinction#endnote_HumanSelfDestructionCitation" rel="nofollow">[8]</a></sup></span>.<sup class="noprint Inline-Template"><span title="The material in the vicinity of this tag seems to express a non-neutral point of view&#160;from September 2008" style="white-space: nowrap;">[<i><a href="/wiki/Wikipedia:POV" title="Wikipedia:POV" class="mw-redirect">opinion needs balancing</a></i>]</span></sup></p>
<p><a name="Omnicide" id="Omnicide"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Human_extinction&amp;action=edit&amp;section=5" title="Edit section: Omnicide">edit</a>]</span> <span class="mw-headline">Omnicide</span></h3>
<p>Omnicide is human extinction as a result of human action. Most commonly it refers to extinction through <a href="/wiki/Nuclear_warfare" title="Nuclear warfare">nuclear warfare</a>,<sup id="cite_ref-2" class="reference"><a href="#cite_note-2" title=""><span>[</span>3<span>]</span></a></sup><sup id="cite_ref-3" class="reference"><a href="#cite_note-3" title=""><span>[</span>4<span>]</span></a></sup><sup id="cite_ref-4" class="reference"><a href="#cite_note-4" title=""><span>[</span>5<span>]</span></a></sup> but it can also apply to extinction through means such as global <a href="/wiki/Anthropogenic" title="Anthropogenic">anthropogenic</a> <a href="/wiki/Environmental_disaster" title="Environmental disaster">ecological catastrophe</a>.<sup id="cite_ref-5" class="reference"><a href="#cite_note-5" title=""><span>[</span>6<span>]</span></a></sup></p>
<p>Omnicide can be considered a subcategory of <a href="/wiki/Genocide" title="Genocide">genocide</a>.<sup id="cite_ref-6" class="reference"><a href="#cite_note-6" title=""><span>[</span>7<span>]</span></a></sup> Using the concept in this way, one can argue, for example, that:</p>
<table style="margin:auto; border-collapse:collapse; border-style:none; background-color:transparent;" class="cquote">
<tr>
<td width="20" valign="top" style="color:#B2B7F2;font-size:35px;font-family:'Times New Roman',serif;font-weight:bold;text-align:left;padding:10px 10px;">“</td>
<td valign="top" style="padding:4px 10px;">The arms race is genocidal in intent given the fact that the United States and the Soviet Union are knowingly preparing to destroy each other as viable national and political groups.<sup id="cite_ref-7" class="reference"><a href="#cite_note-7" title=""><span>[</span>8<span>]</span></a></sup></td>
<td width="20" valign="bottom" style="color:#B2B7F2;font-size:36px;font-family:'Times New Roman',serif;font-weight:bold;text-align:right;padding:10px 10px;">”</td>
</tr>
</table>
<p>As this claim illustrates, the concept of omnicide raises issues of <a href="/wiki/Human_agency" title="Human agency" class="mw-redirect">human agency</a> and, hence, of <a href="/wiki/Moral_responsibility" title="Moral responsibility">moral responsibility</a> in discussions about large-scale social processes like the <a href="/wiki/Nuclear_arms_race" title="Nuclear arms race">nuclear arms race</a> or ecologically destructive industrial production. That is, part of the point of describing a human extinction scenario as 'omnicidal' is to note that, if it were to happen, it would result not just from natural, uncontrollable <a href="/wiki/Evolution" title="Evolution">evolutionary</a> forces, or from some random catastrophe like an asteroid impact, but from deliberate choices made by human beings. This implies that such scenarios are preventable, and that the people whose choices make them more likely to happen should be held morally accountable for such choices. In this context, the label 'omnicide' also works to de-<a href="/wiki/Normalization_(sociology)" title="Normalization (sociology)">normalize</a> the course of action it is applied to.</p>
<p><a name="Scenarios_of_the_world_without_humans" id="Scenarios_of_the_world_without_humans"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Human_extinction&amp;action=edit&amp;section=6" title="Edit section: Scenarios of the world without humans">edit</a>]</span> <span class="mw-headline">Scenarios of the world without humans</span></h2>
<p>The book <i><a href="/wiki/The_World_Without_Us" title="The World Without Us">The World Without Us</a></i> by <a href="/wiki/Alan_Weisman" title="Alan Weisman">Alan Weisman</a> deals with a <a href="/wiki/Thought_experiment" title="Thought experiment">thought experiment</a> on what would happen to the planet and especially man-made infrastructures if humans suddenly disappeared. Alan said that apes, with the highest IQ amongst animals other than humans, may be the species that succeeds humanity. The <a href="/wiki/Discovery_Channel" title="Discovery Channel">Discovery Channel</a> film <i><a href="/wiki/The_Future_Is_Wild" title="The Future Is Wild">The Future Is Wild</a></i> shows the possible future of <a href="/wiki/Evolution" title="Evolution">evolution</a> on Earth without humans. The <a href="/wiki/History_Channel" title="History Channel" class="mw-redirect">History Channel</a> two-hour special <i><a href="/wiki/Life_After_People" title="Life After People">Life After People</a></i> examines the possible future of life on Earth without humans. <a href="/wiki/The_National_Geographic_Channel" title="The National Geographic Channel" class="mw-redirect">The National Geographic Channel</a> ran a special called <i><a href="/wiki/Aftermath:_Population_Zero" title="Aftermath: Population Zero">Aftermath: Population Zero</a></i> envisioning what the world be like if all humans suddenly disappeared.</p>
<p><a name="See_also" id="See_also"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Human_extinction&amp;action=edit&amp;section=7" title="Edit section: See also">edit</a>]</span> <span class="mw-headline">See also</span></h2>
<ul>
<li><a href="/wiki/Disaster" title="Disaster">Disaster</a></li>
<li><a href="/wiki/Doomsday_event" title="Doomsday event">Doomsday event</a></li>
<li><a href="/wiki/Extinction" title="Extinction">Extinction</a></li>
<li><a href="/wiki/Extinction_event" title="Extinction event">Extinction event</a></li>
<li><a href="/w/index.php?title=Law_of_Limited_Competition&amp;action=edit&amp;redlink=1" class="new" title="Law of Limited Competition (page does not exist)">Law of Limited Competition</a> (If violated, <a href="/wiki/Daniel_Quinn" title="Daniel Quinn">Daniel Quinn</a> predicts coextinction for humanity, in the book <a href="/wiki/Ishmael_(novel)" title="Ishmael (novel)">Ishmael</a>.)</li>
<li><a href="/wiki/Novelty_Theory" title="Novelty Theory" class="mw-redirect">Novelty Theory</a> (Mathematically (numerologically?) derived <a href="/wiki/Eschatology" title="Eschatology">eschatology</a>, with arbitrary extinction mechanism.)</li>
<li><a href="/wiki/Risks_to_civilization,_humans_and_planet_Earth" title="Risks to civilization, humans and planet Earth">Risks to civilization, humans and planet Earth</a></li>
<li><a href="/wiki/Voluntary_Human_Extinction_Movement" title="Voluntary Human Extinction Movement">Voluntary Human Extinction Movement</a></li>
<li><a href="/wiki/Mutual_Assured_Destruction" title="Mutual Assured Destruction" class="mw-redirect">Mutual Assured Destruction</a></li>
</ul>
<p><a name="Further_reading" id="Further_reading"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Human_extinction&amp;action=edit&amp;section=8" title="Edit section: Further reading">edit</a>]</span> <span class="mw-headline">Further reading</span></h2>
<ul>
<li>Cawthorne, N. (2004). <i>Doomsday</i>. Arcturus Publishing Limited. <a href="/wiki/Special:BookSources/1841932388" class="internal">ISBN 1-84193-238-8</a></li>
<li>Leslie, J. (1999). <a href="http://lifeboat.com/ex/risking.human.extinction" class="external text" title="http://lifeboat.com/ex/risking.human.extinction" rel="nofollow"><i>Risking Human Extinction</i></a></li>
<li>Leslie, J. (1996). <i>The End of the World: The Science and Ethics of Human Extinction</i>. Routledge. <a href="/wiki/Special:BookSources/0415184479" class="internal">ISBN 0-415-18447-9</a></li>
<li>Russell, J.D. (2008). <i>Trojan Whores ~The Road to Armageddon~ a Prophetic Retrospective, by Jahred Kammen, the Last Liberal</i> by (c)2008 Freedom Press International, 12115 Whitefish Avenue, Manhattan Beach, MN 56442; <a href="/wiki/Special:BookSources/9780615196763" class="internal">ISBN 978-0-615-19676-3</a>.</li>
<li><a href="http://avturchin.narod.ru/Global.htm" class="external text" title="http://avturchin.narod.ru/Global.htm" rel="nofollow">Global catastrophic risks and human extinction library</a></li>
</ul>
<p><a name="References" id="References"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Human_extinction&amp;action=edit&amp;section=9" title="Edit section: References">edit</a>]</span> <span class="mw-headline">References</span></h2>
<div class="references-small">
<ol class="references">
<li id="cite_note-0"><b><a href="#cite_ref-0" title="">^</a></b> <a href="/wiki/Kevin_Warwick" title="Kevin Warwick">Warwick, K</a>: “I,Cyborg”, University of Illinois Press, 2004</li>
<li id="cite_note-1"><b><a href="#cite_ref-1" title="">^</a></b> <a href="http://nobelprize.org/nobel_prizes/peace/laureates/1985/press.html" class="external text" title="http://nobelprize.org/nobel_prizes/peace/laureates/1985/press.html" rel="nofollow">The Nobel Peace Prize 1985 - Presentation Speech</a></li>
<li id="cite_note-2"><b><a href="#cite_ref-2" title="">^</a></b> Somerville, John. 1981. <i>Soviet Marxism and nuclear war&#160;: an international debate&#160;: from the proceedings of the special colloquium of the XVth World Congress of Philosophy</i>. Greenwood Press. Pg.151</li>
<li id="cite_note-3"><b><a href="#cite_ref-3" title="">^</a></b> Goodman, Lisl Marburg and Lee Ann Hoff. 1990. <i>Omnicide: The Nuclear Dilemma</i>. New York: Praeger.</li>
<li id="cite_note-4"><b><a href="#cite_ref-4" title="">^</a></b> Landes, Daniel (ed.). 1991. <i>Confronting Omnicide: Jewish Reflections on Weapons of Mass Destruction</i>. Jason Aronson Publishers.</li>
<li id="cite_note-5"><b><a href="#cite_ref-5" title="">^</a></b> Wilcox, Richard Brian. 2004. <i>The Ecology of Hope: Environmental Grassroots Activism in Japan</i>. Ph.D. Dissertation, Union Institute &amp; University, College of Graduate Studies. Page 55.</li>
<li id="cite_note-6"><b><a href="#cite_ref-6" title="">^</a></b> Jones, Adam. 2006. "A Seminal Work on Genocide", in <i>Security Dialogue</i>, vol. 37(1), pp. 143-144.</li>
<li id="cite_note-7"><b><a href="#cite_ref-7" title="">^</a></b> Santoni, Ronald E., 1987. "Genocide, Nuclear Omnicide, and Individual Responsibility" in <i>Social Science Record</i>, vol. 24(2), pp.38-41.</li>
</ol>
</div>
<div class="references-small" style="margin-left:1.5em;"><a name="Notes" id="Notes"></a>
<h2><span class="editsection">[<a href="/w/index.php?title=Human_extinction&amp;action=edit&amp;section=10" title="Edit section: Notes">edit</a>]</span> <span class="mw-headline">Notes</span></h2>
<p><cite id="endnote_Putnam" style="font-style: normal;"><a href="#ref_Putnam" title=""><b>^</b></a></cite>&#160; <a href="/wiki/John_von_Neumann" title="John von Neumann">Von Neumann</a> said it was <i>"absolutely certain (1) that there would be a <a href="/wiki/Nuclear_warfare" title="Nuclear warfare">nuclear war</a>; and (2) that <u>everyone would die in it</u>"</i> (underline added to quote from: <i>The Nature of the Physical Universe</i> – 1979, John Wiley &amp; Sons, <a href="/wiki/Special:BookSources/0471031909" class="internal">ISBN 0-471-03190-9</a>, in H. Putnam’s essay <i>The place of facts in a world of values</i> - page 113). This example illustrates why respectable scientists are very reluctant to go on record with extinction predictions: they can never be proven right. (The quotation is repeated by Leslie (1996) on page 26, on the subject of <a href="/wiki/Nuclear_warfare" title="Nuclear warfare">nuclear war</a> annihilation, which he still considered a significant risk – in the mid 1990s.)</p>
<p><cite id="endnote_Minimize" style="font-style: normal;"><a href="#ref_Minimize" title=""><b>^</b></a></cite>&#160; Although existential risks are less manageable by individuals than health risks, according to <a href="/w/index.php?title=Ken_Olum&amp;action=edit&amp;redlink=1" class="new" title="Ken Olum (page does not exist)">Ken Olum</a>, <a href="/wiki/Joshua_Knobe" title="Joshua Knobe">Joshua Knobe</a>, and Alexander Vilenkin the possibility of human extinction <i>does</i> have practical implications. For instance, if the “universal” <a href="/wiki/Doomsday_argument" title="Doomsday argument">Doomsday argument</a> is accepted it changes the most likely source of disasters, and hence the most efficient means of preventing them. They write: <i>"...you should be more concerned that a large number of asteroids have not yet been detected than about the particular orbit of each one. You should not worry especially about the chance that some specific nearby star will become a supernova, but more about the chance that supernovas are more deadly to nearby life then we believe."</i> Source: “Practical application” page 39 of the <a href="/wiki/Princeton_University" title="Princeton University">Princeton University</a> paper: <a href="http://www.princeton.edu/~jknobe/physics.pdf" class="external text" title="http://www.princeton.edu/~jknobe/physics.pdf" rel="nofollow">Philosophical Implications of Inflationary Cosmology</a></p>
<p><cite id="endnote_JournalOfReligionAndFilm" style="font-style: normal;"><a href="#ref_JournalOfReligionAndFilm" title=""><b>^</b></a></cite>&#160; The 2000 review <a href="http://www.unomaha.edu/jrf/armagedd.htm" class="external text" title="http://www.unomaha.edu/jrf/armagedd.htm" rel="nofollow">Armageddon at the Millennial Dawn</a> from <i>The Journal of Religion and Film</i> finds that <i>"While end of the world threats perhaps are not avoidable, the cinematic formulation of millennial doom promotes the notion that the end can be averted through employing human ingenuity, scientific advance, and heroism."</i> Since this review was conducted, there had been a Hollywood production which postulates a (far future) outcome where humans are extinct (at least in the wild): <a href="/wiki/A.I._(movie)" title="A.I. (movie)" class="mw-redirect">A.I.</a>.</p>
<p><cite id="endnote_unprecedented" style="font-style: normal;"><a href="#ref_unprecedented" title=""><b>^</b></a></cite>&#160; For research on this, see <i>Psychological science</i> volume 15 (2004): <i><a href="http://www.psycho.unibas.ch/fakultaet/angewandt/articles/hertwig-psysci04.pdf" class="external text" title="http://www.psycho.unibas.ch/fakultaet/angewandt/articles/hertwig-psysci04.pdf" rel="nofollow">Decisions From Experience and the Effect of Rare Events in Risky Choice</a></i>. The under-perception of rare events mentioned above is actually the opposite of the phenomenon originally described by <a href="/wiki/Daniel_Kahneman" title="Daniel Kahneman">Kahneman</a> in "<a href="/wiki/Prospect_theory" title="Prospect theory">prospect theory</a>" (in their original experiments the likelihood of rare events is over-estimated). However, further analysis of the <a href="/wiki/Cognitive_bias" title="Cognitive bias">bias</a> has shown that both forms occur: When judging from <i>description</i> people tend to over-estimate the described probability, so this effect taken alone would indicate that reading the extinction scenarios described here should make the reader over-estimate the likelihood of any probabilities given. However, the effect that is more relevant to common consideration of human extinction is the bias that occurs with estimates from experience, and these are in the opposite direction: When judging from personal experience people who have never heard of or experienced their species become extinct would be expected to dramatically under-estimate its likelihood. <a href="/wiki/Sociobiologist" title="Sociobiologist" class="mw-redirect">Sociobiologist</a> <a href="/wiki/E._O._Wilson" title="E. O. Wilson">E. O. Wilson</a> argued that: "<i>The reason for this myopic fog, evolutionary biologists contend, is that it was actually advantageous during all but the last few millennia of the two million years of existence of the <a href="/wiki/Genus" title="Genus">genus</a> Homo... A premium was placed on close attention to the near future and early reproduction, and little else. Disasters of a magnitude that occur only once every few centuries were forgotten or transmuted into myth.</i>" (Is Humanity Suicidal? <i>New York Times Magazine</i> <span class="mw-formatted-date" title="1993-05-30"><span class="mw-formatted-date" title="05-30"><a href="/wiki/May_30" title="May 30">May 30</a></span>, <a href="/wiki/1993" title="1993">1993</a></span>).</p>
<p><cite id="endnote_HumanSelfDestructionCitation" style="font-style: normal;"><a href="#ref_HumanSelfDestructionCitation" title=""><b>^</b></a></cite>&#160; <a href="http://www.abrupt.org/EDITORIAL/despair.html" class="external text" title="http://www.abrupt.org/EDITORIAL/despair.html" rel="nofollow">Abrupt.org 1996 editorial</a> lists (and condemns) the arguments for human’s tendency to self-destruction. In this view, the <a href="/wiki/History" title="History">history</a> of humanity suggests that humans will be the cause of their own extinction. However, others have reached the opposite conclusion with the same data on violence and hypothesize that as societies develop armies and <a href="/wiki/Weapon" title="Weapon">weapons</a> with greater destructive power, they tend to be used less often. It is claimed that this implies a more secure future, despite the development of <a href="/wiki/Weapons_of_mass_destruction" title="Weapons of mass destruction" class="mw-redirect">WMD</a> technology. As such this argument may constitute a form of <a href="/wiki/Deterrence_theory" title="Deterrence theory">deterrence theory</a>. Counter-arguments against such views include the following: (1) All weapons ever designed have ultimately been used. States with strong military forces tend to engage in military aggression, (2) Although modern states have so far generally shown restraint in unleashing their most potent weapons, whatever rational control was guaranteed by government monopoly over such weapons becomes increasingly irrelevant in a world where individuals have access to the technology of mass destruction (as proposed in <i><a href="/wiki/Our_Final_Hour" title="Our Final Hour">Our Final Hour</a></i>, for example).</p>
<p><cite id="endnote_PlanForDestruction" style="font-style: normal;"><a href="#ref_PlanForDestruction" title=""><b>^</b></a></cite>&#160; <a href="http://www.religioustolerance.org/destruct.htm" class="external text" title="http://www.religioustolerance.org/destruct.htm" rel="nofollow">ReligiousTolerance.org says that <i>Aum Supreme Truth</i> is the only religion known to have planned Armageddon for non-believers</a>. Their intention to unleash deadly <a href="/wiki/Virus" title="Virus">viruses</a> is covered in <i><a href="/wiki/Our_Final_Hour" title="Our Final Hour">Our Final Hour</a></i>, and by <a href="http://www.rickross.com/reference/aum/aum276.html" class="external text" title="http://www.rickross.com/reference/aum/aum276.html" rel="nofollow">Aum watcher, Akihiko Misawa</a>. The <a href="/wiki/Gaia_Liberation_Front" title="Gaia Liberation Front" class="mw-redirect">Gaia Liberation Front</a> advocates (but is not known to have active plans for) total human <a href="/wiki/Genocide" title="Genocide">genocide</a>, see: <a href="http://www.churchofeuthanasia.org/resources/glf/glfsop.html" class="external text" title="http://www.churchofeuthanasia.org/resources/glf/glfsop.html" rel="nofollow">GLF, A Modest Proposal</a>. Leslie, 1996 says that Aum’s collection of nuclear physicists presented a doomsday threat from nuclear destruction as well, especially as the cult included a rocket scientist.</p>
<p><cite id="endnote_Unbiased" style="font-style: normal;"><a href="#ref_Unbiased" title=""><b>^</b></a></cite>&#160; Leslie (1996) discusses the <a href="/wiki/Survivorship_bias" title="Survivorship bias">survivorship bias</a> (which he calls an "observational selection" effect on page 139) he says that the <i><a href="/wiki/A_priori_and_a_posteriori_(philosophy)" title="A priori and a posteriori (philosophy)" class="mw-redirect">a priori</a></i> certainty of observing an "undisasterous past" could make it difficult to argue that we must be safe because nothing terrible has yet occurred. He quotes <a href="/wiki/Holger_Bech_Nielsen" title="Holger Bech Nielsen">Holger Bech Nielsen</a>’s formulation: <i>“We do not even know if there should exist some extremely dangerous decay of say the <a href="/wiki/Proton" title="Proton">proton</a> which caused eradication of the earth, because if it happens we would no longer be there to observe it and if it does not happen there is nothing to observe.”</i> (From: Random dynamics and relations between the number of fermion generations and the fine structure constants, <i>Acta Pysica Polonica B</i>, May 1989).</p>
<p><cite id="endnote_BillJoy" style="font-style: normal;"><a href="#ref_BillJoy" title=""><b>^</b></a></cite>&#160; For example, in the essay <i>Why the future doesn't need us</i>, computer scientist <a href="/wiki/Bill_Joy" title="Bill Joy">Bill Joy</a> argued that human beings are likely to guarantee their own extinction through <a href="/wiki/Transhumanism" title="Transhumanism">transhumanism</a>. See: <a href="http://www.wired.com/wired/archive/8.04/joy_pr.html" class="external text" title="http://www.wired.com/wired/archive/8.04/joy_pr.html" rel="nofollow">Wired archive, <i>Why the future doesn't need us</i></a>.</p>
<p><cite id="endnote_2400" style="font-style: normal;"><a href="#ref_2400" title=""><b>^</b></a></cite>&#160; For the “West Germany” extrapolation see: Leslie, 1996 (<i>The End of the World</i>) in the “War, Pollution, and disease” chapter (page 74). In this section the author also mentions the success (in lowering the birth rate) of programs such as the <a href="/wiki/Sterilization_(surgical_procedure)" title="Sterilization (surgical procedure)">sterilization</a>-for-<a href="/wiki/INR" title="INR">rupees</a> programs in <a href="/wiki/India" title="India">India</a>, and surveys other <a href="/wiki/Infertility" title="Infertility">infertility</a> or falling birth-rate extinciton scenarios. He says that the voluntary small family behaviour may be counter-<a href="/wiki/Evolution" title="Evolution">evolutionary</a>, but that the <a href="/wiki/Meme" title="Meme">meme</a> for small, rich families appears to be spreading rapidly throughout the world. In 2150 the world population is expected to start falling.</p>
<p><cite id="endnote_AlienConquestUnlikely" style="font-style: normal;"><a href="#ref_AlienConquestUnlikely" title=""><b>^</b></a></cite>&#160;See estimate of contact’s probability at <a href="http://www.galactic-guide.com/articles/8R88.html" class="external text" title="http://www.galactic-guide.com/articles/8R88.html" rel="nofollow">galactic-guide</a>. Former <a href="/wiki/NASA" title="NASA">NASA</a> consultant <a href="/wiki/David_Brin" title="David Brin">David Brin</a>'s lengthy rebuttal to <a href="/wiki/SETI" title="SETI">SETI</a> enthusiast's optimism about alien intentions concludes: "The worst mistake of first contact, made throughout history by individuals on both sides of every new encounter, has been the unfortunate habit of making assumptions. It often proved fatal." (<a href="http://www.setileague.org/iaaseti/brin.pdf" class="external text" title="http://www.setileague.org/iaaseti/brin.pdf" rel="nofollow">See full text at SETIleague.org</a>.)</p>
</div>
<table class="navbox" cellspacing="0" style=";">
<tr>
<td style="padding:2px;">
<table cellspacing="0" class="nowraplinks collapsible autocollapse" style="width:100%;background:transparent;color:inherit;;">
<tr>
<th style=";" colspan="2" class="navbox-title">
<div style="float:left; width:6em;text-align:left;">
<div class="noprint plainlinksneverexpand navbar" style="background:none; padding:0; font-weight:normal;;;border:none;; font-size:xx-small;"><a href="/wiki/Template:Doomsday" title="Template:Doomsday"><span title="View this template" style=";;border:none;">v</span></a>&#160;<span style="font-size:80%;">•</span>&#160;<a href="/wiki/Template_talk:Doomsday" title="Template talk:Doomsday"><span title="Discussion about this template" style=";;border:none;">d</span></a>&#160;<span style="font-size:80%;">•</span>&#160;<a href="http://en.wikipedia.org/w/index.php?title=Template:Doomsday&amp;action=edit" class="external text" title="http://en.wikipedia.org/w/index.php?title=Template:Doomsday&amp;action=edit" rel="nofollow"><span title="Edit this template" style=";;border:none;;">e</span></a></div>
</div>
<span style="font-size:110%;"><a href="/wiki/Doomsday" title="Doomsday">Doomsday</a></span></th>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<td colspan="2" style="width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em">
<div>
<p><a href="/wiki/Apocalypse" title="Apocalypse">Apocalypse</a><span style="font-weight:bold;">&#160;·</span> <a href="/wiki/Apocalyptic_and_post-apocalyptic_fiction" title="Apocalyptic and post-apocalyptic fiction">Apocalyptic and post-apocalyptic fiction</a><span style="font-weight:bold;">&#160;·</span> <a href="/wiki/Armageddon" title="Armageddon">Armageddon</a><span style="font-weight:bold;">&#160;·</span> <a href="/wiki/Big_Crunch" title="Big Crunch">Big Crunch</a><span style="font-weight:bold;">&#160;·</span> <a href="/wiki/Big_Rip" title="Big Rip">Big Rip</a><span style="font-weight:bold;">&#160;·</span> <a href="/wiki/Doomsday_argument" title="Doomsday argument">Doomsday argument</a><span style="font-weight:bold;">&#160;·</span> <a href="/wiki/Doomsday_cult" title="Doomsday cult">Doomsday cult</a><span style="font-weight:bold;">&#160;·</span> <a href="/wiki/Doomsday_Clock" title="Doomsday Clock">Doomsday Clock</a><span style="font-weight:bold;">&#160;·</span> <a href="/wiki/Doomsday_device" title="Doomsday device">Doomsday device</a><span style="font-weight:bold;">&#160;·</span> <a href="/wiki/Doomsday_event" title="Doomsday event">Doomsday event</a><span style="font-weight:bold;">&#160;·</span> <a href="/wiki/Doomsday_film" title="Doomsday film">Doomsday film</a><span style="font-weight:bold;">&#160;·</span> <a href="/wiki/Earth#Future" title="Earth">End of planet Earth</a><span style="font-weight:bold;">&#160;·</span> <a href="/wiki/End_time" title="End time">End time</a><span style="font-weight:bold;">&#160;·</span> <a href="/wiki/Eschatology" title="Eschatology">Eschatology</a><span style="font-weight:bold;">&#160;·</span> <strong class="selflink">Human extinction</strong><span style="font-weight:bold;">&#160;·</span> <a href="/wiki/Last_Judgement" title="Last Judgement" class="mw-redirect">Last Judgement</a><span style="font-weight:bold;">&#160;·</span> <a href="/wiki/Planetary_Phase_of_Civilization" title="Planetary Phase of Civilization">Planetary Phase of Civilization</a><span style="font-weight:bold;">&#160;·</span> <a href="/wiki/Ragnar%C3%B6k" title="Ragnarök">Ragnarök</a><span style="font-weight:bold;">&#160;·</span> <a href="/wiki/Risks_to_civilization,_humans_and_planet_Earth" title="Risks to civilization, humans and planet Earth">Risks to civilization, humans and planet Earth</a><span style="font-weight:bold;">&#160;·</span> <a href="/wiki/Societal_collapse" title="Societal collapse">Societal collapse</a><span style="font-weight:bold;">&#160;·</span> <a href="/wiki/Ten_Threats" title="Ten Threats">Ten Threats</a><span style="font-weight:bold;">&#160;·</span> <a href="/wiki/World_War_III" title="World War III">World War III</a></p>
</div>
</div>
</td>
</tr>
</table>
</td>
</tr>
</table>


<!-- 
NewPP limit report
Preprocessor node count: 1200/1000000
Post-expand include size: 24390/2048000 bytes
Template argument size: 7356/2048000 bytes
Expensive parser function count: 6/500
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:1528711-0!1!0!default!!en!2 and timestamp 20090425044332 -->
<div class="printfooter">
Retrieved from "<a href="http://en.wikipedia.org/wiki/Human_extinction">http://en.wikipedia.org/wiki/Human_extinction</a>"</div>
			<div id='catlinks' class='catlinks'><div id="mw-normal-catlinks"><a href="/wiki/Special:Categories" title="Special:Categories">Categories</a>:&#32;<span dir='ltr'><a href="/wiki/Category:Eschatology" title="Category:Eschatology">Eschatology</a></span> | <span dir='ltr'><a href="/wiki/Category:Extinction" title="Category:Extinction">Extinction</a></span></div><div id="mw-hidden-catlinks" class="mw-hidden-cats-hidden">Hidden categories:&#32;<span dir='ltr'><a href="/wiki/Category:Articles_needing_additional_references_from_March_2008" title="Category:Articles needing additional references from March 2008">Articles needing additional references from March 2008</a></span> | <span dir='ltr'><a href="/wiki/Category:All_articles_with_unsourced_statements" title="Category:All articles with unsourced statements">All articles with unsourced statements</a></span> | <span dir='ltr'><a href="/wiki/Category:Articles_with_unsourced_statements_since_March_2009" title="Category:Articles with unsourced statements since March 2009">Articles with unsourced statements since March 2009</a></span> | <span dir='ltr'><a href="/wiki/Category:Articles_with_unsourced_statements_since_December_2007" title="Category:Articles with unsourced statements since December 2007">Articles with unsourced statements since December 2007</a></span> | <span dir='ltr'><a href="/wiki/Category:Articles_with_unsourced_statements_since_February_2009" title="Category:Articles with unsourced statements since February 2009">Articles with unsourced statements since February 2009</a></span> | <span dir='ltr'><a href="/wiki/Category:Articles_with_unsourced_statements_since_February_2007" title="Category:Articles with unsourced statements since February 2007">Articles with unsourced statements since February 2007</a></span> | <span dir='ltr'><a href="/wiki/Category:All_pages_needing_cleanup" title="Category:All pages needing cleanup">All pages needing cleanup</a></span> | <span dir='ltr'><a href="/wiki/Category:Articles_with_minor_POV_problems_from_September_2008" title="Category:Articles with minor POV problems from September 2008">Articles with minor POV problems from September 2008</a></span></div></div>			<!-- end content -->
						<div class="visualClear"></div>
		</div>
	</div>
		</div>
		<div id="column-one">
	<div id="p-cactions" class="portlet">
		<h5>Views</h5>
		<div class="pBody">
			<ul>
	
				 <li id="ca-nstab-main" class="selected"><a href="/wiki/Human_extinction" title="View the content page [c]" accesskey="c">Article</a></li>
				 <li id="ca-talk"><a href="/wiki/Talk:Human_extinction" title="Discussion about the content page [t]" accesskey="t">Discussion</a></li>
				 <li id="ca-edit"><a href="/w/index.php?title=Human_extinction&amp;action=edit" title="You can edit this page. &#10;Please use the preview button before saving. [e]" accesskey="e">Edit this page</a></li>
				 <li id="ca-history"><a href="/w/index.php?title=Human_extinction&amp;action=history" title="Past versions of this page [h]" accesskey="h">History</a></li>			</ul>
		</div>
	</div>
	<div class="portlet" id="p-personal">
		<h5>Personal tools</h5>
		<div class="pBody">
			<ul>
				<li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Human_extinction" title="You are encouraged to log in; however, it is not mandatory. [o]" accesskey="o">Log in / create account</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-logo">
		<a style="background-image: url(http://upload.wikimedia.org/wikipedia/en/b/bc/Wiki.png);" href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
	<div class='generated-sidebar portlet' id='p-navigation'>
		<h5>Navigation</h5>
		<div class='pBody'>
			<ul>
				<li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li>
				<li id="n-contents"><a href="/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li>
				<li id="n-featuredcontent"><a href="/wiki/Portal:Featured_content" title="Featured content — the best of Wikipedia">Featured content</a></li>
				<li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li>
				<li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li>
			</ul>
		</div>
	</div>
	<div id="p-search" class="portlet">
		<h5><label for="searchInput">Search</label></h5>
		<div id="searchBody" class="pBody">
			<form action="/w/index.php" id="searchform"><div>
				<input type='hidden' name="title" value="Special:Search"/>
				<input id="searchInput" name="search" type="text" title="Search Wikipedia [f]" accesskey="f" value="" />
				<input type='submit' name="go" class="searchButton" id="searchGoButton"	value="Go" title="Go to a page with this exact name if one exists" />&nbsp;
				<input type='submit' name="fulltext" class="searchButton" id="mw-searchButton" value="Search" title="Search Wikipedia for this text" />
			</div></form>
		</div>
	</div>
	<div class='generated-sidebar portlet' id='p-interaction'>
		<h5>Interaction</h5>
		<div class='pBody'>
			<ul>
				<li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li>
				<li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li>
				<li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="The list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li>
				<li id="n-contact"><a href="/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact Wikipedia</a></li>
				<li id="n-sitesupport"><a href="http://wikimediafoundation.org/wiki/Donate" title="Support us">Donate to Wikipedia</a></li>
				<li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-tb">
		<h5>Toolbox</h5>
		<div class="pBody">
			<ul>
				<li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Human_extinction" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li>
				<li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Human_extinction" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li>
<li id="t-upload"><a href="/wiki/Wikipedia:Upload" title="Upload files [u]" accesskey="u">Upload file</a></li>
<li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="List of all special pages [q]" accesskey="q">Special pages</a></li>
				<li id="t-print"><a href="/w/index.php?title=Human_extinction&amp;printable=yes" rel="alternate" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>				<li id="t-permalink"><a href="/w/index.php?title=Human_extinction&amp;oldid=285988239" title="Permanent link to this version of the page">Permanent link</a></li><li id="t-cite"><a href="/w/index.php?title=Special:Cite&amp;page=Human_extinction&amp;id=285988239">Cite this page</a></li>			</ul>
		</div>
	</div>
	<div id="p-lang" class="portlet">
		<h5>Languages</h5>
		<div class="pBody">
			<ul>
				<li class="interwiki-he"><a href="http://he.wikipedia.org/wiki/%D7%90%D7%95%D7%9E%D7%A0%D7%99%D7%A1%D7%99%D7%99%D7%93">עברית</a></li>
				<li class="interwiki-ru"><a href="http://ru.wikipedia.org/wiki/%D0%93%D0%B8%D0%B1%D0%B5%D0%BB%D1%8C_%D1%87%D0%B5%D0%BB%D0%BE%D0%B2%D0%B5%D1%87%D0%B5%D1%81%D1%82%D0%B2%D0%B0">Русский</a></li>
			</ul>
		</div>
	</div>
		</div><!-- end of the left (by default at least) column -->
			<div class="visualClear"></div>
			<div id="footer">
				<div id="f-poweredbyico"><a href="http://www.mediawiki.org/"><img src="/skins-1.5/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" /></a></div>
				<div id="f-copyrightico"><a href="http://wikimediafoundation.org/"><img src="/images/wikimedia-button.png" border="0" alt="Wikimedia Foundation"/></a></div>
			<ul id="f-list">
					<li id="lastmod"> This page was last modified on 25 April 2009, at 04:42 (UTC).</li>
					<li id="copyright">All text is available under the terms of the <a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Text_of_the_GNU_Free_Documentation_License" title="Wikipedia:Text of the GNU Free Documentation License">GNU Free Documentation License</a>. (See <b><a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Copyrights" title="Wikipedia:Copyrights">Copyrights</a></b> for details.) <br /> Wikipedia&reg; is a registered trademark of the <a href="http://www.wikimediafoundation.org">Wikimedia Foundation, Inc.</a>, a U.S. registered <a class='internal' href="http://en.wikipedia.org/wiki/501%28c%29#501.28c.29.283.29" title="501(c)(3)">501(c)(3)</a> <a href="http://wikimediafoundation.org/wiki/Deductibility_of_donations">tax-deductible</a> <a class='internal' href="http://en.wikipedia.org/wiki/Non-profit_organization" title="Non-profit organization">nonprofit</a> <a href="http://en.wikipedia.org/wiki/Charitable_organization" title="Charitable organization">charity</a>.<br /></li>
					<li id="privacy"><a href="http://wikimediafoundation.org/wiki/Privacy_policy" title="wikimedia:Privacy policy">Privacy policy</a></li>
					<li id="about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
					<li id="disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
			</ul>
		</div>
</div>

		<script type="text/javascript">if (window.runOnloadHook) runOnloadHook();</script>
<!-- Served by srv219 in 0.605 secs. --></body></html>
