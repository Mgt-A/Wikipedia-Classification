<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
		<meta http-equiv="Content-Style-Type" content="text/css" />
		<meta name="generator" content="MediaWiki 1.15alpha" />
		<meta name="keywords" content="Least squares,Least squares and regression analysis,1801,Adrien-Marie Legendre,Age of Exploration,Alexander Aitken,Astronomy,BHHH algorithm,Best linear unbiased estimator,Calibration curve,Carl Friedrich Gauss" />
		<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Least_squares&amp;action=edit" />
		<link rel="edit" title="Edit this page" href="/w/index.php?title=Least_squares&amp;action=edit" />
		<link rel="apple-touch-icon" href="http://en.wikipedia.org/apple-touch-icon.png" />
		<link rel="shortcut icon" href="/favicon.ico" />
		<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)" />
		<link rel="copyright" href="http://www.gnu.org/copyleft/fdl.html" />
		<link rel="alternate" type="application/rss+xml" title="Wikipedia RSS Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=rss" />
		<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=atom" />
		<title>Least squares - Wikipedia, the free encyclopedia</title>
		<link rel="stylesheet" href="/skins-1.5/common/shared.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/common/commonPrint.css?207xx" type="text/css" media="print" />
		<link rel="stylesheet" href="/skins-1.5/monobook/main.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/chick/main.css?207xx" type="text/css" media="handheld" />
		<!--[if lt IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE50Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE55Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 6]><link rel="stylesheet" href="/skins-1.5/monobook/IE60Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 7]><link rel="stylesheet" href="/skins-1.5/monobook/IE70Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Common.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Print.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="print" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Handheld.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="handheld" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Monobook.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=-&amp;action=raw&amp;maxage=2678400&amp;gen=css" type="text/css" />
		<!--[if lt IE 7]><script type="text/javascript" src="/skins-1.5/common/IEFixes.js?207xx"></script>
		<meta http-equiv="imagetoolbar" content="no" /><![endif]-->

		<script type= "text/javascript">/*<![CDATA[*/
		var skin = "monobook";
		var stylepath = "/skins-1.5";
		var wgArticlePath = "/wiki/$1";
		var wgScriptPath = "/w";
		var wgScript = "/w/index.php";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = "http://en.wikipedia.org";
		var wgCanonicalNamespace = "";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = "Least_squares";
		var wgTitle = "Least squares";
		var wgAction = "view";
		var wgArticleId = "82359";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = "en";
		var wgContentLanguage = "en";
		var wgBreakFrames = false;
		var wgCurRevisionId = 281007823;
		var wgVersion = "1.15alpha";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = ["", ""];
		var wgDigitTransformTable = ["", ""];
		var wgMWSuggestTemplate = "http://en.wikipedia.org/w/api.php?action=opensearch\x26search={searchTerms}\x26namespace={namespaces}\x26suggest";
		var wgDBname = "enwiki";
		var wgSearchNamespaces = [0];
		var wgMWSuggestMessages = ["with suggestions", "no suggestions"];
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		/*]]>*/</script>

		<script type="text/javascript" src="/skins-1.5/common/wikibits.js?207xx"><!-- wikibits js --></script>
		<!-- Head Scripts -->
		<script type="text/javascript" src="/skins-1.5/common/ajax.js?207xx"></script>
		<script type="text/javascript" src="/skins-1.5/common/mwsuggest.js?207xx"></script>
<script type="text/javascript">/*<![CDATA[*/
var wgNotice='';var wgNoticeLocal='';
/*]]>*/</script>		<script type="text/javascript" src="http://upload.wikimedia.org/centralnotice/wikipedia/en/centralnotice.js?207xx"></script>
		<script type="text/javascript" src="/w/index.php?title=-&amp;action=raw&amp;gen=js&amp;useskin=monobook"><!-- site js --></script>
	</head>
<body class="mediawiki ltr ns-0 ns-subject page-Least_squares skin-monobook">
	<div id="globalWrapper">
		<div id="column-content">
	<div id="content">
		<a name="top" id="top"></a>
		<div id="siteNotice"><script type='text/javascript'>if (wgNotice != '') document.writeln(wgNotice);</script></div>		<h1 id="firstHeading" class="firstHeading">Least squares</h1>
		<div id="bodyContent">
			<h3 id="siteSub">From Wikipedia, the free encyclopedia</h3>
			<div id="contentSub"></div>
									<div id="jump-to-nav">Jump to: <a href="#column-one">navigation</a>, <a href="#searchInput">search</a></div>			<!-- start content -->
			<p>The method of <b>least squares</b> or <b>ordinary least squares (OLS)</b> is used to approximately solve <a href="/wiki/Overdetermined_system" title="Overdetermined system">overdetermined systems</a>. Least squares is often applied in statistical contexts, particularly <a href="/wiki/Regression_analysis" title="Regression analysis">regression analysis</a>.</p>
<p>Least squares can be interpreted as a method of fitting data. The best fit in the least-squares sense is that instance of the model for which the sum of <b>squared</b> residuals has its <b>least</b> value, a <a href="/wiki/Errors_and_residuals_in_statistics" title="Errors and residuals in statistics">residual</a> being the difference between an observed value and the value given by the model. The method was first described by <a href="/wiki/Carl_Friedrich_Gauss" title="Carl Friedrich Gauss">Carl Friedrich Gauss</a> around 1794.<sup id="cite_ref-brertscher_0-0" class="reference"><a href="#cite_note-brertscher-0" title=""><span>[</span>1<span>]</span></a></sup> Least squares corresponds to the <a href="/wiki/Maximum_likelihood" title="Maximum likelihood">maximum likelihood</a> criterion if the experimental errors have a <a href="/wiki/Normal_distribution" title="Normal distribution">normal distribution</a> and can also be derived as a <a href="/wiki/Method_of_moments" title="Method of moments">method of moments</a> estimator. Regression analysis is available in most <a href="/wiki/Statistical_software" title="Statistical software" class="mw-redirect">statistical software</a> packages.</p>
<p>The discussion is presented in terms of <a href="/wiki/Polynomial" title="Polynomial">polynomial</a> functions but any function can be used in least-squares data fitting. For example, a <a href="/wiki/Fourier_series" title="Fourier series">Fourier series</a> fit is optimal in the least-squares sense.</p>
<div class="thumb tright">
<div class="thumbinner" style="width:182px;"><a href="/wiki/File:Linear_least_squares2.png" class="image" title="The result of fitting a set of data points with a quadratic function."><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/94/Linear_least_squares2.png/180px-Linear_least_squares2.png" width="180" height="216" border="0" class="thumbimage" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="/wiki/File:Linear_least_squares2.png" class="internal" title="Enlarge"><img src="/skins-1.5/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
The result of fitting a set of data points with a quadratic function.</div>
</div>
</div>
<table id="toc" class="toc" summary="Contents">
<tr>
<td>
<div id="toctitle">
<h2>Contents</h2>
</div>
<ul>
<li class="toclevel-1"><a href="#History"><span class="tocnumber">1</span> <span class="toctext">History</span></a>
<ul>
<li class="toclevel-2"><a href="#Context"><span class="tocnumber">1.1</span> <span class="toctext">Context</span></a></li>
<li class="toclevel-2"><a href="#The_method_itself"><span class="tocnumber">1.2</span> <span class="toctext">The method itself</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Problem_statement"><span class="tocnumber">2</span> <span class="toctext">Problem statement</span></a></li>
<li class="toclevel-1"><a href="#Solving_the_least_squares_problem"><span class="tocnumber">3</span> <span class="toctext">Solving the least squares problem</span></a>
<ul>
<li class="toclevel-2"><a href="#Linear_least_squares"><span class="tocnumber">3.1</span> <span class="toctext">Linear least squares</span></a></li>
<li class="toclevel-2"><a href="#Non-linear_least_squares"><span class="tocnumber">3.2</span> <span class="toctext">Non-linear least squares</span></a></li>
<li class="toclevel-2"><a href="#Differences_between_linear_and_non-linear_least_squares"><span class="tocnumber">3.3</span> <span class="toctext">Differences between linear and non-linear least squares</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Least_squares.2C_regression_analysis_and_statistics"><span class="tocnumber">4</span> <span class="toctext">Least squares, regression analysis and statistics</span></a></li>
<li class="toclevel-1"><a href="#Weighted_least_squares"><span class="tocnumber">5</span> <span class="toctext">Weighted least squares</span></a>
<ul>
<li class="toclevel-2"><a href="#Lasso_method"><span class="tocnumber">5.1</span> <span class="toctext">Lasso method</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#See_also"><span class="tocnumber">6</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1"><a href="#Notes"><span class="tocnumber">7</span> <span class="toctext">Notes</span></a></li>
<li class="toclevel-1"><a href="#References"><span class="tocnumber">8</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1"><a href="#External_links"><span class="tocnumber">9</span> <span class="toctext">External links</span></a></li>
</ul>
</td>
</tr>
</table>
<script type="text/javascript">
//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>
</script>
<p><a name="History" id="History"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Least_squares&amp;action=edit&amp;section=1" title="Edit section: History">edit</a>]</span> <span class="mw-headline">History</span></h2>
<p><a name="Context" id="Context"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Least_squares&amp;action=edit&amp;section=2" title="Edit section: Context">edit</a>]</span> <span class="mw-headline">Context</span></h3>
<p>The method of least squares grew out of the fields of <a href="/wiki/Astronomy" title="Astronomy">astronomy</a> and <a href="/wiki/Geodesy" title="Geodesy">geodesy</a> as scientists and mathematicians sought to provide solutions to the challenges of navigating the Earth's oceans during the <a href="/wiki/Age_of_Exploration" title="Age of Exploration" class="mw-redirect">Age of Exploration</a>. The accurate description of the behavior of celestial bodies was key to enabling ships to sail in open seas where before sailors had relied on land sightings to determine the positions of their ships.</p>
<p>The method was the culmination of several advances that took place during the course of the eighteenth century<sup id="cite_ref-stigler_1-0" class="reference"><a href="#cite_note-stigler-1" title=""><span>[</span>2<span>]</span></a></sup>:</p>
<ul>
<li>The combination of different observations taken under the <i>same</i> conditions as opposed to simply trying one's best to observe and record a single observation accurately. This approach was notably used by <a href="/wiki/Tobias_Mayer" title="Tobias Mayer">Tobias Mayer</a> while studying the <a href="/wiki/Libration" title="Libration">librations</a> of the moon.</li>
<li>The combination of different observations as being the best estimate of the true value; errors decrease with aggregation rather than increase, perhaps first expressed by <a href="/wiki/Roger_Cotes" title="Roger Cotes">Roger Cotes</a>.</li>
<li>The combination of different observations taken under <i>different</i> conditions as notably performed by <a href="/wiki/Roger_Joseph_Boscovich" title="Roger Joseph Boscovich">Roger Joseph Boscovich</a> in his work on the shape of the earth and <a href="/wiki/Pierre-Simon_Laplace" title="Pierre-Simon Laplace">Pierre-Simon Laplace</a> in his work in explaining the differences in motion of <a href="/wiki/Jupiter" title="Jupiter">Jupiter</a> and <a href="/wiki/Saturn" title="Saturn">Saturn</a>.</li>
<li>The development of a criterion that can be evaluated to determine when the solution with the minimum error has been achieved, developed by Laplace in his Method of Situation.</li>
</ul>
<p><a name="The_method_itself" id="The_method_itself"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Least_squares&amp;action=edit&amp;section=3" title="Edit section: The method itself">edit</a>]</span> <span class="mw-headline">The method itself</span></h3>
<p><a href="/wiki/Carl_Friedrich_Gauss" title="Carl Friedrich Gauss">Carl Friedrich Gauss</a> is credited with developing the fundamentals of the basis for least-squares analysis in 1795 at the age of eighteen. <a href="/wiki/Adrien-Marie_Legendre" title="Adrien-Marie Legendre">Legendre</a> was the first to publish the method, however.</p>
<p>An early demonstration of the strength of Gauss's method came when it was used to predict the future location of the newly discovered asteroid <a href="/wiki/Ceres_(asteroid)" title="Ceres (asteroid)" class="mw-redirect">Ceres</a>. On <span class="mw-formatted-date" title="1801-01-01"><span class="mw-formatted-date" title="01-01"><a href="/wiki/January_1" title="January 1">January 1</a></span>, <a href="/wiki/1801" title="1801">1801</a></span>, the Italian astronomer <a href="/wiki/Giuseppe_Piazzi" title="Giuseppe Piazzi">Giuseppe Piazzi</a> discovered Ceres and was able to track its path for 40 days before it was lost in the glare of the sun. Based on this data, it was desired to determine the location of Ceres after it emerged from behind the sun without solving the complicated <a href="/wiki/Kepler%27s_laws_of_planetary_motion" title="Kepler's laws of planetary motion">Kepler's nonlinear equations</a> of planetary motion. The only predictions that successfully allowed Hungarian astronomer <a href="/wiki/Franz_Xaver_von_Zach" title="Franz Xaver von Zach">Franz Xaver von Zach</a> to relocate Ceres were those performed by the 24-year-old Gauss using least-squares analysis.</p>
<p>Gauss did not publish the method until 1809, when it appeared in volume two of his work on celestial mechanics, <i>Theoria Motus Corporum Coelestium in sectionibus conicis solem ambientium</i>. In 1829, Gauss was able to state that the least-squares approach to regression analysis is optimal in the sense that in a linear model where the errors have a mean of zero, are uncorrelated, and have equal variances, the best linear unbiased estimators of the coefficients is the least-squares estimators. This result is known as the <a href="/wiki/Gauss%E2%80%93Markov_theorem" title="Gauss–Markov theorem">Gauss–Markov theorem</a>.</p>
<p>The idea of least-squares analysis was also independently formulated by the Frenchman <a href="/wiki/Adrien-Marie_Legendre" title="Adrien-Marie Legendre">Adrien-Marie Legendre</a> in 1805 and the American <a href="/wiki/Robert_Adrain" title="Robert Adrain">Robert Adrain</a> in 1808.</p>
<p><a name="Problem_statement" id="Problem_statement"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Least_squares&amp;action=edit&amp;section=4" title="Edit section: Problem statement">edit</a>]</span> <span class="mw-headline">Problem statement</span></h2>
<p>The objective consists of adjusting the parameters of a model function so as to best fit a data set. A simple data set consists of <i>n</i> points (data pairs) <img class="tex" alt="(x_i,y_i)\!" src="http://upload.wikimedia.org/math/2/6/9/2699a437b5c6b26330ce5858c1fbf144.png" />, <i>i</i> = 1, ..., <i>n</i>, where <img class="tex" alt="x_i\!" src="http://upload.wikimedia.org/math/e/4/8/e48507c523906c43cf38cc185d56306e.png" /> is an <a href="/wiki/Independent_variable" title="Independent variable" class="mw-redirect">independent variable</a> and <img class="tex" alt="y_i\!" src="http://upload.wikimedia.org/math/0/1/0/01040f3034d7afe34fb516ab4f059e34.png" /> is a <a href="/wiki/Dependent_variable" title="Dependent variable" class="mw-redirect">dependent variable</a> whose value is found by observation. The model function has the form <img class="tex" alt="f(x,\boldsymbol \beta)" src="http://upload.wikimedia.org/math/b/6/9/b692b2e563f9e43ea3dc1587e811ae92.png" />, where the <i>m</i> adjustable parameters are held in the vector <img class="tex" alt="\boldsymbol \beta" src="http://upload.wikimedia.org/math/6/b/f/6bf37cfb9e3eeb9f68c0a32699ac20aa.png" />. We wish to find those parameter values for which the model "best" fits the data. The least squares method defines "best" as when the sum, <i>S</i>, of squared residuals</p>
<dl>
<dd><img class="tex" alt="S=\sum_{i=1}^{n}r_i^2" src="http://upload.wikimedia.org/math/9/b/1/9b17604df27e0c2b6733dbd8f13b26e4.png" /></dd>
</dl>
<p>is a minimum. A <a href="/wiki/Errors_and_residuals_in_statistics" title="Errors and residuals in statistics">residual</a> is defined as the difference between the values of the dependent variable and the predicted values from the estimated model,</p>
<dl>
<dd><img class="tex" alt="r_i= y_i - f(x_i, \hat\boldsymbol \beta),\," src="http://upload.wikimedia.org/math/9/a/0/9a0efb650a3f4795fd579dbcdb6daa88.png" /></dd>
</dl>
<p>An example of a model is that of the straight line. Denoting the intercept as <span class="texhtml">β<sub>0</sub></span> and the slope as <span class="texhtml">β<sub>1</sub></span>, the model function is given by</p>
<dl>
<dd><img class="tex" alt="f(x,\boldsymbol \beta)=\beta_0+\beta_1 x.\," src="http://upload.wikimedia.org/math/c/0/0/c000a5dffdb8d3accb4052d3a300ab73.png" /></dd>
</dl>
<p>See the <a href="/wiki/Linear_least_squares#Motivational_example" title="Linear least squares">example of linear least squares</a> for a fully worked out example of this model.</p>
<p>A data point may consist of more than one independent variable. For an example, when fitting a plane to a set of height measurements, the plane is a function of two independent variables, <i>x</i> and <i>z</i>, say. In the most general case there may be one or more independent variables and one or more dependent variables at each data point.</p>
<p><a name="Solving_the_least_squares_problem" id="Solving_the_least_squares_problem"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Least_squares&amp;action=edit&amp;section=5" title="Edit section: Solving the least squares problem">edit</a>]</span> <span class="mw-headline">Solving the least squares problem</span></h2>
<p>Least squares problems fall into two categories, linear and non-linear. The linear least squares problem has a closed form solution, but the non-linear problem does not and is usually solved by iterative refinement; at each iteration the system is approximated by a linear one, so the core calculation is similar in both cases.</p>
<p>The <a href="/wiki/Maxima_and_minima" title="Maxima and minima">minimum</a> of the sum of squares is found by setting the <a href="/wiki/Gradient" title="Gradient">gradient</a> to zero. Since the model contains <i>m</i> parameters there are <i>m</i> gradient equations.</p>
<dl>
<dd><img class="tex" alt="\frac{\partial S}{\partial \beta_j}=2\sum_i r_i\frac{\partial r_i}{\partial \beta_j}=0,\ j=1,\ldots,m" src="http://upload.wikimedia.org/math/d/8/a/d8a9129a6cd2943d3f53e7f8d4f7d20e.png" /></dd>
</dl>
<p>and since <img class="tex" alt="r_i=y_i-f(x_i,\boldsymbol \beta)\," src="http://upload.wikimedia.org/math/1/3/0/130079e91c42ce4cdd55d30da7c8b80d.png" /> the gradient equations become</p>
<dl>
<dd><img class="tex" alt="-2\sum_i \frac{\partial f(x_i,\boldsymbol \beta)}{\partial \beta_j} r_i=0,\ j=1,\ldots,m" src="http://upload.wikimedia.org/math/6/6/5/665ae71865c43d84de194c2e844407ab.png" /></dd>
</dl>
<p>The gradient equations apply to all least squares problems. Each particular problem requires particular expressions for the model and its partial derivatives.</p>
<p><a name="Linear_least_squares" id="Linear_least_squares"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Least_squares&amp;action=edit&amp;section=6" title="Edit section: Linear least squares">edit</a>]</span> <span class="mw-headline">Linear least squares</span></h3>
<div class="rellink noprint relarticle mainarticle">Main article: <a href="/wiki/Linear_least_squares" title="Linear least squares">Linear least squares</a></div>
<p>A regression model is a linear one when the model comprises a <a href="/wiki/Linear_combination" title="Linear combination">linear combination</a> of the parameters, i.e.</p>
<dl>
<dd><img class="tex" alt=" f(x_i, \beta) = \sum_{j = 1}^{m} \beta_j \phi_j(x_{i})" src="http://upload.wikimedia.org/math/a/e/d/aed89724a2d8d7367563398bbd164d39.png" /></dd>
</dl>
<p>where the coefficients, <span class="texhtml">φ<sub><i>j</i></sub></span>, are functions of <span class="texhtml"><i>x</i><sub><i>i</i></sub></span>.</p>
<p>Letting</p>
<dl>
<dd><img class="tex" alt=" X_{ij}= \frac{\partial f(x_i,\boldsymbol \beta)}{\partial \beta_j}=   \phi_j(x_{i}) . \, " src="http://upload.wikimedia.org/math/7/8/2/78216d0cc06b73bc89f6e7a0f5e23b57.png" /></dd>
</dl>
<p>we can then see that in that case the least square estimate (or estimator, if we are in the context of a random sample), <img class="tex" alt=" \boldsymbol \beta" src="http://upload.wikimedia.org/math/6/b/f/6bf37cfb9e3eeb9f68c0a32699ac20aa.png" /> is given by</p>
<dl>
<dd><img class="tex" alt=" \boldsymbol{\hat\beta} =( X ^TX)^{-1}X^{T}\boldsymbol y " src="http://upload.wikimedia.org/math/4/2/4/42463a6f4db009c27711b37cd7b29083.png" /></dd>
</dl>
<p><br />
For a derivation of this estimate see <a href="/wiki/Linear_least_squares" title="Linear least squares">Linear least squares</a>.</p>
<p><a name="Non-linear_least_squares" id="Non-linear_least_squares"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Least_squares&amp;action=edit&amp;section=7" title="Edit section: Non-linear least squares">edit</a>]</span> <span class="mw-headline">Non-linear least squares</span></h3>
<div class="rellink noprint relarticle mainarticle">Main article: <a href="/wiki/Non-linear_least_squares" title="Non-linear least squares">Non-linear least squares</a></div>
<p>There is no closed-form solution to a non-linear least squares problem. Instead, numerical algorithms are used to find the value of the parameters <span class="texhtml">β</span> which minimize the objective. Most algorithms involve choosing initial values for the parameters. Then, the parameters are refined iteratively, that is, the values are obtained by successive approximation.</p>
<dl>
<dd><img class="tex" alt="\beta_j^{k+1}=\beta^k_j+\Delta \beta_j" src="http://upload.wikimedia.org/math/0/a/7/0a71c50a8893402995b244bdf437f168.png" /></dd>
</dl>
<p><i>k</i> is an iteration number and the vector of increments, <img class="tex" alt="\Delta \beta_j\," src="http://upload.wikimedia.org/math/1/4/5/145c6ffa28fec23a603349c292c7b79a.png" /> is known as the shift vector. In some commonly used algorithms, at each iteration the model may be linearized by approximation to a first-order <a href="/wiki/Taylor_series" title="Taylor series">Taylor series</a> expansion about <img class="tex" alt=" \boldsymbol \beta^k\!" src="http://upload.wikimedia.org/math/1/d/7/1d7a0a2d6f094e41a896b986f234ef4f.png" /></p>
<dl>
<dd><img class="tex" alt="f(x_i,\boldsymbol \beta)=f^k(x_i,\boldsymbol \beta) +\sum_j \frac{\partial f(x_i,\boldsymbol \beta)}{\partial \beta_j} \left(\beta_j-\beta^k_j \right)=f^k(x_i,\boldsymbol \beta) +\sum_j J_{ij} \Delta\beta_j. \, " src="http://upload.wikimedia.org/math/4/e/f/4ef0c096428706a7405cc10b015ed4ce.png" /></dd>
</dl>
<p>The <a href="/wiki/Jacobian" title="Jacobian">Jacobian</a>, <b>J</b>, is a function of constants, the independent variable <i>and</i> the parameters, so it changes from one iteration to the next. The residuals are given by</p>
<dl>
<dd><img class="tex" alt="r_i=y_i- f^k(x_i,\boldsymbol \beta)- \sum_{j=1}^{m} J_{ij}\Delta\beta_j=\Delta y_i- \sum_{j=1}^{m} J_{ij}\Delta\beta_j" src="http://upload.wikimedia.org/math/7/5/9/7598c6a6985ac86b817517c3dd655790.png" /></dd>
</dl>
<p>and the gradient equations become</p>
<dl>
<dd><img class="tex" alt="-2\sum_{i=1}^{n}J_{ij} \left( \Delta y_i-\sum_{j=1}^{m} J_{ij}\Delta \beta_j \right)=0" src="http://upload.wikimedia.org/math/6/4/e/64e52f42b014d536046d9576f73a1c88.png" /></dd>
</dl>
<p>which, on rearrangement, become <i>m</i> simultaneous linear equations, the <b>normal equations</b>.</p>
<dl>
<dd><img class="tex" alt="\sum_{i=1}^{n}\sum_{k=1}^{m} J_{ij}J_{ik}\Delta \beta_k=\sum_{i=1}^{n} J_{ij}\Delta y_i (j=1,\ldots,m)\," src="http://upload.wikimedia.org/math/b/f/6/bf62e89156918e14719ce0c74f339d68.png" /></dd>
</dl>
<p>The normal equations are written in matrix notation as</p>
<dl>
<dd><img class="tex" alt="\mathbf{\left(J^TJ\right)\Delta \boldsymbol \beta=J^T\Delta y}.\," src="http://upload.wikimedia.org/math/a/9/1/a91df3d9be727466aae64d8ceb2f42fb.png" /></dd>
</dl>
<p>These are the defining equations of the <a href="/wiki/Gauss%E2%80%93Newton_algorithm" title="Gauss–Newton algorithm">Gauss–Newton algorithm</a>.</p>
<p><a name="Differences_between_linear_and_non-linear_least_squares" id="Differences_between_linear_and_non-linear_least_squares"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Least_squares&amp;action=edit&amp;section=8" title="Edit section: Differences between linear and non-linear least squares">edit</a>]</span> <span class="mw-headline">Differences between linear and non-linear least squares</span></h3>
<ul>
<li>The model function, <i>f</i>, in LLSQ (linear least squares) is a linear combination of parameters of the form <img class="tex" alt="f = X_{i1}\beta_1 + X_{i2}\beta_2 +\cdots" src="http://upload.wikimedia.org/math/b/f/4/bf4b90cbef23a5a7f15377b48f6fa136.png" /> The model may represent a straight line, a parabola or any other polynomial-type function. In NLLSQ (non-linear least squares) the parameters appear as functions, such as <span class="texhtml">β<sup>2</sup>,<i>e</i><sup>β<i>x</i></sup></span> and so forth. If the derivatives <img class="tex" alt="\partial f /\partial \beta_j" src="http://upload.wikimedia.org/math/1/4/2/1423cbdb61c986d4220512516459284c.png" /> are either constant or depend only on the values of the independent variable, the model is linear in the parameters. Otherwise the model is non-linear.</li>
<li>Many solution algorithms for NLLSQ require initial values for the parameters, LLSQ does not.</li>
<li>Many solution algorithms for NLLSQ require that the Jacobian be calculated. Analytical expressions for the partial derivatives can be complicated. If analytical expressions are impossible to obtain the partial derivatives must be calculated by numerical approximation.</li>
<li>In NLLSQ non-convergence (failure of the algorithm to find a minimum) is a common phenomenon whereas the LLSQ is globally concave so non-convergence is not an issue.</li>
<li>NLLSQ is usually an iterative process. The iterative process has to be terminated when a convergence criterion is satisfied. LLSQ solutions can be computed using direct methods, although problems with large numbers of parameters are typically solved with iterative methods, such as the <a href="/wiki/Gauss%E2%80%93Seidel" title="Gauss–Seidel" class="mw-redirect">Gauss–Seidel</a> method.</li>
<li>In LLSQ the solution is unique, but in NLLSQ there may be multiple minima in the sum of squares.</li>
<li>Under the condition that the errors are uncorrelated with the predictor variables, LLSQ yields unbiased estimates, but even under that condition NLLSQ estimates are generally biased.</li>
</ul>
<p>These differences must be considered whenever the solution to a non-linear least squares problem is being sought.</p>
<p><a name="Least_squares.2C_regression_analysis_and_statistics" id="Least_squares.2C_regression_analysis_and_statistics"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Least_squares&amp;action=edit&amp;section=9" title="Edit section: Least squares, regression analysis and statistics">edit</a>]</span> <span class="mw-headline">Least squares, regression analysis and statistics</span></h2>
<p>The methods of least squares and <a href="/wiki/Regression_analysis" title="Regression analysis">regression analysis</a> are conceptually different. However, the method of least squares is often used to generate estimators and other statistics in regression analysis.</p>
<p>Consider a simple example drawn from physics. A spring should obey <a href="/wiki/Hooke%27s_law" title="Hooke's law">Hooke's law</a> which states that the extension of a spring is proportional to the force, <i>F</i>, applied to it.</p>
<dl>
<dd><img class="tex" alt="f(F_i,k)=kF_i\!" src="http://upload.wikimedia.org/math/7/a/d/7ad95dbd133b305a43dfbf37ec582519.png" /></dd>
</dl>
<p>constitutes the model, where <i>F</i> is the independent variable. To estimate the <a href="/wiki/Force_constant" title="Force constant" class="mw-redirect">force constant</a>, <i>k</i>, a series of <i>n</i> measurements with different forces will produce a set of data, <img class="tex" alt="(F_i, y_i), i=1,n\!" src="http://upload.wikimedia.org/math/3/6/a/36afb51c227691c94622388dcee92aba.png" />, where <i>y<sub>i</sub></i> is a measured spring extension. Each experimental observation will contain some error. If we denote this error <img class="tex" alt="\varepsilon" src="http://upload.wikimedia.org/math/c/6/9/c691dc52cc1ad756972d4629934d37fd.png" />, we may specify an empirical model for our observations,</p>
<dl>
<dd><img class="tex" alt=" y_i = kF_i + \varepsilon_i. \, " src="http://upload.wikimedia.org/math/c/a/6/ca65a8f5dbe9efa10e0ef50385d7bbd7.png" /></dd>
</dl>
<p>There are many methods we might use to estimate the unknown parameter <i>k</i>. Noting that the <i>n</i> equations for the <i>m</i> observations in our data comprise an <a href="/wiki/Overdetermined_system" title="Overdetermined system">overdetermined system</a> with one unknown and <i>n</i> equations, we may choose to estimate <i>k</i> using least squares. The sum of squares to be minimized is</p>
<dl>
<dd><img class="tex" alt=" S = \sum_{i=1}^{n} \left(y_i - kF_i\right)^2. " src="http://upload.wikimedia.org/math/9/1/9/919f8c8ed8825b9cc5653021a4876553.png" /></dd>
</dl>
<p>The least squares estimate of the force constant, <i>k</i>, is given by</p>
<dl>
<dd><img class="tex" alt="\hat k=\frac{\sum_i F_i y_i}{\sum_i F_i^2}." src="http://upload.wikimedia.org/math/f/3/5/f3524f7ab1cb434aff38586b7e6eba11.png" /></dd>
</dl>
<p>Here it is assumed that application of the force <i><b>causes</b></i> the spring to expand and, having derived the force constant by least squares fitting, the extension can be predicted from Hooke's law.</p>
<p>In regression analysis the researcher specifies an empirical model. For example, a very common model is the straight line model which is used to test if there is a linear relationship between dependent and independent variable. If a linear relationship is found to exist, the variables are said to be <a href="/wiki/Correlated" title="Correlated" class="mw-redirect">correlated</a>. However, correlation does not prove causation, as both variables may be correlated with other, hidden, variables, or the dependent variable may "reverse" cause the independent variables, or the variables may be otherwise spuriously correlated. For example, suppose there is a correlation between deaths by drowning and the volume of ice cream sales at a particular beach. Yet, both the number of people going swimming and the volume of ice cream sales increase as the weather gets hotter, and presumably the number of deaths by drowning is correlated with the number of people going swimming. Perhaps an increase in swimmers causes both the other variables to increase.</p>
<p>In order to make statistical tests on the results it is necessary to make assumptions about the nature of the experimental errors. A common (but not necessary) assumption is that the errors belong to a <a href="/wiki/Normal_distribution" title="Normal distribution">Normal distribution</a>. The <a href="/wiki/Central_limit_theorem" title="Central limit theorem">central limit theorem</a> supports the idea that this is a good assumption in many cases.</p>
<ul>
<li>The <a href="/wiki/Gauss%E2%80%93Markov_theorem" title="Gauss–Markov theorem">Gauss–Markov theorem</a>. In a linear model in which the errors have <a href="/wiki/Expectation" title="Expectation">expectation</a> zero conditional on the independent variables, are <a href="/wiki/Uncorrelated" title="Uncorrelated">uncorrelated</a> and have equal <a href="/wiki/Variance" title="Variance">variances</a>, the best linear <a href="/wiki/Unbiased" title="Unbiased" class="mw-redirect">unbiased</a> estimator of any linear combination of the observations, is its least-squares estimator. "Best" means that the least squares estimators of the parameters have minimum variance. The assumption of equal variance is valid when the errors all belong to the same distribution.</li>
<li>In a linear model, if the errors belong to a <a href="/wiki/Normal_distribution" title="Normal distribution">Normal distribution</a> the least squares estimators are also the <a href="/wiki/Linear_model#maximum_likelihood" title="Linear model">maximum likelihood</a> estimators.</li>
</ul>
<p>However, if the errors are not normally distributed, a <a href="/wiki/Central_limit_theorem" title="Central limit theorem">central limit theorem</a> often nonetheless implies that the parameter estimates will be approximately normally distributed so long as the sample is reasonably large. For this reason, given the important property that the error is mean independent of the independent variables, the distribution of the error term is not an important issue in regression analysis. Specifically, it is not typically important whether the error term follows a normal distribution.</p>
<p>In a least squares calculation with unit weights, or in linear regression, the variance on the <i>j</i>th parameter, denoted <img class="tex" alt="\text{var}(\hat{\beta}_j)" src="http://upload.wikimedia.org/math/6/8/c/68cbe2031dcf4df396a45f2efdaf585f.png" />, is usually estimated with</p>
<dl>
<dd><img class="tex" alt="\hat{\text{var}}(\hat{\beta}_j)=\frac{S}{n-m}\left( \left[X^TX\right]^{-1}\right)_{jj}." src="http://upload.wikimedia.org/math/f/e/a/fea70be68c2360badd21a309c208e08d.png" /></dd>
</dl>
<p><a href="/wiki/Confidence_limits" title="Confidence limits" class="mw-redirect">Confidence limits</a> can be found if the <a href="/wiki/Probability_distribution" title="Probability distribution">probability distribution</a> of the parameters is known, or an asymptotic approximation is made, or assumed. Likewise statistical tests on the residuals can be made if the probability distribution of the residuals is known or assumed. The probability distribution of any linear combination of the dependent variables can be derived if the probability distribution of experimental errors is known or assumed. Inference is particularly straightforward if the errors are assumed to follow a normal distribution, which implies that the parameter estimates and residuals will also be normally distributed conditional on the values of the independent variables.</p>
<p><a name="Weighted_least_squares" id="Weighted_least_squares"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Least_squares&amp;action=edit&amp;section=10" title="Edit section: Weighted least squares">edit</a>]</span> <span class="mw-headline">Weighted least squares</span></h2>
<dl>
<dd><i>See also: <a href="/wiki/Weighted_mean" title="Weighted mean">Weighted mean</a></i></dd>
</dl>
<p>The expressions given above are based on the implicit assumption that the errors are uncorrelated with each other and with the independent variables and have equal variance. The <a href="/wiki/Gauss%E2%80%93Markov_theorem" title="Gauss–Markov theorem">Gauss–Markov theorem</a> shows that, when this is so, <img class="tex" alt="\hat\boldsymbol\beta" src="http://upload.wikimedia.org/math/5/4/9/549c14c2c1608f04c400f2a3c5e6471b.png" /> is a <a href="/wiki/Best_linear_unbiased_estimator" title="Best linear unbiased estimator" class="mw-redirect">best linear unbiased estimator</a> (BLUE). If, however, the measurements are uncorrelated but have different uncertainties, a modified approach might be adopted. <a href="/wiki/Alexander_Aitken" title="Alexander Aitken">Aitken</a> showed that when a weighted sum of squared residuals is minimized, <img class="tex" alt="\hat\boldsymbol\beta" src="http://upload.wikimedia.org/math/5/4/9/549c14c2c1608f04c400f2a3c5e6471b.png" /> is BLUE if each weight is equal to the reciprocal of the variance of the measurement.</p>
<dl>
<dd><img class="tex" alt=" S = \sum_{i=1}^{n} W_{ii}r_i^2,\qquad W_{ii}=\frac{1}{\sigma^2_i} " src="http://upload.wikimedia.org/math/3/9/1/391c90f67f5c9d29ac11d6a15aaab2af.png" /></dd>
</dl>
<p>The gradient equations for this sum of squares are</p>
<dl>
<dd><img class="tex" alt="-2\sum_i W_{ii}\frac{\partial f(x_i,\boldsymbol \beta)}{\partial \beta_j} r_i=0,\qquad j=1,\ldots,n" src="http://upload.wikimedia.org/math/3/7/4/374c872e6745399e87eb09fda9fb3633.png" /></dd>
</dl>
<p>which, in a linear least squares system give the modified normal equations</p>
<dl>
<dd><img class="tex" alt="\sum_{i=1}^{n}\sum_{k=1}^{m} X_{ij}W_{ii}X_{ik}\hat \beta_k=\sum_{i=1}^{n} X_{ij}W_{ii}y_i, \qquad j=1,\ldots,m\," src="http://upload.wikimedia.org/math/b/a/b/bab4b7dec00ac45cb53cd5e1291f5cf6.png" /></dd>
</dl>
<p>or</p>
<dl>
<dd><img class="tex" alt="\mathbf{\left(X^TWX\right)\hat \boldsymbol \beta=X^TWy}." src="http://upload.wikimedia.org/math/8/a/d/8ad28fc18f3885e65ef9702b2bf02aeb.png" /></dd>
</dl>
<p>When the observational errors are uncorrelated the weight matrix, <b>W</b>, is diagonal. If the errors are correlated, the resulting estimator is BLUE if the weight matrix is equal to the inverse of the <a href="/wiki/Variance-covariance_matrix" title="Variance-covariance matrix" class="mw-redirect">variance-covariance matrix</a> of the observations.</p>
<p>When the errors are uncorrelated, it is convenient to simplify the calculations to factor the weight matrix as <img class="tex" alt="w_{ii}=\sqrt W_{ii}" src="http://upload.wikimedia.org/math/1/c/c/1cca355471b13f7ae4267b90e124defb.png" />. The normal equations can then be written as</p>
<dl>
<dd><img class="tex" alt="\mathbf{\left(X'^TX'\right)\hat \boldsymbol \beta=X'^Ty'}\," src="http://upload.wikimedia.org/math/1/f/0/1f0f271ebe015851d53aa0f2ed353a45.png" /></dd>
</dl>
<p>where</p>
<dl>
<dd><img class="tex" alt="\mathbf{X'}=\mathbf{wX}, \mathbf{y'}=\mathbf{wy}.\," src="http://upload.wikimedia.org/math/f/7/b/f7bfd5f820689a8c0bc5ccd5eea53c07.png" /></dd>
</dl>
<p>For non-linear least squares systems a similar argument shows that the normal equations should be modified as follows.</p>
<dl>
<dd><img class="tex" alt="\mathbf{\left(J^TWJ\right)\boldsymbol \Delta\beta=J^TW \boldsymbol\Delta y}.\," src="http://upload.wikimedia.org/math/c/5/a/c5a92e9ea8c8c610e02f5e93028d76fb.png" /></dd>
</dl>
<p>Note that for empirical tests, the appropriate <b>W</b> is not known for sure and must be estimated. For this <a href="/wiki/Feasible_Generalized_Least_Squares" title="Feasible Generalized Least Squares" class="mw-redirect">Feasible Generalized Least Squares</a> (FGLS) techniques may be used.</p>
<p><a name="Lasso_method" id="Lasso_method"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Least_squares&amp;action=edit&amp;section=11" title="Edit section: Lasso method">edit</a>]</span> <span class="mw-headline">Lasso method</span></h3>
<p>In some contexts a <a href="/wiki/Regularization_(machine_learning)" title="Regularization (machine learning)" class="mw-redirect">regularized</a> version of the least squares solution may be preferable. The <i>LASSO</i> algorithm, for example, finds a least-squares solution with the constraint that <span class="texhtml">| β | <sub>1</sub></span>, the <a href="/wiki/L1-norm" title="L1-norm" class="mw-redirect">L<sup>1</sup>-norm</a> of the parameter vector, is no greater than a given value. Equivalently, it may solve an unconstrained minimization of the least-squares penalty with <span class="texhtml">α | β | <sub>1</sub></span> added, where <span class="texhtml">α</span> is a constant. (This is the <a href="/wiki/Lagrange_multipliers" title="Lagrange multipliers">Lagrangian</a> form of the constrained problem.) This problem may be solved using <a href="/wiki/Quadratic_programming" title="Quadratic programming">quadratic programming</a> or more general <a href="/wiki/Convex_optimization" title="Convex optimization">convex optimization</a> methods. The L<sup>1</sup>-regularized formulation is useful in some contexts due to its tendency to prefer solutions with fewer nonzero parameter values, effectively reducing the number of variables upon which the given solution is dependent <sup id="cite_ref-2" class="reference"><a href="#cite_note-2" title=""><span>[</span>3<span>]</span></a></sup>.</p>
<p><a name="See_also" id="See_also"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Least_squares&amp;action=edit&amp;section=12" title="Edit section: See also">edit</a>]</span> <span class="mw-headline">See also</span></h2>
<ul>
<li><a href="/wiki/L2_norm" title="L2 norm" class="mw-redirect"><i>L</i><sub>2</sub> norm</a></li>
<li><a href="/wiki/Least_absolute_deviation" title="Least absolute deviation" class="mw-redirect">Least absolute deviation</a></li>
<li><a href="/wiki/Measurement_uncertainty" title="Measurement uncertainty">Measurement uncertainty</a></li>
<li><a href="/wiki/Root_mean_square" title="Root mean square">Root mean square</a></li>
<li><a href="/wiki/Squared_deviations" title="Squared deviations">Squared deviations</a></li>
<li><a href="/wiki/Iteratively_re-weighted_least_squares" title="Iteratively re-weighted least squares" class="mw-redirect">Iteratively re-weighted least squares</a></li>
<li><a href="/wiki/Total_least_squares" title="Total least squares">Total least squares</a></li>
<li><a href="/wiki/Levenberg%E2%80%93Marquardt_algorithm" title="Levenberg–Marquardt algorithm">Levenberg–Marquardt algorithm</a></li>
<li><a href="/wiki/Regression_analysis" title="Regression analysis">Regression analysis</a></li>
<li><a href="/wiki/Partial_least_squares_regression" title="Partial least squares regression">Partial least squares regression</a></li>
</ul>
<p><a name="Notes" id="Notes"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Least_squares&amp;action=edit&amp;section=13" title="Edit section: Notes">edit</a>]</span> <span class="mw-headline">Notes</span></h2>
<ol class="references">
<li id="cite_note-brertscher-0"><b><a href="#cite_ref-brertscher_0-0" title="">^</a></b> <cite style="font-style:normal" class="book" id="CITEREFBretscher.2C_Otto1995">Bretscher, Otto (1995). <i>Linear Algebra With Applications, 3rd ed.</i>. Upper Saddle River NJ: Prentice Hall.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Linear+Algebra+With+Applications%2C+3rd+ed.&amp;rft.aulast=Bretscher%2C+Otto&amp;rft.au=Bretscher%2C+Otto&amp;rft.date=1995&amp;rft.place=Upper+Saddle+River+NJ&amp;rft.pub=Prentice+Hall&amp;rfr_id=info:sid/en.wikipedia.org:Least_squares"><span style="display: none;">&#160;</span></span></li>
<li id="cite_note-stigler-1"><b><a href="#cite_ref-stigler_1-0" title="">^</a></b> <cite style="font-style:normal" class="book" id="CITEREFStigler.2C_Stephen_M.1986">Stigler, Stephen M. (1986). <i>The History of Statistics: The Measurement of Uncertainty Before 1900</i>. Cambridge, MA: Belknap Press of Harvard University Press.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+History+of+Statistics%3A+The+Measurement+of+Uncertainty+Before+1900&amp;rft.aulast=Stigler%2C+Stephen+M.&amp;rft.au=Stigler%2C+Stephen+M.&amp;rft.date=1986&amp;rft.place=Cambridge%2C+MA&amp;rft.pub=Belknap+Press+of+Harvard+University+Press&amp;rfr_id=info:sid/en.wikipedia.org:Least_squares"><span style="display: none;">&#160;</span></span></li>
<li id="cite_note-2"><b><a href="#cite_ref-2" title="">^</a></b> Tibshirani, R. (1996). Regression shrinkage and selection via the lasso. J. Royal. Statist. Soc B., Vol. 58, No. 1, pages 267–288</li>
</ol>
<p><a name="References" id="References"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Least_squares&amp;action=edit&amp;section=14" title="Edit section: References">edit</a>]</span> <span class="mw-headline">References</span></h2>
<ul>
<li>Å. Björck, <i>Numerical Methods for Least Squares Problems</i>, SIAM, 1996 <a href="http://www.ec-securehost.com/SIAM/ot51.html" class="external autonumber" title="http://www.ec-securehost.com/SIAM/ot51.html" rel="nofollow">[1]</a>.</li>
<li>C.R. Rao, H. Toutenburg, A. Fieger, C. Heumann, T. Nittner and S. Scheid, <i>Linear Models: Least Squares and Alternatives</i>, Springer Series in Statistics, 1999.</li>
<li>T. Kariya, H. Kurata, <i>Generalized Least Squares</i>, Wiley, 2004.</li>
<li>J. Wolberg, <i>Data Analysis Using the Method of Least Squares: Extracting the Most Information from Experiments</i>, Springer, 2005.</li>
</ul>
<p><a name="External_links" id="External_links"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Least_squares&amp;action=edit&amp;section=15" title="Edit section: External links">edit</a>]</span> <span class="mw-headline">External links</span></h2>
<ul>
<li><a href="http://academicearth.org/lectures/applications-to-linear-estimation-least-squares" class="external text" title="http://academicearth.org/lectures/applications-to-linear-estimation-least-squares" rel="nofollow">MIT Linear Algebra Lecture on Least Squares</a>, from MIT OpenCourseWare</li>
<li><a href="http://www.personal.psu.edu/faculty/j/h/jhm/f90/lectures/lsq2.html" class="external text" title="http://www.personal.psu.edu/faculty/j/h/jhm/f90/lectures/lsq2.html" rel="nofollow">Derivation of quadratic least squares</a></li>
<li><a href="http://www2.uta.edu/infosys/baker/STATISTICS/Keller7/Keller%20PP%20slides-7/Chapter17.ppt" class="external text" title="http://www2.uta.edu/infosys/baker/STATISTICS/Keller7/Keller%20PP%20slides-7/Chapter17.ppt" rel="nofollow">Power Point Statistics Book</a> -- Excellent slides providing an introductory regression example (University of Texas at Arlington)</li>
</ul>
<table class="navbox" cellspacing="0" style=";">
<tr>
<td style="padding:2px;">
<table cellspacing="0" class="nowraplinks collapsible autocollapse" style="width:100%;background:transparent;color:inherit;;">
<tr>
<th style=";" colspan="2" class="navbox-title">
<div style="float:left; width:6em;text-align:left;">
<div class="noprint plainlinksneverexpand navbar" style="background:none; padding:0; font-weight:normal;;;border:none;; font-size:xx-small;"><a href="/wiki/Template:Least_squares_and_regression_analysis" title="Template:Least squares and regression analysis"><span title="View this template" style=";;border:none;">v</span></a>&#160;•&#160;<a href="/w/index.php?title=Template_talk:Least_squares_and_regression_analysis&amp;action=edit&amp;redlink=1" class="new" title="Template talk:Least squares and regression analysis (page does not exist)"><span title="Discussion about this template" style=";;border:none;">d</span></a>&#160;•&#160;<a href="http://en.wikipedia.org/w/index.php?title=Template:Least_squares_and_regression_analysis&amp;action=edit" class="external text" title="http://en.wikipedia.org/w/index.php?title=Template:Least_squares_and_regression_analysis&amp;action=edit" rel="nofollow"><span title="Edit this template" style=";;border:none;;">e</span></a></div>
</div>
<span style="font-size:110%;">Least squares and regression analysis</span></th>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><strong class="selflink">Least squares</strong></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/Linear_least_squares" title="Linear least squares">Linear least squares</a> - <a href="/wiki/Non-linear_least_squares" title="Non-linear least squares">Non-linear least squares</a> - <a href="/wiki/Partial_least_squares" title="Partial least squares" class="mw-redirect">Partial least squares</a> -<a href="/wiki/Total_least_squares" title="Total least squares">Total least squares</a> - <a href="/wiki/Gauss%E2%80%93Newton_algorithm" title="Gauss–Newton algorithm">Gauss–Newton algorithm</a> - <a href="/wiki/Levenberg%E2%80%93Marquardt_algorithm" title="Levenberg–Marquardt algorithm">Levenberg–Marquardt algorithm</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/Regression_analysis" title="Regression analysis">Regression analysis</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"><a href="/wiki/Linear_regression" title="Linear regression">Linear regression</a> - <a href="/wiki/Nonlinear_regression" title="Nonlinear regression">Nonlinear regression</a> - <a href="/wiki/Linear_model" title="Linear model">Linear model</a> - <a href="/wiki/Generalized_linear_model" title="Generalized linear model">Generalized linear model</a> - <a href="/wiki/Robust_regression" title="Robust regression">Robust regression</a> - <a href="/wiki/Least-squares_estimation_of_linear_regression_coefficients" title="Least-squares estimation of linear regression coefficients">Least-squares estimation of linear regression coefficients</a>- <a href="/wiki/Mean_and_predicted_response" title="Mean and predicted response">Mean and predicted response</a> - <a href="/wiki/Poisson_regression" title="Poisson regression">Poisson regression</a> - <a href="/wiki/Quantile_regression" title="Quantile regression">Quantile regression</a> - <a href="/wiki/Logistic_regression" title="Logistic regression">Logistic regression</a> - <a href="/wiki/Isotonic_regression" title="Isotonic regression">Isotonic regression</a> - <a href="/wiki/Ridge_regression" title="Ridge regression" class="mw-redirect">Ridge regression</a> - <a href="/wiki/Segmented_regression" title="Segmented regression">Segmented regression</a> - <a href="/wiki/Nonparametric_regression" title="Nonparametric regression">Nonparametric regression</a> - <a href="/wiki/Regression_discontinuity" title="Regression discontinuity">Regression discontinuity</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;">Statistics</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/Gauss%E2%80%93Markov_theorem" title="Gauss–Markov theorem">Gauss–Markov theorem</a> - <a href="/wiki/Errors_and_residuals_in_statistics" title="Errors and residuals in statistics">Errors and residuals in statistics</a> - <a href="/wiki/Goodness_of_fit" title="Goodness of fit">Goodness of fit</a> - <a href="/wiki/Studentized_residual" title="Studentized residual">Studentized residual</a> - <a href="/wiki/Mean_squared_error" title="Mean squared error">Mean squared error</a> - <a href="/wiki/R-factor_(crystallography)" title="R-factor (crystallography)">R-factor (crystallography)</a> - <a href="/wiki/Mean_squared_prediction_error" title="Mean squared prediction error">Mean squared prediction error</a> - <a href="/wiki/Minimum_mean-square_error" title="Minimum mean-square error" class="mw-redirect">Minimum mean-square error</a> - <a href="/wiki/Root_mean_square_deviation" title="Root mean square deviation">Root mean square deviation</a> - <a href="/wiki/Squared_deviations" title="Squared deviations">Squared deviations</a> - <a href="/wiki/M-estimator" title="M-estimator">M-estimator</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;">Applications</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"><a href="/wiki/Curve_fitting" title="Curve fitting">Curve fitting</a> - <a href="/wiki/Calibration_curve" title="Calibration curve">Calibration curve</a> - <a href="/wiki/Numerical_smoothing_and_differentiation" title="Numerical smoothing and differentiation">Numerical smoothing and differentiation</a> - <a href="/wiki/Least_mean_squares_filter" title="Least mean squares filter">Least mean squares filter</a> - <a href="/wiki/Recursive_least_squares_filter" title="Recursive least squares filter">Recursive least squares filter</a> - <a href="/wiki/Moving_least_squares" title="Moving least squares">Moving least squares</a> - <a href="/wiki/BHHH_algorithm" title="BHHH algorithm">BHHH algorithm</a></div>
</td>
</tr>
</table>
</td>
</tr>
</table>
<p><span id="interwiki-de-fa"></span></p>


<!-- 
NewPP limit report
Preprocessor node count: 1624/1000000
Post-expand include size: 18040/2048000 bytes
Template argument size: 6070/2048000 bytes
Expensive parser function count: 0/500
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:82359-0!1!0!default!!en!2 and timestamp 20090401032312 -->
<div class="printfooter">
Retrieved from "<a href="http://en.wikipedia.org/wiki/Least_squares">http://en.wikipedia.org/wiki/Least_squares</a>"</div>
			<div id='catlinks' class='catlinks'><div id="mw-normal-catlinks"><a href="/wiki/Special:Categories" title="Special:Categories">Categories</a>:&#32;<span dir='ltr'><a href="/wiki/Category:Applied_mathematics" title="Category:Applied mathematics">Applied mathematics</a></span> | <span dir='ltr'><a href="/wiki/Category:Mathematical_optimization" title="Category:Mathematical optimization">Mathematical optimization</a></span> | <span dir='ltr'><a href="/wiki/Category:Statistical_methods" title="Category:Statistical methods">Statistical methods</a></span> | <span dir='ltr'><a href="/wiki/Category:Regression_analysis" title="Category:Regression analysis">Regression analysis</a></span> | <span dir='ltr'><a href="/wiki/Category:Single_equation_methods_(econometrics)" title="Category:Single equation methods (econometrics)">Single equation methods (econometrics)</a></span> | <span dir='ltr'><a href="/wiki/Category:Mathematical_and_quantitative_methods_(economics)" title="Category:Mathematical and quantitative methods (economics)">Mathematical and quantitative methods (economics)</a></span></div></div>			<!-- end content -->
						<div class="visualClear"></div>
		</div>
	</div>
		</div>
		<div id="column-one">
	<div id="p-cactions" class="portlet">
		<h5>Views</h5>
		<div class="pBody">
			<ul>
	
				 <li id="ca-nstab-main" class="selected"><a href="/wiki/Least_squares" title="View the content page [c]" accesskey="c">Article</a></li>
				 <li id="ca-talk"><a href="/wiki/Talk:Least_squares" title="Discussion about the content page [t]" accesskey="t">Discussion</a></li>
				 <li id="ca-edit"><a href="/w/index.php?title=Least_squares&amp;action=edit" title="You can edit this page. &#10;Please use the preview button before saving. [e]" accesskey="e">Edit this page</a></li>
				 <li id="ca-history"><a href="/w/index.php?title=Least_squares&amp;action=history" title="Past versions of this page [h]" accesskey="h">History</a></li>			</ul>
		</div>
	</div>
	<div class="portlet" id="p-personal">
		<h5>Personal tools</h5>
		<div class="pBody">
			<ul>
				<li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Least_squares" title="You are encouraged to log in; however, it is not mandatory. [o]" accesskey="o">Log in / create account</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-logo">
		<a style="background-image: url(http://upload.wikimedia.org/wikipedia/en/b/bc/Wiki.png);" href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
	<div class='generated-sidebar portlet' id='p-navigation'>
		<h5>Navigation</h5>
		<div class='pBody'>
			<ul>
				<li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li>
				<li id="n-contents"><a href="/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li>
				<li id="n-featuredcontent"><a href="/wiki/Portal:Featured_content" title="Featured content — the best of Wikipedia">Featured content</a></li>
				<li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li>
				<li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li>
			</ul>
		</div>
	</div>
	<div id="p-search" class="portlet">
		<h5><label for="searchInput">Search</label></h5>
		<div id="searchBody" class="pBody">
			<form action="/w/index.php" id="searchform"><div>
				<input type='hidden' name="title" value="Special:Search"/>
				<input id="searchInput" name="search" type="text" title="Search Wikipedia [f]" accesskey="f" value="" />
				<input type='submit' name="go" class="searchButton" id="searchGoButton"	value="Go" title="Go to a page with this exact name if one exists" />&nbsp;
				<input type='submit' name="fulltext" class="searchButton" id="mw-searchButton" value="Search" title="Search Wikipedia for this text" />
			</div></form>
		</div>
	</div>
	<div class='generated-sidebar portlet' id='p-interaction'>
		<h5>Interaction</h5>
		<div class='pBody'>
			<ul>
				<li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li>
				<li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li>
				<li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="The list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li>
				<li id="n-contact"><a href="/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact Wikipedia</a></li>
				<li id="n-sitesupport"><a href="http://wikimediafoundation.org/wiki/Donate" title="Support us">Donate to Wikipedia</a></li>
				<li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-tb">
		<h5>Toolbox</h5>
		<div class="pBody">
			<ul>
				<li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Least_squares" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li>
				<li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Least_squares" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li>
<li id="t-upload"><a href="/wiki/Wikipedia:Upload" title="Upload files [u]" accesskey="u">Upload file</a></li>
<li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="List of all special pages [q]" accesskey="q">Special pages</a></li>
				<li id="t-print"><a href="/w/index.php?title=Least_squares&amp;printable=yes" rel="alternate" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>				<li id="t-permalink"><a href="/w/index.php?title=Least_squares&amp;oldid=281007823" title="Permanent link to this version of the page">Permanent link</a></li><li id="t-cite"><a href="/w/index.php?title=Special:Cite&amp;page=Least_squares&amp;id=281007823">Cite this page</a></li>			</ul>
		</div>
	</div>
	<div id="p-lang" class="portlet">
		<h5>Languages</h5>
		<div class="pBody">
			<ul>
				<li class="interwiki-af"><a href="http://af.wikipedia.org/wiki/Kleinste-kwadratemetode">Afrikaans</a></li>
				<li class="interwiki-ca"><a href="http://ca.wikipedia.org/wiki/M%C3%ADnims_quadrats_ordinaris">Català</a></li>
				<li class="interwiki-cs"><a href="http://cs.wikipedia.org/wiki/Metoda_nejmen%C5%A1%C3%ADch_%C4%8Dtverc%C5%AF">Česky</a></li>
				<li class="interwiki-de"><a href="http://de.wikipedia.org/wiki/Methode_der_kleinsten_Quadrate">Deutsch</a></li>
				<li class="interwiki-es"><a href="http://es.wikipedia.org/wiki/M%C3%ADnimos_cuadrados">Español</a></li>
				<li class="interwiki-eu"><a href="http://eu.wikipedia.org/wiki/Karratu_txikienen_erregresio">Euskara</a></li>
				<li class="interwiki-fa"><a href="http://fa.wikipedia.org/wiki/%DA%A9%D9%85%D8%AA%D8%B1%DB%8C%D9%86_%D9%85%D8%B1%D8%A8%D8%B9%D8%A7%D8%AA">فارسی</a></li>
				<li class="interwiki-fr"><a href="http://fr.wikipedia.org/wiki/M%C3%A9thode_des_moindres_carr%C3%A9s">Français</a></li>
				<li class="interwiki-gl"><a href="http://gl.wikipedia.org/wiki/M%C3%ADnimos_cadrados">Galego</a></li>
				<li class="interwiki-it"><a href="http://it.wikipedia.org/wiki/Minimi_Quadrati">Italiano</a></li>
				<li class="interwiki-he"><a href="http://he.wikipedia.org/wiki/%D7%A9%D7%99%D7%98%D7%AA_%D7%94%D7%A8%D7%99%D7%91%D7%95%D7%A2%D7%99%D7%9D_%D7%94%D7%A4%D7%97%D7%95%D7%AA%D7%99%D7%9D">עברית</a></li>
				<li class="interwiki-la"><a href="http://la.wikipedia.org/wiki/Methodus_quadratorum_minimorum">Latina</a></li>
				<li class="interwiki-hu"><a href="http://hu.wikipedia.org/wiki/Legkisebb_n%C3%A9gyzetek_m%C3%B3dszere">Magyar</a></li>
				<li class="interwiki-nl"><a href="http://nl.wikipedia.org/wiki/Kleinste-kwadratenmethode">Nederlands</a></li>
				<li class="interwiki-ja"><a href="http://ja.wikipedia.org/wiki/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%97%E6%B3%95">日本語</a></li>
				<li class="interwiki-pl"><a href="http://pl.wikipedia.org/wiki/Metoda_najmniejszych_kwadrat%C3%B3w">Polski</a></li>
				<li class="interwiki-pt"><a href="http://pt.wikipedia.org/wiki/M%C3%A9todo_dos_m%C3%ADnimos_quadrados">Português</a></li>
				<li class="interwiki-ru"><a href="http://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BD%D0%B0%D0%B8%D0%BC%D0%B5%D0%BD%D1%8C%D1%88%D0%B8%D1%85_%D0%BA%D0%B2%D0%B0%D0%B4%D1%80%D0%B0%D1%82%D0%BE%D0%B2">Русский</a></li>
				<li class="interwiki-su"><a href="http://su.wikipedia.org/wiki/Kuadrat_leutik">Basa Sunda</a></li>
				<li class="interwiki-fi"><a href="http://fi.wikipedia.org/wiki/Pienimm%C3%A4n_neli%C3%B6summan_menetelm%C3%A4">Suomi</a></li>
				<li class="interwiki-sv"><a href="http://sv.wikipedia.org/wiki/Minstakvadratmetoden">Svenska</a></li>
				<li class="interwiki-vi"><a href="http://vi.wikipedia.org/wiki/B%C3%ACnh_ph%C6%B0%C6%A1ng_t%E1%BB%91i_thi%E1%BB%83u">Tiếng Việt</a></li>
				<li class="interwiki-tr"><a href="http://tr.wikipedia.org/wiki/En_k%C3%BC%C3%A7%C3%BCk_kareler_y%C3%B6ntemi">Türkçe</a></li>
				<li class="interwiki-zh"><a href="http://zh.wikipedia.org/wiki/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95">中文</a></li>
			</ul>
		</div>
	</div>
		</div><!-- end of the left (by default at least) column -->
			<div class="visualClear"></div>
			<div id="footer">
				<div id="f-poweredbyico"><a href="http://www.mediawiki.org/"><img src="/skins-1.5/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" /></a></div>
				<div id="f-copyrightico"><a href="http://wikimediafoundation.org/"><img src="/images/wikimedia-button.png" border="0" alt="Wikimedia Foundation"/></a></div>
			<ul id="f-list">
					<li id="lastmod"> This page was last modified on 1 April 2009, at 03:23.</li>
					<li id="copyright">All text is available under the terms of the <a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Text_of_the_GNU_Free_Documentation_License" title="Wikipedia:Text of the GNU Free Documentation License">GNU Free Documentation License</a>. (See <b><a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Copyrights" title="Wikipedia:Copyrights">Copyrights</a></b> for details.) <br /> Wikipedia&reg; is a registered trademark of the <a href="http://www.wikimediafoundation.org">Wikimedia Foundation, Inc.</a>, a U.S. registered <a class='internal' href="http://en.wikipedia.org/wiki/501%28c%29#501.28c.29.283.29" title="501(c)(3)">501(c)(3)</a> <a href="http://wikimediafoundation.org/wiki/Deductibility_of_donations">tax-deductible</a> <a class='internal' href="http://en.wikipedia.org/wiki/Non-profit_organization" title="Non-profit organization">nonprofit</a> <a href="http://en.wikipedia.org/wiki/Charitable_organization" title="Charitable organization">charity</a>.<br /></li>
					<li id="privacy"><a href="http://wikimediafoundation.org/wiki/Privacy_policy" title="wikimedia:Privacy policy">Privacy policy</a></li>
					<li id="about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
					<li id="disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
			</ul>
		</div>
</div>

		<script type="text/javascript">if (window.runOnloadHook) runOnloadHook();</script>
<!-- Served by srv37 in 0.066 secs. --></body></html>
