<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
		<meta http-equiv="Content-Style-Type" content="text/css" />
		<meta name="generator" content="MediaWiki 1.15alpha" />
		<meta name="keywords" content="Hash table,Articles with unsourced statements since February 2007,Articles with unsourced statements since November 2007,Special:Search/Hash table,Amortized,Amortized analysis,Array,Associative array,Avalanche effect,Balanced tree,Bit array" />
		<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Hash_table&amp;action=edit" />
		<link rel="edit" title="Edit this page" href="/w/index.php?title=Hash_table&amp;action=edit" />
		<link rel="apple-touch-icon" href="http://en.wikipedia.org/apple-touch-icon.png" />
		<link rel="shortcut icon" href="/favicon.ico" />
		<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)" />
		<link rel="copyright" href="http://www.gnu.org/copyleft/fdl.html" />
		<link rel="alternate" type="application/rss+xml" title="Wikipedia RSS Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=rss" />
		<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=atom" />
		<title>Hash table - Wikipedia, the free encyclopedia</title>
		<link rel="stylesheet" href="/skins-1.5/common/shared.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/common/commonPrint.css?207xx" type="text/css" media="print" />
		<link rel="stylesheet" href="/skins-1.5/monobook/main.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/chick/main.css?207xx" type="text/css" media="handheld" />
		<!--[if lt IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE50Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE55Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 6]><link rel="stylesheet" href="/skins-1.5/monobook/IE60Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 7]><link rel="stylesheet" href="/skins-1.5/monobook/IE70Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Common.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Print.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="print" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Handheld.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="handheld" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Monobook.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=-&amp;action=raw&amp;maxage=2678400&amp;gen=css" type="text/css" />
		<!--[if lt IE 7]><script type="text/javascript" src="/skins-1.5/common/IEFixes.js?207xx"></script>
		<meta http-equiv="imagetoolbar" content="no" /><![endif]-->

		<script type= "text/javascript">/*<![CDATA[*/
		var skin = "monobook";
		var stylepath = "/skins-1.5";
		var wgArticlePath = "/wiki/$1";
		var wgScriptPath = "/w";
		var wgScript = "/w/index.php";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = "http://en.wikipedia.org";
		var wgCanonicalNamespace = "";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = "Hash_table";
		var wgTitle = "Hash table";
		var wgAction = "view";
		var wgArticleId = "13833";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = "en";
		var wgContentLanguage = "en";
		var wgBreakFrames = false;
		var wgCurRevisionId = 281664721;
		var wgVersion = "1.15alpha";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = ["", ""];
		var wgDigitTransformTable = ["", ""];
		var wgMWSuggestTemplate = "http://en.wikipedia.org/w/api.php?action=opensearch\x26search={searchTerms}\x26namespace={namespaces}\x26suggest";
		var wgDBname = "enwiki";
		var wgSearchNamespaces = [0];
		var wgMWSuggestMessages = ["with suggestions", "no suggestions"];
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		/*]]>*/</script>

		<script type="text/javascript" src="/skins-1.5/common/wikibits.js?207xx"><!-- wikibits js --></script>
		<!-- Head Scripts -->
		<script type="text/javascript" src="/skins-1.5/common/ajax.js?207xx"></script>
		<script type="text/javascript" src="/skins-1.5/common/mwsuggest.js?207xx"></script>
<script type="text/javascript">/*<![CDATA[*/
var wgNotice='';var wgNoticeLocal='';
/*]]>*/</script>		<script type="text/javascript" src="http://upload.wikimedia.org/centralnotice/wikipedia/en/centralnotice.js?207xx"></script>
		<script type="text/javascript" src="/w/index.php?title=-&amp;action=raw&amp;gen=js&amp;useskin=monobook"><!-- site js --></script>
	</head>
<body class="mediawiki ltr ns-0 ns-subject page-Hash_table skin-monobook">
	<div id="globalWrapper">
		<div id="column-content">
	<div id="content">
		<a name="top" id="top"></a>
		<div id="siteNotice"><script type='text/javascript'>if (wgNotice != '') document.writeln(wgNotice);</script></div>		<h1 id="firstHeading" class="firstHeading">Hash table</h1>
		<div id="bodyContent">
			<h3 id="siteSub">From Wikipedia, the free encyclopedia</h3>
			<div id="contentSub"></div>
									<div id="jump-to-nav">Jump to: <a href="#column-one">navigation</a>, <a href="#searchInput">search</a></div>			<!-- start content -->
			<div class="thumb tright">
<div class="thumbinner" style="width:364px;"><a href="/wiki/File:HASHTB08.svg" class="image" title="A small phone book as a hash table."><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c2/HASHTB08.svg/362px-HASHTB08.svg.png" width="362" height="195" border="0" class="thumbimage" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="/wiki/File:HASHTB08.svg" class="internal" title="Enlarge"><img src="/skins-1.5/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
A small phone book as a hash table.</div>
</div>
</div>
<p>In <a href="/wiki/Computer_science" title="Computer science">computer science</a>, a <b>hash table</b> or <b>hash map</b> is a <a href="/wiki/Data_structure" title="Data structure">data structure</a> that uses a <a href="/wiki/Hash_function" title="Hash function">hash function</a> to efficiently translate certain <a href="/wiki/Unique_key" title="Unique key">keys</a> (e.g., person names) into associated <a href="/wiki/Value_(mathematics)" title="Value (mathematics)">values</a> (e.g., their telephone numbers). The hash function is used to transform the key into the index (the <i>hash</i>) of an <a href="/wiki/Array" title="Array">array</a> element (the <i>slot</i> or <i>bucket</i>) where the corresponding value is to be sought.</p>
<p>Ideally the hash function should map each possible key to a different slot index; but this goal is rarely achievable in practice. Most hash table designs assume that <i><a href="/wiki/Hash_collision" title="Hash collision" class="mw-redirect">hash collisions</a></i> — pairs of different keys with the same hash values — are normal occurrences, and accomodate them in some way.</p>
<p>In a well-dimensioned hash table, the average cost (number of <a href="/wiki/Instruction_(computer_science)" title="Instruction (computer science)">instructions</a>) for each lookup is independent of the number of elements stored in the table. Many hash table designs also allow arbitrary insertions and deletions of key-value pairs, at constant average (indeed, <a href="/wiki/Amortized" title="Amortized" class="mw-redirect">amortized</a>) cost per operation.<sup id="cite_ref-knuth_0-0" class="reference"><a href="#cite_note-knuth-0" title=""><span>[</span>1<span>]</span></a></sup><sup id="cite_ref-cormen_1-0" class="reference"><a href="#cite_note-cormen-1" title=""><span>[</span>2<span>]</span></a></sup></p>
<p>In many situations, hash tables turn out to be more efficient than <a href="/wiki/Search_tree" title="Search tree" class="mw-redirect">search trees</a> or any other <a href="/wiki/Table_(computing)" title="Table (computing)" class="mw-redirect">table</a> lookup structure. For this reason, they are widely used in all kinds of computer <a href="/wiki/Software" title="Software" class="mw-redirect">software</a>.</p>
<table id="toc" class="toc" summary="Contents">
<tr>
<td>
<div id="toctitle">
<h2>Contents</h2>
</div>
<ul>
<li class="toclevel-1"><a href="#Uses"><span class="tocnumber">1</span> <span class="toctext">Uses</span></a>
<ul>
<li class="toclevel-2"><a href="#Associative_tables"><span class="tocnumber">1.1</span> <span class="toctext">Associative tables</span></a></li>
<li class="toclevel-2"><a href="#Database_indices"><span class="tocnumber">1.2</span> <span class="toctext">Database indices</span></a></li>
<li class="toclevel-2"><a href="#Sets"><span class="tocnumber">1.3</span> <span class="toctext">Sets</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Features"><span class="tocnumber">2</span> <span class="toctext">Features</span></a></li>
<li class="toclevel-1"><a href="#Drawbacks"><span class="tocnumber">3</span> <span class="toctext">Drawbacks</span></a></li>
<li class="toclevel-1"><a href="#Collision_resolution"><span class="tocnumber">4</span> <span class="toctext">Collision resolution</span></a>
<ul>
<li class="toclevel-2"><a href="#Separate_chaining"><span class="tocnumber">4.1</span> <span class="toctext">Separate chaining</span></a></li>
<li class="toclevel-2"><a href="#Open_addressing"><span class="tocnumber">4.2</span> <span class="toctext">Open addressing</span></a></li>
<li class="toclevel-2"><a href="#Open_addressing_versus_chaining"><span class="tocnumber">4.3</span> <span class="toctext">Open addressing versus chaining</span></a></li>
<li class="toclevel-2"><a href="#Coalesced_hashing"><span class="tocnumber">4.4</span> <span class="toctext">Coalesced hashing</span></a></li>
<li class="toclevel-2"><a href="#Perfect_hashing"><span class="tocnumber">4.5</span> <span class="toctext">Perfect hashing</span></a></li>
<li class="toclevel-2"><a href="#Dynamic_perfect_hashing"><span class="tocnumber">4.6</span> <span class="toctext">Dynamic perfect hashing</span></a></li>
<li class="toclevel-2"><a href="#Probabilistic_hashing"><span class="tocnumber">4.7</span> <span class="toctext">Probabilistic hashing</span></a></li>
<li class="toclevel-2"><a href="#Robin_Hood_hashing"><span class="tocnumber">4.8</span> <span class="toctext">Robin Hood hashing</span></a></li>
<li class="toclevel-2"><a href="#Cache-conscious_collision_resolution"><span class="tocnumber">4.9</span> <span class="toctext">Cache-conscious collision resolution</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Performance_analysis"><span class="tocnumber">5</span> <span class="toctext">Performance analysis</span></a>
<ul>
<li class="toclevel-2"><a href="#Load_factor"><span class="tocnumber">5.1</span> <span class="toctext">Load factor</span></a></li>
<li class="toclevel-2"><a href="#Operation_cost"><span class="tocnumber">5.2</span> <span class="toctext">Operation cost</span></a></li>
<li class="toclevel-2"><a href="#Dynamic_resizing"><span class="tocnumber">5.3</span> <span class="toctext">Dynamic resizing</span></a></li>
<li class="toclevel-2"><a href="#Incremental_resizing"><span class="tocnumber">5.4</span> <span class="toctext">Incremental resizing</span></a></li>
<li class="toclevel-2"><a href="#Other_solutions"><span class="tocnumber">5.5</span> <span class="toctext">Other solutions</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Choosing_a_good_hash_function"><span class="tocnumber">6</span> <span class="toctext">Choosing a good hash function</span></a></li>
<li class="toclevel-1"><a href="#Implementations"><span class="tocnumber">7</span> <span class="toctext">Implementations</span></a></li>
<li class="toclevel-1"><a href="#See_also"><span class="tocnumber">8</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1"><a href="#References"><span class="tocnumber">9</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1"><a href="#Further_reading"><span class="tocnumber">10</span> <span class="toctext">Further reading</span></a></li>
<li class="toclevel-1"><a href="#External_links"><span class="tocnumber">11</span> <span class="toctext">External links</span></a></li>
</ul>
</td>
</tr>
</table>
<script type="text/javascript">
//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>
</script>
<p><a name="Uses" id="Uses"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=1" title="Edit section: Uses">edit</a>]</span> <span class="mw-headline">Uses</span></h2>
<p><a name="Associative_tables" id="Associative_tables"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=2" title="Edit section: Associative tables">edit</a>]</span> <span class="mw-headline">Associative tables</span></h3>
<p>Hash tables are commonly used to implement all sort of in-memory tables. They are used to implement <a href="/wiki/Associative_array" title="Associative array">associative arrays</a> (arrays whose indices are arbitrary <a href="/wiki/String_(computing)" title="String (computing)" class="mw-redirect">strings</a> or other complicated objects), especially in <a href="/wiki/Interpreter_(computer_science)" title="Interpreter (computer science)" class="mw-redirect">interpreted</a> <a href="/wiki/Programming_language" title="Programming language">programming languages</a> like <a href="/wiki/Gawk" title="Gawk" class="mw-redirect">gawk</a> and <a href="/wiki/Perl" title="Perl">perl</a>.</p>
<p><a name="Database_indices" id="Database_indices"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=3" title="Edit section: Database indices">edit</a>]</span> <span class="mw-headline">Database indices</span></h3>
<p>Hash tables may also be used for <a href="/w/index.php?title=Disk_(computer)&amp;action=edit&amp;redlink=1" class="new" title="Disk (computer) (page does not exist)">disk</a>-based <a href="/wiki/Persistent_data_structure" title="Persistent data structure">persistent data structures</a> and <a href="/wiki/Index_(database)" title="Index (database)">database indices</a>, although <a href="/wiki/Balanced_tree" title="Balanced tree" class="mw-redirect">balanced trees</a> are more popular in these applications.</p>
<p><a name="Sets" id="Sets"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=4" title="Edit section: Sets">edit</a>]</span> <span class="mw-headline">Sets</span></h3>
<p>Besides recovering the entry which has a given key, many hash table implementations can also tell whether such an entry exists or not.</p>
<p>Those structures can therefore be used to implement a <a href="/wiki/Set_data_structure" title="Set data structure" class="mw-redirect">set data structure</a>, which merely records whether a given key belongs to a specified set of keys. In this case, the structure can be simplified by eliminating all parts which have to do with the entry values. Hashing can be used to implement both static and dynamic sets.</p>
<p><a name="Features" id="Features"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=5" title="Edit section: Features">edit</a>]</span> <span class="mw-headline">Features</span></h2>
<p>The main advantage of hash tables over other table data structures is speed. This advantage is more apparent when the number of entries is large (thousands or more). Hash tables are particularly efficient when the maximum number of entries can be predicted in advance, so that the bucket array can be allocated once with the optimum size and never resized.</p>
<p>If the set of key-value pairs is fixed and known ahead of time (so insertions and deletions are not allowed), one may reduce the average lookup cost by a careful choice of the hash function, bucket table size, and internal data structures. In particular, one may be able to devise a hash function that is collision-free, or even perfect (see below). In this case the keys need not be stored in the table.</p>
<p><a name="Drawbacks" id="Drawbacks"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=6" title="Edit section: Drawbacks">edit</a>]</span> <span class="mw-headline">Drawbacks</span></h2>
<p>Hash tables are more difficult to implement than efficient search trees, such as <a href="/w/index.php?title=Danny_Sleator&amp;action=edit&amp;redlink=1" class="new" title="Danny Sleator (page does not exist)">Sleator</a> and <a href="/w/index.php?title=Rober_Endre_Tarjan&amp;action=edit&amp;redlink=1" class="new" title="Rober Endre Tarjan (page does not exist)">Tarjan</a>'s <a href="/wiki/Self-balancing_binary_search_tree" title="Self-balancing binary search tree">self-balancing binary search trees</a>. Choosing an effective hash function for a specific application is more an art than a science. In open-addressed hash tables it is fairly easy to create a poor hash function.</p>
<p>Although hash table lookups use constant time on average, the cost of a good hash function can be significantly higher than the inner loop of the lookup algorithm for typical search tree. Thus hash tables are not efficient for small tables.</p>
<p>For certain string processing applications, such as <a href="/wiki/Spell_checker" title="Spell checker">spell-checking</a>, hash tables are less efficient than <a href="/wiki/Trie" title="Trie">tries</a> or <a href="/wiki/Finite_automata" title="Finite automata" class="mw-redirect">finite automata</a>. Also, If each key is represented by a small enough number of bits, then, instead of a hash table, one may use the key directly as the index into an array of values. Note that there are no collisions in this case.</p>
<p>The entries stored in a hash table can be enumerated efficiently (at constant cost per entry), but only in some pseudo-random order. Listing all <i>n</i> entries in some specific order generally requires a separate sorting step, whose cost per entry proportional to log(<i>n</i>). In comparison, ordered search trees have insertion cost proportional to log(<i>n</i>) but allow listing of all entries, in the search order, at constant cost per entry.</p>
<p>If the the keys are not stored (because the hash function is collision-free), there may be no easy way to enumerate the keys that are present in the table at any given moment.</p>
<p>Although the <i>average</i> cost per operation is constant and fairly small, the cost of a single operation may be quite high. In particular, if the the hash table uses <a href="#dynamic_resizing" title="">dynamic resizing</a>, an insertion or deletion operation may occasionally take time proportional to the number of entries. This may be a serious drawback in real-time or interactive applications.</p>
<p>Hash tables in general exhibit poor <a href="/wiki/Locality_of_reference" title="Locality of reference">locality of reference</a>—that is, the data to be accessed is distributed seemingly at random in memory. Because hash tables cause access patterns that jump around, this can trigger <a href="/wiki/CPU_cache" title="CPU cache">microprocessor cache</a> misses that cause long delays. Compact data structures such as arrays, searched with <a href="/wiki/Linear_search" title="Linear search">linear search</a>, may be faster if the table is relatively small and keys are integers or other short strings. According to <a href="/wiki/Moore%27s_Law" title="Moore's Law" class="mw-redirect">Moore's Law</a>, cache sizes are growing exponentially and so what is considered "small" may be increasing. The optimal performance point varies from system to system.</p>
<p>Hash tables become quite inefficient when there are many collisions. While extremely uneven hash distributions are extremely unlikely to arise by chance, a <a href="/wiki/Black_hat" title="Black hat">malicious adversary</a> with knowledge of the hash function may be able to supply information to a hash which creates worst-case behavior by causing excessive collisions, resulting in very poor performance (i.e., a <a href="/wiki/Denial_of_service_attack" title="Denial of service attack" class="mw-redirect">denial of service attack</a>). In critical applications, either <a href="/wiki/Universal_hashing" title="Universal hashing">universal hashing</a> can be used or a data structure with better worst-case guarantees may be preferable.<sup id="cite_ref-2" class="reference"><a href="#cite_note-2" title=""><span>[</span>3<span>]</span></a></sup></p>
<p><a name="Collision_resolution" id="Collision_resolution"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=7" title="Edit section: Collision resolution">edit</a>]</span> <span class="mw-headline">Collision resolution</span></h2>
<p>Collisions are practically unavoidable when hashing a random subset of a large set of possible keys. For example, if 2500 keys are hashed into a million buckets, even with a perfectly uniform random distribution, there is a 95% chance of two or more keys being hashed to the same slot.</p>
<p>Therefore, most hash table implementations have some <b>collision resolution</b> strategy to handle such events. Some common strategies are described below.</p>
<p><a name="Separate_chaining" id="Separate_chaining"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=8" title="Edit section: Separate chaining">edit</a>]</span> <span class="mw-headline">Separate chaining</span></h3>
<div class="thumb tright">
<div class="thumbinner" style="width:364px;"><a href="/wiki/File:HASHTB32.svg" class="image" title="Hash collision resolved by chaining."><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/34/HASHTB32.svg/362px-HASHTB32.svg.png" width="362" height="195" border="0" class="thumbimage" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="/wiki/File:HASHTB32.svg" class="internal" title="Enlarge"><img src="/skins-1.5/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
Hash collision resolved by chaining.</div>
</div>
</div>
<p>Sometimes called simply <b>chaining</b> or <b>direct chaining</b>, in its simplest form each slot in the array is a <a href="/wiki/Linked_list" title="Linked list">linked list</a>, or the head cell of a linked list, where the list contains the elements that hashed to the same location. Insertion requires finding the correct slot, then appending to either end of the list in that slot; deletion requires searching the list and removal.</p>
<p>Chained hash tables have advantages over open addressed hash tables in that the removal operation is simple and resizing the table can be postponed for a much longer time because performance <a href="/wiki/Graceful_degradation" title="Graceful degradation" class="mw-redirect">degrades more gracefully</a> even when every slot is used. Indeed, many chaining hash tables may not require resizing at all since performance degradation is linear as the table fills. For example, a chaining hash table containing twice its recommended capacity of data would only be about twice as slow on average as the same table at its recommended capacity.</p>
<p>Chained hash tables inherit the disadvantages of linked lists. When storing small records, the overhead of the linked list can be significant. An additional disadvantage is that traversing a linked list has poor <a href="/wiki/Locality_of_reference" title="Locality of reference">cache performance</a>.</p>
<p>Alternative data structures can be used for chains instead of linked lists. By using a <a href="/wiki/Self-balancing_binary_search_tree" title="Self-balancing binary search tree">self-balancing tree</a>, for example, the theoretical worst-case time of a hash table can be brought down to O(log <i>n</i>) rather than O(<i>n</i>). However, since each list is intended to be short, this approach is usually inefficient unless the hash table is designed to run at full capacity or there are unusually high collision rates, as might occur in input designed to cause collisions. <a href="/wiki/Dynamic_array" title="Dynamic array">Dynamic arrays</a> can also be used to decrease space overhead and improve cache performance, forming a cache-conscious resolution scheme as discussed in the section <i><a href="#Cache-conscious_collision_resolution" title="">Cache-conscious collision resolution</a></i>.</p>
<p>Some chaining implementations use an optimization where the first record of each chain is stored in the table. <sup id="cite_ref-cormen_1-1" class="reference"><a href="#cite_note-cormen-1" title=""><span>[</span>2<span>]</span></a></sup> The purpose is to increase cache efficiency of hash table access. In order to avoid wasting large amounts of space, such hash tables would maintain a <i>load factor</i> of 1.0 or greater. The term <b>direct chaining</b> is sometimes used to describe implementations that <i>do not</i> use this optimization.</p>
<p><a name="Open_addressing" id="Open_addressing"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=9" title="Edit section: Open addressing">edit</a>]</span> <span class="mw-headline">Open addressing</span></h3>
<div class="rellink noprint relarticle mainarticle">Main article: <a href="/wiki/Open_addressing" title="Open addressing">Open addressing</a></div>
<div class="thumb tright">
<div class="thumbinner" style="width:364px;"><a href="/wiki/File:HASHTB12.svg" class="image" title="Hash collision resolved by linear probing (interval=1)."><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/90/HASHTB12.svg/362px-HASHTB12.svg.png" width="362" height="226" border="0" class="thumbimage" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="/wiki/File:HASHTB12.svg" class="internal" title="Enlarge"><img src="/skins-1.5/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
Hash collision resolved by linear probing (interval=1).</div>
</div>
</div>
<p>Open addressing hash tables store the records directly within the array. This approach is also called <i>closed hashing</i>. A hash collision is resolved by <i>probing</i>, or searching through alternate locations in the array (following a <i>probe sequence</i>) until either the target record is found, or an unused array slot is found, which indicates that there is no such key in the table. <sup id="cite_ref-tenenbaum90_3-0" class="reference"><a href="#cite_note-tenenbaum90-3" title=""><span>[</span>4<span>]</span></a></sup> Well known probe sequences include:</p>
<dl>
<dt><a href="/wiki/Linear_probing" title="Linear probing">linear probing</a>&#160;</dt>
<dd>in which the interval between probes is fixed - often at 1.</dd>
<dt><a href="/wiki/Quadratic_probing" title="Quadratic probing">quadratic probing</a>&#160;</dt>
<dd>in which the interval between probes increases proportional to the square of the probe number (the interval thus increasing linearly and the indices are described by a quadratic function).</dd>
<dt><a href="/wiki/Double_hashing" title="Double hashing">double hashing</a>&#160;</dt>
<dd>in which the interval between probes is computed by another hash function.</dd>
</dl>
<p><a name="Open_addressing_versus_chaining" id="Open_addressing_versus_chaining"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=10" title="Edit section: Open addressing versus chaining">edit</a>]</span> <span class="mw-headline">Open addressing versus chaining</span></h3>
<p>Chained hash tables have the following benefits over open addressing:</p>
<ul>
<li>They are simple to implement effectively and only require basic data structures.</li>
<li>From the point of view of writing suitable hash functions, chained hash tables are insensitive to clustering, only requiring minimization of collisions. Open addressing depends upon better hash functions to avoid clustering. This is particularly important if novice programmers can add their own hash functions, but even experienced programmers can be caught out by unexpected clustering effects.</li>
<li>They degrade in performance more gracefully. Although chains grow longer as the table fills, a chained hash table cannot "fill up" and does not exhibit the sudden increases in lookup times that occur in a near-full table with open addressing. (<i>see chart</i>)</li>
<li>If the hash table stores large records, about 5 or more words per record, chaining uses less memory than open addressing.</li>
<li>If the hash table is sparse (that is, it has a big array with many free array slots), chaining uses less memory than open addressing even for small records of 2 to 4 words per record due to its external storage.</li>
</ul>
<div class="thumb tright">
<div class="thumbinner" style="width:364px;"><a href="/wiki/File:Hash_table_average_insertion_time.png" class="image" title="This graph compares the average number of cache misses required to lookup elements in tables with chaining and linear probing. As the table passes the 80%-full mark, linear probing's performance drastically degrades."><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Hash_table_average_insertion_time.png/362px-Hash_table_average_insertion_time.png" width="362" height="235" border="0" class="thumbimage" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="/wiki/File:Hash_table_average_insertion_time.png" class="internal" title="Enlarge"><img src="/skins-1.5/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
This graph compares the average number of cache misses required to lookup elements in tables with chaining and linear probing. As the table passes the 80%-full mark, linear probing's performance drastically degrades.</div>
</div>
</div>
<p>For small record sizes (a few words or less) the benefits of in-place open addressing compared to chaining are:</p>
<ul>
<li>They can be more space-efficient than chaining since they don't need to store any pointers or allocate any additional space outside the hash table. Simple linked lists require a word of overhead per element.</li>
<li>Insertions avoid the time overhead of memory allocation, and can even be implemented in the absence of a memory allocator.</li>
<li>Because it uses internal storage, open addressing avoids the extra indirection required for chaining's external storage. It also has better <a href="/wiki/Locality_of_reference" title="Locality of reference">locality of reference</a>, particularly with linear probing. With small record sizes, these factors can yield better performance than chaining, particularly for lookups.</li>
<li>They can be easier to <a href="/wiki/Serialization" title="Serialization">serialize</a>, because they don't use pointers.</li>
</ul>
<p>On the other hand, normal open addressing is a poor choice for large elements, since these elements fill entire <a href="/wiki/CPU_cache" title="CPU cache">cache lines</a> (negating the cache advantage), and a large amount of space is wasted on large empty table slots. If the open addressing table only stores references to elements (external storage), it uses space comparable to chaining even for large records but loses its speed advantage.</p>
<p>Generally speaking, open addressing is better used for hash tables with small records that can be stored within the table (internal storage) and fit in a cache line. They are particularly suitable for elements of one word or less. In cases where the tables are expected to have high load factors, the records are large, or the data is variable-sized, chained hash tables often perform as well or better.</p>
<p>Ultimately, used sensibly, any kind of hash table algorithm is usually fast <i>enough</i>; and the percentage of a calculation spent in hash table code is low. Memory usage is rarely considered excessive. Therefore, in most cases the differences between these algorithms is marginal, and other considerations typically come into play.</p>
<p><a name="Coalesced_hashing" id="Coalesced_hashing"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=11" title="Edit section: Coalesced hashing">edit</a>]</span> <span class="mw-headline">Coalesced hashing</span></h3>
<div class="rellink noprint relarticle mainarticle">Main article: <a href="/wiki/Coalesced_hashing" title="Coalesced hashing">Coalesced hashing</a></div>
<p>A hybrid of chaining and open addressing, coalesced hashing links together chains of nodes within the table itself. <sup id="cite_ref-tenenbaum90_3-1" class="reference"><a href="#cite_note-tenenbaum90-3" title=""><span>[</span>4<span>]</span></a></sup> Like open addressing, it achieves space usage and (somewhat diminished) cache advantages over chaining. Like chaining, it does not exhibit clustering effects; in fact, the table can be efficiently filled to a high density. Unlike chaining, it cannot have more elements than table slots.</p>
<p><a name="Perfect_hashing" id="Perfect_hashing"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=12" title="Edit section: Perfect hashing">edit</a>]</span> <span class="mw-headline">Perfect hashing</span></h3>
<div class="rellink noprint relarticle mainarticle">Main article: <a href="/wiki/Perfect_hash_function" title="Perfect hash function">Perfect hash function</a></div>
<p>If all of the keys that will be used are known ahead of time, and there are no more keys than can fit the hash table, <a href="/wiki/Perfect_hashing" title="Perfect hashing" class="mw-redirect">perfect hashing</a> can be used to create a perfect hash table, in which there will be no collisions. If <a href="/wiki/Minimal_perfect_hashing" title="Minimal perfect hashing" class="mw-redirect">minimal perfect hashing</a> is used, every location in the hash table can be used as well.</p>
<p>Perfect hashing allows for constant time lookups in the worst case. This is in contrast to chaining and open addressing methods, where the time for lookup is low on average, but may be arbitrarily large. A simpler alternative, which also gives worst case constant lookup time, is <a href="/wiki/Cuckoo_hashing" title="Cuckoo hashing">cuckoo hashing</a>.</p>
<p><a name="Dynamic_perfect_hashing" id="Dynamic_perfect_hashing"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=13" title="Edit section: Dynamic perfect hashing">edit</a>]</span> <span class="mw-headline">Dynamic perfect hashing</span></h3>
<p>In dynamic perfect hashing,<sup id="cite_ref-4" class="reference"><a href="#cite_note-4" title=""><span>[</span>5<span>]</span></a></sup> a guarantee of constant worst-case lookup times by using a second-level hash table with no collisions for each bucket is given. If there are <i>k</i> elements in the bucket, the bucket's hash table is given size <i>k</i><sup>2</sup>, and its hash function is selected at random from a <a href="/wiki/Universal_hash_function" title="Universal hash function" class="mw-redirect">universal hash function</a> set. If a collision ever occurs, the table is rebuilt with a different randomly-selected hash function. Because the load factor of the table is kept low (1/<i>k</i>), rebuilding is infrequent and amortized cost of insertions is low.</p>
<p>Although each bucket requires quadratic space, if the keys inserted into the (first-level) hash table are uniformly distributed, the structure as a whole occupies expected O(<i>n</i>) space, since bucket sizes are small with high probability.</p>
<p><a name="Probabilistic_hashing" id="Probabilistic_hashing"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=14" title="Edit section: Probabilistic hashing">edit</a>]</span> <span class="mw-headline">Probabilistic hashing</span></h3>
<p>Perhaps the simplest solution to a collision is to replace the value that is already in the slot with the new value, or slightly less commonly, drop the record that is to be inserted. In later searches, this may result in a search not finding a record which has been inserted. This technique is particularly useful for implementing caching.</p>
<p>An even more space-efficient solution which is similar to this is use a <a href="/wiki/Bit_array" title="Bit array">bit array</a> (an array of one-bit fields) for our table. Initially all bits are set to zero, and when we insert a key, we set the corresponding bit to one. False negatives cannot occur, but <a href="/wiki/False_positives" title="False positives" class="mw-redirect">false positives</a> can, since if the search finds a 1 bit, it will claim that the value was found, even if it was just another value that hashed into the same array slot by coincidence. In reality, such a hash table is merely a specific type of <a href="/wiki/Bloom_filter" title="Bloom filter">Bloom filter</a>.</p>
<p><a name="Robin_Hood_hashing" id="Robin_Hood_hashing"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=15" title="Edit section: Robin Hood hashing">edit</a>]</span> <span class="mw-headline">Robin Hood hashing</span></h3>
<p>One interesting variation on double-hashing collision resolution is that of Robin Hood hashing<sup id="cite_ref-5" class="reference"><a href="#cite_note-5" title=""><span>[</span>6<span>]</span></a></sup>. The idea is that a key already inserted may be displaced by a new key if its probe count is larger than the key at the current position. The net effect of this is that it reduces worst case search times in the table. This is similar to Knuth's ordered hash tables except the criteria for bumping a key does not depend on a direct relationship between the keys. Since both the worst case and the variance on the number of probes is reduced dramatically an interesting variation is to probe the table starting at the expected successful probe value and then expand from that position in both directions.<sup id="cite_ref-6" class="reference"><a href="#cite_note-6" title=""><span>[</span>7<span>]</span></a></sup></p>
<p><a name="Cache-conscious_collision_resolution" id="Cache-conscious_collision_resolution"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=16" title="Edit section: Cache-conscious collision resolution">edit</a>]</span> <span class="mw-headline">Cache-conscious collision resolution</span></h3>
<p>A chained hash table is a simple and flexible data structure but it does not make good use of CPU cache. This is especially the case when variable-length strings are used as keys. When a collision occurs, a linked list is traversed which can attract a surplus of cache-misses. In addition, linked lists will waste an excessive amount of space due to pointers and memory allocation overheads. We can address these issues by replacing linked lists with dynamic arrays, forming a cache-conscious hash table known as an <b>array hash</b>.<sup id="cite_ref-7" class="reference"><a href="#cite_note-7" title=""><span>[</span>8<span>]</span></a></sup></p>
<p>When a string is hashed to a slot, it is appended to the end of the dynamic array that is assigned to that slot. In this manner, nodes and pointers are eliminated and strings are accessed in a sequential manner, promoting good use of cache. The array hash was also shown to be substantially faster and more compact than a chained hash table using 32-bit or 64-bit integer keys. <sup id="cite_ref-8" class="reference"><a href="#cite_note-8" title=""><span>[</span>9<span>]</span></a></sup></p>
<p><a name="Performance_analysis" id="Performance_analysis"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=17" title="Edit section: Performance analysis">edit</a>]</span> <span class="mw-headline">Performance analysis</span></h2>
<p><a name="Load_factor" id="Load_factor"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=18" title="Edit section: Load factor">edit</a>]</span> <span class="mw-headline">Load factor</span></h3>
<p>The <i>load factor</i> of a hash table is the ratio <i>n/s</i> between the number <i>n</i> of key-value pairs stored in the table and the size <i>s</i> of the bucket array. With a good hash function, the average lookup cost grows relatively slowly as the load factor increases, up to 0.7 or so. For larger load factors both the probability of collisions and the cost of handling them increase quite rapidly. In the limit, when the load factor is <i>n</i> (i.e. when <i>s</i> is 1), the hashing provides no benefit.</p>
<p>On the other hand, as the load factor approaches zero, the size of the hash table increases with little improvement in the search cost.</p>
<p><a name="Operation_cost" id="Operation_cost"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=19" title="Edit section: Operation cost">edit</a>]</span> <span class="mw-headline">Operation cost</span></h3>
<p>The cost of a hash table lookup is that of computing the hash function and then scanning the entries of the selected bucket for the desired key. The <i>worst-case</i> scenario is when all entries were inserted into the same bucket, in which case the hash table is ineffective and the cost is that of searching the bucket structure. If that list is linear and unsorted, then all entries have to be scanned, so the cost is proportional to the number <i>n</i> of entries in the table.</p>
<p>On the other hand, if the ditribution of keys is sufficiently uniform, the <i>average</i> cost of a lookup depends only on the load factor, not on the number of entries the table sizea. These <a href="/wiki/Corner_cases" title="Corner cases" class="mw-redirect">corner cases</a> are addressed in mathematical analysis with the <a href="/wiki/SUHA" title="SUHA">Simple Uniform Hashing Assumption</a>, which puts basic assumed conditions on the hash function.</p>
<p><a name="Dynamic_resizing" id="Dynamic_resizing"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=20" title="Edit section: Dynamic resizing">edit</a>]</span> <span class="mw-headline">Dynamic resizing</span></h3>
<p>In order to keep the load factor in a definite range, e.g. between 1/4 and 3/4, many table implementations may expand the table dynamically when items are inserted, and may shrink it when items are deleted. In <a href="/wiki/Java_(programming_language)" title="Java (programming language)">Java</a>'s <a href="http://java.sun.com/javase/6/docs/api/java/util/HashMap.html" class="external text" title="http://java.sun.com/javase/6/docs/api/java/util/HashMap.html" rel="nofollow">HashMap</a> class, for example, the default load factor threshold for table expansion is 0.75.</p>
<p>Specifically, when the load factor exceeds some threshold <i>r</i><sub>max</sub>, a new larger table is <a href="/wiki/Dynamic_memory_allocation" title="Dynamic memory allocation">allocated</a>, all the entries of the old table are removed and inserted into this new table, and the old table is returned to the free storage pool. Symmetrically, when the load factor falls below a second threshold <i>r</i><sub>min</sub>, all entries are moved to a new smaller table. If the table size increases or decreases by a fixed percentage at each expansion, the total cost of these resizings, <a href="/wiki/Amortized_analysis" title="Amortized analysis">amortized</a> over all insert and delete operations, is still a constant, independent of the number of entries <i>n</i> and of the number <i>m</i> of operations performed.</p>
<p>For example, consider a table that was created with the minimum possible size and is doubled each time the load ratio exceeds some threshold. If <i>m</i> elements are inserted into that table, the total number of extra re-insertions that occur in all dynamic resizings of the table is at most <i>m</i>−1. In other words, dynamic resizing roughly doubles the cost of each insert or delete operation.</p>
<p><a name="Incremental_resizing" id="Incremental_resizing"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=21" title="Edit section: Incremental resizing">edit</a>]</span> <span class="mw-headline">Incremental resizing</span></h3>
<p>On the other hand, some hash table implementations, notably in <a href="/wiki/Real-time_system" title="Real-time system" class="mw-redirect">real-time systems</a>, cannot pay the price of enlarging the hash table all at once, because it may interrupt time-critical operations. One simple approach is to initially allocate the table with enough space for the expected number of elements and forbid the addition of too many elements. Another useful but more memory-intensive technique is to perform the resizing gradually:</p>
<ul>
<li>Allocate the new hash table, but leave the old hash table and check both tables during lookups.</li>
<li>Each time an insertion is performed, add that element to the new table and also move <i>k</i> elements from the old table to the new table.</li>
<li>When all elements are removed from the old table, deallocate it.</li>
</ul>
<p>To ensure that the old table will be completely copied over before the new table itself needs to be enlarged, it's necessary to increase the size of the table by a factor of at least (<i>k</i> + 1)/<i>k</i> during the resizing.</p>
<p><a name="Other_solutions" id="Other_solutions"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=22" title="Edit section: Other solutions">edit</a>]</span> <span class="mw-headline">Other solutions</span></h3>
<p><a href="/wiki/Linear_hashing" title="Linear hashing">Linear hashing</a> <sup id="cite_ref-9" class="reference"><a href="#cite_note-9" title=""><span>[</span>10<span>]</span></a></sup> is a hash table algorithm that permits incremental hash table expansion. It is implemented using a single hash table, but with two possible look-up functions.</p>
<p>Another way to decrease the cost of table resizing is to choose a hash function in such a way that the hashes of most values do not change when the table is resized. This approach, called <a href="/wiki/Consistent_hashing" title="Consistent hashing">consistent hashing</a>, is prevalent in disk-based and distributed hashes, where resizing is prohibitively costly.</p>
<p><a name="Choosing_a_good_hash_function" id="Choosing_a_good_hash_function"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=23" title="Edit section: Choosing a good hash function">edit</a>]</span> <span class="mw-headline">Choosing a good hash function</span></h2>
<div class="rellink noprint relarticle mainarticle">Main article: <a href="/wiki/Hash_function" title="Hash function">Hash function</a></div>
<p>A good hash function is essential for good hash table performance. A poor choice of a hash function is likely to lead to <i>clustering</i>.</p>
<p>In which probability of keys mapping to the same hash bucket (i.e. a <i>collision</i>) is significantly greater than would be expected from a random function.</p>
<p><br />
The cost of resolving a collision scales linearly with the number of keys mapping to the same bucket, so excess collisions will degrade performance significantly. In addition, some hash functions are computationally expensive, so the amount of time (and, in some cases, memory) taken to compute the hash may be burdensome.</p>
<p>Choosing a good hash function is tricky. The literature is replete with poor choices, at least when measured by modern standards. For example, the very popular multiplicative hash advocated by <a href="/wiki/Donald_Knuth" title="Donald Knuth">Donald Knuth</a> in <i><a href="/wiki/The_Art_of_Computer_Programming" title="The Art of Computer Programming">The Art of Computer Programming</a></i> (see reference below) has particularly poor clustering behavior. <a href="http://www.concentric.net/~Ttwang/tech/primehash.htm" class="external autonumber" title="http://www.concentric.net/~Ttwang/tech/primehash.htm" rel="nofollow">[1]</a></p>
<p>However, since poor hashing merely degrades hash table performance for particular input key distributions, such problems commonly go undetected.</p>
<p>However, the (presumed) uniformity of the resulting hash value distribution is hardly worth their much larger computational cost and algorithmic complexity. (They may be appropriate, however, to prevent malicious users from <a href="/wiki/Denial_of_service_attack" title="Denial of service attack" class="mw-redirect">sabotaging</a> a netowrk service by submitting requests designed to generate a large number of collisions in the server's hash tables<sup class="noprint Template-Fact"><span title="This claim needs references to reliable sources&#160;since February 2007" style="white-space: nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed">citation needed</a></i>]</span></sup>. Even then, other methods (such as applying a secret <a href="/wiki/Salt_(cryptography)" title="Salt (cryptography)">salt</a> to the data, or using a <a href="/wiki/Universal_hash_function" title="Universal hash function" class="mw-redirect">universal hash function</a>) may be just as effective but much cheaper.</p>
<p>There is no universal consensus on what makes a "good" hash function.</p>
<p>One criterion is <a href="/wiki/Uniform_distribution_(discrete)" title="Uniform distribution (discrete)">uniformity</a> of the distribution of hash values. Bret Mulvey proposes the use of a <a href="/wiki/Chi-square_test" title="Chi-square test">chi-squared test</a> for uniformity, based on <a href="/wiki/Power_of_two" title="Power of two">power of two</a> hash table sizes ranging from 2<sup>1</sup> to 2<sup>16</sup>. This test is considerably more sensitive than many others proposed for measuring hash functions, and finds problems in many popular hash functions.</p>
<p>One desirable property of a hash function is that conversion from the hash value (typically 32 bits) to a bucket index for a particular-size hash table can be done simply by masking, preserving only the lower k bits for a table of size 2<sup>k</sup> (an operation equivalent to computing the hash value <a href="/wiki/Modulo_operation" title="Modulo operation">modulo</a> the table size). This property enables the technique of incremental doubling of the size of the hash table - each bucket in the old table maps to only two in the new table. Because of its use of XOR-folding, the FNV hash does not have this property. Some older hashes are even worse, requiring table sizes to be a prime number rather than a power of two, again computing the bucket index as the hash value modulo the table size. In general, such a requirement is a sign of a fundamentally weak function; using a prime table size is a poor substitute for using a stronger function.</p>
<p>In the absence of a standard measure for hash function strength, the current state of the art is to employ a battery of <a href="/wiki/Statistics" title="Statistics">statistical</a> tests to measure whether the hash function can be readily distinguished from a random function. Arguably a good cryptograhic hash function should have the <a href="/wiki/Avalanche_effect" title="Avalanche effect">avalanche effect</a>, which essentially states that any single-bit change in the input key should affect, on average, half the bits in the output. Bret Mulvey advocates testing the <i>strict avalanche condition</i> in particular, which states that, for any single-bit change, each of the output bits should change with probability one-half, independent of the other bits in the key. Purely additive hash functions such as <a href="/wiki/Cyclic_redundancy_check" title="Cyclic redundancy check">CRC</a> fail this stronger condition miserably.</p>
<p><a name="Implementations" id="Implementations"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=24" title="Edit section: Implementations">edit</a>]</span> <span class="mw-headline">Implementations</span></h2>
<p>While many programming languages already provide hash table functionality (see <i><a href="/wiki/Associative_array#Language_support" title="Associative array">language support for associative arrays</a></i>), there are several independent implementations worth mentioning.</p>
<ul>
<li><a href="http://code.google.com/p/google-sparsehash/" class="external text" title="http://code.google.com/p/google-sparsehash/" rel="nofollow">Google Sparse Hash</a> The Google SparseHash project contains several hash-map implementations in use at Google, with different performance characteristics, including an implementation that optimizes for space and one that optimizes for speed. The memory-optimized one is extremely memory-efficient with only 2 bits/entry of overhead.</li>
<li><a href="http://www.sunrisetel.net/software/devtools/sunrise-data-dictionary.shtml" class="external text" title="http://www.sunrisetel.net/software/devtools/sunrise-data-dictionary.shtml" rel="nofollow">SunriseDD</a> An open source C library for hash table storage of arbitrary data objects with lock-free lookups, built-in reference counting and guaranteed order iteration. The library can participate in external reference counting systems or use its own built-in reference counting. It comes with a variety of hash functions and allows the use of runtime supplied hash functions via callback mechanism. Source code is well documented.</li>
<li><a href="http://uthash.sourceforge.net/" class="external text" title="http://uthash.sourceforge.net/" rel="nofollow">uthash</a> This is an easy-to-use hash table for C structures.</li>
<li>A number of language runtimes and/or standard libraries use hash tables to implement their support for associative arrays.</li>
<li>Software written to minimize memory usage can conserve memory by keeping all allocated strings in a hash table. If an already existing string is found a pointer to that string is returned; otherwise, a new string is allocated and added to the hash table. (This is the normal technique used in Lisp for the names of variables and functions; see the documentation for the intern and intern-soft functions if you are using that language.) The data compression achieved in this manner is usually around 40%.<sup class="noprint Template-Fact"><span title="This claim needs references to reliable sources&#160;since November 2007" style="white-space: nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed">citation needed</a></i>]</span></sup></li>
</ul>
<p><a name="See_also" id="See_also"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=25" title="Edit section: See also">edit</a>]</span> <span class="mw-headline">See also</span></h2>
<div style="-moz-column-count:2; column-count:2;">
<ul>
<li><a href="/wiki/Bloom_filter" title="Bloom filter">Bloom filter</a></li>
<li><a href="/wiki/Distributed_hash_table" title="Distributed hash table">Distributed hash table</a></li>
<li><a href="/wiki/Hash_function" title="Hash function">Hash function</a></li>
<li><a href="/wiki/SUHA" title="SUHA">Simple uniform hashing assumption</a></li>
<li><a href="/wiki/Rabin-Karp_string_search_algorithm" title="Rabin-Karp string search algorithm">Rabin-Karp string search algorithm</a></li>
<li><a href="/wiki/Hash_consing" title="Hash consing">Hash consing</a></li>
<li><a href="/wiki/Hash_list" title="Hash list">Hash list</a></li>
<li><a href="/wiki/Hash_tree" title="Hash tree">Hash tree</a></li>
<li><a href="/wiki/Judy_array" title="Judy array">Judy array</a></li>
<li><a href="/wiki/Jenkins_hash_function" title="Jenkins hash function">Jenkins hash function</a></li>
<li><a href="/wiki/Trie" title="Trie">Trie</a></li>
<li><a href="/wiki/Stable_hashing" title="Stable hashing">Stable hashing</a></li>
<li><a href="/wiki/Extendible_hashing" title="Extendible hashing">Extendible hashing</a></li>
<li><a href="/wiki/Lazy_deletion" title="Lazy deletion">Lazy deletion</a> - a method of deleting from a hash table using open addressing.</li>
<li><a href="/wiki/Unordered_map" title="Unordered map">Unordered map</a></li>
</ul>
</div>
<p><a name="References" id="References"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=26" title="Edit section: References">edit</a>]</span> <span class="mw-headline">References</span></h2>
<div class="references-small">
<ol class="references">
<li id="cite_note-knuth-0"><b><a href="#cite_ref-knuth_0-0" title="">^</a></b> <cite style="font-style:normal" class="book" id="CITEREF.5B.5BDonald_Knuth.5D.5D1998"><a href="/wiki/Donald_Knuth" title="Donald Knuth">Donald Knuth</a> (1998). <i>The Art of Computer Programming'</i>. <b>3: <i>Sorting and Searching</i></b> (2nd ed.). Addison-Wesley. pp.&#160;513–558. <a href="/wiki/Special:BookSources/0201896850" class="internal">ISBN 0-201-89685-0</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Art+of+Computer+Programming%27&amp;rft.aulast=%5B%5BDonald+Knuth%5D%5D&amp;rft.au=%5B%5BDonald+Knuth%5D%5D&amp;rft.date=1998&amp;rft.volume=3%3A+%27%27Sorting+and+Searching%27%27&amp;rft.pages=pp.%26nbsp%3B513%E2%80%93558&amp;rft.edition=2nd&amp;rft.pub=Addison-Wesley&amp;rft.isbn=0-201-89685-0&amp;rfr_id=info:sid/en.wikipedia.org:Hash_table"><span style="display: none;">&#160;</span></span></li>
<li id="cite_note-cormen-1">^ <a href="#cite_ref-cormen_1-0" title=""><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-cormen_1-1" title=""><sup><i><b>b</b></i></sup></a> <cite style="font-style:normal" class="book" id="CITEREFCormen.5B.5BCharles_E._Leiserson.7CLeiserson.2C_Charles_E..5D.5D.3B_.5B.5BRonald_L._Rivest.7CRivest.2C_Ronald_L..5D.5D.3B_.5B.5BClifford_Stein.7CStein.2C_Clifford.5D.5D2009"><a href="/wiki/Thomas_H._Cormen" title="Thomas H. Cormen">Cormen, Thomas H.</a>; <a href="/wiki/Charles_E._Leiserson" title="Charles E. Leiserson">Leiserson, Charles E.</a>; <a href="/wiki/Ronald_L._Rivest" title="Ronald L. Rivest" class="mw-redirect">Rivest, Ronald L.</a>; <a href="/wiki/Clifford_Stein" title="Clifford Stein">Stein, Clifford</a> (2001). <i><a href="/wiki/Introduction_to_Algorithms" title="Introduction to Algorithms">Introduction to Algorithms</a></i> (second edition ed.). MIT Press and McGraw-Hill. pp.&#160;221–252. <a href="/wiki/Special:BookSources/9780262531962" class="internal">ISBN 978-0-262-53196-2</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=%5B%5BIntroduction+to+Algorithms%5D%5D&amp;rft.aulast=Cormen&amp;rft.aufirst=Thomas+H.&amp;rft.au=Cormen%2C+Thomas+H.&amp;rft.au=%5B%5BCharles+E.+Leiserson%7CLeiserson%2C+Charles+E.%5D%5D%3B+%5B%5BRonald+L.+Rivest%7CRivest%2C+Ronald+L.%5D%5D%3B+%5B%5BClifford+Stein%7CStein%2C+Clifford%5D%5D&amp;rft.date=2001&amp;rft.pages=pp.%26nbsp%3B221%E2%80%93252&amp;rft.edition=second+edition&amp;rft.pub=MIT+Press+and+McGraw-Hill&amp;rft.isbn=978-0-262-53196-2&amp;rfr_id=info:sid/en.wikipedia.org:Hash_table"><span style="display: none;">&#160;</span></span></li>
<li id="cite_note-2"><b><a href="#cite_ref-2" title="">^</a></b> Crosby and Wallach's <i><a href="http://www.cs.rice.edu/~scrosby/hash/CrosbyWallach_UsenixSec2003.pdf" class="external text" title="http://www.cs.rice.edu/~scrosby/hash/CrosbyWallach_UsenixSec2003.pdf" rel="nofollow">Denial of Service via Algorithmic Complexity Attacks</a></i>.</li>
<li id="cite_note-tenenbaum90-3">^ <a href="#cite_ref-tenenbaum90_3-0" title=""><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-tenenbaum90_3-1" title=""><sup><i><b>b</b></i></sup></a> <cite style="font-style:normal" class="" id="CITEREFTenenbaumLangsamAugenstein1990">Tenenbaum, Aaron M.; Langsam, Yedidyah; Augenstein, Moshe J. (1990), <i>Data Structures Using C</i>, Prentice Hall, pp.&#160;456–461, pp. 472, <a href="/wiki/Special:BookSources/0131997467" class="internal">ISBN 0-13-199746-7</a></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Data+Structures+Using+C&amp;rft.aulast=Tenenbaum&amp;rft.aufirst=Aaron+M.&amp;rft.au=Tenenbaum%2C+Aaron+M.&amp;rft.au=Langsam%2C+Yedidyah&amp;rft.au=Augenstein%2C+Moshe+J.&amp;rft.date=1990&amp;rft.pages=pp.%26nbsp%3B456%E2%80%93461%2C+pp.+472&amp;rft.pub=Prentice+Hall&amp;rft.isbn=0-13-199746-7&amp;rfr_id=info:sid/en.wikipedia.org:Hash_table"><span style="display: none;">&#160;</span></span></li>
<li id="cite_note-4"><b><a href="#cite_ref-4" title="">^</a></b> Erik Demaine, Jeff Lind. 6.897: Advanced Data Structures. MIT Computer Science and Artificial Intelligence Laboratory. Spring 2003. <a href="http://courses.csail.mit.edu/6.897/spring03/scribe_notes/L2/lecture2.pdf" class="external free" title="http://courses.csail.mit.edu/6.897/spring03/scribe_notes/L2/lecture2.pdf" rel="nofollow">http://courses.csail.mit.edu/6.897/spring03/scribe_notes/L2/lecture2.pdf</a></li>
<li id="cite_note-5"><b><a href="#cite_ref-5" title="">^</a></b> <cite style="font-style:normal" id="Reference-Celis-1986">Celis, Pedro (1986).  Robin Hood hashing. Technical Report Computer Science Department, University of Waterloo CS-86-14.</cite></li>
<li id="cite_note-6"><b><a href="#cite_ref-6" title="">^</a></b> <cite style="font-style:normal" class="" id="CITEREFViola">Viola, Alfredo. "Exact distribution of individual displacements in linear probing hashing". <i>Transactions on Algorithms (TALG)</i> (ACM) <b>Vol 1</b> (Issue 2, October 2005): Pages: 214–242. ISSN:1549-6325.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Exact+distribution+of+individual+displacements+in+linear+probing+hashing&amp;rft.jtitle=Transactions+on+Algorithms+%28TALG%29&amp;rft.aulast=Viola&amp;rft.aufirst=Alfredo&amp;rft.au=Viola%2C+Alfredo&amp;rft.volume=Vol+1&amp;rft.issue=Issue+2%2C+October+2005&amp;rft.pages=Pages%3A+214%E2%80%93242&amp;rft.pub=ACM&amp;rfr_id=info:sid/en.wikipedia.org:Hash_table"><span style="display: none;">&#160;</span></span></li>
<li id="cite_note-7"><b><a href="#cite_ref-7" title="">^</a></b> <cite style="font-style:normal" class="" id="CITEREFAskitisZobel2005">Askitis, Nikolas; Zobel, Justin (2005), "<a href="http://www.springerlink.com/content/b61721172558qt03/" class="external text" title="http://www.springerlink.com/content/b61721172558qt03/" rel="nofollow">Cache-conscious Collision Resolution in String Hash Tables</a>", <i>Proceedings of the 12th String Processing and Information Retrieval (SPIRE 2005)</i> <b>3772</b>: 91–102, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<span class="neverexpand"><a href="http://dx.doi.org/10.1007%2F11575832_11" class="external text" title="http://dx.doi.org/10.1007%2F11575832_11" rel="nofollow">10.1007/11575832_11</a></span>, <a href="/wiki/Special:BookSources/1721172558" class="internal">ISBN 1721172558</a><span class="printonly">, <a href="http://www.springerlink.com/content/b61721172558qt03/" class="external free" title="http://www.springerlink.com/content/b61721172558qt03/" rel="nofollow">http://www.springerlink.com/content/b61721172558qt03/</a></span></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Cache-conscious+Collision+Resolution+in+String+Hash+Tables&amp;rft.jtitle=Proceedings+of+the+12th+String+Processing+and+Information+Retrieval+%28SPIRE+2005%29&amp;rft.aulast=Askitis&amp;rft.aufirst=Nikolas&amp;rft.au=Askitis%2C+Nikolas&amp;rft.au=Zobel%2C+Justin&amp;rft.date=2005&amp;rft.volume=3772&amp;rft.pages=91%E2%80%93102&amp;rft_id=info:doi/10.1007%2F11575832_11&amp;rft.isbn=1721172558&amp;rft_id=http%3A%2F%2Fwww.springerlink.com%2Fcontent%2Fb61721172558qt03%2F&amp;rfr_id=info:sid/en.wikipedia.org:Hash_table"><span style="display: none;">&#160;</span></span></li>
<li id="cite_note-8"><b><a href="#cite_ref-8" title="">^</a></b> <cite style="font-style:normal" class="" id="CITEREFAskitis2009">Askitis, Nikolas (2009), "<a href="http://www.crpit.com/VolumeIndexU.html#Vol91" class="external text" title="http://www.crpit.com/VolumeIndexU.html#Vol91" rel="nofollow">Fast and Compact Hash Tables for Integer Keys</a>", <i>Proceedings of the 32nd Australasian Computer Science Conference (ACSC 2009)</i> <b>91</b>: 113-122, <a href="/wiki/Special:BookSources/9781920682729" class="internal">ISBN 978-1-920682-72-9</a><span class="printonly">, <a href="http://www.crpit.com/VolumeIndexU.html#Vol91" class="external free" title="http://www.crpit.com/VolumeIndexU.html#Vol91" rel="nofollow">http://www.crpit.com/VolumeIndexU.html#Vol91</a></span></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Fast+and+Compact+Hash+Tables+for+Integer+Keys&amp;rft.jtitle=Proceedings+of+the+32nd++Australasian+Computer+Science+Conference++%28ACSC+2009%29&amp;rft.aulast=Askitis&amp;rft.aufirst=Nikolas&amp;rft.au=Askitis%2C+Nikolas&amp;rft.date=2009&amp;rft.volume=91&amp;rft.pages=113-122&amp;rft.isbn=978-1-920682-72-9&amp;rft_id=http%3A%2F%2Fwww.crpit.com%2FVolumeIndexU.html%23Vol91&amp;rfr_id=info:sid/en.wikipedia.org:Hash_table"><span style="display: none;">&#160;</span></span></li>
<li id="cite_note-9"><b><a href="#cite_ref-9" title="">^</a></b> <cite style="font-style:normal">Litwin, Witold (1980). "Linear hashing: A new tool for file and table addressing". <i>Proc. 6th Conference on Very Large Databases</i>: 212-223.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.btitle=Proc.+6th+Conference+on+Very+Large+Databases&amp;rft.atitle=Linear+hashing%3A+A+new+tool+for+file+and+table+addressing&amp;rft.aulast=Litwin&amp;rft.aufirst=Witold&amp;rft.date=1980&amp;rft.pages=212-223"><span style="display: none;">&#160;</span></span></li>
</ol>
</div>
<p><a name="Further_reading" id="Further_reading"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=27" title="Edit section: Further reading">edit</a>]</span> <span class="mw-headline">Further reading</span></h2>
<ul>
<li><a href="/w/index.php?title=Michael_T._Goodrich&amp;action=edit&amp;redlink=1" class="new" title="Michael T. Goodrich (page does not exist)">Michael T. Goodrich</a> and <a href="/w/index.php?title=Roberto_Tamassia&amp;action=edit&amp;redlink=1" class="new" title="Roberto Tamassia (page does not exist)">Roberto Tamassia</a>. <i>Data Structures and Algorithms in Java</i>, 4th edition. John Wiley &amp; Sons, Inc. <a href="/wiki/Special:BookSources/0471738840" class="internal">ISBN 0-471-73884-0</a>. Chapter 9: Maps and Dictionaries. pp.369–418</li>
<li><a href="/w/index.php?title=Aaron_M._Tenenbaum&amp;action=edit&amp;redlink=1" class="new" title="Aaron M. Tenenbaum (page does not exist)">Aaron M. Tenenbaum</a>, <a href="/w/index.php?title=Yedidyah_Langsam&amp;action=edit&amp;redlink=1" class="new" title="Yedidyah Langsam (page does not exist)">Yedidyah Langsam</a>, and <a href="/w/index.php?title=Moshe_J._Augenstein&amp;action=edit&amp;redlink=1" class="new" title="Moshe J. Augenstein (page does not exist)">Moshe J. Augenstein</a>. <i>Data Structures Using C</i>, Prentice Hall <a href="/wiki/Special:BookSources/0131997467" class="internal">ISBN 0-13-199746-7</a>. Chapter 7, Section 7.4 - Hashing. pp.454–502</li>
</ul>
<p><a name="External_links" id="External_links"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Hash_table&amp;action=edit&amp;section=28" title="Edit section: External links">edit</a>]</span> <span class="mw-headline">External links</span></h2>
<table class="metadata plainlinks mbox-small" style="border:1px solid #aaa; background-color:#f9f9f9;">
<tr>
<td class="mbox-image"><a href="http://commons.wikimedia.org/wiki/Special:Search/Hash_table" title="commons:Special:Search/Hash table"><img alt="Sister project" src="http://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/40px-Commons-logo.svg.png" width="40" height="54" border="0" /></a></td>
<td class="mbox-text" style=""><a href="/wiki/Wikimedia_Commons" title="Wikimedia Commons">Wikimedia Commons</a> has media related to: <b><i><a href="http://commons.wikimedia.org/wiki/Category:Hash_tables" class="extiw" title="commons:Category:Hash tables">Hash tables</a> </i></b></td>
</tr>
</table>
<ul>
<li><a href="http://www.burtleburtle.net/bob/hash/doobs.html" class="external text" title="http://www.burtleburtle.net/bob/hash/doobs.html" rel="nofollow">A Hash Function for Hash Table Lookup</a> by Bob Jenkins.</li>
<li><a href="http://bretmulvey.com/hash/" class="external text" title="http://bretmulvey.com/hash/" rel="nofollow">Hash Functions</a> by Bret Mulvey (Pluto Scarab) - with nice graphs</li>
<li><a href="http://www.azillionmonkeys.com/qed/hash.html" class="external text" title="http://www.azillionmonkeys.com/qed/hash.html" rel="nofollow">Hash functions</a> by Paul Hsieh</li>
<li><a href="http://webkit.opendarwin.org/blog/?p=8" class="external text" title="http://webkit.opendarwin.org/blog/?p=8" rel="nofollow">Hashtables, Part 2</a> by Maciej Stachowiak</li>
<li><a href="http://libhashish.sourceforge.net/" class="external text" title="http://libhashish.sourceforge.net/" rel="nofollow">Libhashish</a> is one of the most feature rich hash libraries (built-in hash functions, several collision strategies, extensive analysis functionality, ...)</li>
<li><a href="/wiki/NIST" title="NIST" class="mw-redirect">NIST</a> entry on <a href="http://www.nist.gov/dads/HTML/hashtab.html" class="external text" title="http://www.nist.gov/dads/HTML/hashtab.html" rel="nofollow">hash tables</a></li>
<li>Open addressing hash table removal algorithm from <a href="/wiki/ICI_programming_language" title="ICI programming language" class="mw-redirect">ICI programming language</a>, <i>ici_set_unassign</i> in <a href="http://ici.cvs.sourceforge.net/ici/ici/set.c?view=markup" class="external text" title="http://ici.cvs.sourceforge.net/ici/ici/set.c?view=markup" rel="nofollow">set.c</a> (and other occurrences, with permission).</li>
<li><a href="http://en.wikibooks.org/wiki/Programming:Perl" class="extiw" title="b:Programming:Perl">The Perl Wikibook</a> - <a href="http://en.wikibooks.org/wiki/Programming:Perl_Hash_Variables" class="extiw" title="b:Programming:Perl Hash Variables">Perl Hash Variables</a></li>
<li><a href="http://www.relisoft.com/book/lang/pointer/8hash.html" class="external text" title="http://www.relisoft.com/book/lang/pointer/8hash.html" rel="nofollow">A basic explanation of how the hash table works by Reliable Software</a></li>
<li><a href="http://compgeom.cs.uiuc.edu/~jeffe/teaching/373/notes/06-hashing.pdf" class="external text" title="http://compgeom.cs.uiuc.edu/~jeffe/teaching/373/notes/06-hashing.pdf" rel="nofollow">Lecture on Hash Tables</a></li>
<li><a href="http://www.hashemall.com" class="external text" title="http://www.hashemall.com" rel="nofollow">Hash'em all!</a> — free online text and file hashing with different algorithms</li>
<li><a href="http://www.qdecoder.org/goto/qHashtbl.html" class="external text" title="http://www.qdecoder.org/goto/qHashtbl.html" rel="nofollow">qDecoder's C/C++ dynamic allocatable hash-table implementation</a> — opensource library</li>
<li><a href="http://www.qdecoder.org/goto/qHasharr.html" class="external text" title="http://www.qdecoder.org/goto/qHasharr.html" rel="nofollow">qDecoder's C/C++ static array-based hash-table implementation</a> — opensource library</li>
<li><a href="http://daniel.graziotin.net/hash-maps-with-linear-probing-and-separate-chaining/" class="external text" title="http://daniel.graziotin.net/hash-maps-with-linear-probing-and-separate-chaining/" rel="nofollow">Hash-tables in C</a> — two simple and clear examples of hash tables implementation in C with linear probing and chaining</li>
<li><a href="http://www.cl.cam.ac.uk/~cwc22/hashtable/" class="external text" title="http://www.cl.cam.ac.uk/~cwc22/hashtable/" rel="nofollow">C Hash Table</a></li>
<li><a href="http://wiki.portugal-a-programar.org/c:snippet:hash_table_c" class="external text" title="http://wiki.portugal-a-programar.org/c:snippet:hash_table_c" rel="nofollow">Implementation of HashTable in C</a></li>
<li><a href="http://video.google.com/videoplay?docid=-727485696209877198&amp;q=source%3A014117792397255896270&amp;hl=en" class="external text" title="http://video.google.com/videoplay?docid=-727485696209877198&amp;q=source%3A014117792397255896270&amp;hl=en" rel="nofollow">MIT's Introduction to Algorithms: Hashing 1</a> MIT OCW lecture Video</li>
<li><a href="http://video.google.com/videoplay?docid=2307261494964091254&amp;q=source%3A014117792397255896270&amp;hl=en" class="external text" title="http://video.google.com/videoplay?docid=2307261494964091254&amp;q=source%3A014117792397255896270&amp;hl=en" rel="nofollow">MIT's Introduction to Algorithms: Hashing 2</a> MIT OCW lecture Video</li>
</ul>


<!-- 
NewPP limit report
Preprocessor node count: 3936/1000000
Post-expand include size: 33581/2048000 bytes
Template argument size: 10013/2048000 bytes
Expensive parser function count: 2/500
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:13833-0!1!0!default!!en!2 and timestamp 20090404084429 -->
<div class="printfooter">
Retrieved from "<a href="http://en.wikipedia.org/wiki/Hash_table">http://en.wikipedia.org/wiki/Hash_table</a>"</div>
			<div id='catlinks' class='catlinks'><div id="mw-normal-catlinks"><a href="/wiki/Special:Categories" title="Special:Categories">Categories</a>:&#32;<span dir='ltr'><a href="/wiki/Category:Articles_with_example_C_code" title="Category:Articles with example C code">Articles with example C code</a></span> | <span dir='ltr'><a href="/wiki/Category:Hashing" title="Category:Hashing">Hashing</a></span> | <span dir='ltr'><a href="/wiki/Category:Search_algorithms" title="Category:Search algorithms">Search algorithms</a></span></div><div id="mw-hidden-catlinks" class="mw-hidden-cats-hidden">Hidden categories:&#32;<span dir='ltr'><a href="/wiki/Category:All_articles_with_unsourced_statements" title="Category:All articles with unsourced statements">All articles with unsourced statements</a></span> | <span dir='ltr'><a href="/wiki/Category:Articles_with_unsourced_statements_since_February_2007" title="Category:Articles with unsourced statements since February 2007">Articles with unsourced statements since February 2007</a></span> | <span dir='ltr'><a href="/wiki/Category:Articles_with_unsourced_statements_since_November_2007" title="Category:Articles with unsourced statements since November 2007">Articles with unsourced statements since November 2007</a></span></div></div>			<!-- end content -->
						<div class="visualClear"></div>
		</div>
	</div>
		</div>
		<div id="column-one">
	<div id="p-cactions" class="portlet">
		<h5>Views</h5>
		<div class="pBody">
			<ul>
	
				 <li id="ca-nstab-main" class="selected"><a href="/wiki/Hash_table" title="View the content page [c]" accesskey="c">Article</a></li>
				 <li id="ca-talk"><a href="/wiki/Talk:Hash_table" title="Discussion about the content page [t]" accesskey="t">Discussion</a></li>
				 <li id="ca-edit"><a href="/w/index.php?title=Hash_table&amp;action=edit" title="You can edit this page. &#10;Please use the preview button before saving. [e]" accesskey="e">Edit this page</a></li>
				 <li id="ca-history"><a href="/w/index.php?title=Hash_table&amp;action=history" title="Past versions of this page [h]" accesskey="h">History</a></li>			</ul>
		</div>
	</div>
	<div class="portlet" id="p-personal">
		<h5>Personal tools</h5>
		<div class="pBody">
			<ul>
				<li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Hash_table" title="You are encouraged to log in; however, it is not mandatory. [o]" accesskey="o">Log in / create account</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-logo">
		<a style="background-image: url(http://upload.wikimedia.org/wikipedia/en/b/bc/Wiki.png);" href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
	<div class='generated-sidebar portlet' id='p-navigation'>
		<h5>Navigation</h5>
		<div class='pBody'>
			<ul>
				<li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li>
				<li id="n-contents"><a href="/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li>
				<li id="n-featuredcontent"><a href="/wiki/Portal:Featured_content" title="Featured content — the best of Wikipedia">Featured content</a></li>
				<li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li>
				<li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li>
			</ul>
		</div>
	</div>
	<div id="p-search" class="portlet">
		<h5><label for="searchInput">Search</label></h5>
		<div id="searchBody" class="pBody">
			<form action="/w/index.php" id="searchform"><div>
				<input type='hidden' name="title" value="Special:Search"/>
				<input id="searchInput" name="search" type="text" title="Search Wikipedia [f]" accesskey="f" value="" />
				<input type='submit' name="go" class="searchButton" id="searchGoButton"	value="Go" title="Go to a page with this exact name if one exists" />&nbsp;
				<input type='submit' name="fulltext" class="searchButton" id="mw-searchButton" value="Search" title="Search Wikipedia for this text" />
			</div></form>
		</div>
	</div>
	<div class='generated-sidebar portlet' id='p-interaction'>
		<h5>Interaction</h5>
		<div class='pBody'>
			<ul>
				<li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li>
				<li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li>
				<li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="The list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li>
				<li id="n-contact"><a href="/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact Wikipedia</a></li>
				<li id="n-sitesupport"><a href="http://wikimediafoundation.org/wiki/Donate" title="Support us">Donate to Wikipedia</a></li>
				<li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-tb">
		<h5>Toolbox</h5>
		<div class="pBody">
			<ul>
				<li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Hash_table" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li>
				<li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Hash_table" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li>
<li id="t-upload"><a href="/wiki/Wikipedia:Upload" title="Upload files [u]" accesskey="u">Upload file</a></li>
<li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="List of all special pages [q]" accesskey="q">Special pages</a></li>
				<li id="t-print"><a href="/w/index.php?title=Hash_table&amp;printable=yes" rel="alternate" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>				<li id="t-permalink"><a href="/w/index.php?title=Hash_table&amp;oldid=281664721" title="Permanent link to this version of the page">Permanent link</a></li><li id="t-cite"><a href="/w/index.php?title=Special:Cite&amp;page=Hash_table&amp;id=281664721">Cite this page</a></li>			</ul>
		</div>
	</div>
	<div id="p-lang" class="portlet">
		<h5>Languages</h5>
		<div class="pBody">
			<ul>
				<li class="interwiki-cs"><a href="http://cs.wikipedia.org/wiki/Hashovac%C3%AD_tabulka">Česky</a></li>
				<li class="interwiki-da"><a href="http://da.wikipedia.org/wiki/Hashtabel">Dansk</a></li>
				<li class="interwiki-de"><a href="http://de.wikipedia.org/wiki/Hashtabelle">Deutsch</a></li>
				<li class="interwiki-es"><a href="http://es.wikipedia.org/wiki/Tabla_hash">Español</a></li>
				<li class="interwiki-fa"><a href="http://fa.wikipedia.org/wiki/%D8%AC%D8%AF%D9%88%D9%84_%D9%87%D8%B4">فارسی</a></li>
				<li class="interwiki-fr"><a href="http://fr.wikipedia.org/wiki/Table_de_hachage">Français</a></li>
				<li class="interwiki-it"><a href="http://it.wikipedia.org/wiki/Hash_table">Italiano</a></li>
				<li class="interwiki-he"><a href="http://he.wikipedia.org/wiki/%D7%98%D7%91%D7%9C%D7%AA_%D7%92%D7%99%D7%91%D7%95%D7%91">עברית</a></li>
				<li class="interwiki-lt"><a href="http://lt.wikipedia.org/wiki/D%C4%97stymo_lentel%C4%97">Lietuvių</a></li>
				<li class="interwiki-nl"><a href="http://nl.wikipedia.org/wiki/Hashtabel">Nederlands</a></li>
				<li class="interwiki-ja"><a href="http://ja.wikipedia.org/wiki/%E3%83%8F%E3%83%83%E3%82%B7%E3%83%A5%E3%83%86%E3%83%BC%E3%83%96%E3%83%AB">日本語</a></li>
				<li class="interwiki-no"><a href="http://no.wikipedia.org/wiki/Hashtabell">‪Norsk (bokmål)‬</a></li>
				<li class="interwiki-pl"><a href="http://pl.wikipedia.org/wiki/Tablica_mieszaj%C4%85ca">Polski</a></li>
				<li class="interwiki-pt"><a href="http://pt.wikipedia.org/wiki/Tabela_de_dispers%C3%A3o">Português</a></li>
				<li class="interwiki-ru"><a href="http://ru.wikipedia.org/wiki/%D0%A5%D0%B5%D1%88-%D1%82%D0%B0%D0%B1%D0%BB%D0%B8%D1%86%D0%B0">Русский</a></li>
				<li class="interwiki-sk"><a href="http://sk.wikipedia.org/wiki/Ha%C5%A1ovacia_tabu%C4%BEka">Slovenčina</a></li>
				<li class="interwiki-fi"><a href="http://fi.wikipedia.org/wiki/Hajautustaulu">Suomi</a></li>
				<li class="interwiki-sv"><a href="http://sv.wikipedia.org/wiki/Hashtabell">Svenska</a></li>
				<li class="interwiki-th"><a href="http://th.wikipedia.org/wiki/%E0%B8%95%E0%B8%B2%E0%B8%A3%E0%B8%B2%E0%B8%87%E0%B9%81%E0%B8%AE%E0%B8%8A">ไทย</a></li>
				<li class="interwiki-zh"><a href="http://zh.wikipedia.org/wiki/%E5%93%88%E5%B8%8C%E8%A1%A8">中文</a></li>
			</ul>
		</div>
	</div>
		</div><!-- end of the left (by default at least) column -->
			<div class="visualClear"></div>
			<div id="footer">
				<div id="f-poweredbyico"><a href="http://www.mediawiki.org/"><img src="/skins-1.5/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" /></a></div>
				<div id="f-copyrightico"><a href="http://wikimediafoundation.org/"><img src="/images/wikimedia-button.png" border="0" alt="Wikimedia Foundation"/></a></div>
			<ul id="f-list">
					<li id="lastmod"> This page was last modified on 4 April 2009, at 08:44.</li>
					<li id="copyright">All text is available under the terms of the <a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Text_of_the_GNU_Free_Documentation_License" title="Wikipedia:Text of the GNU Free Documentation License">GNU Free Documentation License</a>. (See <b><a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Copyrights" title="Wikipedia:Copyrights">Copyrights</a></b> for details.) <br /> Wikipedia&reg; is a registered trademark of the <a href="http://www.wikimediafoundation.org">Wikimedia Foundation, Inc.</a>, a U.S. registered <a class='internal' href="http://en.wikipedia.org/wiki/501%28c%29#501.28c.29.283.29" title="501(c)(3)">501(c)(3)</a> <a href="http://wikimediafoundation.org/wiki/Deductibility_of_donations">tax-deductible</a> <a class='internal' href="http://en.wikipedia.org/wiki/Non-profit_organization" title="Non-profit organization">nonprofit</a> <a href="http://en.wikipedia.org/wiki/Charitable_organization" title="Charitable organization">charity</a>.<br /></li>
					<li id="privacy"><a href="http://wikimediafoundation.org/wiki/Privacy_policy" title="wikimedia:Privacy policy">Privacy policy</a></li>
					<li id="about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
					<li id="disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
			</ul>
		</div>
</div>

		<script type="text/javascript">if (window.runOnloadHook) runOnloadHook();</script>
<!-- Served by srv214 in 0.050 secs. --></body></html>
