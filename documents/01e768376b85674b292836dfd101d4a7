<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
		<meta http-equiv="Content-Style-Type" content="text/css" />
		<meta name="generator" content="MediaWiki 1.15alpha" />
		<meta name="keywords" content="Philosophy of artificial intelligence,Alan Newell,Alan Perlis,Alan Turing,Allen Newell,Anthropomorphic,Arithmetic,Artificial brain,Artificial consciousness,Artificial intelligence,Automated Mathematician" />
		<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit" />
		<link rel="edit" title="Edit this page" href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit" />
		<link rel="apple-touch-icon" href="http://en.wikipedia.org/apple-touch-icon.png" />
		<link rel="shortcut icon" href="/favicon.ico" />
		<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)" />
		<link rel="copyright" href="http://www.gnu.org/copyleft/fdl.html" />
		<link rel="alternate" type="application/rss+xml" title="Wikipedia RSS Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=rss" />
		<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=atom" />
		<title>Philosophy of artificial intelligence - Wikipedia, the free encyclopedia</title>
		<link rel="stylesheet" href="/skins-1.5/common/shared.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/common/commonPrint.css?207xx" type="text/css" media="print" />
		<link rel="stylesheet" href="/skins-1.5/monobook/main.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/chick/main.css?207xx" type="text/css" media="handheld" />
		<!--[if lt IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE50Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE55Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 6]><link rel="stylesheet" href="/skins-1.5/monobook/IE60Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 7]><link rel="stylesheet" href="/skins-1.5/monobook/IE70Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Common.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Print.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="print" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Handheld.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="handheld" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Monobook.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=-&amp;action=raw&amp;maxage=2678400&amp;gen=css" type="text/css" />
		<!--[if lt IE 7]><script type="text/javascript" src="/skins-1.5/common/IEFixes.js?207xx"></script>
		<meta http-equiv="imagetoolbar" content="no" /><![endif]-->

		<script type= "text/javascript">/*<![CDATA[*/
		var skin = "monobook";
		var stylepath = "/skins-1.5";
		var wgArticlePath = "/wiki/$1";
		var wgScriptPath = "/w";
		var wgScript = "/w/index.php";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = "http://en.wikipedia.org";
		var wgCanonicalNamespace = "";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = "Philosophy_of_artificial_intelligence";
		var wgTitle = "Philosophy of artificial intelligence";
		var wgAction = "view";
		var wgArticleId = "2958015";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = "en";
		var wgContentLanguage = "en";
		var wgBreakFrames = false;
		var wgCurRevisionId = 285538245;
		var wgVersion = "1.15alpha";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = ["", ""];
		var wgDigitTransformTable = ["", ""];
		var wgMWSuggestTemplate = "http://en.wikipedia.org/w/api.php?action=opensearch\x26search={searchTerms}\x26namespace={namespaces}\x26suggest";
		var wgDBname = "enwiki";
		var wgSearchNamespaces = [0];
		var wgMWSuggestMessages = ["with suggestions", "no suggestions"];
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		/*]]>*/</script>

		<script type="text/javascript" src="/skins-1.5/common/wikibits.js?207xx"><!-- wikibits js --></script>
		<!-- Head Scripts -->
		<script type="text/javascript" src="/skins-1.5/common/ajax.js?207xx"></script>
		<script type="text/javascript" src="/skins-1.5/common/mwsuggest.js?207xx"></script>
<script type="text/javascript">/*<![CDATA[*/
var wgNotice='';var wgNoticeLocal='';
/*]]>*/</script>		<script type="text/javascript" src="http://upload.wikimedia.org/centralnotice/wikipedia/en/centralnotice.js?207xx"></script>
<script type="text/javascript" src="/w/extensions/OggHandler/OggPlayer.js?9"></script>
<script type="text/javascript">
wgOggPlayer.msg = {"ogg-play": "Play", "ogg-pause": "Pause", "ogg-stop": "Stop", "ogg-no-player": "Sorry, your system does not appear to have any supported player software.\nPlease \x3ca href=\"http://www.mediawiki.org/wiki/Extension:OggHandler/Client_download\"\x3edownload a player\x3c/a\x3e.", "ogg-player-videoElement": "Native browser support", "ogg-player-oggPlugin": "Browser plugin", "ogg-player-cortado": "Cortado (Java)", "ogg-player-vlc-mozilla": "VLC", "ogg-player-vlc-activex": "VLC (ActiveX)", "ogg-player-quicktime-mozilla": "QuickTime", "ogg-player-quicktime-activex": "QuickTime (ActiveX)", "ogg-player-totem": "Totem", "ogg-player-kaffeine": "Kaffeine", "ogg-player-kmplayer": "KMPlayer", "ogg-player-mplayerplug-in": "mplayerplug-in", "ogg-player-thumbnail": "Still image only", "ogg-player-selected": "(selected)", "ogg-use-player": "Use player:", "ogg-more": "More…", "ogg-download": "Download file", "ogg-desc-link": "About this file", "ogg-dismiss": "Close", "ogg-player-soundthumb": "No player", "ogg-no-xiphqt": "You do not appear to have the XiphQT component for QuickTime.\nQuickTime cannot play Ogg files without this component.\nPlease \x3ca href=\"http://www.mediawiki.org/wiki/Extension:OggHandler/Client_download\"\x3edownload XiphQT\x3c/a\x3e or choose another player."};
wgOggPlayer.cortadoUrl = "http://upload.wikimedia.org/jars/cortado.jar";
wgOggPlayer.extPathUrl = "/w/extensions/OggHandler";
</script>
<style type="text/css">
.ogg-player-options {
	border: solid 1px #ccc;
	padding: 2pt;
	text-align: left;
	font-size: 10pt;
}
</style>		<script type="text/javascript" src="/w/index.php?title=-&amp;action=raw&amp;gen=js&amp;useskin=monobook"><!-- site js --></script>
	</head>
<body class="mediawiki ltr ns-0 ns-subject page-Philosophy_of_artificial_intelligence skin-monobook">
	<div id="globalWrapper">
		<div id="column-content">
	<div id="content">
		<a name="top" id="top"></a>
		<div id="siteNotice"><script type='text/javascript'>if (wgNotice != '') document.writeln(wgNotice);</script></div>		<h1 id="firstHeading" class="firstHeading">Philosophy of artificial intelligence</h1>
		<div id="bodyContent">
			<h3 id="siteSub">From Wikipedia, the free encyclopedia</h3>
			<div id="contentSub"></div>
									<div id="jump-to-nav">Jump to: <a href="#column-one">navigation</a>, <a href="#searchInput">search</a></div>			<!-- start content -->
			<div class="noprint tright portal" style="border:solid #aaa 1px;margin:0.5em 0 0.5em 0.5em;">
<table style="background:#f9f9f9; font-size:85%; line-height:110%;">
<tr>
<td><a href="/wiki/File:Portal.svg" class="image" title="Portal.svg"><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c9/Portal.svg/28px-Portal.svg.png" width="28" height="28" border="0" /></a></td>
<td style="padding:0 0.2em;"><i><b><a href="/wiki/Portal:Artificial_intelligence" title="Portal:Artificial intelligence">Artificial intelligence portal</a></b></i></td>
</tr>
</table>
</div>
<div class="noprint tright portal" style="border:solid #aaa 1px;margin:0.5em 0 0.5em 0.5em;">
<table style="background:#f9f9f9; font-size:85%; line-height:110%;">
<tr>
<td><a href="/wiki/File:Portal.svg" class="image" title="Portal.svg"><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c9/Portal.svg/28px-Portal.svg.png" width="28" height="28" border="0" /></a></td>
<td style="padding:0 0.2em;"><i><b><a href="/wiki/Portal:Mind_and_Brain" title="Portal:Mind and Brain">Mind and Brain portal</a></b></i></td>
</tr>
</table>
</div>
<div class="rellink boilerplate seealso">See also: <a href="/wiki/Ethics_of_artificial_intelligence" title="Ethics of artificial intelligence">ethics of artificial intelligence</a></div>
<p>The <b>philosophy of artificial intelligence</b> attempts to answer such question as:<sup id="cite_ref-0" class="reference"><a href="#cite_note-0" title=""><span>[</span>1<span>]</span></a></sup></p>
<ul>
<li>Can a machine act intelligently? Can it solve <i>any</i> problem that a person would solve by thinking?</li>
<li>Can a machine have a <a href="/wiki/Philosophy_of_mind" title="Philosophy of mind">mind</a>, mental states and <a href="/wiki/Consciousness" title="Consciousness">consciousness</a> in the same sense humans do? Can it <i>feel</i>?</li>
<li>Are human intelligence and machine intelligence the same? Is the human brain essentially a computer?</li>
</ul>
<p>These three questions reflect the divergent interests of <a href="/wiki/Artificial_intelligence" title="Artificial intelligence">AI researchers</a>, <a href="/wiki/Philosophy" title="Philosophy">philosophers</a> and <a href="/wiki/Cognitive_science" title="Cognitive science">cognitive scientists</a> respectively. The answers to these questions depend on how one defines "intelligence" or "consciousness" and exactly which "machines" are under discussion.</p>
<p>Important <a href="/wiki/Proposition" title="Proposition">propositions</a> in the philosophy of AI include:</p>
<ul>
<li><a href="/wiki/Turing_Test" title="Turing Test" class="mw-redirect">Turing's "polite convention"</a>: <i>If a machine acts as intelligently as a human being, then it is as intelligent as a human being.</i><sup id="cite_ref-T_1-0" class="reference"><a href="#cite_note-T-1" title=""><span>[</span>2<span>]</span></a></sup></li>
<li>The <a href="/wiki/Dartmouth_Conferences" title="Dartmouth Conferences">Dartmouth proposal</a>: <i>"Every aspect of learning or any other feature of intelligence can be so precisely described that a machine can be made to simulate it."</i><sup id="cite_ref-MMRS_2-0" class="reference"><a href="#cite_note-MMRS-2" title=""><span>[</span>3<span>]</span></a></sup></li>
<li><a href="/wiki/Alan_Newell" title="Alan Newell" class="mw-redirect">Newell</a> and <a href="/wiki/Herbert_Simon" title="Herbert Simon">Simon</a>'s <a href="/wiki/Physical_symbol_system" title="Physical symbol system">physical symbol system hypothesis</a>: <i>"A physical symbol system has the necessary and sufficient means of general intelligent action."</i><sup id="cite_ref-NS_3-0" class="reference"><a href="#cite_note-NS-3" title=""><span>[</span>4<span>]</span></a></sup></li>
<li><a href="/wiki/John_Searle" title="John Searle">Searle</a>'s <a href="/wiki/Chinese_room#Strong_AI" title="Chinese room">strong AI hypothesis</a>: <i>"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds."</i><sup id="cite_ref-SWAI_4-0" class="reference"><a href="#cite_note-SWAI-4" title=""><span>[</span>5<span>]</span></a></sup></li>
<li><a href="/wiki/Hobbes" title="Hobbes" class="mw-redirect">Hobbes</a>' <a href="/wiki/Mechanism" title="Mechanism">mechanism</a>: <i>"Reason is nothing but reckoning."</i><sup id="cite_ref-H_5-0" class="reference"><a href="#cite_note-H-5" title=""><span>[</span>6<span>]</span></a></sup></li>
</ul>
<table id="toc" class="toc" summary="Contents">
<tr>
<td>
<div id="toctitle">
<h2>Contents</h2>
</div>
<ul>
<li class="toclevel-1"><a href="#Can_a_machine_display_general_intelligence.3F"><span class="tocnumber">1</span> <span class="toctext">Can a machine display general intelligence?</span></a>
<ul>
<li class="toclevel-2"><a href="#Intelligence"><span class="tocnumber">1.1</span> <span class="toctext">Intelligence</span></a>
<ul>
<li class="toclevel-3"><a href="#Turing_test"><span class="tocnumber">1.1.1</span> <span class="toctext">Turing test</span></a></li>
<li class="toclevel-3"><a href="#Human_intelligence_vs._intelligence_in_general"><span class="tocnumber">1.1.2</span> <span class="toctext">Human intelligence vs. intelligence in general</span></a></li>
</ul>
</li>
<li class="toclevel-2"><a href="#Arguments_that_a_machine_can_display_general_intelligence"><span class="tocnumber">1.2</span> <span class="toctext">Arguments that a machine can display general intelligence</span></a>
<ul>
<li class="toclevel-3"><a href="#The_brain_can_be_simulated"><span class="tocnumber">1.2.1</span> <span class="toctext">The brain can be simulated</span></a></li>
<li class="toclevel-3"><a href="#Human_thinking_is_symbol_processing"><span class="tocnumber">1.2.2</span> <span class="toctext">Human thinking is symbol processing</span></a></li>
<li class="toclevel-3"><a href="#Arguments_against_symbol_processing"><span class="tocnumber">1.2.3</span> <span class="toctext">Arguments against symbol processing</span></a>
<ul>
<li class="toclevel-4"><a href="#Lucas.2C_Penrose_and_G.C3.B6del"><span class="tocnumber">1.2.3.1</span> <span class="toctext">Lucas, Penrose and Gödel</span></a></li>
<li class="toclevel-4"><a href="#Dreyfus:_the_primacy_of_unconscious_skills"><span class="tocnumber">1.2.3.2</span> <span class="toctext">Dreyfus: the primacy of unconscious skills</span></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1"><a href="#Can_a_machine_have_a_mind.2C_consciousness_and_mental_states.3F"><span class="tocnumber">2</span> <span class="toctext">Can a machine have a mind, consciousness and mental states?</span></a>
<ul>
<li class="toclevel-2"><a href="#Consciousness.2C_minds.2C_mental_states.2C_meaning"><span class="tocnumber">2.1</span> <span class="toctext">Consciousness, minds, mental states, meaning</span></a></li>
<li class="toclevel-2"><a href="#Arguments_that_a_computer_can.27t_have_a_mind_and_mental_states"><span class="tocnumber">2.2</span> <span class="toctext">Arguments that a computer can't have a mind and mental states</span></a>
<ul>
<li class="toclevel-3"><a href="#Searle.27s_Chinese_room"><span class="tocnumber">2.2.1</span> <span class="toctext">Searle's Chinese room</span></a></li>
<li class="toclevel-3"><a href="#Related_arguments:_Leibniz.27_mill.2C_Block.27s_telephone_exchange_and_blockhead"><span class="tocnumber">2.2.2</span> <span class="toctext">Related arguments: Leibniz' mill, Block's telephone exchange and blockhead</span></a></li>
<li class="toclevel-3"><a href="#Responses_to_the_Chinese_Room"><span class="tocnumber">2.2.3</span> <span class="toctext">Responses to the Chinese Room</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1"><a href="#Is_thinking_a_kind_of_computation.3F"><span class="tocnumber">3</span> <span class="toctext">Is thinking a kind of computation?</span></a></li>
<li class="toclevel-1"><a href="#Other_related_questions"><span class="tocnumber">4</span> <span class="toctext">Other related questions</span></a>
<ul>
<li class="toclevel-2"><a href="#Can_a_machine_have_emotions.3F"><span class="tocnumber">4.1</span> <span class="toctext">Can a machine have emotions?</span></a></li>
<li class="toclevel-2"><a href="#Can_a_machine_be_self_aware.3F"><span class="tocnumber">4.2</span> <span class="toctext">Can a machine be self aware?</span></a></li>
<li class="toclevel-2"><a href="#Can_a_machine_be_original_or_creative.3F"><span class="tocnumber">4.3</span> <span class="toctext">Can a machine be original or creative?</span></a></li>
<li class="toclevel-2"><a href="#Can_a_machine_have_a_soul.3F"><span class="tocnumber">4.4</span> <span class="toctext">Can a machine have a soul?</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#See_also"><span class="tocnumber">5</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1"><a href="#Notes"><span class="tocnumber">6</span> <span class="toctext">Notes</span></a></li>
<li class="toclevel-1"><a href="#References"><span class="tocnumber">7</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1"><a href="#External_links"><span class="tocnumber">8</span> <span class="toctext">External links</span></a></li>
</ul>
</td>
</tr>
</table>
<script type="text/javascript">
//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>
</script>
<p><a name="Can_a_machine_display_general_intelligence.3F" id="Can_a_machine_display_general_intelligence.3F"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=1" title="Edit section: Can a machine display general intelligence?">edit</a>]</span> <span class="mw-headline">Can a machine display general intelligence?</span></h2>
<p>Is it possible to create a machine that can solve <i>all</i> the problems humans solve using their intelligence? This is the question that AI researchers are most interested in answering. It defines the scope of what machines will be able to do in the future and guides the direction of AI research. It only concerns the <i>behavior</i> of machines and ignores the issues of interest to <a href="/wiki/Psychology" title="Psychology">psychologists</a>, <a href="/wiki/Cognitive_science" title="Cognitive science">cognitive scientists</a> and <a href="/wiki/Philosophy" title="Philosophy">philosophers</a>; to answer this question, it doesn't matter whether a machine is <i>really</i> thinking (as a person thinks) or is just <i>acting like</i> it is thinking.<sup id="cite_ref-6" class="reference"><a href="#cite_note-6" title=""><span>[</span>7<span>]</span></a></sup></p>
<p>The basic position of most AI researchers is summed up in this statement, which appeared in the proposal for the <a href="/wiki/Dartmouth_Conferences" title="Dartmouth Conferences">Dartmouth Conferences</a> of 1956:</p>
<ul>
<li><i>Every aspect of learning or any other feature of intelligence can be so precisely described that a machine can be made to simulate it.</i><sup id="cite_ref-MMRS_2-1" class="reference"><a href="#cite_note-MMRS-2" title=""><span>[</span>3<span>]</span></a></sup></li>
</ul>
<p>Arguments against the basic premise must show that building a working AI system is impossible, because there is some practical limit to the abilities of computers or that there is some special quality of the human mind that is necessary for thinking and yet can't be duplicated by a machine (or by the methods of current AI research). Arguments in favor of the basic premise must show that such a system is possible.</p>
<p>The first step to answering the question is to clearly define "intelligence."</p>
<p><a name="Intelligence" id="Intelligence"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=2" title="Edit section: Intelligence">edit</a>]</span> <span class="mw-headline">Intelligence</span></h3>
<p><a name="Turing_test" id="Turing_test"></a></p>
<h4><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=3" title="Edit section: Turing test">edit</a>]</span> <span class="mw-headline">Turing test</span></h4>
<div class="rellink noprint relarticle mainarticle">Main article: <a href="/wiki/Turing_test" title="Turing test">Turing test</a></div>
<p><a href="/wiki/Alan_Turing" title="Alan Turing">Alan Turing</a>, in a famous and seminal 1950 paper,<sup id="cite_ref-7" class="reference"><a href="#cite_note-7" title=""><span>[</span>8<span>]</span></a></sup> reduced the problem of defining intelligence to a simple question about conversation. He suggests that: if a machine can answer <i>any</i> question put to it, using the same words that an ordinary person would, then we may call that machine intelligent. A modern version of his experimental design would use an online <a href="/wiki/Chat_room" title="Chat room">chat room</a>, where one of the participants is a real person and one of the participants is a computer program. The program passes the test if no one can tell which of the two participants is human.<sup id="cite_ref-T_1-1" class="reference"><a href="#cite_note-T-1" title=""><span>[</span>2<span>]</span></a></sup> Turing notes that no one (except philosophers) ever asks the question "can people think?" He writes "instead of arguing continually over this point, it is usual to have a polite convention that everyone thinks."<sup id="cite_ref-8" class="reference"><a href="#cite_note-8" title=""><span>[</span>9<span>]</span></a></sup> Turing's test extends this polite convention to machines:</p>
<ul>
<li><i>If a machine acts as intelligently as human being, then it is as intelligent as a human being.</i></li>
</ul>
<p><a name="Human_intelligence_vs._intelligence_in_general" id="Human_intelligence_vs._intelligence_in_general"></a></p>
<h4><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=4" title="Edit section: Human intelligence vs. intelligence in general">edit</a>]</span> <span class="mw-headline">Human intelligence vs. intelligence in general</span></h4>
<p>One criticism of the <a href="/wiki/Turing_test" title="Turing test">Turing test</a> is that it is explicitly <a href="/wiki/Anthropomorphic" title="Anthropomorphic" class="mw-redirect">anthropomorphic</a>. If our ultimate goal is to create machines that are <i>more</i> intelligent than people, why should we insist that our machines must closely <i>resemble</i> people? <a href="/wiki/Stuart_J._Russell" title="Stuart J. Russell">Russell</a> and <a href="/wiki/Peter_Norvig" title="Peter Norvig">Norvig</a> write that "aeronautical engineering texts do not define the goal of their field as 'making machines that fly so exactly like pigeons that they can fool other pigeons.'"<sup id="cite_ref-9" class="reference"><a href="#cite_note-9" title=""><span>[</span>10<span>]</span></a></sup> Recent AI research defines intelligence in terms of <a href="/wiki/Intelligent_agent" title="Intelligent agent">intelligent agents</a>. An "agent" is something which perceives and acts in an environment. A "performance measure" defines what counts as success for the agent.<sup id="cite_ref-10" class="reference"><a href="#cite_note-10" title=""><span>[</span>11<span>]</span></a></sup></p>
<ul>
<li><i>If an agent acts so as maximize the expected value of a performance measure based on past experience and knowledge then it is intelligent.</i><sup id="cite_ref-11" class="reference"><a href="#cite_note-11" title=""><span>[</span>12<span>]</span></a></sup></li>
</ul>
<p>Definitions like this one try to capture the essence of intelligence. They have the advantage that, unlike the <a href="/wiki/Turing_test" title="Turing test">Turing test</a>, they don't also test for human traits that we may not want to consider intelligent, like the ability to be insulted or the temptation to lie. They have the disadvantage that they fail to make the commonsense differentiation between "things that think" and "things that don't". By this definition, even a thermostat has a rudimentary intelligence.</p>
<p><a name="Arguments_that_a_machine_can_display_general_intelligence" id="Arguments_that_a_machine_can_display_general_intelligence"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=5" title="Edit section: Arguments that a machine can display general intelligence">edit</a>]</span> <span class="mw-headline">Arguments that a machine can display general intelligence</span></h3>
<p><a name="The_brain_can_be_simulated" id="The_brain_can_be_simulated"></a></p>
<h4><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=6" title="Edit section: The brain can be simulated">edit</a>]</span> <span class="mw-headline">The brain can be simulated</span></h4>
<div class="rellink noprint relarticle mainarticle">Main article: <a href="/wiki/Artificial_brain" title="Artificial brain">artificial brain</a></div>
<div class="thumb tright">
<div class="thumbinner" style="width:242px;">
<div id="ogg_player_1" style="width: 240px;">
<div><a href="/wiki/File:MRI.ogg" class="image" title="MRI.ogg"><img src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/56/MRI.ogg/seek%3D2-MRI.ogg.jpg" width="240" height="256" alt="MRI.ogg" /></a></div>
<div><button onclick="if (typeof(wgOggPlayer)&#160;!= 'undefined') wgOggPlayer.init(false, {&quot;id&quot;: &quot;ogg_player_1&quot;, &quot;videoUrl&quot;: &quot;http://upload.wikimedia.org/wikipedia/commons/5/56/MRI.ogg&quot;, &quot;width&quot;: 240, &quot;height&quot;: 256, &quot;length&quot;: 6, &quot;linkUrl&quot;: &quot;/wiki/File:MRI.ogg&quot;, &quot;isVideo&quot;: true});" style="width: 240px; text-align: center" title="Play video"><img src="/w/extensions/OggHandler/play.png" width="22" height="22" alt="Play video" /></button></div>
</div>
<div class="thumbcaption">
<div class="magnify"><a href="/wiki/File:MRI.ogg" class="internal" title="Enlarge"><img src="/skins-1.5/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
An <a href="/wiki/MRI" title="MRI" class="mw-redirect">MRI</a> scan of a normal adult human brain</div>
</div>
</div>
<p><a href="/wiki/Marvin_Minsky" title="Marvin Minsky">Marvin Minsky</a> writes that "if the nervous system obeys the laws of physics and chemistry, which we have every reason to suppose it does, then .... we ... ought to be able to reproduce the behavior of the nervous system with some physical device."<sup id="cite_ref-12" class="reference"><a href="#cite_note-12" title=""><span>[</span>13<span>]</span></a></sup> This argument, first introduced as early as 1943<sup id="cite_ref-13" class="reference"><a href="#cite_note-13" title=""><span>[</span>14<span>]</span></a></sup> and vividly described by <a href="/wiki/Hans_Moravec" title="Hans Moravec">Hans Moravec</a> in 1988,<sup id="cite_ref-14" class="reference"><a href="#cite_note-14" title=""><span>[</span>15<span>]</span></a></sup> is now associated with futurist <a href="/wiki/Ray_Kurzweil" title="Ray Kurzweil" class="mw-redirect">Ray Kurzweil</a>, who estimates that computer power will be sufficient for a complete brain simulation by the year 2029.<sup id="cite_ref-15" class="reference"><a href="#cite_note-15" title=""><span>[</span>16<span>]</span></a></sup>. A non-real-time simulation of a thalamocortical model that has the size of the human brain (10<sup>11</sup> neurons) was performed in 2005 <a href="http://vesicle.nsi.edu/users/izhikevich/human_brain_simulation/Blue_Brain.htm" class="external autonumber" title="http://vesicle.nsi.edu/users/izhikevich/human_brain_simulation/Blue_Brain.htm" rel="nofollow">[1]</a> and it took 50 days to simulate 1 second of brain dynamics on a cluster of 27 processors (see also<a href="http://vesicle.nsi.edu/users/izhikevich/publications/large-scale_model_of_human_brain.pdf" class="external autonumber" title="http://vesicle.nsi.edu/users/izhikevich/publications/large-scale_model_of_human_brain.pdf" rel="nofollow">[2]</a>).</p>
<p>Few disagree that a brain simulation is possible in theory, even critics of AI such as <a href="/wiki/Hubert_Dreyfus" title="Hubert Dreyfus">Hubert Dreyfus</a> and <a href="/wiki/John_Searle" title="John Searle">John Searle</a>.<sup id="cite_ref-16" class="reference"><a href="#cite_note-16" title=""><span>[</span>17<span>]</span></a></sup> However, Searle points out that, in principle, <i>anything</i> can be simulated by a computer, and so any process at all can be considered "computation", if you're willing to stretch the definition to the breaking point. "What we wanted to know is what distinguishes the mind from thermostats and livers," he writes.<sup id="cite_ref-17" class="reference"><a href="#cite_note-17" title=""><span>[</span>18<span>]</span></a></sup> Any argument that involves simply copying a brain is an argument that admits that we know nothing about how intelligence works. "If we had to know how the brain worked to do AI, we wouldn't bother with AI."<sup id="cite_ref-18" class="reference"><a href="#cite_note-18" title=""><span>[</span>19<span>]</span></a></sup></p>
<p><a name="Human_thinking_is_symbol_processing" id="Human_thinking_is_symbol_processing"></a></p>
<h4><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=7" title="Edit section: Human thinking is symbol processing">edit</a>]</span> <span class="mw-headline">Human thinking is symbol processing</span></h4>
<div class="rellink noprint relarticle mainarticle">Main article: <a href="/wiki/Physical_symbol_system" title="Physical symbol system">physical symbol system</a></div>
<p>In 1963, <a href="/wiki/Alan_Newell" title="Alan Newell" class="mw-redirect">Alan Newell</a> and <a href="/wiki/Herbert_Simon" title="Herbert Simon">Herbert Simon</a> proposed that "symbol manipulation" was the essence of both human and machine intelligence. They wrote:</p>
<ul>
<li><i>A <a href="/wiki/Physical_symbol_system" title="Physical symbol system">physical symbol system</a> has the necessary and sufficient means of general intelligent action.</i><sup id="cite_ref-NS_3-1" class="reference"><a href="#cite_note-NS-3" title=""><span>[</span>4<span>]</span></a></sup></li>
</ul>
<p>This claim is very strong: it implies both that human thinking is a kind of symbol manipulation (because a symbol system is <i>necessary</i> for intelligence) and that machines can be intelligent (because a symbol system is <i>sufficient</i> for intelligence).<sup id="cite_ref-19" class="reference"><a href="#cite_note-19" title=""><span>[</span>20<span>]</span></a></sup> Another version of this position was described by philosopher <a href="/wiki/Hubert_Dreyfus" title="Hubert Dreyfus">Hubert Dreyfus</a>, who called it "the psychological assumption":</p>
<ul>
<li><i>The mind can be viewed as a device operating on bits of information according to formal rules.</i><sup id="cite_ref-20" class="reference"><a href="#cite_note-20" title=""><span>[</span>21<span>]</span></a></sup></li>
</ul>
<p>A distinction is usually made between the kind of high level symbols that directly correspond with objects in the world, such as &lt;dog&gt; and &lt;tail&gt; and the more complex "symbols" that are present in a machine like a <a href="/wiki/Neural_network" title="Neural network">neural network</a>. Early research into AI, called "good old fashioned artificial intelligence" (<a href="/wiki/GOFAI" title="GOFAI">GOFAI</a>) by <a href="/wiki/John_Haugeland" title="John Haugeland">John Haugeland</a>, focused on these kind of high level symbols.<sup id="cite_ref-21" class="reference"><a href="#cite_note-21" title=""><span>[</span>22<span>]</span></a></sup></p>
<p><a name="Arguments_against_symbol_processing" id="Arguments_against_symbol_processing"></a></p>
<h4><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=8" title="Edit section: Arguments against symbol processing">edit</a>]</span> <span class="mw-headline">Arguments against symbol processing</span></h4>
<p>These arguments show that human thinking does not consist (solely) of high level symbol manipulation. They do <i>not</i> show that artificial intelligence is impossible, only that more than symbol processing is required.</p>
<p><a name="Lucas.2C_Penrose_and_G.C3.B6del" id="Lucas.2C_Penrose_and_G.C3.B6del"></a></p>
<h5><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=9" title="Edit section: Lucas, Penrose and Gödel">edit</a>]</span> <span class="mw-headline">Lucas, Penrose and Gödel</span></h5>
<p>In 1931 <a href="/wiki/Kurt_G%C3%B6del" title="Kurt Gödel">Kurt Gödel</a> proved that it is always possible to create <a href="/wiki/Proposition" title="Proposition">statements</a> that a <a href="/wiki/Formal_system" title="Formal system">formal system</a> (such as an AI program) could not prove. A human being, however, can (with some thought) see the truth of these "Gödel statements". This proved to philosopher <a href="/wiki/John_Lucas_(philosopher)" title="John Lucas (philosopher)">John Lucas</a> that human reason would always be superior to machines.<sup id="cite_ref-L_22-0" class="reference"><a href="#cite_note-L-22" title=""><span>[</span>23<span>]</span></a></sup> He wrote "<a href="/wiki/G%C3%B6del%27s_incompleteness_theorem" title="Gödel's incompleteness theorem" class="mw-redirect">Gödel's theorem</a> seems to me to prove that <a href="/wiki/Mechanism" title="Mechanism">mechanism</a> is false, that is, that minds cannot be explained as machines."<sup id="cite_ref-23" class="reference"><a href="#cite_note-23" title=""><span>[</span>24<span>]</span></a></sup> <a href="/wiki/Roger_Penrose" title="Roger Penrose">Roger Penrose</a> expanded on this argument in his 1989 book <a href="/wiki/The_Emperor%27s_New_Mind" title="The Emperor's New Mind">The Emperor's New Mind</a>, where he speculated that <a href="/wiki/Quantum_mechanical" title="Quantum mechanical" class="mw-redirect">quantum mechanical</a> processes inside individual neurons gave humans this special advantage over machines.<sup id="cite_ref-24" class="reference"><a href="#cite_note-24" title=""><span>[</span>25<span>]</span></a></sup></p>
<p><a href="/wiki/Douglas_Hofstadter" title="Douglas Hofstadter">Douglas Hofstadter</a>, in his <a href="/wiki/Pulitzer_prize" title="Pulitzer prize" class="mw-redirect">Pulitzer prize</a> winning book <i><a href="/wiki/G%C3%B6del,_Escher,_Bach:_An_Eternal_Golden_Braid" title="Gödel, Escher, Bach: An Eternal Golden Braid" class="mw-redirect">Gödel, Escher, Bach: An Eternal Golden Braid</a>,</i> explains that these "Gödel-statements" always refer to the system itself, similar to the way the <a href="/wiki/Epimenides_paradox" title="Epimenides paradox">Epimenides paradox</a> uses statements that refer to themselves, such as "this statement is false" or "I am lying".<sup id="cite_ref-25" class="reference"><a href="#cite_note-25" title=""><span>[</span>26<span>]</span></a></sup> But, of course, the <a href="/wiki/Epimenides_paradox" title="Epimenides paradox">Epimenides paradox</a> applies to anything that makes statements, whether they are machines <i>or</i> humans, even Lucas himself. Consider:</p>
<ul>
<li><i>Lucas can't assert the truth of this statement.</i><sup id="cite_ref-26" class="reference"><a href="#cite_note-26" title=""><span>[</span>27<span>]</span></a></sup></li>
</ul>
<p>This statement is true but can't be asserted by Lucas. This shows that Lucas himself is subject to the same limits that he describes for machines, as are all people, and so <a href="/wiki/John_Lucas_(philosopher)" title="John Lucas (philosopher)">Lucas</a>'s argument is pointless.<sup id="cite_ref-27" class="reference"><a href="#cite_note-27" title=""><span>[</span>28<span>]</span></a></sup></p>
<p>Further, <a href="/wiki/Stuart_Russell" title="Stuart Russell">Russell</a> and <a href="/wiki/Peter_Norvig" title="Peter Norvig">Norvig</a> note that Gödel's argument only applies to what can theoretically be proved, given an infinite amount of memory and time. In practice, real machines (including humans) have finite resources and will have difficulty proving many theorems. It is not necessary to prove everything in order to be intelligent.<sup id="cite_ref-28" class="reference"><a href="#cite_note-28" title=""><span>[</span>29<span>]</span></a></sup></p>
<p><a name="Dreyfus:_the_primacy_of_unconscious_skills" id="Dreyfus:_the_primacy_of_unconscious_skills"></a></p>
<h5><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=10" title="Edit section: Dreyfus: the primacy of unconscious skills">edit</a>]</span> <span class="mw-headline">Dreyfus: the primacy of unconscious skills</span></h5>
<div class="rellink noprint relarticle mainarticle">Main article: <a href="/wiki/Dreyfus%27_critique_of_artificial_intelligence" title="Dreyfus' critique of artificial intelligence" class="mw-redirect">Dreyfus' critique of artificial intelligence</a></div>
<p><a href="/wiki/Hubert_Dreyfus" title="Hubert Dreyfus">Hubert Dreyfus</a> argued that human intelligence and expertise depended primarily on unconscious instincts rather than conscious symbolic manipulation, and argued that these unconscious skills would never be captured in formal rules.<sup id="cite_ref-D_29-0" class="reference"><a href="#cite_note-D-29" title=""><span>[</span>30<span>]</span></a></sup></p>
<p><a href="/wiki/Hubert_Dreyfus" title="Hubert Dreyfus">Dreyfus</a>'s argument had been anticipated by <a href="/wiki/Alan_Turing" title="Alan Turing">Turing</a> in his 1950 paper <a href="/wiki/Computing_machinery_and_intelligence" title="Computing machinery and intelligence" class="mw-redirect">Computing machinery and intelligence</a>, where he had classified this as the "argument from the informality of behavior."<sup id="cite_ref-30" class="reference"><a href="#cite_note-30" title=""><span>[</span>31<span>]</span></a></sup> Turing argued in response that, just because we don't know the rules that govern a complex behavior, this does not mean that no such rules exist. He wrote: "we cannot so easily convince ourselves of the absence of complete laws of behaviour ... The only way we know of for finding such laws is scientific observation, and we certainly know of no circumstances under which we could say, 'We have searched enough. There are no such laws.'" <sup id="cite_ref-31" class="reference"><a href="#cite_note-31" title=""><span>[</span>32<span>]</span></a></sup></p>
<p><a href="/wiki/Stuart_J._Russell" title="Stuart J. Russell">Russell</a> and <a href="/wiki/Peter_Norvig" title="Peter Norvig">Norvig</a> point out that, in the years since Dreyfus published his critique, progress has been made towards discovering the "rules" that govern unconscious reasoning.<sup id="cite_ref-32" class="reference"><a href="#cite_note-32" title=""><span>[</span>33<span>]</span></a></sup> The <a href="/wiki/Situated" title="Situated">situated</a> movement in <a href="/wiki/Robotics" title="Robotics">robotics</a> research attempts to capture our unconscious skills at perception and attention.<sup id="cite_ref-33" class="reference"><a href="#cite_note-33" title=""><span>[</span>34<span>]</span></a></sup> <a href="/wiki/Computational_intelligence" title="Computational intelligence">Computational intelligence</a> paradigms, such as <a href="/wiki/Neural_net" title="Neural net" class="mw-redirect">neural nets</a>, <a href="/wiki/Evolutionary_algorithm" title="Evolutionary algorithm">evolutionary algorithms</a> and so on are mostly directed at simulated unconscious reasoning and learning. Research into <a href="/wiki/Commonsense_knowledge" title="Commonsense knowledge" class="mw-redirect">commonsense knowledge</a> has focused on reproducing the "background" or context of knowledge. In fact, AI research in general has moved away from high level symbol manipulation or "<a href="/wiki/GOFAI" title="GOFAI">GOFAI</a>", towards new models that are intended to capture more of our <i>unconscious</i> reasoning. Historian and AI researcher <a href="/wiki/Daniel_Crevier" title="Daniel Crevier">Daniel Crevier</a> wrote that "time has proven the accuracy and perceptiveness of some of Dreyfus's comments. Had he formulated them less aggressively, constructive actions they suggested might have been taken much earlier."<sup id="cite_ref-34" class="reference"><a href="#cite_note-34" title=""><span>[</span>35<span>]</span></a></sup></p>
<p><a name="Can_a_machine_have_a_mind.2C_consciousness_and_mental_states.3F" id="Can_a_machine_have_a_mind.2C_consciousness_and_mental_states.3F"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=11" title="Edit section: Can a machine have a mind, consciousness and mental states?">edit</a>]</span> <span class="mw-headline">Can a machine have a mind, consciousness and mental states?</span></h2>
<p>This is a philosophical question, related to the <a href="/wiki/Problem_of_other_minds" title="Problem of other minds">problem of other minds</a> and the <a href="/wiki/Hard_problem_of_consciousness" title="Hard problem of consciousness">hard problem of consciousness</a>. The question revolves around a position defined by <a href="/wiki/John_Searle" title="John Searle">John Searle</a> as "strong AI":</p>
<ul>
<li><i>A physical symbol system can have a mind and mental states.</i><sup id="cite_ref-SWAI_4-1" class="reference"><a href="#cite_note-SWAI-4" title=""><span>[</span>5<span>]</span></a></sup></li>
</ul>
<p>Searle distinguished this position from what he called "weak AI":</p>
<ul>
<li><i>A physical symbol system can act intelligently.</i><sup id="cite_ref-SWAI_4-2" class="reference"><a href="#cite_note-SWAI-4" title=""><span>[</span>5<span>]</span></a></sup></li>
</ul>
<p><a href="/wiki/John_Searle" title="John Searle">Searle</a> introduced the terms to isolate strong AI from weak AI so he could focus on what he thought was the more interesting and debatable issue. He argued that <i>even if we assume</i> that we had a computer program that acted exactly like a human mind, there would still be a difficult philosophical question that needed to be answered.<sup id="cite_ref-SWAI_4-3" class="reference"><a href="#cite_note-SWAI-4" title=""><span>[</span>5<span>]</span></a></sup></p>
<p>Neither of Searle's two positions are of great concern to AI research, since they do not directly answer the question "can a machine display general intelligence?" (unless it can also be shown that consciousness is <i>necessary</i> for intelligence). There are a few researchers who believe that consciousness is an essential element in intelligence, such as <a href="/wiki/Igor_Aleksander" title="Igor Aleksander">Igor Aleksander</a>, <a href="/wiki/Stan_Franklin" title="Stan Franklin">Stan Franklin</a>, <a href="/wiki/Ron_Sun" title="Ron Sun">Ron Sun</a>, and <a href="/w/index.php?title=Pentti_Haikonen&amp;action=edit&amp;redlink=1" class="new" title="Pentti Haikonen (page does not exist)">Pentti Haikonen</a>, although their definition of "consciousness" strays very close to "intelligence." See <a href="/wiki/Artificial_consciousness" title="Artificial consciousness">artificial consciousness</a>. <a href="/wiki/Alan_Turing" title="Alan Turing">Turing</a> wrote "I do not wish to give the impression that I think there is no mystery about consciousness ... [b]ut I do not think these mysteries necessarily need to be solved before we can answer the question [of whether machines can think]."<sup id="cite_ref-T4_35-0" class="reference"><a href="#cite_note-T4-35" title=""><span>[</span>36<span>]</span></a></sup> <a href="/wiki/Stuart_J._Russell" title="Stuart J. Russell">Russell</a> and <a href="/wiki/Peter_Norvig" title="Peter Norvig">Norvig</a> agree: "Most AI researchers take the weak AI hypothesis for granted, and don't care about the strong AI hypothesis."<sup id="cite_ref-36" class="reference"><a href="#cite_note-36" title=""><span>[</span>37<span>]</span></a></sup></p>
<p>Before we can answer this question, we must be clear what we mean by "minds", "mental states" and "consciousness".</p>
<p><a name="Consciousness.2C_minds.2C_mental_states.2C_meaning" id="Consciousness.2C_minds.2C_mental_states.2C_meaning"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=12" title="Edit section: Consciousness, minds, mental states, meaning">edit</a>]</span> <span class="mw-headline">Consciousness, minds, mental states, meaning</span></h3>
<div class="thumb tright">
<div class="thumbinner" style="width:182px;"><a href="/wiki/File:RobertFuddBewusstsein17Jh.png" class="image" title="Representation of consciousness from the 17th century."><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/RobertFuddBewusstsein17Jh.png/180px-RobertFuddBewusstsein17Jh.png" width="180" height="261" border="0" class="thumbimage" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="/wiki/File:RobertFuddBewusstsein17Jh.png" class="internal" title="Enlarge"><img src="/skins-1.5/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
Representation of consciousness from the 17th century.</div>
</div>
</div>
<p>The words "<a href="/wiki/Mind" title="Mind">mind</a>" and "<a href="/wiki/Consciousness" title="Consciousness">consciousness</a>" are used by different communities in different ways. Some <a href="/wiki/New_age" title="New age" class="mw-redirect">new age</a> thinkers, for example, use the word "consciousness" to describe something similar to <a href="/wiki/Bergson" title="Bergson" class="mw-redirect">Bergson</a>'s "<a href="/wiki/%C3%89lan_vital" title="Élan vital">élan vital</a>": an invisible, energetic fluid that permeates life and especially the mind. <a href="/wiki/Science_fiction" title="Science fiction">Science fiction</a> writers use the word to describe some <a href="/wiki/Essentialism" title="Essentialism">essential</a> property that makes us human: a machine or alien that is "conscious" will be presented as a fully human character, with intelligence, desires, will, insight, pride and so on. (Science fiction writers also use the words "sentience", "sapience," "self-awareness" or "ghost" (as in the <i><a href="/wiki/Ghost_in_the_Shell" title="Ghost in the Shell">Ghost in the Shell</a></i> manga and anime series) to describe this essential human property.) For others, the words "mind" or "consciousness" are used as a kind of secular synonym for the <a href="/wiki/Soul" title="Soul">soul</a>.</p>
<p>For <a href="/wiki/Philosophy" title="Philosophy">philosophers</a>, <a href="/wiki/Neuroscience" title="Neuroscience">neuroscientists</a> and <a href="/wiki/Cognitive_science" title="Cognitive science">cognitive scientists</a>, the words are used in a way that is both more precise and more mundane: they refer to the familiar, everyday experience of having a "thought in your head", like a perception, a dream, an intention or a plan, and to the way we <i>know</i> something, or <i>mean</i> something or <i>understand</i> something. "It's not hard to give a commonsense definition of consciousness" observes philosopher <a href="/wiki/John_Searle" title="John Searle">John Searle</a>.<sup id="cite_ref-37" class="reference"><a href="#cite_note-37" title=""><span>[</span>38<span>]</span></a></sup> What is mysterious and fascinating is not so much <i>what</i> it is but <i>how</i> it is: how does a lump of fatty tissue and electricity give rise to this (familiar) experience of perceiving, meaning or thinking?</p>
<p><a href="/wiki/Philosopher" title="Philosopher" class="mw-redirect">Philosophers</a> call this the <a href="/wiki/Hard_problem_of_consciousness" title="Hard problem of consciousness">hard problem of consciousness</a>. It is the latest version of a classic problem in the <a href="/wiki/Philosophy_of_mind" title="Philosophy of mind">philosophy of mind</a> called the "<a href="/wiki/Mind-body_problem" title="Mind-body problem" class="mw-redirect">mind-body problem</a>."<sup id="cite_ref-38" class="reference"><a href="#cite_note-38" title=""><span>[</span>39<span>]</span></a></sup> A related problem is the problem of <i>meaning</i> or <i>understanding</i> (which philosophers call "<a href="/wiki/Intentionality" title="Intentionality">intentionality</a>"): what is the connection between our <i>thoughts</i> (i.e. patterns of neurons) and <i>what we are thinking about</i> (i.e. objects and situations out in the world)? A third issue is the problem of <i>experience</i> (or "<a href="/wiki/Phenomenology_(philosophy)" title="Phenomenology (philosophy)">phenomenology</a>"): If two people see the same thing, do they have the same experience? Or are there things "inside their head" (called "<a href="/wiki/Qualia" title="Qualia">qualia</a>") that can be different from person to person?<sup id="cite_ref-39" class="reference"><a href="#cite_note-39" title=""><span>[</span>40<span>]</span></a></sup></p>
<p><a href="/wiki/Neurobiologist" title="Neurobiologist">Neurobiologists</a> believe all these problems will be solved as we begin to identify the <a href="/wiki/Neural_correlates_of_consciousness" title="Neural correlates of consciousness">neural correlates of consciousness</a>: the actual machinery in our heads that creates the mind, experience and understanding. Even the harshest critics of <a href="/wiki/Artificial_intelligence" title="Artificial intelligence">artificial intelligence</a> agree that the brain is just a machine, and that consciousness and intelligence are the result of physical processes in the brain.<sup id="cite_ref-40" class="reference"><a href="#cite_note-40" title=""><span>[</span>41<span>]</span></a></sup> The difficult philosophical question is this: can a computer program, running on a digital machine that shuffles the binary digits of zero and one, duplicate the ability of the <a href="/wiki/Neural_correlates_of_consciousness" title="Neural correlates of consciousness">neurons</a> to create <a href="/wiki/Mind" title="Mind">minds</a>, with <a href="/w/index.php?title=Mental_state_(philosophy)&amp;action=edit&amp;redlink=1" class="new" title="Mental state (philosophy) (page does not exist)">mental states</a> (like understanding or perceiving), and ultimately, the experience of <a href="/wiki/Consciousness" title="Consciousness">consciousness</a>?</p>
<p><a name="Arguments_that_a_computer_can.27t_have_a_mind_and_mental_states" id="Arguments_that_a_computer_can.27t_have_a_mind_and_mental_states"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=13" title="Edit section: Arguments that a computer can't have a mind and mental states">edit</a>]</span> <span class="mw-headline">Arguments that a computer can't have a mind and mental states</span></h3>
<p><a name="Searle.27s_Chinese_room" id="Searle.27s_Chinese_room"></a></p>
<h4><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=14" title="Edit section: Searle's Chinese room">edit</a>]</span> <span class="mw-headline">Searle's Chinese room</span></h4>
<div class="rellink noprint relarticle mainarticle">Main article: <a href="/wiki/Chinese_room" title="Chinese room">Chinese room</a></div>
<p><a href="/wiki/John_Searle" title="John Searle">John Searle</a> asks us to consider a thought experiment: suppose we have written a computer program that passes the Turing Test and demonstrates "general intelligent action." Suppose, specifically that the program can converse in fluent Chinese. Write the program on 3x5 cards and give them to an ordinary person. Lock the person into a room and have him follow the instructions on the cards. He will copy out Chinese characters and pass them in and out of the room through a slot. From the outside, it will appear that the Chinese room contains a fully intelligent person who speaks Chinese. The question is this: is there anyone (or anything) in the room that understands Chinese? That is, is there anything that has the <a href="/w/index.php?title=Mental_state_(philosophy)&amp;action=edit&amp;redlink=1" class="new" title="Mental state (philosophy) (page does not exist)">mental state</a> of <a href="/wiki/Understanding" title="Understanding">understanding</a>, or which has <a href="/wiki/Consciousness" title="Consciousness">conscious</a> <a href="/wiki/Awareness" title="Awareness">awareness</a> of what is being discussed in Chinese? The man is clearly not aware. The room can't be aware. The <i>cards</i> certainly aren't aware. <a href="/wiki/John_Searle" title="John Searle">Searle</a> concludes that the <a href="/wiki/Chinese_room" title="Chinese room">Chinese room</a>, or <i>any</i> other <a href="/wiki/Physical_symbol_system" title="Physical symbol system">physical symbol system</a>, cannot have a <a href="/wiki/Mind" title="Mind">mind</a>.<sup id="cite_ref-41" class="reference"><a href="#cite_note-41" title=""><span>[</span>42<span>]</span></a></sup></p>
<p><a href="/wiki/John_Searle" title="John Searle">Searle</a> goes on to argue that actual <a href="/w/index.php?title=Mental_state_(philosophy)&amp;action=edit&amp;redlink=1" class="new" title="Mental state (philosophy) (page does not exist)">mental states</a> and <a href="/wiki/Consciousness" title="Consciousness">consciousness</a> require (yet to be described) "actual physical-chemical properties of actual human brains."<sup id="cite_ref-42" class="reference"><a href="#cite_note-42" title=""><span>[</span>43<span>]</span></a></sup> He argues there are special "causal properties" of <a href="/wiki/Brain" title="Brain">brains</a> and <a href="/wiki/Neuron" title="Neuron">neurons</a> that gives rise to <a href="/wiki/Mind" title="Mind">minds</a>: in his words "brains cause minds."<sup id="cite_ref-43" class="reference"><a href="#cite_note-43" title=""><span>[</span>44<span>]</span></a></sup></p>
<p><a name="Related_arguments:_Leibniz.27_mill.2C_Block.27s_telephone_exchange_and_blockhead" id="Related_arguments:_Leibniz.27_mill.2C_Block.27s_telephone_exchange_and_blockhead"></a></p>
<h4><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=15" title="Edit section: Related arguments: Leibniz' mill, Block's telephone exchange and blockhead">edit</a>]</span> <span class="mw-headline">Related arguments: Leibniz' mill, Block's telephone exchange and blockhead</span></h4>
<p><a href="/wiki/Gottfried_Leibniz" title="Gottfried Leibniz">Gottfried Leibniz</a> made essentially the same argument as <a href="/wiki/John_Searle" title="John Searle">Searle</a> in 1714, using the thought experiment of expanding the brain until it was the size of a <a href="/wiki/Mill_(factory)" title="Mill (factory)" class="mw-redirect">mill</a>.<sup id="cite_ref-44" class="reference"><a href="#cite_note-44" title=""><span>[</span>45<span>]</span></a></sup> In 1974, <a href="/wiki/Lawrence_Davis" title="Lawrence Davis" class="mw-redirect">Lawrence Davis</a> imagined duplicating the brain using telephone lines and offices staffed by people, and in 1978 <a href="/wiki/Ned_Block" title="Ned Block">Ned Block</a> envisioned the entire population of China involved in such a brain simulation. This thought experiment is called "the Chinese Nation" or "the Chinese Gym".<sup id="cite_ref-45" class="reference"><a href="#cite_note-45" title=""><span>[</span>46<span>]</span></a></sup> <a href="/wiki/Ned_Block" title="Ned Block">Ned Block</a> also proposed his "<a href="/wiki/Blockhead" title="Blockhead">blockhead</a>" argument, which is a version of the <a href="/wiki/Chinese_room" title="Chinese room">Chinese room</a> in which the program has been <a href="/wiki/Code_refactoring" title="Code refactoring">re-factored</a> into a simple set of rules of the form "see this, do that", removing all mystery from the program.</p>
<p><a name="Responses_to_the_Chinese_Room" id="Responses_to_the_Chinese_Room"></a></p>
<h4><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=16" title="Edit section: Responses to the Chinese Room">edit</a>]</span> <span class="mw-headline">Responses to the Chinese Room</span></h4>
<p>Responses to the Chinese room emphasize several different points.</p>
<ol>
<li><b>The systems reply</b> and the <b>virtual mind reply</b>:<sup id="cite_ref-46" class="reference"><a href="#cite_note-46" title=""><span>[</span>47<span>]</span></a></sup> This reply argues that <i>the system</i>, including the man, the program, the room, and the cards, is what understands Chinese. Searle claims that the man in the room is the only thing which could possibly "have a mind" or "understand", but others disagree, arguing that it is possible for there to be <i>two</i> minds in the same physical place, similar to the way a computer can simultaneously "be" two machines at once: one physical (like a <a href="/wiki/Macintosh" title="Macintosh">Macintosh</a>) and one "<a href="/wiki/Virtual_machine" title="Virtual machine">virtual</a>" (like a <a href="/wiki/Word_processor" title="Word processor">word processor</a>).</li>
<li><b>Speed, power and complexity replies</b>:<sup id="cite_ref-47" class="reference"><a href="#cite_note-47" title=""><span>[</span>48<span>]</span></a></sup> Several critics point out that the man in the room would probably take millions of years to respond to a simple question, and would require "filing cabinets" of astronomical proportions. This brings the clarity of Searle's intuition into doubt.</li>
<li><b>Robot reply</b>:<sup id="cite_ref-48" class="reference"><a href="#cite_note-48" title=""><span>[</span>49<span>]</span></a></sup> To truly understand, some believe the Chinese Room needs eyes and hands. <a href="/wiki/Hans_Moravec" title="Hans Moravec">Hans Moravec</a> writes: 'If we could graft a robot to a reasoning program, we wouldn't need a person to provide the meaning anymore: it would come from the physical world."<sup id="cite_ref-49" class="reference"><a href="#cite_note-49" title=""><span>[</span>50<span>]</span></a></sup></li>
<li><b>Brain simulator reply</b>:<sup id="cite_ref-50" class="reference"><a href="#cite_note-50" title=""><span>[</span>51<span>]</span></a></sup> What if the program simulates the sequence of nerve firings at the synapses of an actual brain of an actual Chinese speaker? The man in the room would be simulating an actual brain. This is a variation on the "systems reply" that appears more plausible because "the system" now clearly operates like a human brain, which strengthens the intuition that there is something besides the man in the room that could understand Chinese.</li>
<li><b>Other minds reply</b> and the <b>epiphenomena reply</b>:<sup id="cite_ref-51" class="reference"><a href="#cite_note-51" title=""><span>[</span>52<span>]</span></a></sup> Several people have noted that Searle's argument is just a version of the <a href="/wiki/Problem_of_other_minds" title="Problem of other minds">problem of other minds</a>, applied to machines. Since it's difficult to decide if people are "actually" thinking, we shouldn't be surprised that it's difficult to answer the same question about machines. A related idea is that Searle's "causal properties" of neurons are <a href="/wiki/Epiphenomenal" title="Epiphenomenal" class="mw-redirect">epiphenomenal</a>: they have no effect on the real world. Why would natural selection create them in the first place, if they make no difference to behavior?</li>
</ol>
<p><a name="Is_thinking_a_kind_of_computation.3F" id="Is_thinking_a_kind_of_computation.3F"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=17" title="Edit section: Is thinking a kind of computation?">edit</a>]</span> <span class="mw-headline">Is thinking a kind of computation?</span></h2>
<div class="rellink noprint relarticle mainarticle">Main article: <a href="/wiki/Computational_theory_of_mind" title="Computational theory of mind">computational theory of mind</a></div>
<p>This issue is of primary importance to <a href="/wiki/Cognitive_science" title="Cognitive science">cognitive scientists</a>, who study the nature of human thinking and problem solving.</p>
<p>The <a href="/wiki/Computational_theory_of_mind" title="Computational theory of mind">computational theory of mind</a> or "<a href="/wiki/Computationalism" title="Computationalism" class="mw-redirect">computationalism</a>" claims that the relationship between mind and body is similar (if not identical) to the relationship between a <i>running program</i> and a computer. The idea has philosophical roots in <a href="/wiki/Hobbes" title="Hobbes" class="mw-redirect">Hobbes</a> (who claimed reasoning was "nothing more than reckoning"), <a href="/wiki/Leibniz" title="Leibniz" class="mw-redirect">Leibniz</a> (who attempted to create a logical calculus of all human ideas), <a href="/wiki/Hume" title="Hume">Hume</a> (who thought perception could be reduced to "atomic impressions") and even <a href="/wiki/Kant" title="Kant" class="mw-redirect">Kant</a> (who analyzed all experience as controlled by formal rules).<sup id="cite_ref-52" class="reference"><a href="#cite_note-52" title=""><span>[</span>53<span>]</span></a></sup> The latest version is associated with philosophers <a href="/wiki/Hilary_Putnam" title="Hilary Putnam">Hilary Putnam</a> and <a href="/wiki/Jerry_Fodor" title="Jerry Fodor">Jerry Fodor</a>.<sup id="cite_ref-53" class="reference"><a href="#cite_note-53" title=""><span>[</span>54<span>]</span></a></sup></p>
<p>This question bears on our earlier questions: if the human brain is a kind of computer then computers can be both intelligent and conscious, answering both the practical and philosophical questions of AI. In terms of the practical question of AI ("Can a machine display general intelligence?"), some versions of <a href="/wiki/Computationalism" title="Computationalism" class="mw-redirect">computationalism</a> make the claim that (as <a href="/wiki/Hobbes" title="Hobbes" class="mw-redirect">Hobbes</a> wrote):</p>
<ul>
<li><i>Reasoning is nothing but reckoning</i><sup id="cite_ref-H_5-1" class="reference"><a href="#cite_note-H-5" title=""><span>[</span>6<span>]</span></a></sup></li>
</ul>
<p>In other words, our intelligence derives from a form of <i>calculation</i>, similar to <a href="/wiki/Arithmetic" title="Arithmetic">arithmetic</a>. This is the <a href="/wiki/Physical_symbol_system" title="Physical symbol system">physical symbol system</a> hypothesis discussed above, and it implies that artificial intelligence is possible. In terms of the philosophical question of AI ("Can a machine have mind, mental states and consciousness?"), most versions of <a href="/wiki/Computationalism" title="Computationalism" class="mw-redirect">computationalism</a> claim that (as <a href="/wiki/Stevan_Harnad" title="Stevan Harnad">Stevan Harnad</a> characterizes it):</p>
<ul>
<li><i>Mental states are just implementations of (the right) computer programs</i><sup id="cite_ref-HARNAD_54-0" class="reference"><a href="#cite_note-HARNAD-54" title=""><span>[</span>55<span>]</span></a></sup></li>
</ul>
<p>This is <a href="/wiki/John_Searle" title="John Searle">John Searle</a>'s "strong AI" discussed above, and it is the real target of the <a href="/wiki/Chinese_Room" title="Chinese Room" class="mw-redirect">Chinese Room</a> argument (according to <a href="/wiki/Stevan_Harnad" title="Stevan Harnad">Harnad</a>).<sup id="cite_ref-HARNAD_54-1" class="reference"><a href="#cite_note-HARNAD-54" title=""><span>[</span>55<span>]</span></a></sup></p>
<p><a name="Other_related_questions" id="Other_related_questions"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=18" title="Edit section: Other related questions">edit</a>]</span> <span class="mw-headline">Other related questions</span></h2>
<p><a href="/wiki/Alan_Turing" title="Alan Turing">Alan Turing</a> noted that there are many arguments of the form "a machine will never do X", where X can be many things, such as:</p>
<blockquote>
<p>Be kind, resourceful, beautiful, friendly, have initiative, have a sense of humor, tell right from wrong, make mistakes, fall in love, enjoy strawberries and cream, make someone fall in love with it, learn from experience, use words properly, be the subject of its own thought, have as much diversity of behaviour as a man, do something really new.<sup id="cite_ref-T5_55-0" class="reference"><a href="#cite_note-T5-55" title=""><span>[</span>56<span>]</span></a></sup></p>
</blockquote>
<p>Turing argues that these objections are often based on naive assumptions about the versatility of machines or are "disguised forms of the argument from consciousness". Writing a program that exhibits one of these behaviors "will not make much of an impression."<sup id="cite_ref-T5_55-1" class="reference"><a href="#cite_note-T5-55" title=""><span>[</span>56<span>]</span></a></sup> All of these arguments are tangential to the basic premise of AI, unless it can be shown that one of these traits is essential for general intelligence.</p>
<p><a name="Can_a_machine_have_emotions.3F" id="Can_a_machine_have_emotions.3F"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=19" title="Edit section: Can a machine have emotions?">edit</a>]</span> <span class="mw-headline">Can a machine have emotions?</span></h3>
<p><a href="/wiki/Hans_Moravec" title="Hans Moravec">Hans Moravec</a> believes that "robots in general will be quite emotional about being nice people"<sup id="cite_ref-CQ266_56-0" class="reference"><a href="#cite_note-CQ266-56" title=""><span>[</span>57<span>]</span></a></sup> and describes emotions in terms of the behaviors they cause. Fear is a source of urgency. Empathy is a necessary component of good <a href="/wiki/Human_computer_interaction" title="Human computer interaction" class="mw-redirect">human computer interaction</a>. He says robots "will try to please you in an apparently selfless manner because it will get a thrill out of this positive reinforcement. You can interpret this as a kind of love."<sup id="cite_ref-CQ266_56-1" class="reference"><a href="#cite_note-CQ266-56" title=""><span>[</span>57<span>]</span></a></sup> <a href="/wiki/Daniel_Crevier" title="Daniel Crevier">Daniel Crevier</a> writes "Moravec's point is that emotions are just devices for channeling behavior in a direction beneficial to the survival of one's species."<sup id="cite_ref-57" class="reference"><a href="#cite_note-57" title=""><span>[</span>58<span>]</span></a></sup></p>
<p>The question of whether the machine <i>actually feels</i> an emotion, or whether it merely acts as if feeling an emotion is the philosophical question, "can a machine be conscious?" in another form.<sup id="cite_ref-T4_35-1" class="reference"><a href="#cite_note-T4-35" title=""><span>[</span>36<span>]</span></a></sup></p>
<p><a name="Can_a_machine_be_self_aware.3F" id="Can_a_machine_be_self_aware.3F"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=20" title="Edit section: Can a machine be self aware?">edit</a>]</span> <span class="mw-headline">Can a machine be self aware?</span></h3>
<p>"Self awareness", as noted above, is sometimes used by <a href="/wiki/Science_fiction" title="Science fiction">science fiction</a> writers as a name for the <a href="/wiki/Essentialism" title="Essentialism">essential</a> human property that makes a character fully human. <a href="/wiki/Alan_Turing" title="Alan Turing">Turing</a> strips away all other properties of human beings and reduces the question to "can a machine be the subject of its own thought?" Can it <i>think about itself</i>? Viewed in this way, it is obvious that a program can be written that can report on its own internal states, such as a <a href="/wiki/Debugger" title="Debugger">debugger</a>.<sup id="cite_ref-T5_55-2" class="reference"><a href="#cite_note-T5-55" title=""><span>[</span>56<span>]</span></a></sup></p>
<p><a name="Can_a_machine_be_original_or_creative.3F" id="Can_a_machine_be_original_or_creative.3F"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=21" title="Edit section: Can a machine be original or creative?">edit</a>]</span> <span class="mw-headline">Can a machine be original or creative?</span></h3>
<p>Turing reduces this to the question of whether a machine can “take us by surprise" and argues that this is obviously true, as any programmer can attest.<sup id="cite_ref-58" class="reference"><a href="#cite_note-58" title=""><span>[</span>59<span>]</span></a></sup> He notes that, with enough storage capacity, a computer can behave in an astronomical number of different ways.<sup id="cite_ref-59" class="reference"><a href="#cite_note-59" title=""><span>[</span>60<span>]</span></a></sup> It must be possible, even trivial, for a computer that can represent ideas to combine them in new ways. (<a href="/wiki/Douglas_Lenat" title="Douglas Lenat">Douglas Lenat</a>'s <a href="/wiki/Automated_Mathematician" title="Automated Mathematician">Automated Mathematician</a>, as one example, combined ideas to discover new mathematical truths.)</p>
<p>In 2009, scientists at Aberystwyth University in Wales and the U.K's University of Cambridge designed a robot called Adam that they believe to be the first machine to independently come up with new scientific findings.<sup id="cite_ref-60" class="reference"><a href="#cite_note-60" title=""><span>[</span>61<span>]</span></a></sup>. Also in 2009, researchers at <a href="/wiki/Cornell" title="Cornell" class="mw-redirect">Cornell</a> developed a computer program that extrapolated the laws of motion from a pendulum's</p>
<p><a name="Can_a_machine_have_a_soul.3F" id="Can_a_machine_have_a_soul.3F"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=22" title="Edit section: Can a machine have a soul?">edit</a>]</span> <span class="mw-headline">Can a machine have a soul?</span></h3>
<p>Finally, those who believe in the existence of a soul would argue that</p>
<ul>
<li><i>Thinking is a function of man’s immortal soul</i></li>
</ul>
<p><a href="/wiki/Alan_Turing" title="Alan Turing">Alan Turing</a> called this “the theological objection” and writes</p>
<blockquote>
<p>In attempting to construct such machines we should not be irreverently usurping His power of creating souls, any more than we are in the procreation of children: rather we are, in either case, instruments of His will providing mansions for the souls that He creates.<sup id="cite_ref-61" class="reference"><a href="#cite_note-61" title=""><span>[</span>62<span>]</span></a></sup></p>
</blockquote>
<p><a name="See_also" id="See_also"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=23" title="Edit section: See also">edit</a>]</span> <span class="mw-headline">See also</span></h2>
<div>
<table width="100%" border="0" cellspacing="0" cellpadding="0" style="background-color:transparent;table-layout:fixed;">
<tr valign="top">
<td>
<div style="margin-right:20px;">
<ul>
<li><a href="/wiki/Artificial_intelligence" title="Artificial intelligence">Artificial intelligence</a></li>
<li><a href="/wiki/Philosophy_of_information" title="Philosophy of information">Philosophy of information</a></li>
<li><a href="/wiki/Philosophy_of_mind" title="Philosophy of mind">Philosophy of mind</a></li>
<li><a href="/wiki/Brain#Other_matters" title="Brain">Brain (other matters section)</a></li>
<li><a href="/wiki/Computational_theory_of_mind" title="Computational theory of mind">Computational theory of mind</a></li>
<li><a href="/wiki/Functionalism" title="Functionalism">Functionalism</a></li>
</ul>
</div>
</td>
<td>
<div style="margin-right: 20px;">
<ul>
<li><a href="/wiki/Turing_Test" title="Turing Test" class="mw-redirect">Turing Test</a></li>
<li><a href="/wiki/Artificial_brain" title="Artificial brain">Artificial brain</a></li>
<li><a href="/wiki/Physical_symbol_system" title="Physical symbol system">Physical symbol system</a></li>
<li><a href="/wiki/Dreyfus%27_critique_of_artificial_intelligence" title="Dreyfus' critique of artificial intelligence" class="mw-redirect">Dreyfus' critique of artificial intelligence</a></li>
<li><a href="/wiki/Chinese_room" title="Chinese room">Chinese room</a></li>
<li><a href="/wiki/Computing_Machinery_and_Intelligence" title="Computing Machinery and Intelligence">Computing Machinery and Intelligence</a></li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<p><a name="Notes" id="Notes"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=24" title="Edit section: Notes">edit</a>]</span> <span class="mw-headline">Notes</span></h2>
<div class="references-small">
<ol class="references">
<li id="cite_note-0"><b><a href="#cite_ref-0" title="">^</a></b> <a href="#CITEREFRussellNorvig2003" title="">Russell &amp; Norvig 2003</a>, p.&#160;947 define the philosophy of AI as consisting of the first two questions, and the additional question of the <a href="/wiki/Ethics_of_artificial_intelligence" title="Ethics of artificial intelligence">ethics of artificial intelligence</a>. <a href="#CITEREFFearn2007" title="">Fearn 2007</a>, p.&#160;55 writes "In the current literature, philosophy has to chief roles: to determine whether or not such machines would be conscious, and, second, to predict whether or not such machines are possible." The last question bears on the first two.</li>
<li id="cite_note-T-1">^ <a href="#cite_ref-T_1-0" title=""><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-T_1-1" title=""><sup><i><b>b</b></i></sup></a> This is a paraphrase of the essential point of the <a href="/wiki/Turing_Test" title="Turing Test" class="mw-redirect">Turing Test</a>. <a href="#CITEREFTuring1950" title="">Turing 1950</a>, <a href="#CITEREFHaugeland1985" title="">Haugeland 1985</a>, pp.&#160;6-9, <a href="#CITEREFCrevier1993" title="">Crevier 1993</a>, p.&#160;24, <a href="#CITEREFRussellNorvig2003" title="">Russell &amp; Norvig 2003</a>, pp.&#160;2-3 and 948</li>
<li id="cite_note-MMRS-2">^ <a href="#cite_ref-MMRS_2-0" title=""><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-MMRS_2-1" title=""><sup><i><b>b</b></i></sup></a> <a href="#CITEREFMcCarthyMinskyRochesterShannon1955" title="">McCarthy et al. 1955</a>. This assertion was printed in the program for the <a href="/wiki/Dartmouth_Conferences" title="Dartmouth Conferences">Dartmouth Conference</a> of 1956, widely considered the "birth of AI."also <a href="#CITEREFCrevier1993" title="">Crevier 1993</a>, p.&#160;28</li>
<li id="cite_note-NS-3">^ <a href="#cite_ref-NS_3-0" title=""><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-NS_3-1" title=""><sup><i><b>b</b></i></sup></a> <a href="#CITEREFNewellSimon1976" title="">Newell &amp; Simon 1976</a> and <a href="#CITEREFRussellNorvig2003" title="">Russell &amp; Norvig 2003</a>, p.&#160;18</li>
<li id="cite_note-SWAI-4">^ <a href="#cite_ref-SWAI_4-0" title=""><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-SWAI_4-1" title=""><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-SWAI_4-2" title=""><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-SWAI_4-3" title=""><sup><i><b>d</b></i></sup></a> This version is from <a href="#CITEREFSearle1999" title="">Searle (1999)</a>, and is also quoted in <a href="#CITEREFDennett1991" title="">Dennett 1991</a>, p.&#160;435. Searle's original formulation was "The appropriately programmed computer really is a mind, in the sense that computers given the right programs can be literally said to understand and have other cognitive states." <cite class="inline">(<a href="#CITEREFSearle1980" title="">Searle 1980</a>, p.&#160;1)</cite>. Strong AI is defined similarly by <a href="#CITEREFRussellNorvig2003" title="">Russell &amp; Norvig (2003</a>, p.&#160;947): "The assertion that machines could possibly act intelligently (or, perhaps better, act as if they were intelligent) is called the 'weak AI' hypothesis by philosophers, and the assertion that machines that do so are actually thinking (as opposed to simulating thinking) is called the 'strong AI' hypothesis."</li>
<li id="cite_note-H-5">^ <a href="#cite_ref-H_5-0" title=""><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-H_5-1" title=""><sup><i><b>b</b></i></sup></a> <a href="#CITEREFHobbes1651" title="">Hobbes 1651</a>, chpt. 5</li>
<li id="cite_note-6"><b><a href="#cite_ref-6" title="">^</a></b> See <a href="#CITEREFRussellNorvig2003" title="">Russell &amp; Norvig 2003</a>, p.&#160;3, where they make the distinction between <i>acting</i> rationally and <i>being</i> rational, and define AI as the study of the former.</li>
<li id="cite_note-7"><b><a href="#cite_ref-7" title="">^</a></b> <a href="#CITEREFTuring1950" title="">Turing 1950</a> and see <a href="#CITEREFRussellNorvig2003" title="">Russell &amp; Norvig 2003</a>, p.&#160;948, where they call his paper "famous" and write "Turing examined a wide variety of possible objections to the possibility of intelligent machines, including virtually all of those that have been raised in the half century since his paper appeared."</li>
<li id="cite_note-8"><b><a href="#cite_ref-8" title="">^</a></b> <a href="#CITEREFTuring1950" title="">Turing 1950</a> under "The Argument from Consciousness"</li>
<li id="cite_note-9"><b><a href="#cite_ref-9" title="">^</a></b> <a href="#CITEREFRussellNorvig2003" title="">Russell &amp; Norvig 2003</a>, p.&#160;3</li>
<li id="cite_note-10"><b><a href="#cite_ref-10" title="">^</a></b> <a href="#CITEREFRussellNorvig2003" title="">Russell &amp; Norvig 2003</a>, p.&#160;4-5, 32, 35, 36 and 56</li>
<li id="cite_note-11"><b><a href="#cite_ref-11" title="">^</a></b> Russell and Norvig would prefer the word "rational" to "intelligent".</li>
<li id="cite_note-12"><b><a href="#cite_ref-12" title="">^</a></b> <a href="#CITEREFCrevier1993" title="">Crevier 1993</a>, p.&#160;125</li>
<li id="cite_note-13"><b><a href="#cite_ref-13" title="">^</a></b> <a href="#CITEREFPittsMcCullough1943" title="">Pitts &amp; McCullough 1943</a></li>
<li id="cite_note-14"><b><a href="#cite_ref-14" title="">^</a></b> <a href="#CITEREFMoravec1988" title="">Moravec 1988</a></li>
<li id="cite_note-15"><b><a href="#cite_ref-15" title="">^</a></b> <a href="#CITEREFKurzweil2005" title="">Kurzweil 2005</a>, p.&#160;262. Also see <a href="#CITEREFRussellNorvig" title="">Russell Norvig</a>, p.&#160;957 and <a href="#CITEREFCrevier1993" title="">Crevier 1993</a>, pp.&#160;271 and 279. The most extreme form of this argument (the brain replacement scenario) was put forward by <a href="/w/index.php?title=Clark_Glymour&amp;action=edit&amp;redlink=1" class="new" title="Clark Glymour (page does not exist)">Clark Glymour</a> in the mid-70s and was touched on by <a href="/wiki/Zenon_Pylyshyn" title="Zenon Pylyshyn">Zenon Pylyshyn</a> and <a href="/wiki/John_Searle" title="John Searle">John Searle</a> in 1980</li>
<li id="cite_note-16"><b><a href="#cite_ref-16" title="">^</a></b> <a href="/wiki/Hubert_Dreyfus" title="Hubert Dreyfus">Hubert Dreyfus</a> writes: "In general, by accepting the fundamental assumptions that the nervous system is part of the physical world and that all physical processes can described in a mathematical formalism which can in turn be manipulated by a digital computer, one can arrive at the strong claim that the behavior which results from human 'information processing,' whether directly formalizable or not, can always be indirectly reproduced on a digital machine." <cite class="inline">(<a href="#CITEREFDreyfus1972" title="">Dreyfus 1972</a>, pp.&#160;194-5)</cite>. <a href="/wiki/John_Searle" title="John Searle">John Searle</a> writes: "Could a man made machine think? Assuming it possible produce artificially a machine with a nervous system, ... the answer to the question seems to be obviously, yes ... Could a digital computer think? If by 'digital computer' you mean anything at all that has a level of description where it can be correctly described as the instantiation of a computer program, then again the answer is, of course, yes, since we are the instantiations of any number of computer programs, and we can think." <cite class="inline">(<a href="#CITEREFSearle1980" title="">Searle 1980</a>, p.&#160;11)</cite></li>
<li id="cite_note-17"><b><a href="#cite_ref-17" title="">^</a></b> <a href="#CITEREFSearle1980" title="">Searle 1980</a>, p.&#160;7</li>
<li id="cite_note-18"><b><a href="#cite_ref-18" title="">^</a></b> <a href="#CITEREFSearle1980" title="">Searle 1980</a>, p.&#160;14</li>
<li id="cite_note-19"><b><a href="#cite_ref-19" title="">^</a></b> <a href="/wiki/John_Searle" title="John Searle">Searle</a> writes "I like the straight forwardness of the claim." <a href="#CITEREFSearle1980" title="">Searle 1980</a>, p.&#160;4</li>
<li id="cite_note-20"><b><a href="#cite_ref-20" title="">^</a></b> <a href="#CITEREFDreyfus1979" title="">Dreyfus 1979</a>, p.&#160;156</li>
<li id="cite_note-21"><b><a href="#cite_ref-21" title="">^</a></b> <a href="#CITEREFHaugeland1985" title="">Haugeland 1985</a>, p.&#160;5</li>
<li id="cite_note-L-22"><b><a href="#cite_ref-L_22-0" title="">^</a></b> <a href="#CITEREFLucas1961" title="">Lucas 1961</a>, <a href="#CITEREFRussellNorvig2003" title="">Russell &amp; Norvig 2003</a>, pp.&#160;949-950, <a href="#CITEREFHofstadter1979" title="">Hofstadter 1979</a>, pp.&#160;471-473,476-477, <a href="#CITEREFTuring1950" title="">Turing 1950</a> under “The Argument from Mathematics”</li>
<li id="cite_note-23"><b><a href="#cite_ref-23" title="">^</a></b> <a href="#CITEREFLucas1961" title="">Lucas 1961</a>, p.&#160;57-9</li>
<li id="cite_note-24"><b><a href="#cite_ref-24" title="">^</a></b> <a href="#CITEREFPenrose1989" title="">Penrose 1989</a></li>
<li id="cite_note-25"><b><a href="#cite_ref-25" title="">^</a></b> <a href="#CITEREFHofstadter1979" title="">Hofstadter 1979</a></li>
<li id="cite_note-26"><b><a href="#cite_ref-26" title="">^</a></b> According to <a href="#CITEREFHofstadter1979" title="">Hofstadter 1979</a>, p.&#160;476-477, this statement was first proposed by <a href="/w/index.php?title=C._H._Whitely&amp;action=edit&amp;redlink=1" class="new" title="C. H. Whitely (page does not exist)">C. H. Whitely</a></li>
<li id="cite_note-27"><b><a href="#cite_ref-27" title="">^</a></b> <a href="#CITEREFHofstadter1979" title="">Hofstadter 1979</a>, pp.&#160;476-477, <a href="#CITEREFRussellNorvig2003" title="">Russell &amp; Norvig 2003</a>, p.&#160;950, <a href="#CITEREFTuring1950" title="">Turing 1950</a> under “The Argument from Mathematics” where he writes “although it is established that there are limitations to the powers of any particular machine, it has only been stated, without sort of proof, that no such limitations apply to the human intellect.”</li>
<li id="cite_note-28"><b><a href="#cite_ref-28" title="">^</a></b> <a href="#CITEREFRussellNorvig2003" title="">Russell &amp; Norvig 2003</a>, p.&#160;950. They point out that real machines with finite memory can be modeled using <a href="/wiki/First_order_logic" title="First order logic" class="mw-redirect">first order logic</a>, which is formally <a href="/wiki/Decidable" title="Decidable">decidable</a>, and Gödel's argument does not apply to them at all.</li>
<li id="cite_note-D-29"><b><a href="#cite_ref-D_29-0" title="">^</a></b> <a href="#CITEREFDreyfus1972" title="">Dreyfus 1972</a>, <a href="#CITEREFDreyfus1979" title="">Dreyfus 1979</a>, <a href="#CITEREFDreyfusDreyfus1986" title="">Dreyfus &amp; Dreyfus 1986</a>. See also <a href="#CITEREFRussellNorvig2003" title="">Russell &amp; Norvig 2003</a>, pp.&#160;950-952, <a href="#CITEREFCrevier1993120-132" title="">Crevier &amp; 1993 120-132</a> and <a href="#CITEREFHearn2007" title="">Hearn 2007</a>, pp.&#160;50-51</li>
<li id="cite_note-30"><b><a href="#cite_ref-30" title="">^</a></b> <a href="#CITEREFRussellNorvig2003" title="">Russell &amp; Norvig 2003</a>, p.&#160;950-51</li>
<li id="cite_note-31"><b><a href="#cite_ref-31" title="">^</a></b> <a href="#CITEREFTuring1950" title="">Turing 1950</a> under "(8) The Argument from the Informality of Behavior"</li>
<li id="cite_note-32"><b><a href="#cite_ref-32" title="">^</a></b> <a href="#CITEREFRussellNorvig2003" title="">Russell &amp; Norvig 2003</a>, p.&#160;52</li>
<li id="cite_note-33"><b><a href="#cite_ref-33" title="">^</a></b> See <a href="#CITEREFBrooks1990" title="">Brooks 1990</a> and <a href="#CITEREFMoravec1988" title="">Moravec 1988</a></li>
<li id="cite_note-34"><b><a href="#cite_ref-34" title="">^</a></b> <a href="#CITEREFCrevier1993" title="">Crevier 1993</a>, p.&#160;125</li>
<li id="cite_note-T4-35">^ <a href="#cite_ref-T4_35-0" title=""><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-T4_35-1" title=""><sup><i><b>b</b></i></sup></a> <a href="#CITEREFTuring1950" title="">Turing 1950</a> under “(4) The Argument from Consciousness”. See also <a href="#CITEREFRussellNorvig" title="">Russell Norvig</a>, p.&#160;952-3, where they identify Searle's argument with Turing's "Argument from Consciousness."</li>
<li id="cite_note-36"><b><a href="#cite_ref-36" title="">^</a></b> <a href="#CITEREFRussellNorvig2003" title="">Russell &amp; Norvig 2003</a>, p.&#160;947</li>
<li id="cite_note-37"><b><a href="#cite_ref-37" title="">^</a></b> "[P]eople always tell me it was very hard to define consciousness, but I think if you're just looking for the kind of commonsense definition that you get at the beginning of the investigation, and not at the hard nosed scientific definition that comes at the end, it's not hard to give commonsense definition of consciousness." <a href="http://www.abc.net.au/rn/philosopherszone/stories/2006/1639491.htm" class="external text" title="http://www.abc.net.au/rn/philosopherszone/stories/2006/1639491.htm" rel="nofollow">The Philosopher's Zone: The question of consciousness</a>. Also see <a href="#CITEREFDennett1991" title="">Dennett 1991</a></li>
<li id="cite_note-38"><b><a href="#cite_ref-38" title="">^</a></b> <a href="#CITEREFBlackmore2005" title="">Blackmore 2005</a>, p.&#160;2</li>
<li id="cite_note-39"><b><a href="#cite_ref-39" title="">^</a></b> <a href="#CITEREFRussellNorvig2003" title="">Russell &amp; Norvig 2003</a>, p.&#160;954-956</li>
<li id="cite_note-40"><b><a href="#cite_ref-40" title="">^</a></b> For example, <a href="/wiki/John_Searle" title="John Searle">John Searle</a> writes: "Can a machine think? The answer is, obvious, yes. We are precisely such machines." <cite class="inline">(<a href="#CITEREFSearle1980" title="">Searle 1980</a>, p.&#160;11)</cite></li>
<li id="cite_note-41"><b><a href="#cite_ref-41" title="">^</a></b> <a href="#CITEREFSearle1980" title="">Searle 1980</a>. See also <a href="#CITEREFCole2004" title="">Cole 2004</a>, <a href="#CITEREFRussellNorvig2003" title="">Russell &amp; Norvig 2003</a>, pp.&#160;958-960, <a href="#CITEREFCrevier1993" title="">Crevier 1993</a>, pp.&#160;269-272 and <a href="#CITEREFHearn2007" title="">Hearn 2007</a>, pp.&#160;43-50</li>
<li id="cite_note-42"><b><a href="#cite_ref-42" title="">^</a></b> <a href="#CITEREFSearle1980" title="">Searle 1980</a>, p.&#160;13</li>
<li id="cite_note-43"><b><a href="#cite_ref-43" title="">^</a></b> <a href="#CITEREFSearle1984" title="">Searle 1984</a></li>
<li id="cite_note-44"><b><a href="#cite_ref-44" title="">^</a></b> <a href="#CITEREFCole2004" title="">Cole 2004</a>, 2.1, <a href="#CITEREFLeibniz1714" title="">Leibniz 1714</a>, 17</li>
<li id="cite_note-45"><b><a href="#cite_ref-45" title="">^</a></b> <a href="#CITEREFCole2004" title="">Cole 2004</a>, 2.3</li>
<li id="cite_note-46"><b><a href="#cite_ref-46" title="">^</a></b> <a href="#CITEREFSearle1980" title="">Searle 1980</a> under "1. THe Systems Reply (Berkeley)", <a href="#CITEREFCrevier1993" title="">Crevier 1993</a>, p.&#160;269, <a href="#CITEREFRussellNorvig2003" title="">Russell &amp; Norvig 2003</a>, p.&#160;959, <a href="#CITEREFCole2004" title="">Cole 2004</a>, 4.1. Among those who hold to the "system" position (according to Cole) are <a href="/wiki/Ned_Block" title="Ned Block">Ned Block</a>, <a href="/wiki/Jack_Copeland" title="Jack Copeland">Jack Copeland</a>, <a href="/wiki/Daniel_Dennett" title="Daniel Dennett">Daniel Dennett</a>, <a href="/wiki/Jerry_Fodor" title="Jerry Fodor">Jerry Fodor</a>, <a href="/wiki/John_Haugeland" title="John Haugeland">John Haugeland</a>, <a href="/wiki/Ray_Kurzweil" title="Ray Kurzweil" class="mw-redirect">Ray Kurzweil</a> and <a href="/wiki/Georges_Rey" title="Georges Rey">Georges Rey</a>. Those who have defended the "virtual mind" reply include <a href="/wiki/Marvin_Minsky" title="Marvin Minsky">Marvin Minsky</a>, <a href="/wiki/Alan_Perlis" title="Alan Perlis">Alan Perlis</a>, <a href="/wiki/David_Chalmers" title="David Chalmers">David Chalmers</a>, <a href="/wiki/Ned_Block" title="Ned Block">Ned Block</a> and J. Cole (again, according to <a href="#CITEREFCole2004" title="">Cole 2004</a>)</li>
<li id="cite_note-47"><b><a href="#cite_ref-47" title="">^</a></b> <a href="#CITEREFCole2004" title="">Cole 2004</a>, 4.2 ascribes this position to <a href="/wiki/Ned_Block" title="Ned Block">Ned Block</a>, <a href="/wiki/Daniel_Dennett" title="Daniel Dennett">Daniel Dennett</a>, <a href="/w/index.php?title=Tim_Maudlin&amp;action=edit&amp;redlink=1" class="new" title="Tim Maudlin (page does not exist)">Tim Maudlin</a>, <a href="/wiki/David_Chalmers" title="David Chalmers">David Chalmers</a>, <a href="/wiki/Steven_Pinker" title="Steven Pinker">Steven Pinker</a>, <a href="/wiki/Patricia_Churchland" title="Patricia Churchland">Patricia Churchland</a> and others.</li>
<li id="cite_note-48"><b><a href="#cite_ref-48" title="">^</a></b> <a href="#CITEREFSearle1980" title="">Searle 1980</a> under "2. The Robot Reply (Yale)". <a href="#CITEREFCole2004" title="">Cole 2004</a>, 4.3 ascribes this position to <a href="/wiki/Margaret_Boden" title="Margaret Boden">Margaret Boden</a>, <a href="/wiki/Tim_Crane" title="Tim Crane">Tim Crane</a>, <a href="/wiki/Daniel_Dennett" title="Daniel Dennett">Daniel Dennett</a>, <a href="/wiki/Jerry_Fodor" title="Jerry Fodor">Jerry Fodor</a>, <a href="/wiki/Stevan_Harnad" title="Stevan Harnad">Stevan Harnad</a>, <a href="/wiki/Hans_Moravec" title="Hans Moravec">Hans Moravec</a> and <a href="/wiki/Georges_Rey" title="Georges Rey">Georges Rey</a></li>
<li id="cite_note-49"><b><a href="#cite_ref-49" title="">^</a></b> Quoted in <a href="#CITEREFCrevier1993" title="">Crevier 1993</a>, p.&#160;272</li>
<li id="cite_note-50"><b><a href="#cite_ref-50" title="">^</a></b> <a href="#CITEREFSearle1980" title="">Searle 1980</a> under "3. The Brain Simulator Reply (Berkeley and M.I.T.)" <a href="#CITEREFCole2004" title="">Cole 2004</a> ascribes this position to <a href="/wiki/Paul_Churchland" title="Paul Churchland">Paul</a> and <a href="/wiki/Patricia_Churchland" title="Patricia Churchland">Patricia Churchland</a> and <a href="/wiki/Ray_Kurzweil" title="Ray Kurzweil" class="mw-redirect">Ray Kurzweil</a></li>
<li id="cite_note-51"><b><a href="#cite_ref-51" title="">^</a></b> <a href="#CITEREFSearle1980" title="">Searle 1980</a> under "5. The Other Minds Reply", <a href="#CITEREFCole2004" title="">Cole 2004</a>, 4.4. <a href="#CITEREFTuring1950" title="">Turing 1950</a> makes this reply under "(4) The Argument from Consciousness." Cole ascribes this position to <a href="/wiki/Daniel_Dennett" title="Daniel Dennett">Daniel Dennett</a> and <a href="/wiki/Hans_Moravec" title="Hans Moravec">Hans Moravec</a>.</li>
<li id="cite_note-52"><b><a href="#cite_ref-52" title="">^</a></b> <a href="#CITEREFDreyfus1979" title="">Dreyfus 1979</a>, p.&#160;156, <a href="#CITEREFHaugeland" title="">Haugeland</a>, pp.&#160;15-44</li>
<li id="cite_note-53"><b><a href="#cite_ref-53" title="">^</a></b> <a href="#CITEREFHorst2005" title="">Horst 2005</a></li>
<li id="cite_note-HARNAD-54">^ <a href="#cite_ref-HARNAD_54-0" title=""><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-HARNAD_54-1" title=""><sup><i><b>b</b></i></sup></a> <a href="#CITEREFHarnad2001" title="">Harnad 2001</a></li>
<li id="cite_note-T5-55">^ <a href="#cite_ref-T5_55-0" title=""><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-T5_55-1" title=""><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-T5_55-2" title=""><sup><i><b>c</b></i></sup></a> <a href="#CITEREFTuring1950" title="">Turing 1950</a> under "(5) Arguments from Various Disabilities"</li>
<li id="cite_note-CQ266-56">^ <a href="#cite_ref-CQ266_56-0" title=""><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-CQ266_56-1" title=""><sup><i><b>b</b></i></sup></a> Quoted in <a href="#CITEREFCrevier1993" title="">Crevier 1993</a>, p.&#160;266</li>
<li id="cite_note-57"><b><a href="#cite_ref-57" title="">^</a></b> <a href="#CITEREFCrevier1993" title="">Crevier 1993</a>, p.&#160;266</li>
<li id="cite_note-58"><b><a href="#cite_ref-58" title="">^</a></b> <a href="#CITEREFTuring1950" title="">Turing 1950</a> under "(6) Lady Lovelace's Objection"</li>
<li id="cite_note-59"><b><a href="#cite_ref-59" title="">^</a></b> <a href="#CITEREFTuring1950" title="">Turing 1950</a> under "(5) Argument from Various Disabilities"</li>
<li id="cite_note-60"><b><a href="#cite_ref-60" title="">^</a></b> <a href="http://news.cnet.com/8301-17938_105-10211175-1.html?tag=newsLatestHeadlinesArea.0" class="external free" title="http://news.cnet.com/8301-17938_105-10211175-1.html?tag=newsLatestHeadlinesArea.0" rel="nofollow">http://news.cnet.com/8301-17938_105-10211175-1.html?tag=newsLatestHeadlinesArea.0</a></li>
<li id="cite_note-61"><b><a href="#cite_ref-61" title="">^</a></b> <a href="#CITEREFTuring1950" title="">Turing 1950</a> under "(1) The Theological Objection”, although it should be noted that he also writes “I am not very impressed with theological arguments whatever they may be used to support”</li>
</ol>
</div>
<p><a name="References" id="References"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=25" title="Edit section: References">edit</a>]</span> <span class="mw-headline">References</span></h2>
<ul>
<li><cite style="font-style:normal" class="" id="CITEREFBlackmore2005"><a href="/wiki/Susan_Blackmore" title="Susan Blackmore">Blackmore, Susan</a> (2005), <i>Consciousness: A Very Short Introduction</i>, Oxford University Press</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Consciousness%3A+A+Very+Short+Introduction&amp;rft.aulast=Blackmore&amp;rft.aufirst=Susan&amp;rft.au=Blackmore%2C+Susan&amp;rft.date=2005&amp;rft.pub=Oxford+University+Press&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal" class="" id="CITEREFBrooks1990"><a href="/wiki/Rodney_Brooks" title="Rodney Brooks">Brooks, Rodney</a> (1990), "<a href="http://people.csail.mit.edu/brooks/papers/elephants.pdf" class="external text" title="http://people.csail.mit.edu/brooks/papers/elephants.pdf" rel="nofollow">Elephants Don't Play Chess</a>" (PDF), <i>Robotics and Autonomous Systems</i> <b>6</b>: 3–15, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<span class="neverexpand"><a href="http://dx.doi.org/10.1016%2FS0921-8890%2805%2980025-9" class="external text" title="http://dx.doi.org/10.1016%2FS0921-8890%2805%2980025-9" rel="nofollow">10.1016/S0921-8890(05)80025-9</a></span><span class="printonly">, <a href="http://people.csail.mit.edu/brooks/papers/elephants.pdf" class="external free" title="http://people.csail.mit.edu/brooks/papers/elephants.pdf" rel="nofollow">http://people.csail.mit.edu/brooks/papers/elephants.pdf</a></span><span class="reference-accessdate">, retrieved on 2007-08-30</span></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Elephants+Don%27t+Play+Chess&amp;rft.jtitle=Robotics+and+Autonomous+Systems&amp;rft.aulast=Brooks&amp;rft.aufirst=Rodney&amp;rft.au=Brooks%2C+Rodney&amp;rft.date=1990&amp;rft.volume=6&amp;rft.pages=3%E2%80%9315&amp;rft_id=info:doi/10.1016%2FS0921-8890%2805%2980025-9&amp;rft_id=http%3A%2F%2Fpeople.csail.mit.edu%2Fbrooks%2Fpapers%2Felephants.pdf&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal" class="" id="CITEREFCole2004">Cole, David (Fall 2004), <a href="http://plato.stanford.edu/archives/fall2004/entries/chinese-room/" class="external text" title="http://plato.stanford.edu/archives/fall2004/entries/chinese-room/" rel="nofollow">"The Chinese Room Argument"</a>, in Zalta, Edward N., <i>The Stanford Encyclopedia of Philosophy</i><span class="printonly">, <a href="http://plato.stanford.edu/archives/fall2004/entries/chinese-room/" class="external free" title="http://plato.stanford.edu/archives/fall2004/entries/chinese-room/" rel="nofollow">http://plato.stanford.edu/archives/fall2004/entries/chinese-room/</a></span></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=The+Chinese+Room+Argument&amp;rft.atitle=The+Stanford+Encyclopedia+of+Philosophy&amp;rft.aulast=Cole&amp;rft.aufirst=David&amp;rft.au=Cole%2C+David&amp;rft.date=Fall+2004&amp;rft_id=http%3A%2F%2Fplato.stanford.edu%2Farchives%2Ffall2004%2Fentries%2Fchinese-room%2F&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span>.</li>
<li><cite style="font-style:normal" class="" id="CITEREFCrevier1993"><a href="/wiki/Daniel_Crevier" title="Daniel Crevier">Crevier, Daniel</a> (1993), <i>AI: The Tumultuous Search for Artificial Intelligence</i>, New York, NY: BasicBooks, <a href="/wiki/Special:BookSources/0465029973" class="internal">ISBN 0-465-02997-3</a></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=AI%3A+The+Tumultuous+Search+for+Artificial+Intelligence&amp;rft.aulast=Crevier&amp;rft.aufirst=Daniel&amp;rft.au=Crevier%2C+Daniel&amp;rft.date=1993&amp;rft.place=New+York%2C+NY&amp;rft.pub=BasicBooks&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal" class="" id="CITEREFDennett1991"><a href="/wiki/Daniel_Dennett" title="Daniel Dennett">Dennett, Daniel</a> (1991), <i><a href="/wiki/Consciousness_Explained" title="Consciousness Explained">Consciousness Explained</a></i>, The Penguin Press, <a href="/wiki/Special:BookSources/0713990376" class="internal">ISBN 0-7139-9037-6</a></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=%5B%5BConsciousness+Explained%5D%5D&amp;rft.aulast=Dennett&amp;rft.aufirst=Daniel&amp;rft.au=Dennett%2C+Daniel&amp;rft.date=1991&amp;rft.pub=The+Penguin+Press&amp;rft.isbn=0-7139-9037-6&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal" class="" id="CITEREFDreyfus1972"><a href="/wiki/Hubert_Dreyfus" title="Hubert Dreyfus">Dreyfus, Hubert</a> (1972), <i><a href="/wiki/What_Computers_Can%27t_Do" title="What Computers Can't Do">What Computers Can't Do</a></i>, New York: MIT Press, <a href="/wiki/Special:BookSources/0060110821" class="internal">ISBN 0060110821</a></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=%5B%5BWhat+Computers+Can%27t+Do%5D%5D&amp;rft.aulast=Dreyfus&amp;rft.aufirst=Hubert&amp;rft.au=Dreyfus%2C+Hubert&amp;rft.date=1972&amp;rft.place=New+York&amp;rft.pub=MIT+Press&amp;rft.isbn=0060110821&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal" class="" id="CITEREFDreyfus1979"><a href="/wiki/Hubert_Dreyfus" title="Hubert Dreyfus">Dreyfus, Hubert</a> (1979), <i>What Computers</i> Still <i>Can't Do</i>, New York: MIT Press</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=What+Computers+%27%27Still%27%27+Can%27t+Do&amp;rft.aulast=Dreyfus&amp;rft.aufirst=Hubert&amp;rft.au=Dreyfus%2C+Hubert&amp;rft.date=1979&amp;rft.place=New+York&amp;rft.pub=MIT+Press&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span>.</li>
<li><cite style="font-style:normal" class="" id="CITEREFDreyfusDreyfus1986"><a href="/wiki/Hubert_Dreyfus" title="Hubert Dreyfus">Dreyfus, Hubert</a>; Dreyfus, Stuart (1986), <i>Mind over Machine: The Power of Human Intuition and Expertise in the Era of the Computer</i>, Oxford, UK: Blackwell</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Mind+over+Machine%3A+The+Power+of+Human+Intuition+and+Expertise+in+the+Era+of+the+Computer&amp;rft.aulast=Dreyfus&amp;rft.aufirst=Hubert&amp;rft.au=Dreyfus%2C+Hubert&amp;rft.au=Dreyfus%2C+Stuart&amp;rft.date=1986&amp;rft.place=Oxford%2C+UK&amp;rft.pub=Blackwell&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal" class="" id="CITEREFFearn2007">Fearn, Nicholas (2007), <i>The Latest Answers to the Oldest Questions: A Philosophical Adventure with the World's Greatest Thinkers</i>, New York: Grove Press</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Latest+Answers+to+the+Oldest+Questions%3A+A+Philosophical+Adventure+with+the+World%27s+Greatest+Thinkers&amp;rft.aulast=Fearn&amp;rft.aufirst=Nicholas&amp;rft.au=Fearn%2C+Nicholas&amp;rft.date=2007&amp;rft.place=New+York&amp;rft.pub=Grove+Press&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal" class="" id="CITEREFGladwell2005"><a href="/wiki/Malcolm_Gladwell" title="Malcolm Gladwell">Gladwell, Malcolm</a> (2005), <i><a href="/wiki/Blink_(book)" title="Blink (book)">Blink: The Power of Thinking Without Thinking</a></i>, Boston: Little, Brown, <a href="/wiki/Special:BookSources/0316172324" class="internal">ISBN 0-316-17232-4</a></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=%5B%5BBlink+%28book%29%7CBlink%3A+The+Power+of+Thinking+Without+Thinking%5D%5D&amp;rft.aulast=Gladwell&amp;rft.aufirst=Malcolm&amp;rft.au=Gladwell%2C+Malcolm&amp;rft.date=2005&amp;rft.place=Boston&amp;rft.pub=Little%2C+Brown&amp;rft.isbn=0-316-17232-4&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span>.</li>
<li><cite style="font-style:normal" class="" id="CITEREFHarnad2001"><a href="/wiki/Stevan_Harnad" title="Stevan Harnad">Harnad, Stevan</a> (2001), <a href="http://cogprints.org/4023/1/searlbook.htm" class="external text" title="http://cogprints.org/4023/1/searlbook.htm" rel="nofollow">"What's Wrong and Right About Searle's Chinese Room Argument?"</a>, in Bishop, M.; Preston, J., <i>Essays on Searle's Chinese Room Argument</i>, Oxford University Press<span class="printonly">, <a href="http://cogprints.org/4023/1/searlbook.htm" class="external free" title="http://cogprints.org/4023/1/searlbook.htm" rel="nofollow">http://cogprints.org/4023/1/searlbook.htm</a></span></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=What%27s+Wrong+and+Right+About+Searle%27s+Chinese+Room+Argument%3F&amp;rft.atitle=Essays+on+Searle%27s+Chinese+Room+Argument&amp;rft.aulast=Harnad&amp;rft.aufirst=Stevan&amp;rft.au=Harnad%2C+Stevan&amp;rft.date=2001&amp;rft.pub=Oxford+University+Press&amp;rft_id=http%3A%2F%2Fcogprints.org%2F4023%2F1%2Fsearlbook.htm&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal" class="" id="CITEREFHobbes1651"><a href="/wiki/Hobbes" title="Hobbes" class="mw-redirect">Hobbes</a> (1651), <i><a href="/wiki/Leviathan" title="Leviathan">Leviathan</a></i></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=%5B%5BLeviathan%5D%5D&amp;rft.aulast=Hobbes&amp;rft.au=Hobbes&amp;rft.date=1651&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span>.</li>
<li><cite style="font-style:normal" class="" id="CITEREFHofstadter1979"><a href="/wiki/Douglas_Hofstadter" title="Douglas Hofstadter">Hofstadter, Douglas</a> (1979), <i><a href="/wiki/G%C3%B6del,_Escher,_Bach" title="Gödel, Escher, Bach">Gödel, Escher, Bach: an Eternal Golden Braid</a></i></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=%5B%5BG%C3%B6del%2C+Escher%2C+Bach%7CG%C3%B6del%2C+Escher%2C+Bach%3A+an+Eternal+Golden+Braid%5D%5D&amp;rft.aulast=Hofstadter&amp;rft.aufirst=Douglas&amp;rft.au=Hofstadter%2C+Douglas&amp;rft.date=1979&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span>.</li>
<li><cite style="font-style:normal" class="" id="CITEREFHorst2005">Horst, Steven (Fall 2005), <a href="http://plato.stanford.edu/archives/fall2005/entries/computational-mind/" class="external text" title="http://plato.stanford.edu/archives/fall2005/entries/computational-mind/" rel="nofollow">"The Computational Theory of Mind"</a>, in Zalta, Edward N., <i>The Stanford Encyclopedia of Philosophy</i><span class="printonly">, <a href="http://plato.stanford.edu/archives/fall2005/entries/computational-mind/" class="external free" title="http://plato.stanford.edu/archives/fall2005/entries/computational-mind/" rel="nofollow">http://plato.stanford.edu/archives/fall2005/entries/computational-mind/</a></span></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=The+Computational+Theory+of+Mind&amp;rft.atitle=The+Stanford+Encyclopedia+of+Philosophy&amp;rft.aulast=Horst&amp;rft.aufirst=Steven&amp;rft.au=Horst%2C+Steven&amp;rft.date=Fall+2005&amp;rft_id=http%3A%2F%2Fplato.stanford.edu%2Farchives%2Ffall2005%2Fentries%2Fcomputational-mind%2F&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span>.</li>
<li><cite style="font-style:normal" class="" id="CITEREFKurzweil2005"><a href="/wiki/Ray_Kurzweil" title="Ray Kurzweil" class="mw-redirect">Kurzweil, Ray</a> (2005), <i><a href="/wiki/The_Singularity_is_Near" title="The Singularity is Near" class="mw-redirect">The Singularity is Near</a></i>, New York: Viking Press, <a href="/wiki/Special:BookSources/0670033847" class="internal">ISBN 0-670-03384-7</a></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=%5B%5BThe+Singularity+is+Near%5D%5D&amp;rft.aulast=Kurzweil&amp;rft.aufirst=Ray&amp;rft.au=Kurzweil%2C+Ray&amp;rft.date=2005&amp;rft.place=New+York&amp;rft.pub=Viking+Press&amp;rft.isbn=0-670-03384-7&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span>.</li>
<li><cite style="font-style:normal" class="" id="CITEREFLucas1961"><a href="/wiki/John_Lucas_(philosopher)" title="John Lucas (philosopher)">Lucas, John</a> (1961), <a href="http://users.ox.ac.uk/~jrlucas/Godel/mmg.html" class="external text" title="http://users.ox.ac.uk/~jrlucas/Godel/mmg.html" rel="nofollow">"Minds, Machines and Gödel"</a>, in Anderson, A.R., <i>Minds and Machines</i><span class="printonly">, <a href="http://users.ox.ac.uk/~jrlucas/Godel/mmg.html" class="external free" title="http://users.ox.ac.uk/~jrlucas/Godel/mmg.html" rel="nofollow">http://users.ox.ac.uk/~jrlucas/Godel/mmg.html</a></span></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=Minds%2C+Machines+and+G%C3%B6del&amp;rft.atitle=Minds+and+Machines&amp;rft.aulast=Lucas&amp;rft.aufirst=John&amp;rft.au=Lucas%2C+John&amp;rft.date=1961&amp;rft_id=http%3A%2F%2Fusers.ox.ac.uk%2F%7Ejrlucas%2FGodel%2Fmmg.html&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span>.</li>
<li><cite style="font-style:normal" class="" id="CITEREFMcCarthyMinskyRochesterShannon1955"><a href="/wiki/John_McCarthy_(computer_scientist)" title="John McCarthy (computer scientist)">McCarthy, John</a>; <a href="/wiki/Marvin_Minsky" title="Marvin Minsky">Minsky, Marvin</a>; <a href="/wiki/Nathan_Rochester" title="Nathan Rochester" class="mw-redirect">Rochester, Nathan</a>; <a href="/wiki/Claude_Shannon" title="Claude Shannon">Shannon, Claude</a> (1955), <i><a href="http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html" class="external text" title="http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html" rel="nofollow">A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence</a></i><span class="printonly">, <a href="http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html" class="external free" title="http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html" rel="nofollow">http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html</a></span></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=A+Proposal+for+the+Dartmouth+Summer+Research+Project+on+Artificial+Intelligence&amp;rft.aulast=McCarthy&amp;rft.aufirst=John&amp;rft.au=McCarthy%2C+John&amp;rft.au=Minsky%2C+Marvin&amp;rft.au=Rochester%2C+Nathan&amp;rft.au=Shannon%2C+Claude&amp;rft.date=1955&amp;rft_id=http%3A%2F%2Fwww-formal.stanford.edu%2Fjmc%2Fhistory%2Fdartmouth%2Fdartmouth.html&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span>.</li>
<li><cite style="font-style:normal" class="" id="CITEREFMcDermott1997">McDermott, Drew (May 14, 1997), "<a href="http://www.psych.utoronto.ca/~reingold/courses/ai/cache/mcdermott.html" class="external text" title="http://www.psych.utoronto.ca/~reingold/courses/ai/cache/mcdermott.html" rel="nofollow">How Intelligent is Deep Blue</a>", <i>New York Times</i><span class="printonly">, <a href="http://www.psych.utoronto.ca/~reingold/courses/ai/cache/mcdermott.html" class="external free" title="http://www.psych.utoronto.ca/~reingold/courses/ai/cache/mcdermott.html" rel="nofollow">http://www.psych.utoronto.ca/~reingold/courses/ai/cache/mcdermott.html</a></span></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=How+Intelligent+is+Deep+Blue&amp;rft.jtitle=New+York+Times&amp;rft.aulast=McDermott&amp;rft.aufirst=Drew&amp;rft.au=McDermott%2C+Drew&amp;rft.date=May+14%2C+1997&amp;rft_id=http%3A%2F%2Fwww.psych.utoronto.ca%2F%7Ereingold%2Fcourses%2Fai%2Fcache%2Fmcdermott.html&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal" class="" id="CITEREFMoravec1988"><a href="/wiki/Hans_Moravec" title="Hans Moravec">Moravec, Hans</a> (1988), <i>Mind Children</i>, Harvard University Press</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Mind+Children&amp;rft.aulast=Moravec&amp;rft.aufirst=Hans&amp;rft.au=Moravec%2C+Hans&amp;rft.date=1988&amp;rft.pub=Harvard+University+Press&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal" class="" id="CITEREFNewellSimon1963"><a href="/wiki/Allen_Newell" title="Allen Newell">Newell, Allen</a>; Simon, H. A. (1963), "GPS: A Program that Simulates Human Thought", in Feigenbaum, E.A.; Feldman, J., <i>Computers and Thought</i>, McGraw-Hill</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=GPS%3A+A+Program+that+Simulates+Human+Thought&amp;rft.atitle=Computers+and+Thought&amp;rft.aulast=Newell&amp;rft.aufirst=Allen&amp;rft.au=Newell%2C+Allen&amp;rft.au=Simon%2C+H.+A.&amp;rft.date=1963&amp;rft.pub=McGraw-Hill&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal" class="" id="CITEREFNewellSimon1976"><a href="/wiki/Allen_Newell" title="Allen Newell">Newell, Allen</a>; Simon, H. A. (1976), <a href="http://www.rci.rutgers.edu/~cfs/472_html/AI_SEARCH/PSS/PSSH4.html" class="external text" title="http://www.rci.rutgers.edu/~cfs/472_html/AI_SEARCH/PSS/PSSH4.html" rel="nofollow">"Computer Science as Empirical Inquiry: Symbols and Search"</a>, <i>Communications of the ACM</i>, <b>19</b><span class="printonly">, <a href="http://www.rci.rutgers.edu/~cfs/472_html/AI_SEARCH/PSS/PSSH4.html" class="external free" title="http://www.rci.rutgers.edu/~cfs/472_html/AI_SEARCH/PSS/PSSH4.html" rel="nofollow">http://www.rci.rutgers.edu/~cfs/472_html/AI_SEARCH/PSS/PSSH4.html</a></span></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=Computer+Science+as+Empirical+Inquiry%3A+Symbols+and+Search&amp;rft.atitle=Communications+of+the+ACM&amp;rft.aulast=Newell&amp;rft.aufirst=Allen&amp;rft.au=Newell%2C+Allen&amp;rft.au=Simon%2C+H.+A.&amp;rft.date=1976&amp;rft.volume=19&amp;rft.issue=3&amp;rft_id=http%3A%2F%2Fwww.rci.rutgers.edu%2F%7Ecfs%2F472_html%2FAI_SEARCH%2FPSS%2FPSSH4.html&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal" class="" id="CITEREFRussellNorvig2003"><a href="/wiki/Stuart_J._Russell" title="Stuart J. Russell">Russell, Stuart J.</a>; <a href="/wiki/Peter_Norvig" title="Peter Norvig">Norvig, Peter</a> (2003), <i><a href="http://aima.cs.berkeley.edu/" class="external text" title="http://aima.cs.berkeley.edu/" rel="nofollow">Artificial Intelligence: A Modern Approach</a></i> (2nd ed.), Upper Saddle River, NJ: Prentice Hall, <a href="/wiki/Special:BookSources/0137903952" class="internal">ISBN 0-13-790395-2</a><span class="printonly">, <a href="http://aima.cs.berkeley.edu/" class="external free" title="http://aima.cs.berkeley.edu/" rel="nofollow">http://aima.cs.berkeley.edu/</a></span></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+Intelligence%3A+A+Modern+Approach&amp;rft.aulast=Russell&amp;rft.aufirst=Stuart+J.&amp;rft.au=Russell%2C+Stuart+J.&amp;rft.au=Norvig%2C+Peter&amp;rft.date=2003&amp;rft.edition=2nd&amp;rft.place=Upper+Saddle+River%2C+NJ&amp;rft.pub=Prentice+Hall&amp;rft_id=http%3A%2F%2Faima.cs.berkeley.edu%2F&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal" class="" id="CITEREFPenrose1989"><a href="/wiki/Roger_Penrose" title="Roger Penrose">Penrose, Roger</a> (1989), <i><a href="/wiki/The_Emperor%27s_New_Mind" title="The Emperor's New Mind">The Emperor's New Mind: Concerning Computers, Minds, and The Laws of Physics</a></i>, Oxford University Press, <a href="/wiki/Special:BookSources/0140145346" class="internal">ISBN 0-14-014534-6</a></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=%5B%5BThe+Emperor%27s+New+Mind%7CThe+Emperor%27s+New+Mind%3A+Concerning+Computers%2C+Minds%2C+and+The+Laws+of+Physics%5D%5D&amp;rft.aulast=Penrose&amp;rft.aufirst=Roger&amp;rft.au=Penrose%2C+Roger&amp;rft.date=1989&amp;rft.pub=Oxford+University+Press&amp;rft.isbn=0-14-014534-6&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal" class="" id="CITEREFSearle1980"><a href="/wiki/John_Searle" title="John Searle">Searle, John</a> (1980), "<a href="http://members.aol.com/NeoNoetics/MindsBrainsPrograms.html" class="external text" title="http://members.aol.com/NeoNoetics/MindsBrainsPrograms.html" rel="nofollow">Minds, Brains and Programs</a>", <i>Behavioral and Brain Sciences</i> <b>3</b> (3): 417–457<span class="printonly">, <a href="http://members.aol.com/NeoNoetics/MindsBrainsPrograms.html" class="external free" title="http://members.aol.com/NeoNoetics/MindsBrainsPrograms.html" rel="nofollow">http://members.aol.com/NeoNoetics/MindsBrainsPrograms.html</a></span></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Minds%2C+Brains+and+Programs&amp;rft.jtitle=Behavioral+and+Brain+Sciences&amp;rft.aulast=Searle&amp;rft.aufirst=John&amp;rft.au=Searle%2C+John&amp;rft.date=1980&amp;rft.volume=3&amp;rft.issue=3&amp;rft.pages=417%E2%80%93457&amp;rft_id=http%3A%2F%2Fmembers.aol.com%2FNeoNoetics%2FMindsBrainsPrograms.html&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal" class="" id="CITEREFSearle1992">Searle, John (1992), <i>The Rediscovery of the the Mind</i>, Cambridge, Massachusetts: M.I.T. Press</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Rediscovery+of+the+the+Mind&amp;rft.aulast=Searle&amp;rft.aufirst=John&amp;rft.au=Searle%2C+John&amp;rft.date=1992&amp;rft.place=Cambridge%2C+Massachusetts&amp;rft.pub=M.I.T.+Press&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal" class="" id="CITEREFSearle1999"><a href="/wiki/John_Searle" title="John Searle">Searle, John</a> (1999), <i>Mind, language and society</i>, New York, NY: Basic Books, <a href="/wiki/Special:BookSources/0465045219" class="internal">ISBN 0465045219</a>, <a href="/wiki/Online_Computer_Library_Center" title="Online Computer Library Center">OCLC</a> <a href="http://worldcat.org/oclc/231867665+43689264" class="external text" title="http://worldcat.org/oclc/231867665+43689264" rel="nofollow">231867665 43689264</a></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Mind%2C+language+and+society&amp;rft.aulast=Searle&amp;rft.aufirst=John&amp;rft.au=Searle%2C+John&amp;rft.date=1999&amp;rft.place=New+York%2C+NY&amp;rft.pub=Basic+Books&amp;rft_id=info:oclcnum/231867665+43689264&amp;rft.isbn=0465045219&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal" class="" id="CITEREFTuring1950"><a href="/wiki/Alan_Turing" title="Alan Turing">Turing, Alan</a> (October 1950), "<a href="http://loebner.net/Prizef/TuringArticle.html" class="external text" title="http://loebner.net/Prizef/TuringArticle.html" rel="nofollow">Computing Machinery and Intelligence</a>", <i><a href="/wiki/Mind_(journal)" title="Mind (journal)">Mind</a></i> <b>LIX</b> (236): 433–460, <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<span class="neverexpand"><a href="http://dx.doi.org/10.1093%2Fmind%2FLIX.236.433" class="external text" title="http://dx.doi.org/10.1093%2Fmind%2FLIX.236.433" rel="nofollow">10.1093/mind/LIX.236.433</a></span>, <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a> <a href="http://worldcat.org/issn/0026-4423" class="external text" title="http://worldcat.org/issn/0026-4423" rel="nofollow">0026-4423</a><span class="printonly">, <a href="http://loebner.net/Prizef/TuringArticle.html" class="external free" title="http://loebner.net/Prizef/TuringArticle.html" rel="nofollow">http://loebner.net/Prizef/TuringArticle.html</a></span><span class="reference-accessdate">, retrieved on 2008-08-18</span></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Computing+Machinery+and+Intelligence&amp;rft.jtitle=%5B%5BMind+%28journal%29%7CMind%5D%5D&amp;rft.aulast=Turing&amp;rft.aufirst=Alan&amp;rft.au=Turing%2C+Alan&amp;rft.date=October+1950&amp;rft.volume=LIX&amp;rft.issue=236&amp;rft.pages=433%E2%80%93460&amp;rft_id=info:doi/10.1093%2Fmind%2FLIX.236.433&amp;rft.issn=0026-4423&amp;rft_id=http%3A%2F%2Floebner.net%2FPrizef%2FTuringArticle.html&amp;rfr_id=info:sid/en.wikipedia.org:Philosophy_of_artificial_intelligence"><span style="display: none;">&#160;</span></span></li>
</ul>
<p><a name="External_links" id="External_links"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit&amp;section=26" title="Edit section: External links">edit</a>]</span> <span class="mw-headline">External links</span></h2>
<ul>
<li><a href="http://www.shawnkilmer.com/?p=92" class="external text" title="http://www.shawnkilmer.com/?p=92" rel="nofollow">Research Paper: Philosophy of Consciousness and Ethics In Artificial Intelligence</a></li>
</ul>


<!-- 
NewPP limit report
Preprocessor node count: 19183/1000000
Post-expand include size: 129091/2048000 bytes
Template argument size: 28901/2048000 bytes
Expensive parser function count: 0/500
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:2958015-0!1!0!default!!en!2 and timestamp 20090422224101 -->
<div class="printfooter">
Retrieved from "<a href="http://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence">http://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence</a>"</div>
			<div id='catlinks' class='catlinks'><div id="mw-normal-catlinks"><a href="/wiki/Special:Categories" title="Special:Categories">Categories</a>:&#32;<span dir='ltr'><a href="/wiki/Category:Philosophy_of_artificial_intelligence" title="Category:Philosophy of artificial intelligence">Philosophy of artificial intelligence</a></span> | <span dir='ltr'><a href="/wiki/Category:Philosophy_by_field" title="Category:Philosophy by field">Philosophy by field</a></span></div></div>			<!-- end content -->
						<div class="visualClear"></div>
		</div>
	</div>
		</div>
		<div id="column-one">
	<div id="p-cactions" class="portlet">
		<h5>Views</h5>
		<div class="pBody">
			<ul>
	
				 <li id="ca-nstab-main" class="selected"><a href="/wiki/Philosophy_of_artificial_intelligence" title="View the content page [c]" accesskey="c">Article</a></li>
				 <li id="ca-talk"><a href="/wiki/Talk:Philosophy_of_artificial_intelligence" title="Discussion about the content page [t]" accesskey="t">Discussion</a></li>
				 <li id="ca-edit"><a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=edit" title="You can edit this page. &#10;Please use the preview button before saving. [e]" accesskey="e">Edit this page</a></li>
				 <li id="ca-history"><a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;action=history" title="Past versions of this page [h]" accesskey="h">History</a></li>			</ul>
		</div>
	</div>
	<div class="portlet" id="p-personal">
		<h5>Personal tools</h5>
		<div class="pBody">
			<ul>
				<li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Philosophy_of_artificial_intelligence" title="You are encouraged to log in; however, it is not mandatory. [o]" accesskey="o">Log in / create account</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-logo">
		<a style="background-image: url(http://upload.wikimedia.org/wikipedia/en/b/bc/Wiki.png);" href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
	<div class='generated-sidebar portlet' id='p-navigation'>
		<h5>Navigation</h5>
		<div class='pBody'>
			<ul>
				<li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li>
				<li id="n-contents"><a href="/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li>
				<li id="n-featuredcontent"><a href="/wiki/Portal:Featured_content" title="Featured content — the best of Wikipedia">Featured content</a></li>
				<li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li>
				<li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li>
			</ul>
		</div>
	</div>
	<div id="p-search" class="portlet">
		<h5><label for="searchInput">Search</label></h5>
		<div id="searchBody" class="pBody">
			<form action="/w/index.php" id="searchform"><div>
				<input type='hidden' name="title" value="Special:Search"/>
				<input id="searchInput" name="search" type="text" title="Search Wikipedia [f]" accesskey="f" value="" />
				<input type='submit' name="go" class="searchButton" id="searchGoButton"	value="Go" title="Go to a page with this exact name if one exists" />&nbsp;
				<input type='submit' name="fulltext" class="searchButton" id="mw-searchButton" value="Search" title="Search Wikipedia for this text" />
			</div></form>
		</div>
	</div>
	<div class='generated-sidebar portlet' id='p-interaction'>
		<h5>Interaction</h5>
		<div class='pBody'>
			<ul>
				<li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li>
				<li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li>
				<li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="The list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li>
				<li id="n-contact"><a href="/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact Wikipedia</a></li>
				<li id="n-sitesupport"><a href="http://wikimediafoundation.org/wiki/Donate" title="Support us">Donate to Wikipedia</a></li>
				<li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-tb">
		<h5>Toolbox</h5>
		<div class="pBody">
			<ul>
				<li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Philosophy_of_artificial_intelligence" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li>
				<li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Philosophy_of_artificial_intelligence" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li>
<li id="t-upload"><a href="/wiki/Wikipedia:Upload" title="Upload files [u]" accesskey="u">Upload file</a></li>
<li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="List of all special pages [q]" accesskey="q">Special pages</a></li>
				<li id="t-print"><a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;printable=yes" rel="alternate" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>				<li id="t-permalink"><a href="/w/index.php?title=Philosophy_of_artificial_intelligence&amp;oldid=285538245" title="Permanent link to this version of the page">Permanent link</a></li><li id="t-cite"><a href="/w/index.php?title=Special:Cite&amp;page=Philosophy_of_artificial_intelligence&amp;id=285538245">Cite this page</a></li>			</ul>
		</div>
	</div>
	<div id="p-lang" class="portlet">
		<h5>Languages</h5>
		<div class="pBody">
			<ul>
				<li class="interwiki-fa"><a href="http://fa.wikipedia.org/wiki/%D9%81%D9%84%D8%B3%D9%81%D9%87_%D9%87%D9%88%D8%B4_%D9%85%D8%B5%D9%86%D9%88%D8%B9%DB%8C">فارسی</a></li>
				<li class="interwiki-ru"><a href="http://ru.wikipedia.org/wiki/%D0%A4%D0%B8%D0%BB%D0%BE%D1%81%D0%BE%D1%84%D0%B8%D1%8F_%D0%B8%D1%81%D0%BA%D1%83%D1%81%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D0%BE%D0%B3%D0%BE_%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D0%B0">Русский</a></li>
			</ul>
		</div>
	</div>
		</div><!-- end of the left (by default at least) column -->
			<div class="visualClear"></div>
			<div id="footer">
				<div id="f-poweredbyico"><a href="http://www.mediawiki.org/"><img src="/skins-1.5/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" /></a></div>
				<div id="f-copyrightico"><a href="http://wikimediafoundation.org/"><img src="/images/wikimedia-button.png" border="0" alt="Wikimedia Foundation"/></a></div>
			<ul id="f-list">
					<li id="lastmod"> This page was last modified on 22 April 2009, at 22:41 (UTC).</li>
					<li id="copyright">All text is available under the terms of the <a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Text_of_the_GNU_Free_Documentation_License" title="Wikipedia:Text of the GNU Free Documentation License">GNU Free Documentation License</a>. (See <b><a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Copyrights" title="Wikipedia:Copyrights">Copyrights</a></b> for details.) <br /> Wikipedia&reg; is a registered trademark of the <a href="http://www.wikimediafoundation.org">Wikimedia Foundation, Inc.</a>, a U.S. registered <a class='internal' href="http://en.wikipedia.org/wiki/501%28c%29#501.28c.29.283.29" title="501(c)(3)">501(c)(3)</a> <a href="http://wikimediafoundation.org/wiki/Deductibility_of_donations">tax-deductible</a> <a class='internal' href="http://en.wikipedia.org/wiki/Non-profit_organization" title="Non-profit organization">nonprofit</a> <a href="http://en.wikipedia.org/wiki/Charitable_organization" title="Charitable organization">charity</a>.<br /></li>
					<li id="privacy"><a href="http://wikimediafoundation.org/wiki/Privacy_policy" title="wikimedia:Privacy policy">Privacy policy</a></li>
					<li id="about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
					<li id="disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
			</ul>
		</div>
</div>

		<script type="text/javascript">if (window.runOnloadHook) runOnloadHook();</script>
<!-- Served by srv182 in 0.061 secs. --></body></html>
