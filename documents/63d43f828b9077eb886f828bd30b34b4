<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
		<meta http-equiv="Content-Style-Type" content="text/css" />
		<meta name="generator" content="MediaWiki 1.15alpha" />
		<meta name="keywords" content="Normal distribution,Articles with unsourced statements since March 2008,Articles with unsourced statements since February 2008,Statistics,ProbDistributions,Statistics,2005,68-95-99.7 rule,Abraham de Moivre,Abramowitz and Stegun,Adrien Marie Legendre" />
		<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Normal_distribution&amp;action=edit" />
		<link rel="edit" title="Edit this page" href="/w/index.php?title=Normal_distribution&amp;action=edit" />
		<link rel="apple-touch-icon" href="http://en.wikipedia.org/apple-touch-icon.png" />
		<link rel="shortcut icon" href="/favicon.ico" />
		<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)" />
		<link rel="copyright" href="http://www.gnu.org/copyleft/fdl.html" />
		<link rel="alternate" type="application/rss+xml" title="Wikipedia RSS Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=rss" />
		<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=atom" />
		<title>Normal distribution - Wikipedia, the free encyclopedia</title>
		<link rel="stylesheet" href="/skins-1.5/common/shared.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/common/commonPrint.css?207xx" type="text/css" media="print" />
		<link rel="stylesheet" href="/skins-1.5/monobook/main.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/chick/main.css?207xx" type="text/css" media="handheld" />
		<!--[if lt IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE50Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE55Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 6]><link rel="stylesheet" href="/skins-1.5/monobook/IE60Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 7]><link rel="stylesheet" href="/skins-1.5/monobook/IE70Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Common.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Print.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="print" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Handheld.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="handheld" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Monobook.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=-&amp;action=raw&amp;maxage=2678400&amp;gen=css" type="text/css" />
		<!--[if lt IE 7]><script type="text/javascript" src="/skins-1.5/common/IEFixes.js?207xx"></script>
		<meta http-equiv="imagetoolbar" content="no" /><![endif]-->

		<script type= "text/javascript">/*<![CDATA[*/
		var skin = "monobook";
		var stylepath = "/skins-1.5";
		var wgArticlePath = "/wiki/$1";
		var wgScriptPath = "/w";
		var wgScript = "/w/index.php";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = "http://en.wikipedia.org";
		var wgCanonicalNamespace = "";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = "Normal_distribution";
		var wgTitle = "Normal distribution";
		var wgAction = "view";
		var wgArticleId = "21462";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = "en";
		var wgContentLanguage = "en";
		var wgBreakFrames = false;
		var wgCurRevisionId = 282175274;
		var wgVersion = "1.15alpha";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = ["", ""];
		var wgDigitTransformTable = ["", ""];
		var wgMWSuggestTemplate = "http://en.wikipedia.org/w/api.php?action=opensearch\x26search={searchTerms}\x26namespace={namespaces}\x26suggest";
		var wgDBname = "enwiki";
		var wgSearchNamespaces = [0];
		var wgMWSuggestMessages = ["with suggestions", "no suggestions"];
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		/*]]>*/</script>

		<script type="text/javascript" src="/skins-1.5/common/wikibits.js?207xx"><!-- wikibits js --></script>
		<!-- Head Scripts -->
		<script type="text/javascript" src="/skins-1.5/common/ajax.js?207xx"></script>
		<script type="text/javascript" src="/skins-1.5/common/mwsuggest.js?207xx"></script>
<script type="text/javascript">/*<![CDATA[*/
var wgNotice='';var wgNoticeLocal='';
/*]]>*/</script>		<script type="text/javascript" src="http://upload.wikimedia.org/centralnotice/wikipedia/en/centralnotice.js?207xx"></script>
		<script type="text/javascript" src="/w/index.php?title=-&amp;action=raw&amp;gen=js&amp;useskin=monobook"><!-- site js --></script>
	</head>
<body class="mediawiki ltr ns-0 ns-subject page-Normal_distribution skin-monobook">
	<div id="globalWrapper">
		<div id="column-content">
	<div id="content">
		<a name="top" id="top"></a>
		<div id="siteNotice"><script type='text/javascript'>if (wgNotice != '') document.writeln(wgNotice);</script></div>		<h1 id="firstHeading" class="firstHeading">Normal distribution</h1>
		<div id="bodyContent">
			<h3 id="siteSub">From Wikipedia, the free encyclopedia</h3>
			<div id="contentSub"></div>
									<div id="jump-to-nav">Jump to: <a href="#column-one">navigation</a>, <a href="#searchInput">search</a></div>			<!-- start content -->
			<table class="infobox bordered" style="width:325px; font-size:95%;">
<caption>Normal</caption>
<tr style="text-align: center;">
<td colspan="2">Probability density function<br />
<a href="/wiki/File:Normal_Distribution_PDF.svg" class="image" title="Probability density function for the normal distribution"><img alt="Probability density function for the normal distribution" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Normal_Distribution_PDF.svg/360px-Normal_Distribution_PDF.svg.png" width="360" height="230" border="0" /></a><br />
<small>The red line is the standard normal distribution</small></td>
</tr>
<tr style="text-align: center;">
<td colspan="2">Cumulative distribution function<br />
<a href="/wiki/File:Normal_Distribution_CDF.svg" class="image" title="Cumulative distribution function for the normal distribution"><img alt="Cumulative distribution function for the normal distribution" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/Normal_Distribution_CDF.svg/360px-Normal_Distribution_CDF.svg.png" width="360" height="230" border="0" /></a><br />
<small>Colors match the image above</small></td>
</tr>
<tr>
<th>Parameters</th>
<td><span class="texhtml">μ</span> <a href="/wiki/Location_parameter" title="Location parameter">location</a> (<a href="/wiki/Real_number" title="Real number">real</a>)<br />
<span class="texhtml">σ<sup>2</sup> &gt; 0</span> squared <a href="/wiki/Scale_parameter" title="Scale parameter">scale</a> (real)</td>
</tr>
<tr>
<th><a href="/wiki/Support_(mathematics)" title="Support (mathematics)">Support</a></th>
<td><img class="tex" alt="x \in\mathbb{R}\!" src="http://upload.wikimedia.org/math/1/3/4/134371814b4cd0aff7ff0c43121df4ab.png" /></td>
</tr>
<tr>
<th><a href="/wiki/Probability_density_function" title="Probability density function">Probability density function</a> (pdf)</th>
<td><img class="tex" alt="\frac{1}{\sigma \sqrt{2\pi} } \exp \left(-\frac{(x-\mu)^2}{2\sigma ^2} \right) " src="http://upload.wikimedia.org/math/6/0/5/605cea7cca0f8ae63e8b130b19aa60fd.png" /></td>
</tr>
<tr>
<th><a href="/wiki/Cumulative_distribution_function" title="Cumulative distribution function">Cumulative distribution function</a> (cdf)</th>
<td><img class="tex" alt="\frac12 \left(1+\mathrm{erf}\left( \frac{x-\mu}{\sigma\sqrt2}\right) \right)" src="http://upload.wikimedia.org/math/a/d/d/add7445bf7ff45aed96ccf38569f830d.png" /></td>
</tr>
<tr>
<th><a href="/wiki/Expected_value" title="Expected value">Mean</a></th>
<td><span class="texhtml">μ</span></td>
</tr>
<tr>
<th><a href="/wiki/Median" title="Median">Median</a></th>
<td><span class="texhtml">μ</span></td>
</tr>
<tr>
<th><a href="/wiki/Mode_(statistics)" title="Mode (statistics)">Mode</a></th>
<td><span class="texhtml">μ</span></td>
</tr>
<tr>
<th><a href="/wiki/Variance" title="Variance">Variance</a></th>
<td><span class="texhtml">σ<sup>2</sup></span></td>
</tr>
<tr>
<th><a href="/wiki/Skewness" title="Skewness">Skewness</a></th>
<td>0</td>
</tr>
<tr>
<th>Excess <a href="/wiki/Kurtosis" title="Kurtosis">kurtosis</a></th>
<td>0</td>
</tr>
<tr>
<th><a href="/wiki/Information_entropy" title="Information entropy" class="mw-redirect">Entropy</a></th>
<td><img class="tex" alt="\ln\left(\sigma\sqrt{2\,\pi\,e}\right)\!" src="http://upload.wikimedia.org/math/3/3/f/33f3293ba13afcb869241b03ac4f81a5.png" /></td>
</tr>
<tr>
<th><a href="/wiki/Moment-generating_function" title="Moment-generating function">Moment-generating function</a> (mgf)</th>
<td><img class="tex" alt="M_X(t)= \exp\left(\mu\,t+\frac{\sigma^2 t^2}{2}\right)" src="http://upload.wikimedia.org/math/6/4/c/64c6b97caa97f3237b3fc67327e982f3.png" /></td>
</tr>
<tr>
<th><a href="/wiki/Characteristic_function_(probability_theory)" title="Characteristic function (probability theory)">Characteristic function</a></th>
<td><img class="tex" alt="\chi_X(t)=\exp\left(\mu\,i\,t-\frac{\sigma^2 t^2}{2}\right)" src="http://upload.wikimedia.org/math/2/5/c/25cab1945d15a447f29e5cb30421f8d1.png" /></td>
</tr>
</table>
<p>In <a href="/wiki/Probability_theory" title="Probability theory">probability theory</a> and <a href="/wiki/Statistics" title="Statistics">statistics</a>, the <b>normal distribution</b> or <b>Gaussian distribution</b> is a continuous <a href="/wiki/Probability_distribution" title="Probability distribution">probability distribution</a> that describes data that clusters around a <a href="/wiki/Expected_value" title="Expected value">mean</a> or average. The graph of the associated <a href="/wiki/Probability_density_function" title="Probability density function">probability density function</a> is bell-shaped, with a peak at the mean, and is known as the <b><a href="/wiki/Gaussian_function" title="Gaussian function">Gaussian function</a></b> or <b>bell curve</b>.</p>
<p>The normal distribution can be used to describe, at least approximately, any <a href="/wiki/Random_variable" title="Random variable">variable</a> that tends to cluster around the mean. For example, the heights of adult males in the United States are roughly normally distributed, with a mean of about 70 inches. Most men have a height close to the mean, though a small number of <a href="/wiki/Outlier" title="Outlier">outliers</a> have a height significantly above or below the mean. A <a href="/wiki/Histogram" title="Histogram">histogram</a> of male heights will appear similar to a bell curve, with the correspondence becoming closer if more data is used.</p>
<p>For theoretical reasons (such as the <a href="/wiki/Central_limit_theorem" title="Central limit theorem">central limit theorem</a>), any <a href="/wiki/Random_variable" title="Random variable">variable</a> that is the sum of a large number of <a href="/wiki/Independence_(probability_theory)" title="Independence (probability theory)">independent</a> factors is likely to be normally distributed. For this reason, the normal distribution is used throughout <a href="/wiki/Statistics" title="Statistics">statistics</a>, <a href="/wiki/Natural_science" title="Natural science">natural science</a>, and <a href="/wiki/Social_science" title="Social science" class="mw-redirect">social science</a><sup id="cite_ref-0" class="reference"><a href="#cite_note-0" title=""><span>[</span>1<span>]</span></a></sup> as a simple model for complex phenomena. For example, the <a href="/wiki/Observational_error" title="Observational error">observational error</a> in an experiment is usually assumed to follow a normal distribution, and the <a href="/wiki/Propagation_of_uncertainty" title="Propagation of uncertainty">propagation of uncertainty</a> is computed using this assumption.</p>
<p>The probability density function for a normal distribution is given by the formula</p>
<dl>
<dd><img class="tex" alt="p(x) = \frac{1}{\sigma \sqrt{2\pi}} \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)," src="http://upload.wikimedia.org/math/8/3/2/83204805d2e6d513c103aed8a4232f46.png" /></dd>
</dl>
<p>where <i>μ</i> is the mean, <i>σ</i> is the <a href="/wiki/Standard_deviation" title="Standard deviation">standard deviation</a> (a measure of the “width” of the bell), and exp denotes the <a href="/wiki/Exponential_function" title="Exponential function">exponential function</a>. For a mean of 0 and a standard deviation of 1, this formula simplifies to</p>
<dl>
<dd><img class="tex" alt="p(x) = \frac{1}{\sqrt{2\pi}} e^{-x^2/2}," src="http://upload.wikimedia.org/math/3/d/0/3d063306f42f5f6f262ab5cf10be1b2b.png" /></dd>
</dl>
<p>which is known as the <b>standard normal distribution</b>. When properly scaled and translated, the corresponding <a href="/wiki/Cumulative_distribution_function" title="Cumulative distribution function">cumulative distribution function</a> is known as the <a href="/wiki/Error_function" title="Error function">error function</a>.</p>
<p>The Gaussian distribution is named for <a href="/wiki/Carl_Friedrich_Gauss" title="Carl Friedrich Gauss">Carl Friedrich Gauss</a>, who used it to analyze astronomical data<sup id="cite_ref-1" class="reference"><a href="#cite_note-1" title=""><span>[</span>2<span>]</span></a></sup>, and defined the formula for its probability density function.</p>
<table id="toc" class="toc" summary="Contents">
<tr>
<td>
<div id="toctitle">
<h2>Contents</h2>
</div>
<ul>
<li class="toclevel-1"><a href="#History"><span class="tocnumber">1</span> <span class="toctext">History</span></a></li>
<li class="toclevel-1"><a href="#Characterization"><span class="tocnumber">2</span> <span class="toctext">Characterization</span></a>
<ul>
<li class="toclevel-2"><a href="#Probability_density_function"><span class="tocnumber">2.1</span> <span class="toctext">Probability density function</span></a></li>
<li class="toclevel-2"><a href="#Cumulative_distribution_function"><span class="tocnumber">2.2</span> <span class="toctext">Cumulative distribution function</span></a>
<ul>
<li class="toclevel-3"><a href="#Strict_lower_and_upper_bounds_for_the_cdf"><span class="tocnumber">2.2.1</span> <span class="toctext">Strict lower and upper bounds for the cdf</span></a></li>
</ul>
</li>
<li class="toclevel-2"><a href="#Generating_functions"><span class="tocnumber">2.3</span> <span class="toctext">Generating functions</span></a>
<ul>
<li class="toclevel-3"><a href="#Moment_generating_function"><span class="tocnumber">2.3.1</span> <span class="toctext">Moment generating function</span></a></li>
<li class="toclevel-3"><a href="#Cumulant_generating_function"><span class="tocnumber">2.3.2</span> <span class="toctext">Cumulant generating function</span></a></li>
<li class="toclevel-3"><a href="#Characteristic_function"><span class="tocnumber">2.3.3</span> <span class="toctext">Characteristic function</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1"><a href="#Properties"><span class="tocnumber">3</span> <span class="toctext">Properties</span></a>
<ul>
<li class="toclevel-2"><a href="#Standardizing_normal_random_variables"><span class="tocnumber">3.1</span> <span class="toctext">Standardizing normal random variables</span></a></li>
<li class="toclevel-2"><a href="#Moments"><span class="tocnumber">3.2</span> <span class="toctext">Moments</span></a></li>
<li class="toclevel-2"><a href="#The_central_limit_theorem"><span class="tocnumber">3.3</span> <span class="toctext">The central limit theorem</span></a></li>
<li class="toclevel-2"><a href="#Infinite_divisibility"><span class="tocnumber">3.4</span> <span class="toctext">Infinite divisibility</span></a></li>
<li class="toclevel-2"><a href="#Stability"><span class="tocnumber">3.5</span> <span class="toctext">Stability</span></a></li>
<li class="toclevel-2"><a href="#Standard_deviation_and_confidence_intervals"><span class="tocnumber">3.6</span> <span class="toctext">Standard deviation and confidence intervals</span></a></li>
<li class="toclevel-2"><a href="#Exponential_family_form"><span class="tocnumber">3.7</span> <span class="toctext">Exponential family form</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Complex_normal_distribution"><span class="tocnumber">4</span> <span class="toctext">Complex normal distribution</span></a></li>
<li class="toclevel-1"><a href="#Related_distributions"><span class="tocnumber">5</span> <span class="toctext">Related distributions</span></a></li>
<li class="toclevel-1"><a href="#Descriptive_and_inferential_statistics"><span class="tocnumber">6</span> <span class="toctext">Descriptive and inferential statistics</span></a>
<ul>
<li class="toclevel-2"><a href="#Scores"><span class="tocnumber">6.1</span> <span class="toctext">Scores</span></a></li>
<li class="toclevel-2"><a href="#Normality_tests"><span class="tocnumber">6.2</span> <span class="toctext">Normality tests</span></a></li>
<li class="toclevel-2"><a href="#Estimation_of_parameters"><span class="tocnumber">6.3</span> <span class="toctext">Estimation of parameters</span></a>
<ul>
<li class="toclevel-3"><a href="#Maximum_likelihood_estimation_of_parameters"><span class="tocnumber">6.3.1</span> <span class="toctext">Maximum likelihood estimation of parameters</span></a>
<ul>
<li class="toclevel-4"><a href="#Surprising_generalization"><span class="tocnumber">6.3.1.1</span> <span class="toctext">Surprising generalization</span></a></li>
</ul>
</li>
<li class="toclevel-3"><a href="#Unbiased_estimation_of_parameters"><span class="tocnumber">6.3.2</span> <span class="toctext">Unbiased estimation of parameters</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1"><a href="#Occurrence"><span class="tocnumber">7</span> <span class="toctext">Occurrence</span></a>
<ul>
<li class="toclevel-2"><a href="#Photon_counting"><span class="tocnumber">7.1</span> <span class="toctext">Photon counting</span></a></li>
<li class="toclevel-2"><a href="#Measurement_errors"><span class="tocnumber">7.2</span> <span class="toctext">Measurement errors</span></a></li>
<li class="toclevel-2"><a href="#Physical_characteristics_of_biological_specimens"><span class="tocnumber">7.3</span> <span class="toctext">Physical characteristics of biological specimens</span></a></li>
<li class="toclevel-2"><a href="#Financial_variables"><span class="tocnumber">7.4</span> <span class="toctext">Financial variables</span></a></li>
<li class="toclevel-2"><a href="#Distribution_in_testing_and_intelligence"><span class="tocnumber">7.5</span> <span class="toctext">Distribution in testing and intelligence</span></a></li>
<li class="toclevel-2"><a href="#Diffusion_equation"><span class="tocnumber">7.6</span> <span class="toctext">Diffusion equation</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Use_in_computational_statistics"><span class="tocnumber">8</span> <span class="toctext">Use in computational statistics</span></a>
<ul>
<li class="toclevel-2"><a href="#Generating_values_for_normal_random_variables"><span class="tocnumber">8.1</span> <span class="toctext">Generating values for normal random variables</span></a></li>
<li class="toclevel-2"><a href="#Numerical_approximations_of_the_normal_distribution_and_its_cdf"><span class="tocnumber">8.2</span> <span class="toctext">Numerical approximations of the normal distribution and its cdf</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#See_also"><span class="tocnumber">9</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1"><a href="#Notes"><span class="tocnumber">10</span> <span class="toctext">Notes</span></a></li>
<li class="toclevel-1"><a href="#References"><span class="tocnumber">11</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1"><a href="#External_links"><span class="tocnumber">12</span> <span class="toctext">External links</span></a></li>
</ul>
</td>
</tr>
</table>
<script type="text/javascript">
//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>
</script>
<p><a name="History" id="History"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=1" title="Edit section: History">edit</a>]</span> <span class="mw-headline">History</span></h2>
<p>The normal distribution was first introduced by <a href="/wiki/Abraham_de_Moivre" title="Abraham de Moivre">Abraham de Moivre</a> in an article in the year 1733,<sup id="cite_ref-2" class="reference"><a href="#cite_note-2" title=""><span>[</span>3<span>]</span></a></sup> which was reprinted in the second edition of his <i><a href="/wiki/The_Doctrine_of_Chances" title="The Doctrine of Chances">The Doctrine of Chances</a></i>, 1738 in the context of approximating certain <a href="/wiki/Binomial_distribution" title="Binomial distribution">binomial distributions</a> for large <i>n</i>. His result was extended by <a href="/wiki/Pierre_Simon_de_Laplace" title="Pierre Simon de Laplace" class="mw-redirect">Laplace</a> in his book <i><a href="/wiki/Analytical_Theory_of_Probabilities" title="Analytical Theory of Probabilities" class="mw-redirect">Analytical Theory of Probabilities</a></i> (1812), and is now called the <a href="/wiki/Theorem_of_de_Moivre-Laplace" title="Theorem of de Moivre-Laplace" class="mw-redirect">theorem of de Moivre-Laplace</a>.</p>
<p>Laplace used the normal distribution in the <a href="/wiki/Analysis_of_errors" title="Analysis of errors" class="mw-redirect">analysis of errors</a> of experiments. The important <a href="/wiki/Method_of_least_squares" title="Method of least squares" class="mw-redirect">method of least squares</a> was introduced by <a href="/wiki/Adrien_Marie_Legendre" title="Adrien Marie Legendre" class="mw-redirect">Legendre</a> in 1805. <a href="/wiki/Carl_Friedrich_Gauss" title="Carl Friedrich Gauss">Gauss</a>, who claimed to have used the method since 1794, justified it rigorously in 1809 by assuming a normal distribution of the errors. The fact the distribution is sometimes called Gaussian is an example of <a href="/wiki/Stigler%27s_Law" title="Stigler's Law" class="mw-redirect">Stigler's Law</a>.</p>
<p>The name "bell curve" goes back to <a href="/wiki/Esprit_Jouffret" title="Esprit Jouffret">Esprit Jouffret</a> who first used the term "bell surface" in 1872 for a <a href="/wiki/Multivariate_normal_distribution" title="Multivariate normal distribution">bivariate normal</a> with independent components. The name "normal distribution" was coined independently by <a href="/wiki/Charles_S._Peirce" title="Charles S. Peirce" class="mw-redirect">Charles S. Peirce</a>, <a href="/wiki/Francis_Galton" title="Francis Galton">Francis Galton</a> and <a href="/wiki/Wilhelm_Lexis" title="Wilhelm Lexis">Wilhelm Lexis</a> around 1875.<sup class="noprint Template-Fact"><span title="This claim needs references to reliable sources&#160;since March 2008" style="white-space: nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed">citation needed</a></i>]</span></sup> Despite this terminology, other probability distributions may be more appropriate in some contexts; see the discussion of <a href="#Occurrence" title="">occurrence</a>, below.</p>
<p><a name="Characterization" id="Characterization"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=2" title="Edit section: Characterization">edit</a>]</span> <span class="mw-headline">Characterization</span></h2>
<p>There are various ways to <a href="/wiki/Characterization_(mathematics)" title="Characterization (mathematics)">characterize</a> a <a href="/wiki/Probability_distribution" title="Probability distribution">probability distribution</a>. The most visual is the <a href="/wiki/Probability_density_function" title="Probability density function">probability density function</a> (PDF). Equivalent ways are the <a href="/wiki/Cumulative_distribution_function" title="Cumulative distribution function">cumulative distribution function</a>, the <a href="/wiki/Moment_(mathematics)" title="Moment (mathematics)">moments</a>, the <a href="/wiki/Cumulant" title="Cumulant">cumulants</a>, the <a href="/wiki/Characteristic_function_(probability_theory)" title="Characteristic function (probability theory)">characteristic function</a>, the <a href="/wiki/Moment-generating_function" title="Moment-generating function">moment-generating function</a>, the cumulant-<a href="/wiki/Generating_function" title="Generating function">generating function</a>, and <a href="/wiki/Maxwell%27s_theorem" title="Maxwell's theorem">Maxwell's theorem</a>. See <a href="/wiki/Probability_distribution" title="Probability distribution">probability distribution</a> for a discussion.</p>
<p>To indicate that a real-valued <a href="/wiki/Random_variable" title="Random variable">random variable</a> <i>X</i> is normally distributed with mean <i>μ</i> and variance <i>σ</i><sup>2</sup> ≥ 0, we write</p>
<dl>
<dd><img class="tex" alt="X \sim N(\mu, \sigma^2).\,\!" src="http://upload.wikimedia.org/math/3/a/5/3a53382a03360033edc63fb08a592d9a.png" /></dd>
</dl>
<p>While it is certainly useful for certain limit theorems (e.g. <a href="/wiki/Estimator#Asymptotic_normality" title="Estimator">asymptotic normality of estimators</a>) and for the theory of <a href="/wiki/Gaussian_process" title="Gaussian process">Gaussian processes</a> to consider the probability distribution concentrated at <i>μ</i> (see <a href="/wiki/Dirac_measure" title="Dirac measure">Dirac measure</a>) as a distribution with mean <i>μ</i> and variance <i>σ</i><sup>2</sup> = 0, this degenerate case is often excluded from the considerations because no density with respect to the <a href="/wiki/Lebesgue_measure" title="Lebesgue measure">Lebesgue measure</a> exists.</p>
<p>The normal distribution may also be parameterized using a <a href="/wiki/Precision" title="Precision">precision</a> parameter <i>τ</i>, defined as the reciprocal of <i>σ</i><sup>2</sup>. This parameterization has an advantage in numerical applications where <i>σ</i><sup>2</sup> is very close to zero and is more convenient to work with in analysis as <i>τ</i> is a <a href="/wiki/Exponential_family#Interpretation" title="Exponential family">natural parameter</a> of the normal distribution.</p>
<p><a name="Probability_density_function" id="Probability_density_function"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=3" title="Edit section: Probability density function">edit</a>]</span> <span class="mw-headline">Probability density function</span></h3>
<div class="floatright"><a href="/wiki/File:Normal_Distribution_PDF.svg" class="image" title="Probability density function for the normal distribution"><img alt="Probability density function for the normal distribution" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Normal_Distribution_PDF.svg/260px-Normal_Distribution_PDF.svg.png" width="260" height="166" border="0" /></a></div>
<p>The continuous <a href="/wiki/Probability_density_function" title="Probability density function">probability density function</a> of the <b>normal distribution</b> is the <a href="/wiki/Gaussian_function" title="Gaussian function">Gaussian function</a></p>
<dl>
<dd><img class="tex" alt="\varphi_{\mu,\sigma^2}(x) = \frac{1}{\sigma\sqrt{2\pi}} \,e^{ -\frac{(x- \mu)^2}{2\sigma^2}} = \frac{1}{\sigma} \varphi\left(\frac{x - \mu}{\sigma}\right),\quad x\in\mathbb{R}," src="http://upload.wikimedia.org/math/e/8/c/e8cf730ec1a7587ee84403dbc1c64008.png" /></dd>
</dl>
<p>where <i>σ</i> &gt; 0 is the <a href="/wiki/Standard_deviation" title="Standard deviation">standard deviation</a>, the real parameter <i>μ</i> is the <a href="/wiki/Expected_value" title="Expected value">expected value</a>, and</p>
<dl>
<dd><img class="tex" alt="\varphi(x)=\varphi_{0,1}(x)=\frac{e^{-x^2/2}}{\sqrt{2\pi\,}}, \,\quad x\in\mathbb{R}," src="http://upload.wikimedia.org/math/4/a/1/4a13599010e5b2223d470324aded2980.png" /></dd>
</dl>
<p>is the density function of the "standard" normal distribution: i.e., the normal distribution with <i>μ</i> = 0 and <i>σ</i> = 1. The <a href="/wiki/Integral" title="Integral">integral</a> of <img class="tex" alt="\varphi_{\mu,\sigma^2}" src="http://upload.wikimedia.org/math/d/c/9/dc9632c51d1d882c947182e4bae14b72.png" /> over the <a href="/wiki/Real_line" title="Real line">real line</a> is equal to one as shown in the <a href="/wiki/Gaussian_integral" title="Gaussian integral">Gaussian integral</a> article.</p>
<p>As a Gaussian function with the denominator of the exponent equal to 2, the standard normal density function <img class="tex" alt="\varphi_{}" src="http://upload.wikimedia.org/math/6/2/7/6270e0b9f032707ae0de870f76533e6f.png" /> is an <a href="/wiki/Eigenfunction" title="Eigenfunction">eigenfunction</a> of the <a href="/wiki/Fourier_transform" title="Fourier transform">Fourier transform</a>.</p>
<p>The probability density function has notable properties including:</p>
<ul>
<li>symmetry about its mean <i>μ</i></li>
<li>the <a href="/wiki/Mode_(statistics)" title="Mode (statistics)">mode</a> and <a href="/wiki/Median" title="Median">median</a> both equal the mean <i>μ</i></li>
<li>the <a href="/wiki/Inflection_point" title="Inflection point">inflection points</a> of the curve occur one standard deviation away from the mean, i.e. at <i>μ</i>&#160;−&#160;<i>σ</i> and <i>μ</i>&#160;+&#160;<i>σ</i>.</li>
</ul>
<p><a name="Cumulative_distribution_function" id="Cumulative_distribution_function"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=4" title="Edit section: Cumulative distribution function">edit</a>]</span> <span class="mw-headline">Cumulative distribution function</span></h3>
<div class="floatright"><a href="/wiki/File:Normal_Distribution_CDF.svg" class="image" title="Cumulative distribution function for the normal distribution"><img alt="Cumulative distribution function for the normal distribution" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/Normal_Distribution_CDF.svg/360px-Normal_Distribution_CDF.svg.png" width="360" height="230" border="0" /></a></div>
<p>The <a href="/wiki/Cumulative_distribution_function" title="Cumulative distribution function">cumulative distribution function</a> (cdf) of a <a href="/wiki/Probability_distribution" title="Probability distribution">probability distribution</a>, evaluated at a number (lower-case) <i>x</i>, is the probability of the event that a <a href="/wiki/Random_variable" title="Random variable">random variable</a> (capital) <i>X</i> with that distribution is less than or equal to <i>x</i>. The cumulative distribution function of the normal distribution is expressed in terms of the density function as follows:</p>
<dl>
<dd><img class="tex" alt=" \begin{align}
\Phi_{\mu,\sigma^2}(x)
&amp;{}=\int_{-\infty}^x\varphi_{\mu,\sigma^2}(u)\,du\\
&amp;{}=\frac{1}{\sigma\sqrt{2\pi}}
\int_{-\infty}^x
\exp
  \Bigl( -\frac{(u - \mu)^2}{2\sigma^2}
\ \Bigr)\, du ,\quad x\in\mathbb{R}\\
\end{align}
" src="http://upload.wikimedia.org/math/0/d/6/0d6d29564649c2b89454b26db0fa4e06.png" /></dd>
</dl>
<p>The standard normal cdf is just the general cdf evaluated with <i>μ</i> = 0 and <i>σ</i> = 1:</p>
<dl>
<dd><img class="tex" alt="
\Phi(x) = \Phi_{0,1}(x)
= \frac{1}{\sqrt{2\pi}}
\int_{-\infty}^x
\exp\Bigl(-\frac{u^2}{2}\Bigr)
\, du, \quad x\in\mathbb{R}.
" src="http://upload.wikimedia.org/math/e/e/6/ee6afc55216c30d88141b7036ac08fc1.png" /></dd>
</dl>
<p>The standard normal cdf can be expressed in terms of a <a href="/wiki/Special_function" title="Special function" class="mw-redirect">special function</a> called the <a href="/wiki/Error_function" title="Error function">error function</a>, as</p>
<dl>
<dd><img class="tex" alt="
\Phi(x)
=\frac{1}{2} \Bigl[ 1 + \operatorname{erf} \Bigl( \frac{x}{\sqrt{2}} \Bigr) \Bigr],
\quad x\in\mathbb{R},
" src="http://upload.wikimedia.org/math/0/0/3/003dabb870f6a1fc0521a85000ea8090.png" /></dd>
</dl>
<p>and the cdf itself can hence be expressed as</p>
<dl>
<dd><img class="tex" alt="
\Phi_{\mu,\sigma^2}(x)
=\frac{1}{2} \Bigl[ 1 + \operatorname{erf} \Bigl( \frac{x-\mu}{\sigma\sqrt{2}} \Bigr) \Bigr],
\quad x\in\mathbb{R}.
" src="http://upload.wikimedia.org/math/3/5/3/3537f96b6dfa850f2e6fcb765a03c28c.png" /></dd>
</dl>
<p>The complement of the standard normal cdf, <span class="texhtml">1 − Φ(<i>x</i>)</span>, is often denoted <span class="texhtml"><i>Q</i>(<i>x</i>)</span>, and is sometimes referred to simply as the <b>Q-function</b>, especially in engineering texts.<sup id="cite_ref-3" class="reference"><a href="#cite_note-3" title=""><span>[</span>4<span>]</span></a></sup><sup id="cite_ref-4" class="reference"><a href="#cite_note-4" title=""><span>[</span>5<span>]</span></a></sup> This represents the tail probability of the Gaussian distribution. Other definitions of the Q-function, all of which are simple transformations of <span class="texhtml">Φ</span>, are also used occasionally.<sup id="cite_ref-5" class="reference"><a href="#cite_note-5" title=""><span>[</span>6<span>]</span></a></sup></p>
<p>The inverse standard normal cumulative distribution function, or <a href="/wiki/Quantile_function" title="Quantile function">quantile function</a>, can be expressed in terms of the inverse error function:</p>
<dl>
<dd><img class="tex" alt="
\Phi^{-1}(p)
= \sqrt2
\;\operatorname{erf}^{-1} (2p - 1),
\quad p\in(0,1),
" src="http://upload.wikimedia.org/math/2/1/6/216bd2d30bee874f23df5025501fc11a.png" /></dd>
</dl>
<p>and the inverse cumulative distribution function can hence be expressed as</p>
<dl>
<dd><img class="tex" alt="
\Phi_{\mu,\sigma^2}^{-1}(p)
= \mu + \sigma\Phi^{-1}(p)
= \mu + \sigma\sqrt2
\; \operatorname{erf}^{-1}(2p - 1),
\quad p\in(0,1).
" src="http://upload.wikimedia.org/math/8/7/6/8760685b66c896427f92e5252c13f4fe.png" /></dd>
</dl>
<p>This quantile function is sometimes called the <a href="/wiki/Probit" title="Probit">probit</a> function. There is no elementary <a href="/wiki/Primitive_(integral)" title="Primitive (integral)" class="mw-redirect">primitive</a> for the probit function. This is not to say merely that none is known, but rather that the non-existence of such an elementary primitive has been proven. Several accurate methods exist for approximating the quantile function for the normal distribution - see <a href="/wiki/Quantile_function" title="Quantile function">quantile function</a> for a discussion and references.</p>
<p>The values Φ(<i>x</i>) may be approximated very accurately by a variety of methods, such as <a href="/wiki/Numerical_integration" title="Numerical integration">numerical integration</a>, <a href="/wiki/Taylor_series" title="Taylor series">Taylor series</a>, <a href="/wiki/Asymptotic_series" title="Asymptotic series" class="mw-redirect">asymptotic series</a> and <a href="/wiki/Gauss%27s_continued_fraction#Of_Kummer.27s_confluent_hypergeometric_function" title="Gauss's continued fraction">continued fractions</a>.</p>
<p><a name="Strict_lower_and_upper_bounds_for_the_cdf" id="Strict_lower_and_upper_bounds_for_the_cdf"></a></p>
<h4><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=5" title="Edit section: Strict lower and upper bounds for the cdf">edit</a>]</span> <span class="mw-headline">Strict lower and upper bounds for the cdf</span></h4>
<p>For large <i>x</i> the standard normal cdf <img class="tex" alt="\scriptstyle\Phi(x)" src="http://upload.wikimedia.org/math/c/c/5/cc57e4f204394489bae179e29e37342e.png" /> is close to 1 and <img class="tex" alt="\scriptstyle\Phi(-x)\,{=}\,1\,{-}\,\Phi(x)" src="http://upload.wikimedia.org/math/7/1/8/718022d3a4e16e2cc9bcb0fa4af44b76.png" /> is close to 0. The elementary bounds</p>
<dl>
<dd><img class="tex" alt="
\frac{x}{1+x^2}\varphi(x)&lt;1-\Phi(x)&lt;\frac{\varphi(x)}{x}, \qquad x&gt;0,
" src="http://upload.wikimedia.org/math/e/7/8/e78b5da834658b5e515529f0dc9f1d2e.png" /></dd>
</dl>
<p>in terms of the density <img class="tex" alt="\scriptstyle\varphi" src="http://upload.wikimedia.org/math/4/5/5/455136e0a43e7634fcc7d2904c0612d9.png" /> are useful.</p>
<p>Using the <a href="/wiki/Integration_by_substitution" title="Integration by substitution">substitution</a> <i>v</i>&#160;=&#160;<i>u</i>²/2, the upper bound is derived as follows:</p>
<dl>
<dd><img class="tex" alt="
\begin{align}
1-\Phi(x)
&amp;=\int_x^\infty\varphi(u)\,du\\
&amp;&lt;\int_x^\infty\frac ux\varphi(u)\,du
=\int_{x^2/2}^\infty\frac{e^{-v}}{x\sqrt{2\pi}}\,dv
=-\biggl.\frac{e^{-v}}{x\sqrt{2\pi}}\biggr|_{x^2/2}^\infty
=\frac{\varphi(x)}{x}.
\end{align}
" src="http://upload.wikimedia.org/math/f/9/3/f935cea14742da939222bbafe1276d3a.png" /></dd>
</dl>
<p>Similarly, using <img class="tex" alt="\scriptstyle\varphi'(u)\,{=}\,-u\,\varphi(u)" src="http://upload.wikimedia.org/math/4/c/4/4c477cf2ebb1709861de34160880d771.png" /> and the <a href="/wiki/Quotient_rule" title="Quotient rule">quotient rule</a>,</p>
<dl>
<dd><img class="tex" alt="
\begin{align}
\Bigl(1+\frac1{x^2}\Bigr)(1-\Phi(x))
&amp;=\int_x^\infty \Bigl(1+\frac1{x^2}\Bigr)\varphi(u)\,du\\
&amp;&gt;\int_x^\infty \Bigl(1+\frac1{u^2}\Bigr)\varphi(u)\,du
=-\biggl.\frac{\varphi(u)}u\biggr|_x^\infty
=\frac{\varphi(x)}x.
\end{align}
" src="http://upload.wikimedia.org/math/3/b/2/3b20ea237bc27a24b461d75d45e9b79a.png" /></dd>
</dl>
<p>Solving for <img class="tex" alt="\scriptstyle 1\,{-}\,\Phi(x)\," src="http://upload.wikimedia.org/math/7/2/d/72d8d9eac77ab922c98663247b1f5ee3.png" /> provides the lower bound.</p>
<p><a name="Generating_functions" id="Generating_functions"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=6" title="Edit section: Generating functions">edit</a>]</span> <span class="mw-headline">Generating functions</span></h3>
<p><a name="Moment_generating_function" id="Moment_generating_function"></a></p>
<h4><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=7" title="Edit section: Moment generating function">edit</a>]</span> <span class="mw-headline">Moment generating function</span></h4>
<p>The <a href="/wiki/Moment_generating_function" title="Moment generating function" class="mw-redirect">moment generating function</a> is defined as the <a href="/wiki/Expected_value" title="Expected value">expected value</a> of exp(<i>tX</i>). For a normal distribution, the moment generating function is</p>
<dl>
<dd><img class="tex" alt="
\begin{align}
M_X(t) &amp; {} = \mathrm{E} \left[ \exp{(tX)} \right] \\
&amp; {} = \int_{-\infty}^{\infty}  \frac{1}{\sigma \sqrt{2\pi} }
\exp{\left( -\frac{(x - \mu)^2}{2 \sigma^2} \right)}
\exp{(tx)} \, dx \\
&amp; {} = \exp{ \left(  \mu t + \frac{\sigma^2 t^2}{2} \right)}
\end{align}
" src="http://upload.wikimedia.org/math/e/c/3/ec3e32bd3a987126f3c3b40e239fa768.png" /></dd>
</dl>
<p>as can be seen by <a href="/wiki/Completing_the_square" title="Completing the square">completing the square</a> in the exponent.</p>
<p><a name="Cumulant_generating_function" id="Cumulant_generating_function"></a></p>
<h4><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=8" title="Edit section: Cumulant generating function">edit</a>]</span> <span class="mw-headline">Cumulant generating function</span></h4>
<p>The <a href="/wiki/Cumulant" title="Cumulant">cumulant</a> generating function is the logarithm of the moment generating function: <i>g</i>(<i>t</i>) = μ<i>t</i>&#160;+&#160;σ<sup>2</sup><i>t</i><sup>2</sup>/2. Since this is a quadratic polynomial in <i>t</i>, only the first two cumulants are nonzero.</p>
<p><a name="Characteristic_function" id="Characteristic_function"></a></p>
<h4><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=9" title="Edit section: Characteristic function">edit</a>]</span> <span class="mw-headline">Characteristic function</span></h4>
<p>The <a href="/wiki/Characteristic_function_(probability_theory)" title="Characteristic function (probability theory)">characteristic function</a> is defined as the <a href="/wiki/Expected_value" title="Expected value">expected value</a> of exp(<i>itX</i>), where <i>i</i> is the <a href="/wiki/Imaginary_unit" title="Imaginary unit">imaginary unit</a>. So the characteristic function is obtained by replacing <i>t</i> with <i>it</i> in the moment-generating function.</p>
<p>For a normal distribution, the characteristic function is <sup id="cite_ref-6" class="reference"><a href="#cite_note-6" title=""><span>[</span>7<span>]</span></a></sup></p>
<dl>
<dd><img class="tex" alt="\begin{align}
\chi_X(t;\mu,\sigma) &amp;{} = M_X(i t) = \mathrm{E}
\left[ \exp(i t X) \right] \\
&amp;{}=
\int_{-\infty}^{\infty}
\frac{1}{\sigma \sqrt{2\pi}}
\exp
\left(- \frac{(x - \mu)^2}{2\sigma^2}
\right)
\exp(i t x)
\, dx \\
&amp;{}=
\exp
\left(
i \mu t - \frac{\sigma^2 t^2}{2}
\right).
\end{align}
" src="http://upload.wikimedia.org/math/3/7/e/37e8462c5cc0193558226a94aa4f2a03.png" /></dd>
</dl>
<p><a name="Properties" id="Properties"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=10" title="Edit section: Properties">edit</a>]</span> <span class="mw-headline">Properties</span></h2>
<p>Some properties of the normal distribution:</p>
<ol>
<li>If <img class="tex" alt="X \sim N(\mu, \sigma^2)" src="http://upload.wikimedia.org/math/7/4/4/744888b68a64964aacef3bcd8d6777e7.png" /> and <span class="texhtml"><i>a</i></span> and <span class="texhtml"><i>b</i></span> are <a href="/wiki/Real_number" title="Real number">real numbers</a>, then <img class="tex" alt="a X + b \sim N(a \mu + b, (a \sigma)^2)" src="http://upload.wikimedia.org/math/7/0/1/701cfc64a709902a1270c47864119652.png" /> (see <a href="/wiki/Expected_value" title="Expected value">expected value</a> and <a href="/wiki/Variance" title="Variance">variance</a>).</li>
<li>If <img class="tex" alt="X \sim N(\mu_X, \sigma^2_X)" src="http://upload.wikimedia.org/math/e/a/c/eac9f1d639c15276cf22d85ff11a7b6a.png" /> and <img class="tex" alt="Y \sim N(\mu_Y, \sigma^2_Y)" src="http://upload.wikimedia.org/math/2/e/2/2e26b49dbd44bb0b4650744a65f83097.png" /> are <a href="/wiki/Statistical_independence" title="Statistical independence" class="mw-redirect">independent</a> normal <a href="/wiki/Random_variable" title="Random variable">random variables</a>, then:
<ul>
<li>Their sum is normally distributed with <img class="tex" alt="U = X + Y \sim N(\mu_X + \mu_Y, \sigma^2_X + \sigma^2_Y)" src="http://upload.wikimedia.org/math/8/1/f/81fcbdfdcfb20f9af35db82829da43b0.png" /> (<a href="/wiki/Sum_of_normally_distributed_random_variables" title="Sum of normally distributed random variables">proof</a>). Interestingly, the converse holds: if two independent random variables have a normally-distributed sum, then they must be normal themselves — this is known as <a href="/wiki/Cram%C3%A9r%27s_theorem" title="Cramér's theorem">Cramér's theorem</a>.</li>
<li>Their difference is normally distributed with <img class="tex" alt="V = X - Y \sim N(\mu_X - \mu_Y, \sigma^2_X + \sigma^2_Y)" src="http://upload.wikimedia.org/math/8/b/2/8b22e1778fd0e4548eda237bad71aa44.png" />.</li>
<li>If the variances of <i>X</i> and <i>Y</i> are equal, then <i>U</i> and <i>V</i> are independent of each other.</li>
<li>The <a href="/wiki/Kullback-Leibler_divergence" title="Kullback-Leibler divergence" class="mw-redirect">Kullback-Leibler divergence</a>, <img class="tex" alt="D_{\rm KL}( X \| Y ) =
{ 1 \over 2 } \left(2 \log \left( { \sigma_Y \over \sigma_X } \right) + \frac{\sigma^2_X}{\sigma^2_Y} +
\frac{\left(\mu_Y - \mu_X\right)^2}{\sigma^2_Y} - 1\right).
" src="http://upload.wikimedia.org/math/f/a/a/faa191bdea3479405e655ea3e7b36e63.png" /></li>
</ul>
</li>
<li>If <img class="tex" alt="X \sim N(0, \sigma^2_X)" src="http://upload.wikimedia.org/math/1/a/3/1a368150e2171639da10166086a11bd3.png" /> and <img class="tex" alt="Y \sim N(0, \sigma^2_Y)" src="http://upload.wikimedia.org/math/9/d/4/9d49cf31b33111492ae2884c760231e9.png" /> are independent normal random variables, then:
<ul>
<li>Their product <span class="texhtml"><i>X</i><i>Y</i></span> follows a distribution with density <span class="texhtml"><i>p</i></span> given by
<dl>
<dd><img class="tex" alt="p(z) = \frac{1}{\pi\,\sigma_X\,\sigma_Y} \; K_0\left(\frac{|z|}{\sigma_X\,\sigma_Y}\right)," src="http://upload.wikimedia.org/math/b/0/0/b009e9a11285d981783c4467debe66e0.png" /> where <span class="texhtml"><i>K</i><sub>0</sub></span> is a <a href="/wiki/Bessel_function#Modified_Bessel_functions" title="Bessel function">modified Bessel function of the second kind</a>.</dd>
</dl>
</li>
<li>Their ratio follows a <a href="/wiki/Cauchy_distribution" title="Cauchy distribution">Cauchy distribution</a> with <img class="tex" alt="X/Y \sim \mathrm{Cauchy}(0, \sigma_X/\sigma_Y)" src="http://upload.wikimedia.org/math/1/f/c/1fc3faa96303a0341027aacb3a8e5c5d.png" />. Thus the Cauchy distribution is a special kind of <a href="/wiki/Ratio_distribution" title="Ratio distribution">ratio distribution</a>.</li>
</ul>
</li>
<li>If <img class="tex" alt="X_1, \dots, X_n" src="http://upload.wikimedia.org/math/e/8/e/e8eacc087b64e56391a3b8ddf4216d77.png" /> are independent standard normal variables, then <img class="tex" alt="X_1^2 + \cdots + X_n^2" src="http://upload.wikimedia.org/math/4/b/8/4b82e42397459f7359433c6673601109.png" /> has a <a href="/wiki/Chi-square_distribution" title="Chi-square distribution">chi-square distribution</a> with <i>n</i> degrees of freedom.</li>
<li>If <img class="tex" alt="X_1,\dots,X_n" src="http://upload.wikimedia.org/math/e/8/e/e8eacc087b64e56391a3b8ddf4216d77.png" /> are independent standard normal variables, then the <a href="/wiki/Sample_mean" title="Sample mean" class="mw-redirect">sample mean</a> <img class="tex" alt="\bar{X}=(X_1+\cdots+X_n)/n" src="http://upload.wikimedia.org/math/f/8/e/f8ee4c5b552319c9e1183d3d89355316.png" /> and <a href="/wiki/Sample_variance" title="Sample variance" class="mw-redirect">sample variance</a> <img class="tex" alt="S^2=((X_1-\bar{X})^2+\cdots+(X_n-\bar{X})^2)/(n-1)" src="http://upload.wikimedia.org/math/b/0/a/b0a33006cefd0b7d37794e42ec213a35.png" /> are <a href="/wiki/Statistical_independence" title="Statistical independence" class="mw-redirect">independent</a>. This property <a href="/wiki/Characterization_(mathematics)" title="Characterization (mathematics)">characterizes</a> normal distributions (and helps to explain why the <a href="/wiki/F-test" title="F-test">F-test</a> is non-robust with respect to non-normality!)</li>
</ol>
<p><a name="Standardizing_normal_random_variables" id="Standardizing_normal_random_variables"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=11" title="Edit section: Standardizing normal random variables">edit</a>]</span> <span class="mw-headline">Standardizing normal random variables</span></h3>
<p>As a consequence of Property 1, it is possible to relate all normal random variables to the standard normal.</p>
<p>If <span class="texhtml"><i>X</i></span> ~ <span class="texhtml"><i>N</i>(μ,σ<sup>2</sup>)</span>, then</p>
<dl>
<dd><img class="tex" alt="Z = \frac{X - \mu}{\sigma} \!" src="http://upload.wikimedia.org/math/f/7/a/f7aa6c4c6f1dc137bb57a719ca20edb0.png" /></dd>
</dl>
<p>is a <a href="/wiki/Standard_normal_random_variable" title="Standard normal random variable" class="mw-redirect">standard normal random variable</a>: <span class="texhtml"><i>Z</i></span> ~ <span class="texhtml"><i>N</i>(0,1)</span>. An important consequence is that the cdf of a general normal distribution is therefore</p>
<dl>
<dd><img class="tex" alt="\Pr(X \le x)
=
\Phi
\left(
\frac{x-\mu}{\sigma}
\right)
=
\frac{1}{2}
\left(
1 + \operatorname{erf}
\left(
  \frac{x-\mu}{\sigma\sqrt{2}}
\right)
\right)
.
" src="http://upload.wikimedia.org/math/7/b/0/7b0e968a9422be89bc5054772359a82a.png" /></dd>
</dl>
<p>Conversely, if <span class="texhtml"><i>Z</i></span> is a standard normal distribution, <span class="texhtml"><i>Z</i></span> ~ <span class="texhtml"><i>N</i>(0,1)</span>, then</p>
<dl>
<dd><span class="texhtml"><i>X</i> = σ<i>Z</i> + μ</span></dd>
</dl>
<p>is a normal random variable with mean <span class="texhtml">μ</span> and variance <span class="texhtml">σ<sup>2</sup></span>.</p>
<p>The standard normal distribution has been tabulated (usually in the form of value of the cumulative distribution function Φ), and the other normal distributions are the simple transformations, as described above, of the standard one. Therefore, one can use tabulated values of the cdf of the standard normal distribution to find values of the cdf of a general normal distribution.</p>
<p><a name="Moments" id="Moments"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=12" title="Edit section: Moments">edit</a>]</span> <span class="mw-headline">Moments</span></h3>
<p>The first few <a href="/wiki/Moment_(mathematics)" title="Moment (mathematics)">moments</a> of the normal distribution are:</p>
<table class="wikitable">
<tr bgcolor="#CCCCCC">
<th>Number</th>
<th>Raw moment</th>
<th>Central moment</th>
<th>Cumulant</th>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>1</td>
<td></td>
</tr>
<tr>
<td>1</td>
<td><span class="texhtml">μ</span></td>
<td>0</td>
<td><span class="texhtml">μ</span></td>
</tr>
<tr>
<td>2</td>
<td><span class="texhtml">μ<sup>2</sup> + σ<sup>2</sup></span></td>
<td><span class="texhtml">σ<sup>2</sup></span></td>
<td><span class="texhtml">σ<sup>2</sup></span></td>
</tr>
<tr>
<td>3</td>
<td><span class="texhtml">μ<sup>3</sup> + 3μσ<sup>2</sup></span></td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>4</td>
<td><span class="texhtml">μ<sup>4</sup> + 6μ<sup>2</sup>σ<sup>2</sup> + 3σ<sup>4</sup></span></td>
<td><span class="texhtml">3σ<sup>4</sup></span></td>
<td>0</td>
</tr>
<tr>
<td>5</td>
<td><span class="texhtml">μ<sup>5</sup> + 10μ<sup>3</sup>σ<sup>2</sup> + 15μσ<sup>4</sup></span></td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>6</td>
<td><span class="texhtml">μ<sup>6</sup> + 15μ<sup>4</sup>σ<sup>2</sup> + 45μ<sup>2</sup>σ<sup>4</sup> + 15σ<sup>6</sup></span></td>
<td><span class="texhtml">15σ<sup>6</sup></span></td>
<td>0</td>
</tr>
<tr>
<td>7</td>
<td><span class="texhtml">μ<sup>7</sup> + 21μ<sup>5</sup>σ<sup>2</sup> + 105μ<sup>3</sup>σ<sup>4</sup> + 105μσ<sup>6</sup></span></td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>8</td>
<td><span class="texhtml">μ<sup>8</sup> + 28μ<sup>6</sup>σ<sup>2</sup> + 210μ<sup>4</sup>σ<sup>4</sup> + 420μ<sup>2</sup>σ<sup>6</sup> + 105σ<sup>8</sup></span></td>
<td><span class="texhtml">105σ<sup>8</sup></span></td>
<td>0</td>
</tr>
</table>
<p>All <a href="/wiki/Cumulant" title="Cumulant">cumulants</a> of the normal distribution beyond the second are zero.</p>
<p>Higher central moments (of order 2<i>k</i>) are given by the formula</p>
<dl>
<dd><img class="tex" alt=" E\left[(X-\mu)^{2k}\right]=\frac{(2k)!}{2^k k!} \sigma^{2k}. " src="http://upload.wikimedia.org/math/c/4/5/c45d4d22ee1da09add1af6a69a6e5d7e.png" /></dd>
</dl>
<p><a name="The_central_limit_theorem" id="The_central_limit_theorem"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=13" title="Edit section: The central limit theorem">edit</a>]</span> <span class="mw-headline">The central limit theorem</span></h3>
<div class="rellink noprint relarticle mainarticle">Main article: <a href="/wiki/Central_limit_theorem" title="Central limit theorem">central limit theorem</a></div>
<div class="thumb tright">
<div class="thumbinner" style="width:327px;"><a href="/wiki/File:Normal_approximation_to_binomial.svg" class="image" title="Plot of the pdf of a normal distribution with μ = 12 and σ = 3, approximating the pdf of a binomial distribution with n = 48 and p = 1/4"><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Normal_approximation_to_binomial.svg/325px-Normal_approximation_to_binomial.svg.png" width="325" height="260" border="0" class="thumbimage" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="/wiki/File:Normal_approximation_to_binomial.svg" class="internal" title="Enlarge"><img src="/skins-1.5/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
Plot of the pdf of a normal distribution with μ = 12 and σ = 3, approximating the pdf of a binomial distribution with <i>n</i> = 48 and <i>p</i> = 1/4</div>
</div>
</div>
<p>Under certain conditions (such as being <a href="/wiki/Independent_and_identically-distributed_random_variables" title="Independent and identically-distributed random variables">independent and identically-distributed</a> with finite variance), the sum of a large number of random variables is approximately normally distributed — this is the central limit theorem.</p>
<p>The practical importance of the central limit theorem is that the normal cumulative distribution function can be used as an approximation to some other cumulative distribution functions, for example:</p>
<ul>
<li>A <a href="/wiki/Binomial_distribution" title="Binomial distribution">binomial distribution</a> with parameters <i>n</i> and <i>p</i> is approximately normal for large <i>n</i> and <i>p</i> not too close to 1 or 0 (some books recommend using this approximation only if <i>np</i> and <i>n</i>(1&#160;−&#160;<i>p</i>) are both at least 5; in this case, a <a href="/wiki/Continuity_correction" title="Continuity correction">continuity correction</a> should be applied).<br />
The approximating normal distribution has parameters μ = <i>np</i>, σ<sup>2</sup> = <i>np</i>(1&#160;−&#160;<i>p</i>).</li>
</ul>
<ul>
<li>A <a href="/wiki/Poisson_distribution" title="Poisson distribution">Poisson distribution</a> with parameter λ is approximately normal for large λ.<br />
The approximating normal distribution has parameters μ = σ<sup>2</sup> = λ.</li>
</ul>
<p>Whether these approximations are sufficiently accurate depends on the purpose for which they are needed, and the rate of convergence to the normal distribution. It is typically the case that such approximations are less accurate in the tails of the distribution. A general upper bound of the approximation error of the cumulative distribution function is given by the <a href="/wiki/Berry%E2%80%93Ess%C3%A9en_theorem" title="Berry–Esséen theorem">Berry–Esséen theorem</a>.</p>
<p><a name="Infinite_divisibility" id="Infinite_divisibility"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=14" title="Edit section: Infinite divisibility">edit</a>]</span> <span class="mw-headline">Infinite divisibility</span></h3>
<p>The normal distributions are <a href="/wiki/Infinite_divisibility_(probability)" title="Infinite divisibility (probability)">infinitely divisible</a> probability distributions: Given a mean <i>μ</i>, a variance <i>σ</i> <sup>2</sup>&#160;≥&#160;0, and a natural number <i>n</i>, the sum <i>X</i><sub>1</sub>&#160;+ .&#160;.&#160;.&#160;+ <i>X<sub>n</sub></i> of <i>n</i> independent random variables</p>
<dl>
<dd><img class="tex" alt="X_1,X_2,\dots,X_n \sim N(\mu/n, \sigma^2\!/n)\," src="http://upload.wikimedia.org/math/0/9/b/09be8f8bffbfafdaaa5618c76ad0ed9b.png" /></dd>
</dl>
<p>has this specified normal distribution (to verify this, use <a href="/wiki/Sum_of_normally_distributed_random_variables" title="Sum of normally distributed random variables">characteristic functions or convolution</a> and <a href="/wiki/Mathematical_induction" title="Mathematical induction">mathematical induction</a>).</p>
<p><a name="Stability" id="Stability"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=15" title="Edit section: Stability">edit</a>]</span> <span class="mw-headline">Stability</span></h3>
<p>The normal distributions are strictly <a href="/wiki/Stable_distribution" title="Stable distribution">stable</a> probability distributions.</p>
<p><a name="Standard_deviation_and_confidence_intervals" id="Standard_deviation_and_confidence_intervals"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=16" title="Edit section: Standard deviation and confidence intervals">edit</a>]</span> <span class="mw-headline">Standard deviation and confidence intervals</span></h3>
<div class="thumb tright">
<div class="thumbinner" style="width:327px;"><a href="/wiki/File:Standard_deviation_diagram.svg" class="image" title="Dark blue is less than one standard deviation from the mean.  For the normal distribution, this accounts for about 68% of the set (dark blue) while two standard deviations from the mean (medium and dark blue) account for about 95% and three standard deviations (light, medium, and dark blue) account for about 99.7%."><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Standard_deviation_diagram.svg/325px-Standard_deviation_diagram.svg.png" width="325" height="163" border="0" class="thumbimage" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="/wiki/File:Standard_deviation_diagram.svg" class="internal" title="Enlarge"><img src="/skins-1.5/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
Dark blue is less than one <a href="/wiki/Standard_deviation" title="Standard deviation">standard deviation</a> from the <a href="/wiki/Mean" title="Mean">mean</a>. For the normal distribution, this accounts for about 68% of the set (dark blue) while two standard deviations from the mean (medium and dark blue) account for about 95% and three standard deviations (light, medium, and dark blue) account for about 99.7%.</div>
</div>
</div>
<p>About 68% of values drawn from a normal distribution are within one standard deviation σ&#160;&gt;&#160;0 away from the mean μ; about 95% of the values are within two standard deviations and about 99.7% lie within three standard deviations. This is known as the "<a href="/wiki/68-95-99.7_rule" title="68-95-99.7 rule">68-95-99.7 rule</a>" or the "<a href="/wiki/Empirical_rule" title="Empirical rule" class="mw-redirect">empirical rule</a>."</p>
<p>To be more precise, the area under the bell curve between μ&#160;−&#160;<i>n</i>σ and μ&#160;+&#160;<i>n</i>σ in terms of the cumulative normal distribution function is given by</p>
<dl>
<dd><img class="tex" alt="\begin{align}&amp;\Phi_{\mu,\sigma^2}(\mu+n\sigma)-\Phi_{\mu,\sigma^2}(\mu-n\sigma)\\
&amp;=\Phi(n)-\Phi(-n)=2\Phi(n)-1=\mathrm{erf}\bigl(n/\sqrt{2}\,\bigr),\end{align}" src="http://upload.wikimedia.org/math/e/d/a/eda145b29049a270ea9ac8a93852f66c.png" /></dd>
</dl>
<p>where erf is the <a href="/wiki/Error_function" title="Error function">error function</a>. To 12 decimal places, the values for the 1-, 2-, up to 6-sigma points are:</p>
<table class="wikitable" style="text-align:center">
<tr bgcolor="#CCCCCC">
<th>&#160;<img class="tex" alt="n\," src="http://upload.wikimedia.org/math/a/9/5/a957404c96e59f1746f97ab668c8e1f8.png" />&#160;</th>
<th><img class="tex" alt="\mathrm{erf}\bigl(n/\sqrt{2}\,\bigr)\," src="http://upload.wikimedia.org/math/f/9/b/f9be6bb9366eb6957592702f1aeb8852.png" /></th>
</tr>
<tr>
<td>1</td>
<td>&#160;0.682689492137&#160;</td>
</tr>
<tr>
<td>2</td>
<td>0.954499736104</td>
</tr>
<tr>
<td>3</td>
<td>0.997300203937</td>
</tr>
<tr>
<td>4</td>
<td>0.999936657516</td>
</tr>
<tr>
<td>5</td>
<td>0.999999426697</td>
</tr>
<tr>
<td>6</td>
<td>0.999999998027</td>
</tr>
</table>
<p>The next table gives the reverse relation of sigma multiples corresponding to a few often used values for the area under the bell curve. These values are useful to determine (asymptotic) <a href="/wiki/Confidence_interval" title="Confidence interval">confidence intervals</a> of the specified levels based on normally distributed (or <a href="/wiki/Estimator#Asymptotic_normality" title="Estimator">asymptotically normal</a>) <a href="/wiki/Estimator" title="Estimator">estimators</a>:</p>
<table class="wikitable" style="text-align:center">
<tr bgcolor="#CCCCCC">
<th>&#160;<img class="tex" alt="\mathrm{erf}\bigl(n/\sqrt{2}\,\bigr)" src="http://upload.wikimedia.org/math/f/a/6/fa67ac81cc20ebe494d103dbaf82aa86.png" />&#160;</th>
<th><img class="tex" alt="n\," src="http://upload.wikimedia.org/math/a/9/5/a957404c96e59f1746f97ab668c8e1f8.png" />&#160;</th>
</tr>
<tr>
<td>0.80</td>
<td>&#160;1.28155&#160;</td>
</tr>
<tr>
<td>0.90</td>
<td>1.64485</td>
</tr>
<tr>
<td>0.95</td>
<td>1.95996</td>
</tr>
<tr>
<td>0.98</td>
<td>2.32635</td>
</tr>
<tr>
<td>0.99</td>
<td>2.57583</td>
</tr>
<tr>
<td>0.995</td>
<td>2.80703</td>
</tr>
<tr>
<td>0.998</td>
<td>3.09023</td>
</tr>
<tr>
<td>0.999</td>
<td>3.29052</td>
</tr>
<tr>
<td>0.9999</td>
<td>3.8906</td>
</tr>
<tr>
<td>0.99999</td>
<td>4.4172</td>
</tr>
</table>
<p>where the value on the left of the table is the proportion of values that will fall within a given interval and <i>n</i> is a multiple of the standard deviation that specifies the width of the interval.</p>
<p><a name="Exponential_family_form" id="Exponential_family_form"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=17" title="Edit section: Exponential family form">edit</a>]</span> <span class="mw-headline">Exponential family form</span></h3>
<p>The Normal distribution is a two-parameter <a href="/wiki/Exponential_family" title="Exponential family">exponential family form</a> with natural parameters μ and 1/σ<sup>2</sup>, and natural statistics <i>X</i> and <i>X</i><sup>2</sup>. The canonical form has parameters <img class="tex" alt="{\mu \over \sigma^2}" src="http://upload.wikimedia.org/math/6/6/d/66df9aac994e6a8ea9cc06b1cc0c776f.png" /> and <img class="tex" alt="{1 \over \sigma^2}" src="http://upload.wikimedia.org/math/3/f/e/3fe28694087012d2ba28ab97f4a6b418.png" /> and sufficient statistics <img class="tex" alt="\sum  x " src="http://upload.wikimedia.org/math/3/5/0/350173c119b3d463b62e0b4652b236d4.png" /> and <img class="tex" alt="-{1 \over 2} \sum  x^2. " src="http://upload.wikimedia.org/math/f/3/9/f39d4ac183ef3ac4be54a68ecb60ed0a.png" /></p>
<p><a name="Complex_normal_distribution" id="Complex_normal_distribution"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=18" title="Edit section: Complex normal distribution">edit</a>]</span> <span class="mw-headline">Complex normal distribution</span></h2>
<p>Consider the complex Gaussian random variable,</p>
<dl>
<dd><img class="tex" alt="
Z=X+iY\,
" src="http://upload.wikimedia.org/math/3/8/4/3846c58224f32eb63cb9af01dba206d3.png" /></dd>
</dl>
<p>where <i>X</i> and <i>Y</i> are real and independent Gaussian variables with equal variances <img class="tex" alt="\sigma_r^2" src="http://upload.wikimedia.org/math/4/f/7/4f783b17edc97d759d6310207f15a66d.png" />. The pdf of the joint variables is then</p>
<dl>
<dd><img class="tex" alt="
\frac{1}{2\,\pi\,\sigma_r^2} e^{-(x^2+y^2)/(2 \sigma_r ^2)}.
" src="http://upload.wikimedia.org/math/d/0/5/d05312c0b660c21133cbd2051e941a6c.png" /></dd>
</dl>
<p>Because <img class="tex" alt="\sigma_Z =\sqrt{2}\sigma_r" src="http://upload.wikimedia.org/math/a/d/e/ade3e09463e81ca181a7e1de26468785.png" />, the resulting pdf for the complex Gaussian variable <i>Z</i> is</p>
<dl>
<dd><img class="tex" alt="
\frac{1}{\pi\,\sigma_Z^2} e^{-|Z|^2\!/\sigma_Z^2}.
" src="http://upload.wikimedia.org/math/e/4/c/e4c9a348d522b49bbf13aa15a8698b4d.png" /></dd>
</dl>
<p><a name="Related_distributions" id="Related_distributions"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=19" title="Edit section: Related distributions">edit</a>]</span> <span class="mw-headline">Related distributions</span></h2>
<ul>
<li><img class="tex" alt="R \sim \mathrm{Rayleigh}(\sigma)" src="http://upload.wikimedia.org/math/0/2/d/02d7002654c387c62ce994e6184d8981.png" /> is a <a href="/wiki/Rayleigh_distribution" title="Rayleigh distribution">Rayleigh distribution</a> if <img class="tex" alt="R = \sqrt{X^2 + Y^2}" src="http://upload.wikimedia.org/math/8/2/3/82394d64f910992fbd59654ae09d1016.png" /> where <img class="tex" alt="X \sim N(0, \sigma^2)" src="http://upload.wikimedia.org/math/6/6/3/663420f997d09c583d021ab9e58ce19a.png" /> and <img class="tex" alt="Y \sim N(0, \sigma^2)" src="http://upload.wikimedia.org/math/c/3/c/c3ca752b6a9d81fe356ccfa7c3c9ac52.png" /> are two independent normal distributions.</li>
<li><img class="tex" alt="Y \sim \chi_{\nu}^2" src="http://upload.wikimedia.org/math/2/6/3/263b03672200fc829ba95f4651f1607d.png" /> is a <a href="/wiki/Chi-square_distribution" title="Chi-square distribution">chi-square distribution</a> with <span class="texhtml">ν</span> <a href="/wiki/Degrees_of_freedom_(statistics)" title="Degrees of freedom (statistics)">degrees of freedom</a> if <img class="tex" alt="Y = \sum_{k=1}^{\nu} X_k^2" src="http://upload.wikimedia.org/math/f/8/6/f866c1f5f0db1418fb7c8adae6043808.png" /> where <img class="tex" alt="X_k \sim N(0,1)" src="http://upload.wikimedia.org/math/0/1/7/01725323a7ad5a5ecd9e665083b9b60d.png" /> for <img class="tex" alt="k=1,\dots,\nu" src="http://upload.wikimedia.org/math/3/2/6/3266063c0c346f762ca500127846e0fa.png" /> and are independent.</li>
<li><img class="tex" alt="Y \sim \mathrm{Cauchy}(\mu = 0, \theta = 1)" src="http://upload.wikimedia.org/math/c/0/c/c0ca42785040f031f3094036ee16d583.png" /> is a <a href="/wiki/Cauchy_distribution" title="Cauchy distribution">Cauchy distribution</a> if <span class="texhtml"><i>Y</i> = <i>X</i><sub>1</sub> / <i>X</i><sub>2</sub></span> for <img class="tex" alt="X_1 \sim N(0,1)" src="http://upload.wikimedia.org/math/8/4/e/84ef0edb213a12471be241719be94a67.png" /> and <img class="tex" alt="X_2 \sim N(0,1)" src="http://upload.wikimedia.org/math/1/c/d/1cd0d122818db7b62f37d1ac3fad5ccf.png" /> are two <a href="/wiki/Statistical_independence" title="Statistical independence" class="mw-redirect">independent</a> normal distributions.</li>
</ul>
<ul>
<li><img class="tex" alt="Y \sim \mbox{Log-N}(\mu, \sigma^2)" src="http://upload.wikimedia.org/math/7/8/5/785f015d644c0090f293aa41a051c21c.png" /> is a <a href="/wiki/Log-normal_distribution" title="Log-normal distribution">log-normal distribution</a> if <span class="texhtml"><i>Y</i> = <i>e</i><sup><i>X</i></sup></span> and <img class="tex" alt="X \sim N(\mu, \sigma^2)" src="http://upload.wikimedia.org/math/7/4/4/744888b68a64964aacef3bcd8d6777e7.png" />.</li>
</ul>
<ul>
<li>Relation to <a href="/wiki/Stable_distribution" title="Stable distribution">stable distribution</a>: if <img class="tex" alt="X\sim \textrm{stable}(2,\beta,\sigma/\sqrt{2},\mu)" src="http://upload.wikimedia.org/math/7/9/7/797c142f21a0b58be0c01996377222e0.png" /> then <img class="tex" alt="X \sim N(\mu,\sigma^2)" src="http://upload.wikimedia.org/math/7/4/4/744888b68a64964aacef3bcd8d6777e7.png" />.</li>
</ul>
<ul>
<li><a href="/wiki/Truncated_normal_distribution" title="Truncated normal distribution">Truncated normal distribution</a>. If <img class="tex" alt="X \sim N(\mu, \sigma^2),\!" src="http://upload.wikimedia.org/math/4/b/5/4b5014ecb9e82cc8fcb1fe51d29a3b1b.png" /> then truncating <i>X</i> below at <span class="texhtml"><i>A</i></span> and above at <span class="texhtml"><i>B</i></span> will lead to a random variable with mean <img class="tex" alt="E(X)=\mu + \frac{\sigma(\varphi_1-\varphi_2)}{T},\!" src="http://upload.wikimedia.org/math/3/3/8/338ea5f5da32ea4e8c66715f472d014d.png" /> where <img class="tex" alt="T=\Phi\left(\frac{B-\mu}{\sigma}\right)-\Phi\left(\frac{A-\mu}{\sigma}\right), \; \varphi_1 = \varphi\left(\frac{A-\mu}{\sigma}\right), \; \varphi_2 = \varphi\left(\frac{B-\mu}{\sigma}\right)" src="http://upload.wikimedia.org/math/d/5/8/d585042effa2995bbdde4f98076d6e4f.png" /> and <img class="tex" alt="\varphi" src="http://upload.wikimedia.org/math/3/5/3/3538eb9c84efdcbd130c4c953781cfdb.png" /> is the <a href="/wiki/Probability_density_function" title="Probability density function">probability density function</a> of a standard normal random variable.</li>
</ul>
<ul>
<li>If <span class="texhtml"><i>X</i></span> is a random variable with a normal distribution, and <span class="texhtml"><i>Y</i> = | <i>X</i> |</span> , then <span class="texhtml"><i>Y</i></span> has a <a href="/wiki/Folded_normal_distribution" title="Folded normal distribution">folded normal distribution</a>.</li>
</ul>
<p><a name="Descriptive_and_inferential_statistics" id="Descriptive_and_inferential_statistics"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=20" title="Edit section: Descriptive and inferential statistics">edit</a>]</span> <span class="mw-headline">Descriptive and inferential statistics</span></h2>
<p><a name="Scores" id="Scores"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=21" title="Edit section: Scores">edit</a>]</span> <span class="mw-headline">Scores</span></h3>
<p>Many scores are derived from the normal distribution, including <a href="/wiki/Percentile_rank" title="Percentile rank">percentile ranks</a> ("percentiles" or "quantiles"), <a href="/wiki/Normal_curve_equivalent" title="Normal curve equivalent">normal curve equivalents</a>, <a href="/wiki/Stanine" title="Stanine">stanines</a>, <a href="/wiki/Standard_score" title="Standard score">z-scores</a>, and T-scores. Additionally, a number of behavioral <a href="/wiki/Statistics" title="Statistics">statistical</a> procedures are based on the assumption that scores are normally distributed; for example, <a href="/wiki/Student%27s_t-test" title="Student's t-test">t-tests</a> and <a href="/wiki/Analysis_of_variance" title="Analysis of variance">ANOVAs</a> (see below). <a href="/wiki/Bell_curve_grading" title="Bell curve grading">Bell curve grading</a> assigns relative grades based on a normal distribution of scores.</p>
<table class="metadata plainlinks ambox mbox-small-left ambox-notice" style="margin: 4px 1em 4px 0; width: 238px; border-collapse: collapse; font-size: 88%; line-height: 1.25em;">
<tr>
<td class="mbox-image"><a href="/wiki/File:Wiki_letter_w.svg" class="image" title="Wiki letter w.svg"><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Wiki_letter_w.svg/20px-Wiki_letter_w.svg.png" width="20" height="20" border="0" /></a></td>
<td class="mbox-text" style="">This section requires <a href="http://en.wikipedia.org/w/index.php?title=Normal_distribution&amp;action=edit" class="external text" title="http://en.wikipedia.org/w/index.php?title=Normal_distribution&amp;action=edit" rel="nofollow">expansion</a>.</td>
</tr>
</table>
<p><a name="Normality_tests" id="Normality_tests"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=22" title="Edit section: Normality tests">edit</a>]</span> <span class="mw-headline">Normality tests</span></h3>
<div class="rellink noprint relarticle mainarticle">Main article: <a href="/wiki/Normality_test" title="Normality test">normality test</a></div>
<p>Normality tests check a given set of data for similarity to the normal distribution. The <a href="/wiki/Null_hypothesis" title="Null hypothesis">null hypothesis</a> is that the data set is similar to the normal distribution, therefore a sufficiently small <a href="/wiki/P-value" title="P-value">P-value</a> indicates non-normal data.</p>
<ul>
<li><a href="/wiki/Kolmogorov%E2%80%93Smirnov_test" title="Kolmogorov–Smirnov test">Kolmogorov–Smirnov test</a></li>
<li><a href="/wiki/Lilliefors_test" title="Lilliefors test">Lilliefors test</a></li>
<li><a href="/wiki/Anderson%E2%80%93Darling_test" title="Anderson–Darling test">Anderson–Darling test</a></li>
<li><a href="/w/index.php?title=Ryan%E2%80%93Joiner_test&amp;action=edit&amp;redlink=1" class="new" title="Ryan–Joiner test (page does not exist)">Ryan–Joiner test</a></li>
<li><a href="/wiki/Shapiro%E2%80%93Wilk_test" title="Shapiro–Wilk test">Shapiro–Wilk test</a></li>
<li><a href="/wiki/Normal_probability_plot" title="Normal probability plot">Normal probability plot</a> (<a href="/wiki/Rankit" title="Rankit">rankit</a> plot)</li>
<li><a href="/wiki/Jarque%E2%80%93Bera_test" title="Jarque–Bera test">Jarque–Bera test</a></li>
<li><a href="/w/index.php?title=Spiegelhalter%27s_omnibus_test&amp;action=edit&amp;redlink=1" class="new" title="Spiegelhalter's omnibus test (page does not exist)">Spiegelhalter's omnibus test</a></li>
</ul>
<p><a name="Estimation_of_parameters" id="Estimation_of_parameters"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=23" title="Edit section: Estimation of parameters">edit</a>]</span> <span class="mw-headline">Estimation of parameters</span></h3>
<p><a name="Maximum_likelihood_estimation_of_parameters" id="Maximum_likelihood_estimation_of_parameters"></a></p>
<h4><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=24" title="Edit section: Maximum likelihood estimation of parameters">edit</a>]</span> <span class="mw-headline">Maximum likelihood estimation of parameters</span></h4>
<p>Suppose</p>
<dl>
<dd><img class="tex" alt="X_1,\dots,X_n" src="http://upload.wikimedia.org/math/e/8/e/e8eacc087b64e56391a3b8ddf4216d77.png" /></dd>
</dl>
<p>are <a href="/wiki/Statistical_independence" title="Statistical independence" class="mw-redirect">independent</a> and each is normally distributed with expectation <i>μ</i> and variance <i>σ</i><sup>&#160;2</sup> &gt; 0. In the language of statisticians, the observed values of these <i>n</i> random variables make up a "sample of size <i>n</i> from a normally distributed population." It is desired to estimate the "population mean" <i>μ</i> and the "population standard deviation" <i>σ</i>, based on the observed values of this sample. The continuous joint probability density function of these <i>n</i> independent random variables is</p>
<dl>
<dd><img class="tex" alt="\begin{align}f(x_1,\dots,x_n;\mu,\sigma)
&amp;= \prod_{i=1}^n \varphi_{\mu,\sigma^2}(x_i)\\
&amp;=\frac1{(\sigma\sqrt{2\pi})^n}\prod_{i=1}^n \exp\biggl(-{1 \over 2} \Bigl({x_i-\mu \over \sigma}\Bigr)^2\biggr),
\quad(x_1,\ldots,x_n)\in\mathbb{R}^n.
\end{align}
" src="http://upload.wikimedia.org/math/1/e/f/1ef5fd09c4942300b6edf89167412ab6.png" /></dd>
</dl>
<p>As a function of <i>μ</i> and <i>σ</i>, the <a href="/wiki/Likelihood_function" title="Likelihood function">likelihood function</a> based on the observations <i>X</i><sub>1</sub>, ..., <i>X</i><sub><i>n</i></sub> is</p>
<dl>
<dd><img class="tex" alt="
L(\mu,\sigma) = \frac C{\sigma^n} \exp\left(-{\sum_{i=1}^n (X_i-\mu)^2 \over 2\sigma^2}\right),
\quad\mu\in\mathbb{R},\ \sigma&gt;0,
" src="http://upload.wikimedia.org/math/9/6/6/9661f489fcefc8c08551fadfa03f1108.png" /></dd>
</dl>
<p>with some constant <i>C</i> &gt; 0 (which in general would be even allowed to depend on <i>X</i><sub>1</sub>, ..., <i>X</i><sub><i>n</i></sub>, but will vanish anyway when partial derivatives of the log-likelihood function with respect to the parameters are computed, see below).</p>
<p>In the method of <a href="/wiki/Maximum_likelihood" title="Maximum likelihood">maximum likelihood</a>, the values of <i>μ</i> and <i>σ</i> that maximize the likelihood function are taken as estimates of the population parameters <i>μ</i> and <i>σ</i>.</p>
<p>Usually in maximizing a function of two variables, one might consider <a href="/wiki/Partial_derivative" title="Partial derivative">partial derivatives</a>. But here we will exploit the fact that the value of <i>μ</i> that maximizes the likelihood function with <i>σ</i> fixed does not depend on <i>σ</i>. Therefore, we can find that value of <i>μ</i>, then substitute it for <i>μ</i> in the likelihood function, and finally find the value of <i>σ</i> that maximizes the resulting expression.</p>
<p>It is evident that the likelihood function is a decreasing function of the sum</p>
<dl>
<dd><img class="tex" alt="\sum_{i=1}^n (X_i-\mu)^2. \,\!" src="http://upload.wikimedia.org/math/d/c/d/dcdb239464bff0c2e7116c297542fd6f.png" /></dd>
</dl>
<p>So we want the value of <i>μ</i> that <i>minimizes</i> this sum. Let</p>
<dl>
<dd><img class="tex" alt="\overline{X}_n=(X_1+\cdots+X_n)/n" src="http://upload.wikimedia.org/math/0/9/9/099f51351a0745068723b888b290803c.png" /></dd>
</dl>
<p>be the "sample mean" based on the <i>n</i> observations. Observe that</p>
<dl>
<dd><img class="tex" alt="
\begin{align}
\sum_{i=1}^n (X_i-\mu)^2
&amp;=\sum_{i=1}^n\bigl((X_i-\overline{X}_n)+(\overline{X}_n-\mu)\bigr)^2\\
&amp;=\sum_{i=1}^n(X_i-\overline{X}_n)^2 + 2(\overline{X}_n-\mu)\underbrace{\sum_{i=1}^n (X_i-\overline{X}_n)}_{=\,0} + \sum_{i=1}^n (\overline{X}_n-\mu)^2\\
&amp;=\sum_{i=1}^n(X_i-\overline{X}_n)^2 + n(\overline{X}_n-\mu)^2.
\end{align}
" src="http://upload.wikimedia.org/math/0/e/3/0e373807170105a24cfaaa4742d92c46.png" /></dd>
</dl>
<p>Only the last term depends on <i>μ</i> and it is minimized by</p>
<dl>
<dd><img class="tex" alt="\widehat{\mu}_n=\overline{X}_n." src="http://upload.wikimedia.org/math/c/7/d/c7d6e35b614f7bd59400bddb5dbc7c5a.png" /></dd>
</dl>
<p>That is the maximum-likelihood estimate of <i>μ</i> based on the <i>n</i> observations <i>X</i><sub>1</sub>, ..., <i>X</i><sub><i>n</i></sub>. When we substitute that estimate for <i>μ</i> into the likelihood function, we get</p>
<dl>
<dd><img class="tex" alt="L(\overline{X}_n,\sigma) = \frac C{\sigma^n} \exp\biggl(-{\sum_{i=1}^n (X_i-\overline{X}_n)^2 \over 2\sigma^2}\biggr),
\quad\sigma&gt;0." src="http://upload.wikimedia.org/math/1/8/5/185f223ff69fcf06c2d9a472cfcb8d32.png" /></dd>
</dl>
<p>It is conventional to denote the "log-likelihood function", i.e., the logarithm of the likelihood function, by a lower-case <i>ℓ</i>, and we have</p>
<dl>
<dd><img class="tex" alt="\ell(\overline{X}_n,\sigma)=\log C-n\log\sigma-{\sum_{i=1}^n(X_i-\overline{X}_n)^2 \over 2\sigma^2},
\quad\sigma&gt;0," src="http://upload.wikimedia.org/math/c/a/0/ca0731f310bc4a80c60ae04c46bf97df.png" /></dd>
</dl>
<p>and then</p>
<dl>
<dd><img class="tex" alt="
\begin{align}
{\partial \over \partial\sigma}\ell(\overline{X}_n,\sigma)
&amp;=-{n \over \sigma} +{\sum_{i=1}^n (X_i-\overline{X}_n)^2 \over \sigma^3}\\
&amp;=-{n \over \sigma^3}\biggl(\sigma^2-{1 \over n}\sum_{i=1}^n (X_i-\overline{X}_n)^2 \biggr),
\quad\sigma&gt;0.
\end{align}
" src="http://upload.wikimedia.org/math/3/b/3/3b349f10f4c462a40cc60c7020090276.png" /></dd>
</dl>
<p>This derivative is positive, zero, or negative according as <i>σ</i><sup>2</sup> is between 0 and</p>
<dl>
<dd><img class="tex" alt="\hat\sigma_n^2:={1 \over n}\sum_{i=1}^n(X_i-\overline{X}_n)^2," src="http://upload.wikimedia.org/math/f/6/1/f6162edb59042594e6066c09affff7bb.png" /></dd>
</dl>
<p>or equal to that quantity, or greater than that quantity. (If there is just one observation, meaning that <i>n</i> = 1, or if <i>X</i><sub>1</sub> = ... = <i>X</i><sub><i>n</i></sub>, which only happens with probability zero, then <img class="tex" alt="\hat\sigma{}_n^2=0" src="http://upload.wikimedia.org/math/8/b/4/8b4b446d7733e9cf3104fa34d09f239d.png" /> by this formula, reflecting the fact that in these cases the likelihood function is unbounded as <i>σ</i> decreases to zero.)</p>
<p>Consequently this average of squares of <a href="/wiki/Errors_and_residuals_in_statistics" title="Errors and residuals in statistics">residuals</a> is the maximum-likelihood estimate of <i>σ</i><sup>2</sup>, and its square root is the maximum-likelihood estimate of <i>σ</i> based on the <i>n</i> observations. This estimator <img class="tex" alt="\hat\sigma{}_n^2" src="http://upload.wikimedia.org/math/8/d/e/8dea9ba052f2685db2327ec200daa5b8.png" /> is <a href="/wiki/Estimator_bias" title="Estimator bias" class="mw-redirect">biased</a>, but has a smaller <a href="/wiki/Mean_squared_error" title="Mean squared error">mean squared error</a> than the usual unbiased estimator, which is <i>n</i>/(<i>n</i>&#160;−&#160;1) times this estimator.</p>
<p><a name="Surprising_generalization" id="Surprising_generalization"></a></p>
<h5><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=25" title="Edit section: Surprising generalization">edit</a>]</span> <span class="mw-headline">Surprising generalization</span></h5>
<p>The derivation of the maximum-likelihood estimator of the <a href="/wiki/Covariance_matrix" title="Covariance matrix">covariance matrix</a> of a <a href="/wiki/Multivariate_normal_distribution" title="Multivariate normal distribution">multivariate normal distribution</a> is subtle. It involves the <a href="/wiki/Spectral_theorem" title="Spectral theorem">spectral theorem</a> and the reason it can be better to view a <a href="/wiki/Scalar_(mathematics)" title="Scalar (mathematics)">scalar</a> as the <a href="/wiki/Trace_(linear_algebra)" title="Trace (linear algebra)">trace</a> of a 1×1 <a href="/wiki/Matrix_(mathematics)" title="Matrix (mathematics)">matrix</a> than as a mere scalar. See <a href="/wiki/Estimation_of_covariance_matrices" title="Estimation of covariance matrices">estimation of covariance matrices</a>.</p>
<p><a name="Unbiased_estimation_of_parameters" id="Unbiased_estimation_of_parameters"></a></p>
<h4><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=26" title="Edit section: Unbiased estimation of parameters">edit</a>]</span> <span class="mw-headline">Unbiased estimation of parameters</span></h4>
<p>The maximum likelihood estimator of the population mean <i>μ</i> from a sample is an <a href="/wiki/Unbiased_estimator" title="Unbiased estimator" class="mw-redirect">unbiased estimator</a> of the mean. The maximum likelihood estimator of the variance is unbiased if we assume the population is known <i>a priori</i>, but in practice that does not happen. However, if we are faced with a sample and have no knowledge of the mean or the variance of the population from which it is drawn, as assumed in the maximum likelihood derivation above, then the maximum likelihood estimator of the variance is biased. An unbiased estimator of the variance <i>σ</i><sup>2</sup> is:</p>
<dl>
<dd><img class="tex" alt="
S^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X})^2.
" src="http://upload.wikimedia.org/math/0/d/e/0debce5d084f617b4cd82f2278eef7fd.png" /></dd>
</dl>
<p>This "sample variance" follows a <a href="/wiki/Gamma_distribution" title="Gamma distribution">Gamma distribution</a> if all <i>X</i><sub><i>i</i></sub> are <a href="/wiki/Independent_and_identically-distributed_random_variables" title="Independent and identically-distributed random variables">independent and identically-distributed</a>:</p>
<dl>
<dd><img class="tex" alt="
S^2 \sim \operatorname{Gamma}\left(\frac{n-1}{2},\frac{2 \sigma^2}{n-1}\right),
" src="http://upload.wikimedia.org/math/4/2/5/4258ef8f4e9bd14fb642dd3c2aafb6f0.png" /></dd>
</dl>
<p>with mean <img class="tex" alt="\operatorname{E}(S^2)=\sigma^2" src="http://upload.wikimedia.org/math/3/8/7/38727d7695142ea80320cdf3c0336ec8.png" /> and variance <img class="tex" alt="\operatorname{Var}(S^2)=2\sigma^4/(n-1)." src="http://upload.wikimedia.org/math/d/5/2/d5202d8e43eb6163eeda83b90dadd347.png" /></p>
<p>The maximum likelihood estimate of the standard deviation is the square root of the maximum likelihood estimate of the variance. However, neither this nor the square root of the sample variance provides an unbiased estimate for standard deviation: see <a href="/wiki/Unbiased_estimation_of_standard_deviation" title="Unbiased estimation of standard deviation">unbiased estimation of standard deviation</a> for formulae particular to the normal distribution.</p>
<p><a name="Occurrence" id="Occurrence"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=27" title="Edit section: Occurrence">edit</a>]</span> <span class="mw-headline">Occurrence</span></h2>
<p><i>Approximately</i> normal distributions occur in many situations, as explained by the <a href="/wiki/Central_limit_theorem" title="Central limit theorem">central limit theorem</a>. When there is reason to suspect the presence of a large number of small effects <i>acting additively and independently</i>, it is reasonable to assume that observations will be normal. There are statistical methods to empirically test that assumption, for example the <a href="/wiki/Kolmogorov-Smirnov_test" title="Kolmogorov-Smirnov test" class="mw-redirect">Kolmogorov-Smirnov test</a>.</p>
<p>Effects can also act as <i>multiplicative</i> (rather than additive) modifications. In that case, the assumption of normality is not justified, and it is the <a href="/wiki/Logarithm" title="Logarithm">logarithm</a> of the variable of interest that is normally distributed. The distribution of the directly observed variable is then called <a href="/wiki/Log-normal_distribution" title="Log-normal distribution">log-normal</a>.</p>
<p>Finally, if there is a single external influence which has a large effect on the variable under consideration, the assumption of normality is not justified either. This is true even if, when the external variable is held constant, the resulting marginal distributions are indeed normal. The full distribution will be a superposition of normal variables, which is not in general normal. This is related to the theory of errors (see below).</p>
<p>To summarize, here is a list of situations where approximate normality is sometimes assumed. For a fuller discussion, see below.</p>
<ul>
<li>In counting problems, where the <a href="/wiki/Central_limit_theorem" title="Central limit theorem">central limit theorem</a> includes a discrete-to-continuum approximation and where <a href="/wiki/Infinite_divisibility" title="Infinite divisibility">infinitely divisible</a> and <a href="/wiki/Indecomposable_distribution" title="Indecomposable distribution">decomposable</a> distributions are involved, such as
<ul>
<li><a href="/wiki/Binomial_distribution" title="Binomial distribution">Binomial random variables</a>, associated with yes/no questions;</li>
<li><a href="/wiki/Poisson_distribution" title="Poisson distribution">Poisson random variables</a>, associated with <a href="/w/index.php?title=Rare_event&amp;action=edit&amp;redlink=1" class="new" title="Rare event (page does not exist)">rare events</a>;</li>
</ul>
</li>
<li>In physiological measurements of biological specimens:
<ul>
<li>The <i>logarithm</i> of measures of size of living tissue (length, height, skin area, weight);</li>
<li>The <i>length</i> of <i>inert</i> appendages (hair, claws, nails, teeth) of biological specimens, <i>in the direction of growth</i>; presumably the thickness of tree bark also falls under this category;</li>
<li>Other physiological measures may be normally distributed, but there is no reason to expect that <i>a priori</i>;</li>
</ul>
</li>
<li>Measurement errors are often <i>assumed</i> to be normally distributed, and any deviation from normality is considered something which should be explained;</li>
<li>Financial variables, in the <a href="/wiki/Black%E2%80%93Scholes_model" title="Black–Scholes model" class="mw-redirect">Black–Scholes model</a>
<ul>
<li>Changes in the <i>logarithm</i> of exchange rates, price indices, and stock market indices; these variables behave like compound interest, not like simple interest, and so are multiplicative;</li>
<li>While the Black–Scholes model assumes normality, in reality these variables exhibit <a href="/wiki/Heavy_tails" title="Heavy tails" class="mw-redirect">heavy tails</a>, as seen in <a href="/wiki/Stock_market_crash" title="Stock market crash">stock market crashes</a>;</li>
<li>Other financial variables may be normally distributed, but there is no reason to expect that <i>a priori</i>;</li>
</ul>
</li>
<li>Light intensity
<ul>
<li>The intensity of laser light is normally distributed;</li>
<li>Thermal light has a <a href="/wiki/Bose%E2%80%93Einstein_statistics" title="Bose–Einstein statistics">Bose–Einstein</a> distribution on very short time scales, and a normal distribution on longer timescales due to the central limit theorem.</li>
</ul>
</li>
</ul>
<p>Of relevance to biology and economics is the fact that complex systems tend to display <a href="/wiki/Power_law" title="Power law">power laws</a> rather than normality.</p>
<p><a name="Photon_counting" id="Photon_counting"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=28" title="Edit section: Photon counting">edit</a>]</span> <span class="mw-headline">Photon counting</span></h3>
<p>Light intensity from a single source varies with time, as thermal fluctuations can be observed if the light is analyzed at sufficiently high time resolution. Quantum mechanics interprets measurements of light intensity as <a href="/wiki/Photon" title="Photon">photon</a> counting, where the natural assumption is to use the <a href="/wiki/Poisson_distribution" title="Poisson distribution">Poisson distribution</a>. When light intensity is integrated over large times longer than the coherence time, the Poisson-to-normal approximation is appropriate.</p>
<p><a name="Measurement_errors" id="Measurement_errors"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=29" title="Edit section: Measurement errors">edit</a>]</span> <span class="mw-headline">Measurement errors</span></h3>
<p>Normality is the <i>central <b>assumption</b></i> of the mathematical <a href="/wiki/Theory_of_errors" title="Theory of errors" class="mw-redirect">theory of errors</a>. Similarly, in statistical model-fitting, an indicator of goodness of fit is that the <a href="/wiki/Errors_and_residuals_in_statistics" title="Errors and residuals in statistics">residuals</a> (as the errors are called in that setting) be independent and normally distributed. The assumption is that any deviation from normality needs to be explained. In that sense, both in model-fitting and in the theory of errors, normality is the only observation that need not be explained, being expected. However, if the original data are not normally distributed (for instance if they follow a <a href="/wiki/Cauchy_distribution" title="Cauchy distribution">Cauchy distribution</a>), then the residuals will also not be normally distributed. This fact is usually ignored in practice.</p>
<p>Repeated measurements of the same quantity are expected to yield results which are clustered around a particular value. If all major sources of errors have been taken into account, it is <i>assumed</i> that the remaining error must be the result of a large number of very small <i>additive</i> effects, and hence normal. Deviations from normality are interpreted as indications of systematic errors which have not been taken into account. Whether this assumption is valid is debatable.</p>
<p>A famous and oft-quoted remark attributed to <a href="/wiki/Gabriel_Lippmann" title="Gabriel Lippmann">Gabriel Lippmann</a> says: "Everyone believes in the [normal] law of errors: the mathematicians, because they think it is an experimental fact; and the experimenters, because they suppose it is a theorem of mathematics."<sup class="noprint Template-Fact"><span title="This claim needs references to reliable sources&#160;since February 2008" style="white-space: nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed">citation needed</a></i>]</span></sup> Another source may be <a href="http://en.wikiquote.org/wiki/Henri_Poincaré#Misattributed" class="external text" title="http://en.wikiquote.org/wiki/Henri_Poincaré#Misattributed" rel="nofollow">Henri Poincaré</a>.</p>
<p><a name="Physical_characteristics_of_biological_specimens" id="Physical_characteristics_of_biological_specimens"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=30" title="Edit section: Physical characteristics of biological specimens">edit</a>]</span> <span class="mw-headline">Physical characteristics of biological specimens</span></h3>
<p>The sizes of full-grown animals is approximately <a href="/wiki/Lognormal" title="Lognormal" class="mw-redirect">lognormal</a>. The evidence and an explanation based on models of growth was first published in the 1932 book <i><a href="/w/index.php?title=Problems_of_Relative_Growth&amp;action=edit&amp;redlink=1" class="new" title="Problems of Relative Growth (page does not exist)">Problems of Relative Growth</a></i> by <a href="/wiki/Julian_Huxley" title="Julian Huxley">Julian Huxley</a>.</p>
<p>Differences in size due to sexual dimorphism, or other polymorphisms like the worker/soldier/queen division in social insects, further make the distribution of sizes deviate from lognormality.</p>
<p>The assumption that linear size of biological specimens is normal (rather than lognormal) leads to a non-normal distribution of weight (since weight or volume is roughly proportional to the 2nd or 3rd power of length, and Gaussian distributions are only preserved by linear transformations), and conversely assuming that weight is normal leads to non-normal lengths. This is a problem, because there is no <i>a priori</i> reason why one of length, or body mass, and not the other, should be normally distributed. Lognormal distributions, on the other hand, are preserved by powers so the "problem" goes away if lognormality is assumed.</p>
<p>On the other hand, there are some biological measures where normality is assumed, such as blood pressure of adult humans. This is supposed to be normally distributed, but only after separating males and females into different populations (each of which is normally distributed).</p>
<p><a name="Financial_variables" id="Financial_variables"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=31" title="Edit section: Financial variables">edit</a>]</span> <span class="mw-headline">Financial variables</span></h3>
<div class="thumb tright">
<div class="thumbinner" style="width:182px;"><a href="/wiki/File:Crowd_outside_nyse.jpg" class="image" title="The normal model of asset price movements does not capture extreme movements such as stock market crashes."><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e1/Crowd_outside_nyse.jpg/180px-Crowd_outside_nyse.jpg" width="180" height="250" border="0" class="thumbimage" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="/wiki/File:Crowd_outside_nyse.jpg" class="internal" title="Enlarge"><img src="/skins-1.5/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
The normal model of asset price movements does not capture extreme movements such as <a href="/wiki/Stock_market_crashes" title="Stock market crashes" class="mw-redirect">stock market crashes</a>.</div>
</div>
</div>
<p>Already in 1900 <a href="/wiki/Louis_Bachelier" title="Louis Bachelier">Louis Bachelier</a> proposed representing price changes of <a href="/wiki/Stock" title="Stock">stocks</a> using the normal distribution. This approach has since been modified slightly. Because of the multiplicative nature of <a href="/wiki/Compound_interest" title="Compound interest">compounding</a> of returns, financial indicators such as <a href="/wiki/Stock" title="Stock">stock</a> values and <a href="/wiki/Commodity" title="Commodity">commodity</a> <a href="/wiki/Price" title="Price">prices</a> exhibit "multiplicative behavior". As such, their periodic changes (e.g., yearly changes) are not normal, but rather <a href="/wiki/Lognormal" title="Lognormal" class="mw-redirect">lognormal</a> - i.e. <i>logarithmic returns</i> as opposed to values are normally distributed. This is still the most commonly used hypothesis in <a href="/wiki/Finance" title="Finance">finance</a>, in particular in <a href="/wiki/Option_pricing" title="Option pricing" class="mw-redirect">option pricing</a> in the <a href="/wiki/Black%E2%80%93Scholes_model" title="Black–Scholes model" class="mw-redirect">Black–Scholes model</a>.</p>
<p>However, in reality financial variables exhibit <a href="/wiki/Heavy_tails" title="Heavy tails" class="mw-redirect">heavy tails</a>, and thus the assumption of normality understates the probability of extreme events such as <a href="/wiki/Stock_market_crashes" title="Stock market crashes" class="mw-redirect">stock market crashes</a>. Corrections to this model have been suggested by mathematicians such as <a href="/wiki/Beno%C3%AEt_Mandelbrot" title="Benoît Mandelbrot">Benoît Mandelbrot</a>, who observed that the changes in logarithm over short periods (such as a day) are approximated well by distributions that do not have a finite variance, and therefore the central limit theorem does not apply. Rather, the sum of many such changes gives <a href="/wiki/Levy_skew_alpha-stable_distribution" title="Levy skew alpha-stable distribution" class="mw-redirect">log-Levy distributions</a>.</p>
<p><a name="Distribution_in_testing_and_intelligence" id="Distribution_in_testing_and_intelligence"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=32" title="Edit section: Distribution in testing and intelligence">edit</a>]</span> <span class="mw-headline">Distribution in testing and intelligence</span></h3>
<p>Sometimes, the difficulty and number of questions on an <a href="/wiki/Intelligence_quotient" title="Intelligence quotient">IQ</a> test is selected in order to yield normal distributed results. Or else, the raw test scores are converted to IQ values by fitting them to the normal distribution. In either case, it is the deliberate result of test construction or score interpretation that leads to IQ scores being normally distributed for the majority of the population. However, the question whether <i><a href="/wiki/Intelligence_(trait)" title="Intelligence (trait)" class="mw-redirect">intelligence</a></i> itself is normally distributed is more involved, because <a href="/wiki/Intelligence_(trait)" title="Intelligence (trait)" class="mw-redirect">intelligence</a> is a <a href="/wiki/Latent_variable" title="Latent variable">latent variable</a>, therefore its distribution cannot be observed directly.</p>
<p><a name="Diffusion_equation" id="Diffusion_equation"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=33" title="Edit section: Diffusion equation">edit</a>]</span> <span class="mw-headline">Diffusion equation</span></h3>
<p>The probability density function of the normal distribution is closely related to the (homogeneous and isotropic) <a href="/wiki/Diffusion_equation" title="Diffusion equation">diffusion equation</a> and therefore also to the <a href="/wiki/Heat_equation" title="Heat equation">heat equation</a>. This <a href="/wiki/Partial_differential_equation" title="Partial differential equation">partial differential equation</a> describes the time evolution of a mass-density function under <a href="/wiki/Diffusion" title="Diffusion" class="mw-redirect">diffusion</a>. In particular, the probability density function</p>
<dl>
<dd><img class="tex" alt="\varphi_{0,t}(x) = \frac{1}{\sqrt{2\pi t\,}}\exp\left(-\frac{x^2}{2t}\right), " src="http://upload.wikimedia.org/math/c/0/d/c0de21d71d17c3edd21266854b305a4f.png" /></dd>
</dl>
<p>for the normal distribution with expected value 0 and variance <i>t</i> satisfies the diffusion equation:</p>
<dl>
<dd><img class="tex" alt=" \frac{\partial}{\partial t} \varphi_{0,t}(x) = \frac{1}{2} \frac{\partial^2}{\partial x^2} \varphi_{0,t}(x). " src="http://upload.wikimedia.org/math/0/6/1/0614c1455b4bef4b914153a570f7b460.png" /></dd>
</dl>
<p>If the mass-density at time <i>t</i>&#160;=&#160;0 is given by a <a href="/wiki/Dirac_delta" title="Dirac delta" class="mw-redirect">Dirac delta</a>, which essentially means that all mass is initially concentrated in a single point, then the mass-density function at time <i>t</i> will have the form of the normal probability density function with variance linearly growing with <i>t</i>. This connection is no coincidence: diffusion is due to <a href="/wiki/Brownian_motion" title="Brownian motion">Brownian motion</a> which is mathematically described by a <a href="/wiki/Wiener_process" title="Wiener process">Wiener process</a>, and such a process at time <i>t</i> will also result in a normal distribution with variance linearly growing with <i>t</i>.</p>
<p>More generally, if the initial mass-density is given by a function φ(<i>x</i>), then the mass-density at time <i>t</i> will be given by the <a href="/wiki/Convolution" title="Convolution">convolution</a> of φ and a normal probability density function.</p>
<p><a name="Use_in_computational_statistics" id="Use_in_computational_statistics"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=34" title="Edit section: Use in computational statistics">edit</a>]</span> <span class="mw-headline">Use in computational statistics</span></h2>
<p>The normal distribution arises in many areas of <a href="/wiki/Statistics" title="Statistics">statistics</a>. For example, the <a href="/wiki/Sampling_distribution" title="Sampling distribution">sampling distribution</a> of the <a href="/wiki/Sample_mean" title="Sample mean" class="mw-redirect">sample mean</a> is approximately normal, even if the distribution of the population from which the sample is taken is not normal. In addition, the normal distribution maximizes <a href="/wiki/Information_entropy" title="Information entropy" class="mw-redirect">information entropy</a> among all distributions with known mean and variance, which makes it the natural choice of underlying distribution for data summarized in terms of sample mean and variance. The normal distribution is the most widely used family of distributions in statistics and many statistical tests are based on the assumption of normality.</p>
<p><a name="Generating_values_for_normal_random_variables" id="Generating_values_for_normal_random_variables"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=35" title="Edit section: Generating values for normal random variables">edit</a>]</span> <span class="mw-headline">Generating values for normal random variables</span></h3>
<p>For computer simulations, it is often useful to generate values that have a normal distribution. There are several methods and the most basic is to invert the standard normal cdf. More efficient methods are also known, one such method being the <a href="/wiki/Box-Muller_transform" title="Box-Muller transform" class="mw-redirect">Box-Muller transform</a>. An even faster algorithm is the <a href="/wiki/Ziggurat_algorithm" title="Ziggurat algorithm">ziggurat algorithm</a>. These are discussed below. A simple approach that is easy to program is as follows. Simply sum 12 uniform (0,1) deviates and subtract 6 (half of 12). This is quite usable in many applications. The sum over these 12 values has an <a href="/wiki/Irwin-Hall_distribution" title="Irwin-Hall distribution">Irwin-Hall distribution</a>; 12 is chosen to give the sum a variance of exactly one. The resulting random deviates are limited to the range (−6,&#160;6) and have a density which is a 12-section eleventh-order polynomial approximation to the normal distribution.<sup id="cite_ref-7" class="reference"><a href="#cite_note-7" title=""><span>[</span>8<span>]</span></a></sup></p>
<p>The <a href="/wiki/Box-Muller_transform" title="Box-Muller transform" class="mw-redirect">Box-Muller method</a> says that, if you have two independent random numbers <i>U</i> and <i>V</i> <a href="/wiki/Uniform_distribution" title="Uniform distribution">uniformly distributed</a> on (0, 1], (e.g. the output from a <a href="/wiki/Random_number_generator" title="Random number generator" class="mw-redirect">random number generator</a>), then two independent standard normally distributed random variables are <i>X</i> and <i>Y</i>, where:</p>
<dl>
<dd><img class="tex" alt="X = \sqrt{- 2 \ln U} \, \cos(2 \pi V) ," src="http://upload.wikimedia.org/math/3/8/9/389f2f8e442d31446125137013bcdf74.png" /></dd>
</dl>
<dl>
<dd><img class="tex" alt="Y = \sqrt{- 2 \ln U} \, \sin(2 \pi V) ." src="http://upload.wikimedia.org/math/9/a/d/9ad7e807b2e70220e436d5af971663b7.png" /></dd>
</dl>
<p>This formulation arises because the chi-square distribution with two degrees of freedom (see property 4 above) is an easily-generated <a href="/wiki/Exponential_distribution" title="Exponential distribution">exponential</a> random variable (which corresponds to the quantity ln<i>U</i> in these equations). Thus an angle is chosen uniformly around the circle via the random variable <i>V</i>, a radius is chosen to be exponential and then transformed to (normally distributed) <i>x</i> and <i>y</i> coordinates.</p>
<p>A method that is much faster than the Box-Muller transform but which is still exact is the so-called <a href="/wiki/Ziggurat_algorithm" title="Ziggurat algorithm">Ziggurat algorithm</a> developed by <a href="/wiki/George_Marsaglia" title="George Marsaglia">George Marsaglia</a>. In about 97% of all cases it uses only two random numbers, one random integer and one random uniform, one multiplication and an if-test. Only in 3% of the cases where the combination of those two falls outside the "core of the ziggurat" a kind of rejection sampling using logarithms, exponentials and more uniform random numbers has to be employed.</p>
<p>There is also some investigation into the connection between the fast <a href="/wiki/Hadamard_transform" title="Hadamard transform">Hadamard transform</a> and the normal distribution, since the transform employs just addition and subtraction and by the central limit theorem random numbers from almost any distribution will be transformed into the normal distribution. In this regard a series of Hadamard transforms can be combined with random permutations to turn arbitrary data sets into a normally-distributed data.</p>
<p><a name="Numerical_approximations_of_the_normal_distribution_and_its_cdf" id="Numerical_approximations_of_the_normal_distribution_and_its_cdf"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=36" title="Edit section: Numerical approximations of the normal distribution and its cdf">edit</a>]</span> <span class="mw-headline">Numerical approximations of the normal distribution and its cdf</span></h3>
<p>The normal distribution function is widely used in scientific and statistical computing. Therefore, it has been implemented in various ways.</p>
<p>The <a href="/wiki/GNU_Scientific_Library" title="GNU Scientific Library">GNU Scientific Library</a> calculates values of the standard normal cdf using <a href="/wiki/Piecewise" title="Piecewise">piecewise</a> approximations by <a href="/wiki/Rational_function" title="Rational function">rational functions</a>. Another approximation method uses third-degree polynomials on intervals.<sup id="cite_ref-8" class="reference"><a href="#cite_note-8" title=""><span>[</span>9<span>]</span></a></sup> The article on the <a href="/wiki/Bc_programming_language" title="Bc programming language">bc programming language</a> gives an example of how to compute the cdf in Gnu bc.</p>
<p>For a more detailed discussion of how to calculate the normal distribution, see <a href="/wiki/Donald_Knuth" title="Donald Knuth">Knuth</a>'s <i><a href="/wiki/The_Art_of_Computer_Programming" title="The Art of Computer Programming">The Art of Computer Programming</a></i>, section 3.4.1C.</p>
<p><a name="See_also" id="See_also"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=37" title="Edit section: See also">edit</a>]</span> <span class="mw-headline">See also</span></h2>
<div class="noprint tright portal" style="border:solid #aaa 1px;margin:0.5em 0 0.5em 0.5em;">
<table style="background:#f9f9f9; font-size:85%; line-height:110%;">
<tr>
<td><a href="/wiki/File:Fisher_iris_versicolor_sepalwidth.svg" class="image" title="Fisher iris versicolor sepalwidth.svg"><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Fisher_iris_versicolor_sepalwidth.svg/42px-Fisher_iris_versicolor_sepalwidth.svg.png" width="42" height="28" border="0" /></a></td>
<td style="padding:0 0.2em;"><i><b><a href="/wiki/Portal:Statistics" title="Portal:Statistics">Statistics portal</a></b></i></td>
</tr>
</table>
</div>
<ul>
<li><a href="/wiki/Behrens%E2%80%93Fisher_problem" title="Behrens–Fisher problem">Behrens–Fisher problem</a></li>
<li><a href="/wiki/Bell_curve_grading" title="Bell curve grading">Bell curve grading</a></li>
<li><a href="/wiki/Central_limit_theorem" title="Central limit theorem">Central limit theorem</a> - re-averaged sum of a sufficiently large number of identically distributed independent random variables each with finite mean and variance will be approximately normally distributed</li>
<li><a href="/wiki/Chi_square_distribution" title="Chi square distribution" class="mw-redirect">Chi square distribution</a></li>
<li><a href="/wiki/Data_transformation_(statistics)" title="Data transformation (statistics)">Data transformation (statistics)</a> - simple techniques to transform data into normal distribution</li>
<li><a href="/wiki/Erd%C5%91s-Kac_theorem" title="Erdős-Kac theorem" class="mw-redirect">Erdős-Kac theorem</a>, on the occurrence of the normal distribution in <a href="/wiki/Number_theory" title="Number theory">number theory</a></li>
<li><a href="/wiki/Gaussian_blur" title="Gaussian blur">Gaussian blur</a>, <a href="/wiki/Convolution" title="Convolution">convolution</a> using the normal distribution as a kernel</li>
<li><a href="/wiki/Gaussian_function" title="Gaussian function">Gaussian function</a></li>
<li><a href="/wiki/Gaussian_process" title="Gaussian process">Gaussian process</a>
<ul>
<li><a href="/wiki/Wiener_process" title="Wiener process">Wiener process</a></li>
<li><a href="/wiki/Brownian_bridge" title="Brownian bridge">Brownian bridge</a></li>
<li><a href="/wiki/Ornstein-Uhlenbeck_process" title="Ornstein-Uhlenbeck process" class="mw-redirect">Ornstein-Uhlenbeck process</a></li>
</ul>
</li>
<li><a href="/wiki/Iannis_Xenakis" title="Iannis Xenakis">Iannis Xenakis</a>, Gaussian distribution in <a href="/wiki/Music" title="Music">music</a>.</li>
<li><a href="/wiki/Inverse_Gaussian_distribution" title="Inverse Gaussian distribution">Inverse Gaussian distribution</a></li>
<li><a href="/wiki/Logistic_distribution" title="Logistic distribution">Logistic distribution</a></li>
<li><a href="/wiki/Logit" title="Logit">Logit</a> function</li>
<li><a href="/wiki/Lognormal_distribution" title="Lognormal distribution" class="mw-redirect">Lognormal distribution</a></li>
<li><a href="/wiki/Multivariate_normal_distribution" title="Multivariate normal distribution">Multivariate normal distribution</a></li>
<li><a href="/wiki/Matrix_normal_distribution" title="Matrix normal distribution">Matrix normal distribution</a></li>
<li><a href="/wiki/Normal-gamma_distribution" title="Normal-gamma distribution">Normal-gamma distribution</a></li>
<li><a href="/wiki/Normally_distributed_and_uncorrelated_does_not_imply_independent" title="Normally distributed and uncorrelated does not imply independent">Normally distributed and uncorrelated does not imply independent</a> (an example of two normally distributed uncorrelated random variables that are not independent; this cannot happen in the presence of <a href="/wiki/Multivariate_normal_distribution" title="Multivariate normal distribution">joint normality</a>)</li>
<li><a href="/wiki/Pearson_distribution" title="Pearson distribution">Pearson distribution</a> Generalized family of probability distributions that extend the Gaussian distribution to include different skewness and kurtosis values</li>
<li><a href="/wiki/Probit_function" title="Probit function" class="mw-redirect">Probit function</a></li>
<li><a href="/wiki/Sample_size" title="Sample size">Sample size</a></li>
<li><a href="/wiki/Skew_normal_distribution" title="Skew normal distribution">Skew normal distribution</a></li>
<li><a href="/wiki/Student%27s_t-distribution" title="Student's t-distribution">Student's t-distribution</a></li>
<li><a href="/wiki/Sum_of_normally_distributed_random_variables" title="Sum of normally distributed random variables">Sum of normally distributed random variables</a></li>
<li><a href="/wiki/Truncated_normal_distribution" title="Truncated normal distribution">Truncated normal distribution</a></li>
<li><a href="/wiki/Tweedie_distributions" title="Tweedie distributions">Tweedie distributions</a></li>
</ul>
<p><a name="Notes" id="Notes"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=38" title="Edit section: Notes">edit</a>]</span> <span class="mw-headline">Notes</span></h2>
<div class="references-small references-column-count references-column-count-2" style="-moz-column-count:2; column-count:2;">
<ol class="references">
<li id="cite_note-0"><b><a href="#cite_ref-0" title="">^</a></b> <a href="http://findarticles.com/p/articles/mi_g2699/is_0002/ai_2699000241" class="external text" title="http://findarticles.com/p/articles/mi_g2699/is_0002/ai_2699000241" rel="nofollow">Gale Encyclopedia of Psychology - Normal Distribution</a></li>
<li id="cite_note-1"><b><a href="#cite_ref-1" title="">^</a></b> Havil, 2003</li>
<li id="cite_note-2"><b><a href="#cite_ref-2" title="">^</a></b> Abraham de Moivre, "Approximatio ad Summam Terminorum Binomii (<i>a</i>&#160;+&#160;<i>b</i>)<sup><i>n</i></sup> in Seriem expansi" (printed on 12 November 1733 in London for private circulation). This pamphlet has been reprinted in: <b>(1)</b> Richard C. Archibald (1926) “A rare pamphlet of Moivre and some of his discoveries,” <i>Isis</i>, vol. 8, pages 671-683; <b>(2)</b> Helen M. Walker, “De Moivre on the law of normal probability” in David Eugene Smith, <i>A Source Book in Mathematics</i> [New York, New York: McGraw-Hill, 1929; reprinted: New York, New York: Dover, 1959], vol. 2, pages 566-575.; <b>(3)</b> Abraham De Moivre, <i>The Doctrine of Chances</i> (2nd ed.) [London: H. Woodfall, 1738; reprinted: London: Cass, 1967], pages 235-243; (3rd ed.) [London: A Millar, 1756; reprinted: New York, New York: Chelsea, 1967], pages 243-254; <b>(4)</b> Florence N. David, <i>Games, Gods and Gambling: A History of Probability and Statistical Ideas</i> [London: Griffin, 1962], Appendix 5, pages 254-267.</li>
<li id="cite_note-3"><b><a href="#cite_ref-3" title="">^</a></b> <a href="http://cnx.org/content/m11537/latest/" class="external text" title="http://cnx.org/content/m11537/latest/" rel="nofollow">The Q-function</a></li>
<li id="cite_note-4"><b><a href="#cite_ref-4" title="">^</a></b> <a href="http://www.eng.tau.ac.il/~jo/academic/Q.pdf" class="external free" title="http://www.eng.tau.ac.il/~jo/academic/Q.pdf" rel="nofollow">http://www.eng.tau.ac.il/~jo/academic/Q.pdf</a></li>
<li id="cite_note-5"><b><a href="#cite_ref-5" title="">^</a></b> <a href="http://mathworld.wolfram.com/NormalDistributionFunction.html" class="external text" title="http://mathworld.wolfram.com/NormalDistributionFunction.html" rel="nofollow">Normal Distribution Function - from Wolfram MathWorld</a></li>
<li id="cite_note-6"><b><a href="#cite_ref-6" title="">^</a></b> <cite style="font-style:normal" class="web" id="CITEREFM.A._Sanders">M.A. Sanders. <a href="http://www.planetmathematics.com/CharNormal.pdf" class="external text" title="http://www.planetmathematics.com/CharNormal.pdf" rel="nofollow">"Characteristic function of the univariate normal distribution"</a><span class="printonly">. <a href="http://www.planetmathematics.com/CharNormal.pdf" class="external free" title="http://www.planetmathematics.com/CharNormal.pdf" rel="nofollow">http://www.planetmathematics.com/CharNormal.pdf</a></span><span class="reference-accessdate">. Retrieved on 2009-03-06</span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=Characteristic+function+of+the+univariate+normal+distribution&amp;rft.atitle=&amp;rft.aulast=M.A.+Sanders&amp;rft.au=M.A.+Sanders&amp;rft_id=http%3A%2F%2Fwww.planetmathematics.com%2FCharNormal.pdf&amp;rfr_id=info:sid/en.wikipedia.org:Normal_distribution"><span style="display: none;">&#160;</span></span></li>
<li id="cite_note-7"><b><a href="#cite_ref-7" title="">^</a></b> Johnson NL, Kotz S, Balakrishnan N. (1995) Continuous Univariate Distributions Volume 2, Wiley. Equation(26.48)</li>
<li id="cite_note-8"><b><a href="#cite_ref-8" title="">^</a></b> <cite style="font-style:normal" class="web" id="CITEREFAndy_Salter">Andy Salter. <a href="http://www.doc.ic.ac.uk/~dfg/AndysSplineTutorial/BSplines.html" class="external text" title="http://www.doc.ic.ac.uk/~dfg/AndysSplineTutorial/BSplines.html" rel="nofollow">"B-Spline curves"</a><span class="printonly">. <a href="http://www.doc.ic.ac.uk/~dfg/AndysSplineTutorial/BSplines.html" class="external free" title="http://www.doc.ic.ac.uk/~dfg/AndysSplineTutorial/BSplines.html" rel="nofollow">http://www.doc.ic.ac.uk/~dfg/AndysSplineTutorial/BSplines.html</a></span><span class="reference-accessdate">. Retrieved on 2008-12-05</span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=B-Spline+curves&amp;rft.atitle=&amp;rft.aulast=Andy+Salter&amp;rft.au=Andy+Salter&amp;rft_id=http%3A%2F%2Fwww.doc.ic.ac.uk%2F%7Edfg%2FAndysSplineTutorial%2FBSplines.html&amp;rfr_id=info:sid/en.wikipedia.org:Normal_distribution"><span style="display: none;">&#160;</span></span></li>
</ol>
</div>
<p><a name="References" id="References"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=39" title="Edit section: References">edit</a>]</span> <span class="mw-headline">References</span></h2>
<div class="references-small" style="margin-left:1.5em;">
<ul>
<li>John Aldrich. <a href="http://jeff560.tripod.com/stat.html" class="external text" title="http://jeff560.tripod.com/stat.html" rel="nofollow">Earliest Uses of Symbols in Probability and Statistics</a>. Electronic document, retrieved <span class="mw-formatted-date" title="2005-03-20"><span class="mw-formatted-date" title="03-20"><a href="/wiki/March_20" title="March 20">March 20</a></span>, <a href="/wiki/2005" title="2005">2005</a></span>. (<i>See "Symbols associated with the Normal Distribution".</i>)</li>
<li><a href="/wiki/Abraham_de_Moivre" title="Abraham de Moivre">Abraham de Moivre</a> (1738). <i><a href="/wiki/The_Doctrine_of_Chances" title="The Doctrine of Chances">The Doctrine of Chances</a></i>.</li>
<li><a href="/wiki/Stephen_Jay_Gould" title="Stephen Jay Gould">Stephen Jay Gould</a> (1981). <i><a href="/wiki/The_Mismeasure_of_Man" title="The Mismeasure of Man">The Mismeasure of Man</a></i>. First edition. W. W. Norton. <a href="/wiki/Special:BookSources/0393014894" class="internal">ISBN 0-393-01489-4</a> .</li>
<li>Havil, 2003. <i>Gamma, Exploring Euler's Constant</i>, Princeton, NJ: Princeton University Press, p. 157.</li>
<li><a href="/wiki/Richard_Herrnstein" title="Richard Herrnstein">R. J. Herrnstein</a> and <a href="/wiki/Charles_Murray" title="Charles Murray">Charles Murray</a> (1994). <i><a href="/wiki/The_Bell_Curve" title="The Bell Curve">The Bell Curve</a>: Intelligence and Class Structure in American Life</i>. <a href="/wiki/Free_Press" title="Free Press">Free Press</a>. <a href="/wiki/Special:BookSources/0029146739" class="internal">ISBN 0-02-914673-9</a> .</li>
<li><a href="/wiki/Pierre-Simon_Laplace" title="Pierre-Simon Laplace">Pierre-Simon Laplace</a> (1812). <i><a href="/wiki/Analytical_Theory_of_Probabilities" title="Analytical Theory of Probabilities" class="mw-redirect">Analytical Theory of Probabilities</a></i>.</li>
<li>Jeff Miller, John Aldrich, et al. <a href="http://jeff560.tripod.com/mathword.html" class="external text" title="http://jeff560.tripod.com/mathword.html" rel="nofollow">Earliest Known Uses of Some of the Words of Mathematics</a>. In particular, the entries for <a href="http://jeff560.tripod.com/b.html" class="external text" title="http://jeff560.tripod.com/b.html" rel="nofollow">"bell-shaped and bell curve"</a>, <a href="http://jeff560.tripod.com/n.html" class="external text" title="http://jeff560.tripod.com/n.html" rel="nofollow">"normal" (distribution)</a>, <a href="http://jeff560.tripod.com/g.html" class="external text" title="http://jeff560.tripod.com/g.html" rel="nofollow">"Gaussian"</a>, and <a href="http://jeff560.tripod.com/e.html" class="external text" title="http://jeff560.tripod.com/e.html" rel="nofollow">"Error, law of error, theory of errors, etc."</a>. Electronic documents, retrieved <span class="mw-formatted-date" title="2005-12-13"><span class="mw-formatted-date" title="12-13"><a href="/wiki/December_13" title="December 13">December 13</a></span>, <a href="/wiki/2005" title="2005">2005</a></span>.</li>
<li>S. M. Stigler (1999). <i>Statistics on the Table</i>, chapter 22. Harvard University Press. (<i>History of the term "normal distribution".</i>)</li>
<li><a href="/wiki/Eric_W._Weisstein" title="Eric W. Weisstein">Eric W. Weisstein</a> et al. <a href="http://mathworld.wolfram.com/NormalDistribution.html" class="external text" title="http://mathworld.wolfram.com/NormalDistribution.html" rel="nofollow">Normal Distribution</a> at <a href="/wiki/MathWorld" title="MathWorld">MathWorld</a>. Electronic document, retrieved <span class="mw-formatted-date" title="2005-03-20"><span class="mw-formatted-date" title="03-20"><a href="/wiki/March_20" title="March 20">March 20</a></span>, <a href="/wiki/2005" title="2005">2005</a></span>.</li>
<li>Marvin Zelen and Norman C. Severo (1964). Probability Functions. <a href="http://www.math.sfu.ca/~cbm/aands/page_931.htm" class="external text" title="http://www.math.sfu.ca/~cbm/aands/page_931.htm" rel="nofollow">Chapter 26</a> of <i><a href="/wiki/Abramowitz_and_Stegun" title="Abramowitz and Stegun">Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables</a></i>, ed, by <a href="/wiki/Milton_Abramowitz" title="Milton Abramowitz">Milton Abramowitz</a> and <a href="/wiki/Irene_A._Stegun" title="Irene A. Stegun" class="mw-redirect">Irene A. Stegun</a>. <a href="/wiki/National_Bureau_of_Standards" title="National Bureau of Standards" class="mw-redirect">National Bureau of Standards</a>.</li>
</ul>
</div>
<p><a name="External_links" id="External_links"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Normal_distribution&amp;action=edit&amp;section=40" title="Edit section: External links">edit</a>]</span> <span class="mw-headline">External links</span></h2>
<p><b>The normal distribution</b></p>
<ul>
<li><a href="http://mathworld.wolfram.com/NormalDistribution.html" class="external text" title="http://mathworld.wolfram.com/NormalDistribution.html" rel="nofollow">Mathworld: Normal Distribution</a></li>
<li><a href="http://planetmath.org/encyclopedia/NormalRandomVariable.html" class="external text" title="http://planetmath.org/encyclopedia/NormalRandomVariable.html" rel="nofollow">PlanetMath: normal random variable</a></li>
<li><a href="http://courses.ncssm.edu/math/Stat_Inst/Stats2007/Stat%20and%20Calc/Calc%20Derivation%20of%20Normal%20Dist.pdf" class="external text" title="http://courses.ncssm.edu/math/Stat_Inst/Stats2007/Stat%20and%20Calc/Calc%20Derivation%20of%20Normal%20Dist.pdf" rel="nofollow">Intuitive derivation</a>.</li>
<li><a href="http://www.visualstatistics.net/Statistics/Euler/Euler.htm" class="external text" title="http://www.visualstatistics.net/Statistics/Euler/Euler.htm" rel="nofollow">Is normal distribution due to Karl Gauss? Euler, his family of gamma functions, and place in history of statistics</a></li>
<li><a href="http://www.visualstatistics.net/Statistics/Maxwell%20Demons/Maxwell%20Demons.htm" class="external text" title="http://www.visualstatistics.net/Statistics/Maxwell%20Demons/Maxwell%20Demons.htm" rel="nofollow">Maxwell demons: Simulating probability distributions with functions of propositional calculus</a></li>
<li><a href="http://www.portfoliomonkey.com/flash/galtonboard/galtonboard.html" class="external text" title="http://www.portfoliomonkey.com/flash/galtonboard/galtonboard.html" rel="nofollow">Visualization of normal distribution</a></li>
</ul>
<p><b>Online results and applications</b></p>
<ul>
<li><a href="http://www.hyper-metrix.com/processing-js/docs/index.php?page=Bell%20Curves" class="external text" title="http://www.hyper-metrix.com/processing-js/docs/index.php?page=Bell%20Curves" rel="nofollow">Drawing Normal/Bell Curves with JavaScript</a></li>
<li><a href="http://www.digitalreview.com.ar/normaldistribution/" class="external text" title="http://www.digitalreview.com.ar/normaldistribution/" rel="nofollow">Normal distribution table</a></li>
<li><a href="http://www.math.unb.ca/~knight/utility/NormTble.htm" class="external text" title="http://www.math.unb.ca/~knight/utility/NormTble.htm" rel="nofollow">Public Domain Normal Distribution Table</a></li>
<li><a href="http://www.vias.org/simulations/simusoft_distcalc.html" class="external text" title="http://www.vias.org/simulations/simusoft_distcalc.html" rel="nofollow">Distribution Calculator</a> – Calculates probabilities and critical values for normal, <i><a href="/wiki/Student%27s_t-distribution" title="Student's t-distribution">t</a></i>, <a href="/wiki/Chi-square_distribution" title="Chi-square distribution">chi-square</a> and <a href="/wiki/F-distribution" title="F-distribution"><i>F</i>-distribution</a>.</li>
<li><a href="http://www-stat.stanford.edu/~naras/jsm/NormalDensity/NormalDensity.html" class="external text" title="http://www-stat.stanford.edu/~naras/jsm/NormalDensity/NormalDensity.html" rel="nofollow">Java Applet on Normal Distributions</a></li>
<li><a href="http://socr.stat.ucla.edu/htmls/SOCR_Distributions.html" class="external text" title="http://socr.stat.ucla.edu/htmls/SOCR_Distributions.html" rel="nofollow">Interactive Distribution Modeler (incl. Normal Distribution)</a>.</li>
<li><a href="http://www.danielsoper.com/statcalc/calc02.aspx" class="external text" title="http://www.danielsoper.com/statcalc/calc02.aspx" rel="nofollow">Free Area Under the Normal Curve Calculator</a> from Daniel Soper's <i>Free Statistics Calculators</i> website.</li>
<li><a href="http://www.measuringusability.com/normal_curve.php" class="external text" title="http://www.measuringusability.com/normal_curve.php" rel="nofollow">Interactive Graph of the Standard Normal Curve</a> Quickly Visualize the one and two-tailed area of the Standard Normal Curve</li>
<li><a href="http://www.random-science-tools.com/maths/normal-distribution.htm" class="external text" title="http://www.random-science-tools.com/maths/normal-distribution.htm" rel="nofollow">Javascript calculator which calculates the probability that a value randomly chosen from a Normal Distribution is greater than, less than or between chosen values</a></li>
<li><a href="http://itunes.apple.com/WebObjects/MZStore.woa/wa/viewSoftware?id=308502456&amp;mt=8" class="external text" title="http://itunes.apple.com/WebObjects/MZStore.woa/wa/viewSoftware?id=308502456&amp;mt=8" rel="nofollow">Standard Normal Distribution Table for the iPhone</a></li>
</ul>
<p><b>Algorithms and approximations</b></p>
<ul>
<li><a href="http://www.gnu.org/software/gsl/manual/html_node/Random-Number-Distributions.html" class="external text" title="http://www.gnu.org/software/gsl/manual/html_node/Random-Number-Distributions.html" rel="nofollow">GNU Scientific Library – Reference Manual – The Gaussian Distribution</a></li>
<li><a href="http://www.sitmo.com/doc/Calculating_the_Cumulative_Normal_Distribution" class="external text" title="http://www.sitmo.com/doc/Calculating_the_Cumulative_Normal_Distribution" rel="nofollow">Calculating the Cumulative Normal distribution, C++, VBA</a>, sitmo.com</li>
<li><a href="http://home.online.no/~pjacklam/notes/invnorm/" class="external text" title="http://home.online.no/~pjacklam/notes/invnorm/" rel="nofollow">An algorithm for computing the inverse normal cumulative distribution function</a> by Peter J. Acklam – has examples for several <a href="/wiki/Programming_language" title="Programming language">programming languages</a></li>
<li><a href="http://www2.isye.gatech.edu/~christos/3044/inv_normal.pdf" class="external text" title="http://www2.isye.gatech.edu/~christos/3044/inv_normal.pdf" rel="nofollow">An Approximation to the Inverse Normal(0, 1) Distribution</a>, gatech.edu</li>
<li><a href="http://www.math.sfu.ca/~cbm/aands/page_932.htm" class="external text" title="http://www.math.sfu.ca/~cbm/aands/page_932.htm" rel="nofollow"><i>Handbook of Mathematical Functions</i>: Polynomial and Rational Approximations for P(x) and Z(x)</a>, Abramowitz and Stegun</li>
</ul>
<table class="navbox" cellspacing="0" style=";">
<tr>
<td style="padding:2px;">
<table cellspacing="0" class="nowraplinks collapsible autocollapse" style="width:100%;background:transparent;color:inherit;;">
<tr>
<th style=";" colspan="2" class="navbox-title">
<div style="float:left; width:6em;text-align:left;">
<div class="noprint plainlinksneverexpand navbar" style="background:none; padding:0; font-weight:normal;;;border:none;; font-size:xx-small;"><a href="/wiki/Template:ProbDistributions" title="Template:ProbDistributions"><span title="View this template" style=";;border:none;">v</span></a>&#160;<span style="font-size:80%;">•</span>&#160;<a href="/wiki/Template_talk:ProbDistributions" title="Template talk:ProbDistributions"><span title="Discussion about this template" style=";;border:none;">d</span></a>&#160;<span style="font-size:80%;">•</span>&#160;<a href="http://en.wikipedia.org/w/index.php?title=Template:ProbDistributions&amp;action=edit" class="external text" title="http://en.wikipedia.org/w/index.php?title=Template:ProbDistributions&amp;action=edit" rel="nofollow"><span title="Edit this template" style=";;border:none;;">e</span></a></div>
</div>
<span style="font-size:110%;"><a href="/wiki/Probability_distribution" title="Probability distribution">Probability distributions</a></span></th>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<td colspan="2" style="width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"></div>
<table cellspacing="0" class="nowraplinks collapsible collapsed navbox-subgroup" style="width:100%;;;;">
<tr>
<th style=";;" colspan="2" class="navbox-title">
<div style="float:left; width:6em;text-align:left;">&#160;</div>
<span style="font-size:100%;"><a href="/wiki/Probability_distribution#with_finite_support" title="Probability distribution">Discrete univariate with finite support</a></span></th>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<td colspan="2" style="width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><span style="white-space:nowrap"><a href="/wiki/Benford%27s_law" title="Benford's law">Benford</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Bernoulli_distribution" title="Bernoulli distribution">Bernoulli</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Binomial_distribution" title="Binomial distribution">binomial</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Categorical_distribution" title="Categorical distribution">categorical</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Hypergeometric_distribution" title="Hypergeometric distribution">hypergeometric</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Rademacher_distribution" title="Rademacher distribution">Rademacher</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Uniform_distribution_(discrete)" title="Uniform distribution (discrete)">discrete uniform</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Zipf%27s_law" title="Zipf's law">Zipf</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Zipf-Mandelbrot_law" title="Zipf-Mandelbrot law" class="mw-redirect">Zipf-Mandelbrot</a></span></div>
</td>
</tr>
</table>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td colspan="2" style="width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"></div>
<table cellspacing="0" class="nowraplinks collapsible collapsed navbox-subgroup" style="width:100%;;;;">
<tr>
<th style=";;" colspan="2" class="navbox-title">
<div style="float:left; width:6em;text-align:left;">&#160;</div>
<span style="font-size:100%;"><a href="/wiki/Probability_distribution#with_infinite_support" title="Probability distribution">Discrete univariate with infinite support</a></span></th>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<td colspan="2" style="width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><span style="white-space:nowrap"><a href="/wiki/Boltzmann_distribution" title="Boltzmann distribution">Boltzmann</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Conway-Maxwell-Poisson_distribution" title="Conway-Maxwell-Poisson distribution">Conway-Maxwell-Poisson</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Compound_Poisson_distribution" title="Compound Poisson distribution">compound Poisson</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Discrete_phase-type_distribution" title="Discrete phase-type distribution">discrete phase-type</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Extended_negative_binomial_distribution" title="Extended negative binomial distribution">extended negative binomial</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Gauss-Kuzmin_distribution" title="Gauss-Kuzmin distribution" class="mw-redirect">Gauss-Kuzmin</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Geometric_distribution" title="Geometric distribution">geometric</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Logarithmic_distribution" title="Logarithmic distribution">logarithmic</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Negative_binomial_distribution" title="Negative binomial distribution">negative binomial</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Parabolic_fractal_distribution" title="Parabolic fractal distribution">parabolic fractal</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Poisson_distribution" title="Poisson distribution">Poisson</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Skellam_distribution" title="Skellam distribution">Skellam</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Yule%E2%80%93Simon_distribution" title="Yule–Simon distribution">Yule-Simon</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Zeta_distribution" title="Zeta distribution">zeta</a></span></div>
</td>
</tr>
</table>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td colspan="2" style="width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"></div>
<table cellspacing="0" class="nowraplinks collapsible collapsed navbox-subgroup" style="width:100%;;;;">
<tr>
<th style=";;" colspan="2" class="navbox-title">
<div style="float:left; width:6em;text-align:left;">&#160;</div>
<span style="font-size:100%;"><a href="/wiki/Statistical_distribution#Supported_on_a_bounded_interval" title="Statistical distribution" class="mw-redirect">Continuous univariate supported on a bounded interval, e.g. [0,1]</a></span></th>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<td colspan="2" style="width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><span style="white-space:nowrap"><a href="/wiki/Beta_distribution" title="Beta distribution">Beta</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Irwin-Hall_distribution" title="Irwin-Hall distribution">Irwin-Hall</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Kumaraswamy_distribution" title="Kumaraswamy distribution">Kumaraswamy</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Raised_cosine_distribution" title="Raised cosine distribution">raised cosine</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Triangular_distribution" title="Triangular distribution">triangular</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/U-quadratic_distribution" title="U-quadratic distribution">U-quadratic</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Uniform_distribution_(continuous)" title="Uniform distribution (continuous)">uniform</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Wigner_semicircle_distribution" title="Wigner semicircle distribution">Wigner semicircle</a></span></div>
</td>
</tr>
</table>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td colspan="2" style="width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"></div>
<table cellspacing="0" class="nowraplinks collapsible collapsed navbox-subgroup" style="width:100%;;;;">
<tr>
<th style=";;" colspan="2" class="navbox-title">
<div style="float:left; width:6em;text-align:left;">&#160;</div>
<span style="font-size:100%;"><a href="/wiki/Statistical_distribution#Supported_on_semi-infinite_intervals.2C_usually_.5B0.2C.E2.88.9E.29" title="Statistical distribution" class="mw-redirect">Continuous univariate supported on a semi-infinite interval, usually [0,∞)</a></span></th>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<td colspan="2" style="width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><span style="white-space:nowrap"><a href="/wiki/Beta_prime_distribution" title="Beta prime distribution">Beta prime</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Bose%E2%80%93Einstein_statistics" title="Bose–Einstein statistics">Bose–Einstein</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Burr_distribution" title="Burr distribution">Burr</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Chi-square_distribution" title="Chi-square distribution">chi-square</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Chi_distribution" title="Chi distribution">chi</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Phase-type_distribution#coxian_distribution" title="Phase-type distribution">Coxian</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Erlang_distribution" title="Erlang distribution">Erlang</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Exponential_distribution" title="Exponential distribution">exponential</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/F-distribution" title="F-distribution"><i>F</i></a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Fermi%E2%80%93Dirac_statistics" title="Fermi–Dirac statistics">Fermi-Dirac</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Folded_normal_distribution" title="Folded normal distribution">folded normal</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Fr%C3%A9chet_distribution" title="Fréchet distribution">Fréchet</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Gamma_distribution" title="Gamma distribution">Gamma</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Generalized_extreme_value_distribution" title="Generalized extreme value distribution">generalized extreme value</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Generalized_inverse_Gaussian_distribution" title="Generalized inverse Gaussian distribution">generalized inverse Gaussian</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Half-logistic_distribution" title="Half-logistic distribution">half-logistic</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Half-normal_distribution" title="Half-normal distribution">half-normal</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Hotelling%27s_T-square_distribution" title="Hotelling's T-square distribution">Hotelling's T-square</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Hyper-exponential_distribution" title="Hyper-exponential distribution">hyper-exponential</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Hypoexponential_distribution" title="Hypoexponential distribution">hypoexponential</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Inverse-chi-square_distribution" title="Inverse-chi-square distribution">inverse chi-square</a> (<a href="/wiki/Scaled-inverse-chi-square_distribution" title="Scaled-inverse-chi-square distribution">scaled inverse chi-square</a>)&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Inverse_Gaussian_distribution" title="Inverse Gaussian distribution">inverse Gaussian</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Inverse-gamma_distribution" title="Inverse-gamma distribution">inverse gamma</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/L%C3%A9vy_distribution" title="Lévy distribution">Lévy</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Log-normal_distribution" title="Log-normal distribution">log-normal</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Log-logistic_distribution" title="Log-logistic distribution">log-logistic</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Maxwell%E2%80%93Boltzmann_distribution" title="Maxwell–Boltzmann distribution">Maxwell-Boltzmann</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Maxwell_speed_distribution" title="Maxwell speed distribution">Maxwell speed</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Nakagami_distribution" title="Nakagami distribution">Nakagami</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Noncentral_chi-square_distribution" title="Noncentral chi-square distribution">noncentral chi-square</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Pareto_distribution" title="Pareto distribution">Pareto</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Phase-type_distribution" title="Phase-type distribution">phase-type</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Rayleigh_distribution" title="Rayleigh distribution">Rayleigh</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Relativistic_Breit%E2%80%93Wigner_distribution" title="Relativistic Breit–Wigner distribution">relativistic Breit–Wigner</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Rice_distribution" title="Rice distribution">Rice</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Rosin%E2%80%93Rammler_distribution" title="Rosin–Rammler distribution" class="mw-redirect">Rosin–Rammler</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Shifted_Gompertz_distribution" title="Shifted Gompertz distribution">shifted Gompertz</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Truncated_normal_distribution" title="Truncated normal distribution">truncated normal</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Type-2_Gumbel_distribution" title="Type-2 Gumbel distribution">type-2 Gumbel</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Weibull_distribution" title="Weibull distribution">Weibull</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Wilks%27_lambda_distribution" title="Wilks' lambda distribution">Wilks' lambda</a></span></div>
</td>
</tr>
</table>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td colspan="2" style="width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"></div>
<table cellspacing="0" class="nowraplinks collapsible uncollapsed navbox-subgroup" style="width:100%;;;;">
<tr>
<th style=";;" colspan="2" class="navbox-title">
<div style="float:left; width:6em;text-align:left;">&#160;</div>
<span style="font-size:100%;"><a href="/wiki/Statistical_distribution#Supported_on_the_whole_real_line" title="Statistical distribution" class="mw-redirect">Continuous univariate supported on the whole real line (-∞,∞)</a></span></th>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<td colspan="2" style="width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><span style="white-space:nowrap"><a href="/wiki/Cauchy_distribution" title="Cauchy distribution">Cauchy</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Extreme_value_distribution" title="Extreme value distribution" class="mw-redirect">extreme value</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Exponential_power_distribution" title="Exponential power distribution">exponential power</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Fisher%27s_z-distribution" title="Fisher's z-distribution">Fisher's z</a> &#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Generalized_normal_distribution" title="Generalized normal distribution">generalized normal</a> &#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Generalised_hyperbolic_distribution" title="Generalised hyperbolic distribution">generalized hyperbolic</a> &#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Gumbel_distribution" title="Gumbel distribution">Gumbel</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Hyperbolic_secant_distribution" title="Hyperbolic secant distribution">hyperbolic secant</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Landau_distribution" title="Landau distribution">Landau</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Laplace_distribution" title="Laplace distribution">Laplace</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Logistic_distribution" title="Logistic distribution">logistic</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><strong class="selflink">normal (Gaussian)</strong>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Normal-inverse_Gaussian_distribution" title="Normal-inverse Gaussian distribution">normal inverse Gaussian</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Skew_normal_distribution" title="Skew normal distribution">skew normal</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Stable_distribution" title="Stable distribution">stable</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Student%27s_t-distribution" title="Student's t-distribution">Student's <i>t</i></a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Type-1_Gumbel_distribution" title="Type-1 Gumbel distribution">type-1 Gumbel</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Variance-gamma_distribution" title="Variance-gamma distribution">Variance-Gamma</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Voigt_profile" title="Voigt profile">Voigt</a></span></div>
</td>
</tr>
</table>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td colspan="2" style="width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"></div>
<table cellspacing="0" class="nowraplinks collapsible collapsed navbox-subgroup" style="width:100%;;;;">
<tr>
<th style=";;" colspan="2" class="navbox-title">
<div style="float:left; width:6em;text-align:left;">&#160;</div>
<span style="font-size:100%;"><a href="/wiki/Joint_probability_distribution" title="Joint probability distribution">Multivariate (joint)</a></span></th>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<td colspan="2" style="width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><span style="white-space:nowrap"><i>Discrete:</i> <a href="/wiki/Ewens%27s_sampling_formula" title="Ewens's sampling formula">Ewens</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Beta-binomial_model" title="Beta-binomial model">Beta-binomial</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Multinomial_distribution" title="Multinomial distribution">multinomial</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Multivariate_Polya_distribution" title="Multivariate Polya distribution">multivariate Polya</a><br />
<i>Continuous:</i> <a href="/wiki/Dirichlet_distribution" title="Dirichlet distribution">Dirichlet</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Generalized_Dirichlet_distribution" title="Generalized Dirichlet distribution">Generalized Dirichlet</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Multivariate_normal_distribution" title="Multivariate normal distribution">multivariate normal</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Multivariate_Student_distribution" title="Multivariate Student distribution">multivariate Student</a> &#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Normal-scaled_inverse_gamma_distribution" title="Normal-scaled inverse gamma distribution">normal-scaled inverse gamma</a> &#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Normal-gamma_distribution" title="Normal-gamma distribution">normal-gamma</a><br />
<i><a href="/wiki/Probability_distribution#Matrix-valued_distributions" title="Probability distribution">Matrix-valued</a>:</i> <a href="/wiki/Inverse-Wishart_distribution" title="Inverse-Wishart distribution">inverse-Wishart</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Matrix_normal_distribution" title="Matrix normal distribution">matrix normal</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Wishart_distribution" title="Wishart distribution">Wishart</a></span></div>
</td>
</tr>
</table>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td colspan="2" style="width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"></div>
<table cellspacing="0" class="nowraplinks collapsible collapsed navbox-subgroup" style="width:100%;;;;">
<tr>
<th style=";;" colspan="2" class="navbox-title">
<div style="float:left; width:6em;text-align:left;">&#160;</div>
<span style="font-size:100%;"><a href="/wiki/Directional_statistics" title="Directional statistics">Directional</a>, <a href="/wiki/Degenerate_distribution" title="Degenerate distribution">degenerate</a>, and <a href="/wiki/Singular_distribution" title="Singular distribution">singular</a></span></th>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<td colspan="2" style="width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><span style="white-space:nowrap"><i><a href="/wiki/Directional_statistics" title="Directional statistics">Directional</a>:</i> <a href="/wiki/Kent_distribution" title="Kent distribution">Kent</a> &#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Von_Mises_distribution" title="Von Mises distribution">von Mises</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Von_Mises%E2%80%93Fisher_distribution" title="Von Mises–Fisher distribution">von Mises–Fisher</a><br />
<i><a href="/wiki/Degenerate_distribution" title="Degenerate distribution">Degenerate</a>:</i> <a href="/wiki/Degenerate_distribution" title="Degenerate distribution">discrete degenerate</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Dirac_delta_function" title="Dirac delta function">Dirac delta function</a><br />
<i><a href="/wiki/Singular_distribution" title="Singular distribution">Singular</a>:</i> <a href="/wiki/Cantor_distribution" title="Cantor distribution">Cantor</a></span></div>
</td>
</tr>
</table>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td colspan="2" style="width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"></div>
<table cellspacing="0" class="nowraplinks collapsible collapsed navbox-subgroup" style="width:100%;;;;">
<tr>
<th style=";;" colspan="2" class="navbox-title">
<div style="float:left; width:6em;text-align:left;">&#160;</div>
<span style="font-size:100%;">Families</span></th>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<td colspan="2" style="width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><span style="white-space:nowrap"><a href="/wiki/Exponential_family" title="Exponential family">exponential</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Natural_exponential_family" title="Natural exponential family">natural exponential</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Location-scale_family" title="Location-scale family">location-scale</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Maximum_entropy_probability_distribution" title="Maximum entropy probability distribution">maximum entropy</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Pearson_distribution" title="Pearson distribution">Pearson</a>&#160;<b>·</b></span> <span style="white-space:nowrap"><a href="/wiki/Tweedie_distributions" title="Tweedie distributions">Tweedie</a></span></div>
</td>
</tr>
</table>
</td>
</tr>
</table>
</td>
</tr>
</table>
<table class="navbox" cellspacing="0" style=";">
<tr>
<td style="padding:2px;">
<table cellspacing="0" class="nowraplinks collapsible autocollapse" style="width:100%;background:transparent;color:inherit;;">
<tr>
<th style=";" colspan="2" class="navbox-title">
<div style="float:left; width:6em;text-align:left;">
<div class="noprint plainlinksneverexpand navbar" style="background:none; padding:0; font-weight:normal;;;border:none;; font-size:xx-small;"><a href="/wiki/Template:Statistics" title="Template:Statistics"><span title="View this template" style=";;border:none;">v</span></a>&#160;<span style="font-size:80%;">•</span>&#160;<a href="/wiki/Template_talk:Statistics" title="Template talk:Statistics"><span title="Discussion about this template" style=";;border:none;">d</span></a>&#160;<span style="font-size:80%;">•</span>&#160;<a href="http://en.wikipedia.org/w/index.php?title=Template:Statistics&amp;action=edit" class="external text" title="http://en.wikipedia.org/w/index.php?title=Template:Statistics&amp;action=edit" rel="nofollow"><span title="Edit this template" style=";;border:none;;">e</span></a></div>
</div>
<span style="font-size:110%;"><a href="/wiki/Statistics" title="Statistics">Statistics</a></span></th>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/Design_of_experiments" title="Design of experiments">Design of experiments</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/Statistical_population" title="Statistical population">Population</a>&#160;• <a href="/wiki/Sampling_(statistics)" title="Sampling (statistics)">Sampling</a>&#160;• <a href="/wiki/Stratified_sampling" title="Stratified sampling">Stratified sampling</a>&#160;• <a href="/wiki/Replication_(statistics)" title="Replication (statistics)">Replication</a>&#160;• <a href="/wiki/Blocking_(statistics)" title="Blocking (statistics)">Blocking</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/Sample_size" title="Sample size">Sample size estimation</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"><a href="/wiki/Null_hypothesis" title="Null hypothesis">Null hypothesis</a>&#160;• <a href="/wiki/Alternative_hypothesis" title="Alternative hypothesis">Alternative hypothesis</a>&#160;• <a href="/wiki/Type_I_and_Type_II_errors" title="Type I and Type II errors" class="mw-redirect">Type I and Type II errors</a>&#160;• <a href="/wiki/Statistical_power" title="Statistical power">Statistical power</a>&#160;• <a href="/wiki/Effect_size" title="Effect size">Effect size</a>&#160;• <a href="/wiki/Standard_error_(statistics)" title="Standard error (statistics)">Standard error</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/Descriptive_statistics" title="Descriptive statistics">Descriptive statistics</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"></div>
<table cellspacing="0" class="nowraplinks navbox-subgroup" style="width:100%;;;;">
<tr>
<td class="navbox-group" style=";padding-left:0em;padding-right:0em;;">
<div style="padding:0em 0.75em;"><a href="/wiki/Continuous_probability_distribution" title="Continuous probability distribution">Continuous data</a></div>
</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"></div>
<table cellspacing="0" class="nowraplinks navbox-subgroup" style="width:100%;;;;">
<tr>
<td class="navbox-group" style=";padding-left:0em;padding-right:0em;;">
<div style="padding:0em 0.75em;"><a href="/wiki/Location_parameter" title="Location parameter">Location</a></div>
</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/Mean" title="Mean">Mean</a> (<a href="/wiki/Arithmetic_mean" title="Arithmetic mean">Arithmetic</a>, <a href="/wiki/Geometric_mean" title="Geometric mean">Geometric</a>, <a href="/wiki/Harmonic_mean" title="Harmonic mean">Harmonic</a>)&#160;• <a href="/wiki/Median" title="Median">Median</a>&#160;• <a href="/wiki/Mode_(statistics)" title="Mode (statistics)">Mode</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";padding-left:0em;padding-right:0em;;">
<div style="padding:0em 0.75em;"><a href="/wiki/Statistical_dispersion" title="Statistical dispersion">Dispersion</a></div>
</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"><a href="/wiki/Range_(statistics)" title="Range (statistics)">Range</a>&#160;• <a href="/wiki/Standard_deviation" title="Standard deviation">Standard deviation</a>&#160;• <a href="/wiki/Coefficient_of_variation" title="Coefficient of variation">Coefficient of variation</a>&#160;• <a href="/wiki/Percentile" title="Percentile">Percentile</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";padding-left:0em;padding-right:0em;;">
<div style="padding:0em 0.75em;"><a href="/wiki/Moment_(mathematics)" title="Moment (mathematics)">Moments</a></div>
</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/Variance" title="Variance">Variance</a>&#160;• <a href="/wiki/Semivariance" title="Semivariance">Semivariance</a>&#160;• <a href="/wiki/Skewness" title="Skewness">Skewness</a>&#160;• <a href="/wiki/Kurtosis" title="Kurtosis">Kurtosis</a></div>
</td>
</tr>
</table>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";padding-left:0em;padding-right:0em;;">
<div style="padding:0em 0.75em;"><a href="/wiki/Discrete_probability_distribution" title="Discrete probability distribution">Categorical data</a></div>
</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"><a href="/wiki/Frequency_(statistics)" title="Frequency (statistics)">Frequency</a>&#160;• <a href="/wiki/Contingency_table" title="Contingency table">Contingency table</a></div>
</td>
</tr>
</table>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/Statistical_inference" title="Statistical inference">Inferential statistics</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"><a href="/wiki/Bayesian_inference" title="Bayesian inference">Bayesian inference</a>&#160;• <a href="/wiki/Frequentist_inference" title="Frequentist inference" class="mw-redirect">Frequentist inference</a>&#160;• <a href="/wiki/Statistical_hypothesis_testing" title="Statistical hypothesis testing">Hypothesis testing</a>&#160;• <a href="/wiki/Statistical_significance" title="Statistical significance">Significance</a>&#160;• <a href="/wiki/P-value" title="P-value">P-value</a>&#160;• <a href="/wiki/Interval_estimation" title="Interval estimation">Interval estimation</a>&#160;• <a href="/wiki/Confidence_interval" title="Confidence interval">Confidence interval</a>&#160;• <a href="/wiki/Meta-analysis" title="Meta-analysis">Meta-analysis</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;">General estimation</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/Bayesian_estimator" title="Bayesian estimator" class="mw-redirect">Bayesian estimator</a>&#160;• <a href="/wiki/Maximum_likelihood" title="Maximum likelihood">Maximum likelihood</a>&#160;• <a href="/wiki/Method_of_moments_(statistics)" title="Method of moments (statistics)">Method of moments</a>&#160;• <a href="/wiki/Minimum_distance_estimation" title="Minimum distance estimation">Minimum distance</a>&#160;• <a href="/wiki/Maximum_spacing_estimation" title="Maximum spacing estimation">Maximum spacing</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;">Specific tests</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"><a href="/wiki/Z-test" title="Z-test">Z-test (normal)</a>&#160;• <a href="/wiki/Student%27s_t-test" title="Student's t-test">Student's t-test</a>&#160;• <a href="/wiki/Chi-square_test" title="Chi-square test">Chi-square test</a>&#160;• <a href="/wiki/F-test" title="F-test">F-test</a>&#160;• <a href="/wiki/Sensitivity_and_specificity" title="Sensitivity and specificity">Sensitivity and specificity</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/Survival_analysis" title="Survival analysis">Survival analysis</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/Survival_function" title="Survival function">Survival function</a>&#160;• <a href="/wiki/Kaplan-Meier_estimator" title="Kaplan-Meier estimator">Kaplan-Meier</a>&#160;• <a href="/wiki/Logrank_test" title="Logrank test">Logrank test</a>&#160;• <a href="/wiki/Failure_rate" title="Failure rate">Failure rate</a>&#160;• <a href="/wiki/Proportional_hazards_models" title="Proportional hazards models">Proportional hazards models</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/Correlation" title="Correlation">Correlation</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"><a href="/wiki/Pearson_product-moment_correlation_coefficient" title="Pearson product-moment correlation coefficient">Pearson product-moment correlation coefficient</a>&#160;• <a href="/wiki/Rank_correlation" title="Rank correlation">Rank correlation</a> (<a href="/wiki/Spearman%27s_rank_correlation_coefficient" title="Spearman's rank correlation coefficient">Spearman's rho</a>, <a href="/wiki/Kendall_tau_rank_correlation_coefficient" title="Kendall tau rank correlation coefficient">Kendall's tau</a>)&#160;• <a href="/wiki/Confounding_variable" title="Confounding variable" class="mw-redirect">Confounding variable</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/Linear_model" title="Linear model">Linear models</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/General_linear_model" title="General linear model">General linear model</a>&#160;• <a href="/wiki/Generalized_linear_model" title="Generalized linear model">Generalized linear model</a>&#160;• <a href="/wiki/Analysis_of_variance" title="Analysis of variance">Analysis of variance</a>&#160;• <a href="/wiki/Analysis_of_covariance" title="Analysis of covariance">Analysis of covariance</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/Regression_analysis" title="Regression analysis">Regression analysis</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"><a href="/wiki/Linear_regression" title="Linear regression">Linear regression</a>&#160;• <a href="/wiki/Nonlinear_regression" title="Nonlinear regression">Nonlinear regression</a>&#160;• <a href="/wiki/Nonparametric_regression" title="Nonparametric regression">Nonparametric regression</a>&#160;• <a href="/wiki/Semiparametric_regression" title="Semiparametric regression">Semiparametric regression</a>&#160;• <a href="/wiki/Logistic_regression" title="Logistic regression">Logistic regression</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/Statistical_graphics" title="Statistical graphics">Statistical graphics</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/Bar_chart" title="Bar chart">Bar chart</a>&#160;• <a href="/wiki/Biplot" title="Biplot">Biplot</a>&#160;• <a href="/wiki/Box_plot" title="Box plot">Box plot</a>&#160;• <a href="/wiki/Control_chart" title="Control chart">Control chart</a>&#160;• <a href="/wiki/Forest_plot" title="Forest plot">Forest plot</a>&#160;• <a href="/wiki/Histogram" title="Histogram">Histogram</a>&#160;• <a href="/wiki/Q-Q_plot" title="Q-Q plot">Q-Q plot</a>&#160;• <a href="/wiki/Run_chart" title="Run chart">Run chart</a>&#160;• <a href="/wiki/Scatter_plot" title="Scatter plot">Scatter plot</a>&#160;• <a href="/wiki/Stemplot" title="Stemplot">Stemplot</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/History_of_statistics" title="History of statistics">History</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"><a href="/wiki/History_of_statistics" title="History of statistics">History of statistics</a>&#160;• <a href="/wiki/Founders_of_statistics" title="Founders of statistics">Founders of statistics</a>&#160;• <a href="/wiki/Timeline_of_probability_and_statistics" title="Timeline of probability and statistics">Timeline of probability and statistics</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;">Publications</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/List_of_scientific_journals_in_statistics" title="List of scientific journals in statistics">Journals in statistics</a>&#160;• <a href="/wiki/List_of_important_publications_in_statistics" title="List of important publications in statistics">Important publications</a></div>
</td>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<td class="navbox-abovebelow" style=";" colspan="2"><b><a href="/wiki/Category:Statistics" title="Category:Statistics">Category</a></b>&#160;• <b><a href="/wiki/Portal:Statistics" title="Portal:Statistics">Portal</a></b>&#160;• <b><a href="/wiki/Topic_outline_of_statistics" title="Topic outline of statistics">Topic outline</a></b>&#160;• <b><a href="/wiki/List_of_statistics_topics" title="List of statistics topics">List of topics</a></b></td>
</tr>
</table>
</td>
</tr>
</table>


<!-- 
NewPP limit report
Preprocessor node count: 5728/1000000
Post-expand include size: 192512/2048000 bytes
Template argument size: 106110/2048000 bytes
Expensive parser function count: 2/500
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:21462-0!1!0!default!!en!2 and timestamp 20090406193733 -->
<div class="printfooter">
Retrieved from "<a href="http://en.wikipedia.org/wiki/Normal_distribution">http://en.wikipedia.org/wiki/Normal_distribution</a>"</div>
			<div id='catlinks' class='catlinks'><div id="mw-normal-catlinks"><a href="/wiki/Special:Categories" title="Special:Categories">Categories</a>:&#32;<span dir='ltr'><a href="/wiki/Category:Continuous_distributions" title="Category:Continuous distributions">Continuous distributions</a></span></div><div id="mw-hidden-catlinks" class="mw-hidden-cats-hidden">Hidden categories:&#32;<span dir='ltr'><a href="/wiki/Category:All_articles_with_unsourced_statements" title="Category:All articles with unsourced statements">All articles with unsourced statements</a></span> | <span dir='ltr'><a href="/wiki/Category:Articles_with_unsourced_statements_since_March_2008" title="Category:Articles with unsourced statements since March 2008">Articles with unsourced statements since March 2008</a></span> | <span dir='ltr'><a href="/wiki/Category:Articles_to_be_expanded_since_May_2008" title="Category:Articles to be expanded since May 2008">Articles to be expanded since May 2008</a></span> | <span dir='ltr'><a href="/wiki/Category:All_articles_to_be_expanded" title="Category:All articles to be expanded">All articles to be expanded</a></span> | <span dir='ltr'><a href="/wiki/Category:Articles_with_unsourced_statements_since_February_2008" title="Category:Articles with unsourced statements since February 2008">Articles with unsourced statements since February 2008</a></span> | <span dir='ltr'><a href="/wiki/Category:Statistics_articles_linked_to_the_portal" title="Category:Statistics articles linked to the portal">Statistics articles linked to the portal</a></span> | <span dir='ltr'><a href="/wiki/Category:Statistics_articles_with_navigational_template" title="Category:Statistics articles with navigational template">Statistics articles with navigational template</a></span></div></div>			<!-- end content -->
						<div class="visualClear"></div>
		</div>
	</div>
		</div>
		<div id="column-one">
	<div id="p-cactions" class="portlet">
		<h5>Views</h5>
		<div class="pBody">
			<ul>
	
				 <li id="ca-nstab-main" class="selected"><a href="/wiki/Normal_distribution" title="View the content page [c]" accesskey="c">Article</a></li>
				 <li id="ca-talk"><a href="/wiki/Talk:Normal_distribution" title="Discussion about the content page [t]" accesskey="t">Discussion</a></li>
				 <li id="ca-edit"><a href="/w/index.php?title=Normal_distribution&amp;action=edit" title="You can edit this page. &#10;Please use the preview button before saving. [e]" accesskey="e">Edit this page</a></li>
				 <li id="ca-history"><a href="/w/index.php?title=Normal_distribution&amp;action=history" title="Past versions of this page [h]" accesskey="h">History</a></li>			</ul>
		</div>
	</div>
	<div class="portlet" id="p-personal">
		<h5>Personal tools</h5>
		<div class="pBody">
			<ul>
				<li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Normal_distribution" title="You are encouraged to log in; however, it is not mandatory. [o]" accesskey="o">Log in / create account</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-logo">
		<a style="background-image: url(http://upload.wikimedia.org/wikipedia/en/b/bc/Wiki.png);" href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
	<div class='generated-sidebar portlet' id='p-navigation'>
		<h5>Navigation</h5>
		<div class='pBody'>
			<ul>
				<li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li>
				<li id="n-contents"><a href="/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li>
				<li id="n-featuredcontent"><a href="/wiki/Portal:Featured_content" title="Featured content — the best of Wikipedia">Featured content</a></li>
				<li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li>
				<li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li>
			</ul>
		</div>
	</div>
	<div id="p-search" class="portlet">
		<h5><label for="searchInput">Search</label></h5>
		<div id="searchBody" class="pBody">
			<form action="/w/index.php" id="searchform"><div>
				<input type='hidden' name="title" value="Special:Search"/>
				<input id="searchInput" name="search" type="text" title="Search Wikipedia [f]" accesskey="f" value="" />
				<input type='submit' name="go" class="searchButton" id="searchGoButton"	value="Go" title="Go to a page with this exact name if one exists" />&nbsp;
				<input type='submit' name="fulltext" class="searchButton" id="mw-searchButton" value="Search" title="Search Wikipedia for this text" />
			</div></form>
		</div>
	</div>
	<div class='generated-sidebar portlet' id='p-interaction'>
		<h5>Interaction</h5>
		<div class='pBody'>
			<ul>
				<li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li>
				<li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li>
				<li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="The list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li>
				<li id="n-contact"><a href="/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact Wikipedia</a></li>
				<li id="n-sitesupport"><a href="http://wikimediafoundation.org/wiki/Donate" title="Support us">Donate to Wikipedia</a></li>
				<li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-tb">
		<h5>Toolbox</h5>
		<div class="pBody">
			<ul>
				<li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Normal_distribution" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li>
				<li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Normal_distribution" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li>
<li id="t-upload"><a href="/wiki/Wikipedia:Upload" title="Upload files [u]" accesskey="u">Upload file</a></li>
<li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="List of all special pages [q]" accesskey="q">Special pages</a></li>
				<li id="t-print"><a href="/w/index.php?title=Normal_distribution&amp;printable=yes" rel="alternate" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>				<li id="t-permalink"><a href="/w/index.php?title=Normal_distribution&amp;oldid=282175274" title="Permanent link to this version of the page">Permanent link</a></li><li id="t-cite"><a href="/w/index.php?title=Special:Cite&amp;page=Normal_distribution&amp;id=282175274">Cite this page</a></li>			</ul>
		</div>
	</div>
	<div id="p-lang" class="portlet">
		<h5>Languages</h5>
		<div class="pBody">
			<ul>
				<li class="interwiki-ar"><a href="http://ar.wikipedia.org/wiki/%D8%AA%D9%88%D8%B2%D9%8A%D8%B9_%D8%A7%D8%AD%D8%AA%D9%85%D8%A7%D9%84%D9%8A_%D8%B7%D8%A8%D9%8A%D8%B9%D9%8A">العربية</a></li>
				<li class="interwiki-az"><a href="http://az.wikipedia.org/wiki/Normal_paylanma">Azərbaycan</a></li>
				<li class="interwiki-ca"><a href="http://ca.wikipedia.org/wiki/Distribuci%C3%B3_normal">Català</a></li>
				<li class="interwiki-cs"><a href="http://cs.wikipedia.org/wiki/Norm%C3%A1ln%C3%AD_rozd%C4%9Blen%C3%AD">Česky</a></li>
				<li class="interwiki-cy"><a href="http://cy.wikipedia.org/wiki/Dosraniad_normal">Cymraeg</a></li>
				<li class="interwiki-da"><a href="http://da.wikipedia.org/wiki/Normalfordeling">Dansk</a></li>
				<li class="interwiki-de"><a href="http://de.wikipedia.org/wiki/Normalverteilung">Deutsch</a></li>
				<li class="interwiki-es"><a href="http://es.wikipedia.org/wiki/Distribuci%C3%B3n_normal">Español</a></li>
				<li class="interwiki-eo"><a href="http://eo.wikipedia.org/wiki/Normala_distribuo">Esperanto</a></li>
				<li class="interwiki-fa"><a href="http://fa.wikipedia.org/wiki/%D8%AA%D9%88%D8%B2%DB%8C%D8%B9_%D9%86%D8%B1%D9%85%D8%A7%D9%84">فارسی</a></li>
				<li class="interwiki-fr"><a href="http://fr.wikipedia.org/wiki/Loi_normale">Français</a></li>
				<li class="interwiki-gl"><a href="http://gl.wikipedia.org/wiki/Distribuci%C3%B3n_normal">Galego</a></li>
				<li class="interwiki-ko"><a href="http://ko.wikipedia.org/wiki/%EC%A0%95%EA%B7%9C%EB%B6%84%ED%8F%AC">한국어</a></li>
				<li class="interwiki-hr"><a href="http://hr.wikipedia.org/wiki/Normalna_raspodjela">Hrvatski</a></li>
				<li class="interwiki-id"><a href="http://id.wikipedia.org/wiki/Distribusi_normal">Bahasa Indonesia</a></li>
				<li class="interwiki-is"><a href="http://is.wikipedia.org/wiki/Normaldreifing">Íslenska</a></li>
				<li class="interwiki-it"><a href="http://it.wikipedia.org/wiki/Variabile_casuale_normale">Italiano</a></li>
				<li class="interwiki-he"><a href="http://he.wikipedia.org/wiki/%D7%94%D7%AA%D7%A4%D7%9C%D7%92%D7%95%D7%AA_%D7%A0%D7%95%D7%A8%D7%9E%D7%9C%D7%99%D7%AA">עברית</a></li>
				<li class="interwiki-la"><a href="http://la.wikipedia.org/wiki/Distributio_normalis">Latina</a></li>
				<li class="interwiki-lv"><a href="http://lv.wikipedia.org/wiki/Norm%C4%81lsadal%C4%ABjums">Latviešu</a></li>
				<li class="interwiki-lt"><a href="http://lt.wikipedia.org/wiki/Normalusis_skirstinys">Lietuvių</a></li>
				<li class="interwiki-hu"><a href="http://hu.wikipedia.org/wiki/Norm%C3%A1lis_eloszl%C3%A1s">Magyar</a></li>
				<li class="interwiki-mr"><a href="http://mr.wikipedia.org/wiki/%E0%A4%B8%E0%A4%BE%E0%A4%AE%E0%A4%BE%E0%A4%A8%E0%A5%8D%E0%A4%AF_%E0%A4%B5%E0%A4%BF%E0%A4%A4%E0%A4%B0%E0%A4%A3">मराठी</a></li>
				<li class="interwiki-nl"><a href="http://nl.wikipedia.org/wiki/Normale_verdeling">Nederlands</a></li>
				<li class="interwiki-ja"><a href="http://ja.wikipedia.org/wiki/%E6%AD%A3%E8%A6%8F%E5%88%86%E5%B8%83">日本語</a></li>
				<li class="interwiki-no"><a href="http://no.wikipedia.org/wiki/Normalfordeling">‪Norsk (bokmål)‬</a></li>
				<li class="interwiki-pl"><a href="http://pl.wikipedia.org/wiki/Rozk%C5%82ad_normalny">Polski</a></li>
				<li class="interwiki-pt"><a href="http://pt.wikipedia.org/wiki/Distribui%C3%A7%C3%A3o_normal">Português</a></li>
				<li class="interwiki-ru"><a href="http://ru.wikipedia.org/wiki/%D0%9D%D0%BE%D1%80%D0%BC%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B5_%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5">Русский</a></li>
				<li class="interwiki-simple"><a href="http://simple.wikipedia.org/wiki/Normal_distribution">Simple English</a></li>
				<li class="interwiki-sk"><a href="http://sk.wikipedia.org/wiki/Norm%C3%A1lne_rozdelenie">Slovenčina</a></li>
				<li class="interwiki-sl"><a href="http://sl.wikipedia.org/wiki/Normalna_porazdelitev">Slovenščina</a></li>
				<li class="interwiki-sr"><a href="http://sr.wikipedia.org/wiki/%D0%9D%D0%BE%D1%80%D0%BC%D0%B0%D0%BB%D0%BD%D0%B0_%D1%80%D0%B0%D1%81%D0%BF%D0%BE%D0%B4%D0%B5%D0%BB%D0%B0">Српски / Srpski</a></li>
				<li class="interwiki-su"><a href="http://su.wikipedia.org/wiki/Sebaran_normal">Basa Sunda</a></li>
				<li class="interwiki-fi"><a href="http://fi.wikipedia.org/wiki/Normaalijakauma">Suomi</a></li>
				<li class="interwiki-sv"><a href="http://sv.wikipedia.org/wiki/Normalf%C3%B6rdelning">Svenska</a></li>
				<li class="interwiki-vi"><a href="http://vi.wikipedia.org/wiki/Ph%C3%A2n_ph%E1%BB%91i_chu%E1%BA%A9n">Tiếng Việt</a></li>
				<li class="interwiki-tr"><a href="http://tr.wikipedia.org/wiki/Normal_da%C4%9F%C4%B1l%C4%B1m">Türkçe</a></li>
				<li class="interwiki-uk"><a href="http://uk.wikipedia.org/wiki/%D0%9D%D0%BE%D1%80%D0%BC%D0%B0%D0%BB%D1%8C%D0%BD%D0%B8%D0%B9_%D1%80%D0%BE%D0%B7%D0%BF%D0%BE%D0%B4%D1%96%D0%BB">Українська</a></li>
				<li class="interwiki-ur"><a href="http://ur.wikipedia.org/wiki/%D9%85%D8%B9%D9%85%D9%88%D9%84_%D8%AA%D9%88%D8%B2%DB%8C%D8%B9">اردو</a></li>
				<li class="interwiki-zh"><a href="http://zh.wikipedia.org/wiki/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83">中文</a></li>
			</ul>
		</div>
	</div>
		</div><!-- end of the left (by default at least) column -->
			<div class="visualClear"></div>
			<div id="footer">
				<div id="f-poweredbyico"><a href="http://www.mediawiki.org/"><img src="/skins-1.5/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" /></a></div>
				<div id="f-copyrightico"><a href="http://wikimediafoundation.org/"><img src="/images/wikimedia-button.png" border="0" alt="Wikimedia Foundation"/></a></div>
			<ul id="f-list">
					<li id="lastmod"> This page was last modified on 6 April 2009, at 19:37.</li>
					<li id="copyright">All text is available under the terms of the <a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Text_of_the_GNU_Free_Documentation_License" title="Wikipedia:Text of the GNU Free Documentation License">GNU Free Documentation License</a>. (See <b><a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Copyrights" title="Wikipedia:Copyrights">Copyrights</a></b> for details.) <br /> Wikipedia&reg; is a registered trademark of the <a href="http://www.wikimediafoundation.org">Wikimedia Foundation, Inc.</a>, a U.S. registered <a class='internal' href="http://en.wikipedia.org/wiki/501%28c%29#501.28c.29.283.29" title="501(c)(3)">501(c)(3)</a> <a href="http://wikimediafoundation.org/wiki/Deductibility_of_donations">tax-deductible</a> <a class='internal' href="http://en.wikipedia.org/wiki/Non-profit_organization" title="Non-profit organization">nonprofit</a> <a href="http://en.wikipedia.org/wiki/Charitable_organization" title="Charitable organization">charity</a>.<br /></li>
					<li id="privacy"><a href="http://wikimediafoundation.org/wiki/Privacy_policy" title="wikimedia:Privacy policy">Privacy policy</a></li>
					<li id="about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
					<li id="disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
			</ul>
		</div>
</div>

		<script type="text/javascript">if (window.runOnloadHook) runOnloadHook();</script>
<!-- Served by srv211 in 0.047 secs. --></body></html>
