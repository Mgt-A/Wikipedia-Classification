<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
		<meta http-equiv="Content-Style-Type" content="text/css" />
		<meta name="generator" content="MediaWiki 1.15alpha" />
		<meta name="keywords" content="Motion capture,Articles lacking sources from May 2008,3D animation,6DOF,A Christmas Carol (2009 film),Academy Award for Best Animated Feature,Alice in Wonderland (2010 film),Animation,Augmented Reality,Beowulf (2007 film),Cars (film)" />
		<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Motion_capture&amp;action=edit" />
		<link rel="edit" title="Edit this page" href="/w/index.php?title=Motion_capture&amp;action=edit" />
		<link rel="apple-touch-icon" href="http://en.wikipedia.org/apple-touch-icon.png" />
		<link rel="shortcut icon" href="/favicon.ico" />
		<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)" />
		<link rel="copyright" href="http://www.gnu.org/copyleft/fdl.html" />
		<link rel="alternate" type="application/rss+xml" title="Wikipedia RSS Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=rss" />
		<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=atom" />
		<title>Motion capture - Wikipedia, the free encyclopedia</title>
		<link rel="stylesheet" href="/skins-1.5/common/shared.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/common/commonPrint.css?207xx" type="text/css" media="print" />
		<link rel="stylesheet" href="/skins-1.5/monobook/main.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/chick/main.css?207xx" type="text/css" media="handheld" />
		<!--[if lt IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE50Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE55Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 6]><link rel="stylesheet" href="/skins-1.5/monobook/IE60Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 7]><link rel="stylesheet" href="/skins-1.5/monobook/IE70Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Common.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Print.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="print" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Handheld.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="handheld" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Monobook.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=-&amp;action=raw&amp;maxage=2678400&amp;gen=css" type="text/css" />
		<!--[if lt IE 7]><script type="text/javascript" src="/skins-1.5/common/IEFixes.js?207xx"></script>
		<meta http-equiv="imagetoolbar" content="no" /><![endif]-->

		<script type= "text/javascript">/*<![CDATA[*/
		var skin = "monobook";
		var stylepath = "/skins-1.5";
		var wgArticlePath = "/wiki/$1";
		var wgScriptPath = "/w";
		var wgScript = "/w/index.php";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = "http://en.wikipedia.org";
		var wgCanonicalNamespace = "";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = "Motion_capture";
		var wgTitle = "Motion capture";
		var wgAction = "view";
		var wgArticleId = "396968";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = "en";
		var wgContentLanguage = "en";
		var wgBreakFrames = false;
		var wgCurRevisionId = 282186526;
		var wgVersion = "1.15alpha";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = ["", ""];
		var wgDigitTransformTable = ["", ""];
		var wgMWSuggestTemplate = "http://en.wikipedia.org/w/api.php?action=opensearch\x26search={searchTerms}\x26namespace={namespaces}\x26suggest";
		var wgDBname = "enwiki";
		var wgSearchNamespaces = [0];
		var wgMWSuggestMessages = ["with suggestions", "no suggestions"];
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		/*]]>*/</script>

		<script type="text/javascript" src="/skins-1.5/common/wikibits.js?207xx"><!-- wikibits js --></script>
		<!-- Head Scripts -->
		<script type="text/javascript" src="/skins-1.5/common/ajax.js?207xx"></script>
		<script type="text/javascript" src="/skins-1.5/common/mwsuggest.js?207xx"></script>
<script type="text/javascript">/*<![CDATA[*/
var wgNotice='';var wgNoticeLocal='';
/*]]>*/</script>		<script type="text/javascript" src="http://upload.wikimedia.org/centralnotice/wikipedia/en/centralnotice.js?207xx"></script>
		<script type="text/javascript" src="/w/index.php?title=-&amp;action=raw&amp;gen=js&amp;useskin=monobook"><!-- site js --></script>
	</head>
<body class="mediawiki ltr ns-0 ns-subject page-Motion_capture skin-monobook">
	<div id="globalWrapper">
		<div id="column-content">
	<div id="content">
		<a name="top" id="top"></a>
		<div id="siteNotice"><script type='text/javascript'>if (wgNotice != '') document.writeln(wgNotice);</script></div>		<h1 id="firstHeading" class="firstHeading">Motion capture</h1>
		<div id="bodyContent">
			<h3 id="siteSub">From Wikipedia, the free encyclopedia</h3>
			<div id="contentSub"></div>
									<div id="jump-to-nav">Jump to: <a href="#column-one">navigation</a>, <a href="#searchInput">search</a></div>			<!-- start content -->
			<table class="metadata plainlinks ambox ambox-content" style="">
<tr>
<td class="mbox-image">
<div style="width: 52px;"><a href="/wiki/File:Question_book-new.svg" class="image" title="Question book-new.svg"><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/50px-Question_book-new.svg.png" width="50" height="39" border="0" /></a></div>
</td>
<td class="mbox-text" style="">This article <b>does not <a href="/wiki/Wikipedia:Citing_sources" title="Wikipedia:Citing sources">cite</a> any <a href="/wiki/Wikipedia:Verifiability" title="Wikipedia:Verifiability">references or sources</a></b>. Please help <a href="http://en.wikipedia.org/w/index.php?title=Motion_capture&amp;action=edit" class="external text" title="http://en.wikipedia.org/w/index.php?title=Motion_capture&amp;action=edit" rel="nofollow">improve this article</a> by adding citations to <a href="/wiki/Wikipedia:Reliable_sources" title="Wikipedia:Reliable sources">reliable sources</a> (ideally, using <i><a href="/wiki/Wikipedia:Footnotes" title="Wikipedia:Footnotes">inline citations</a></i>). Unsourced material may be <a href="/wiki/Template:Fact" title="Template:Fact">challenged</a> and <a href="/wiki/Wikipedia:BURDEN" title="Wikipedia:BURDEN" class="mw-redirect">removed</a>. <small><i>(May 2008)</i></small></td>
</tr>
</table>
<p><b>Motion capture</b>, <b>motion tracking</b>, or <b>mocap</b> are terms used to describe the process of recording <a href="/wiki/Motion_(physics)" title="Motion (physics)">movement</a> and translating that movement onto a digital model. Initially invented in <a href="/wiki/Scotland" title="Scotland">Scotland</a>, it is used in <a href="/wiki/Military_science" title="Military science">military</a>, entertainment, sports, and medical applications. In <a href="/wiki/Filmmaking" title="Filmmaking">filmmaking</a> it refers to recording actions of human actors, and using that information to animate digital character models in <a href="/wiki/3D_animation" title="3D animation" class="mw-redirect">3D animation</a>. When it includes face, fingers and captures subtle expressions, it is often referred to as <b>performance capture</b>.</p>
<table id="toc" class="toc" summary="Contents">
<tr>
<td>
<div id="toctitle">
<h2>Contents</h2>
</div>
<ul>
<li class="toclevel-1"><a href="#The_procedure"><span class="tocnumber">1</span> <span class="toctext">The procedure</span></a></li>
<li class="toclevel-1"><a href="#Advantages"><span class="tocnumber">2</span> <span class="toctext">Advantages</span></a></li>
<li class="toclevel-1"><a href="#Disadvantages"><span class="tocnumber">3</span> <span class="toctext">Disadvantages</span></a></li>
<li class="toclevel-1"><a href="#Applications"><span class="tocnumber">4</span> <span class="toctext">Applications</span></a></li>
<li class="toclevel-1"><a href="#Methods_and_systems"><span class="tocnumber">5</span> <span class="toctext">Methods and systems</span></a></li>
<li class="toclevel-1"><a href="#Optical_systems"><span class="tocnumber">6</span> <span class="toctext">Optical systems</span></a>
<ul>
<li class="toclevel-2"><a href="#Optical:_Passive_Markers"><span class="tocnumber">6.1</span> <span class="toctext">Optical: Passive Markers</span></a></li>
<li class="toclevel-2"><a href="#Optical:_Active_marker"><span class="tocnumber">6.2</span> <span class="toctext">Optical: Active marker</span></a></li>
<li class="toclevel-2"><a href="#Optical:_Time_modulated_active_marker"><span class="tocnumber">6.3</span> <span class="toctext">Optical: Time modulated active marker</span></a></li>
<li class="toclevel-2"><a href="#Optical:_Semi-passive_Imperceptible_Marker"><span class="tocnumber">6.4</span> <span class="toctext">Optical: Semi-passive Imperceptible Marker</span></a></li>
<li class="toclevel-2"><a href="#Optical:_Markerless"><span class="tocnumber">6.5</span> <span class="toctext">Optical: Markerless</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Non-optical_systems"><span class="tocnumber">7</span> <span class="toctext">Non-optical systems</span></a>
<ul>
<li class="toclevel-2"><a href="#Inertial_systems"><span class="tocnumber">7.1</span> <span class="toctext">Inertial systems</span></a></li>
<li class="toclevel-2"><a href="#Mechanical_motion"><span class="tocnumber">7.2</span> <span class="toctext">Mechanical motion</span></a></li>
<li class="toclevel-2"><a href="#Magnetic_systems"><span class="tocnumber">7.3</span> <span class="toctext">Magnetic systems</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Related_techniques"><span class="tocnumber">8</span> <span class="toctext">Related techniques</span></a>
<ul>
<li class="toclevel-2"><a href="#Facial_Motion_Capture"><span class="tocnumber">8.1</span> <span class="toctext">Facial Motion Capture</span></a></li>
<li class="toclevel-2"><a href="#RF_Positioning"><span class="tocnumber">8.2</span> <span class="toctext">RF Positioning</span></a></li>
<li class="toclevel-2"><a href="#Non_Traditional_Systems"><span class="tocnumber">8.3</span> <span class="toctext">Non Traditional Systems</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#See_also"><span class="tocnumber">9</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1"><a href="#External_links"><span class="tocnumber">10</span> <span class="toctext">External links</span></a></li>
</ul>
</td>
</tr>
</table>
<script type="text/javascript">
//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>
</script>
<p><a name="The_procedure" id="The_procedure"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Motion_capture&amp;action=edit&amp;section=1" title="Edit section: The procedure">edit</a>]</span> <span class="mw-headline">The procedure</span></h2>
<p>In motion capture sessions, movements of one or more actors are sampled many times per second, although with most techniques (recent developments from ILM use images for 2D motion capture and project into 3D) motion capture records only the movements of the actor, not his/her visual appearance. This <i>animation data</i> is mapped to a 3D model so that the model performs the same actions as the actor. This is comparable to the older technique of <a href="/wiki/Rotoscope" title="Rotoscope" class="mw-redirect">rotoscope</a> where the visual appearance of the motion of an actor was filmed, then the film used as a guide for the frame by frame motion of a hand-drawn animated character.</p>
<p>Camera movements can also be motion captured so that a virtual camera in the scene will pan, tilt, or dolly around the stage driven by a camera operator, while the actor is performing and the motion capture system can capture the camera and props as well as the actor's performance. This allows the computer generated characters, images and sets, to have the same perspective as the video images from the camera. A computer processes the data and displays the movements of the actor, providing the desired camera positions in terms of objects in the set. Retroactively obtaining camera movement data from the captured footage is known as <a href="/wiki/Match_moving" title="Match moving">match moving</a>.</p>
<p><a name="Advantages" id="Advantages"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Motion_capture&amp;action=edit&amp;section=2" title="Edit section: Advantages">edit</a>]</span> <span class="mw-headline">Advantages</span></h2>
<p>Motion capture offers several advantages over traditional <a href="/wiki/Computer_animation" title="Computer animation">computer animation</a> of a 3D model:</p>
<ul>
<li>More rapid, even real time results can be obtained. In entertainment applications this can reduce the costs of keyframe-based animation. For example: <a href="/wiki/Hand_Over" title="Hand Over" class="mw-redirect">Hand Over</a></li>
</ul>
<ul>
<li>The amount of work does not vary with the complexity or length of the performance to the same degree when using traditional techniques. This allows many tests to be done with different styles or deliveries.</li>
</ul>
<ul>
<li>Complex movement and realistic physical interactions such as secondary motions, weight and exchange of forces can be easily recreated in a physically accurate manner.</li>
</ul>
<p><a name="Disadvantages" id="Disadvantages"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Motion_capture&amp;action=edit&amp;section=3" title="Edit section: Disadvantages">edit</a>]</span> <span class="mw-headline">Disadvantages</span></h2>
<ul>
<li>Specific hardware and special programs are required to obtain and process the data.</li>
</ul>
<ul>
<li>The cost of the software and equipment, personnel required can be prohibitive for small productions.</li>
</ul>
<ul>
<li>The capture system may have specific requirements for the space it is operated in depending on camera field of view.</li>
</ul>
<ul>
<li>When problems occur it is easier to reshoot the scene rather than trying to manipulate the data. Only a few systems allow real time viewing of the data to decide if the take needs to be redone.</li>
</ul>
<ul>
<li>Capturing motion for quadruped characters can be difficult.</li>
</ul>
<ul>
<li>The results are limited to what can be performed within the capture volume without extra editing of the data.</li>
</ul>
<ul>
<li>Movement that does not follow the laws of physics generally cannot be captured.</li>
</ul>
<ul>
<li>Traditional animation techniques such as added emphasis on anticipation and follow through, secondary motion or manipulating the shape of the character as with squash and stretch animation techniques must be added later.</li>
</ul>
<ul>
<li>If the computer model has different proportions from the capture subject artifacts may occur. For example, if a cartoon character has large, over-sized hands, these may intersect strangely with any other body part when the human actor brings them too close to his body.</li>
</ul>
<ul>
<li>The real life performance may not translate on to the computer model as expected.</li>
</ul>
<p><a name="Applications" id="Applications"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Motion_capture&amp;action=edit&amp;section=4" title="Edit section: Applications">edit</a>]</span> <span class="mw-headline">Applications</span></h2>
<p><a href="/wiki/Video_game" title="Video game">Video games</a> often use motion capture to animate athletes, martial artists, and other in-game characters.</p>
<p>Movies use motion capture for CG effects, in some cases replacing traditional cel animation, and for completely <a href="/wiki/Computer-generated_imagery" title="Computer-generated imagery">computer-generated</a> creatures, such as <a href="/wiki/Jar_Jar_Binks" title="Jar Jar Binks">Jar Jar Binks</a>, <a href="/wiki/Gollum" title="Gollum">Gollum</a>, <a href="/wiki/The_Mummy_(1999_film)" title="The Mummy (1999 film)">The Mummy</a>, and <a href="/wiki/Peter_Jackson%27s_King_Kong" title="Peter Jackson's King Kong" class="mw-redirect">King Kong</a>.</p>
<p><i><a href="/wiki/Sinbad:_Beyond_the_Veil_of_Mists" title="Sinbad: Beyond the Veil of Mists">Sinbad: Beyond the Veil of Mists</a></i> was the first movie made primarily with motion capture, although many character animators also worked on the film.</p>
<p>In producing entire feature films with <a href="/wiki/Computer_animation" title="Computer animation">computer animation</a>, the industry is currently split between studios that use motion capture, and studios that do not. Out of the three nominees for the 2006 <a href="/wiki/Academy_Award_for_Best_Animated_Feature" title="Academy Award for Best Animated Feature">Academy Award for Best Animated Feature</a>, two of the nominees (<i><a href="/wiki/Monster_House_(film)" title="Monster House (film)">Monster House</a></i> and the winner <i><a href="/wiki/Happy_Feet" title="Happy Feet">Happy Feet</a></i>) used motion capture, and only <a href="/wiki/Pixar" title="Pixar">Pixar's</a> <i><a href="/wiki/Cars_(film)" title="Cars (film)">Cars</a></i> was animated without motion capture. In the ending credits of <a href="/wiki/Pixar" title="Pixar">Pixar's</a> film <i><a href="/wiki/Ratatouille_(film)" title="Ratatouille (film)">Ratatouille</a></i>, a stamp appears labelling the film as "100% Pure Animation -- No Motion Capture!"</p>
<p>Motion capture has begun to be used extensively to produce films which attempt to simulate or approximate the look of live-action cinema, with nearly photorealistic digital character models. <i><a href="/wiki/The_Polar_Express_(film)" title="The Polar Express (film)">The Polar Express</a></i> used motion capture to allow <a href="/wiki/Tom_Hanks" title="Tom Hanks">Tom Hanks</a> to perform as several distinct digital characters (in which he also provided the voices). The 2007 adaptation of the saga <i><a href="/wiki/Beowulf_(2007_film)" title="Beowulf (2007 film)">Beowulf</a></i> animated digital characters whose appearances were based in part on the actors who provided their motions and voices. <a href="/wiki/The_Walt_Disney_Company" title="The Walt Disney Company">The Walt Disney Company</a> has announced that it will distribute <a href="/wiki/Robert_Zemeckis" title="Robert Zemeckis">Robert Zemeckis</a>'s <i><a href="/wiki/A_Christmas_Carol_(2009_film)" title="A Christmas Carol (2009 film)">A Christmas Carol</a></i> and <a href="/wiki/Tim_Burton" title="Tim Burton">Tim Burton</a>'s <i><a href="/wiki/Alice_in_Wonderland_(2010_film)" title="Alice in Wonderland (2010 film)">Alice in Wonderland</a></i> using this technique.</p>
<p><a href="/wiki/Virtual_Reality" title="Virtual Reality" class="mw-redirect">Virtual Reality</a> and <a href="/wiki/Augmented_Reality" title="Augmented Reality" class="mw-redirect">Augmented Reality</a> allow users to interact with digital content in real-time. This can be useful for training simulations, visual perception tests, or performing a virtual walk-throughs in a 3D environment. Motion capture technology is frequently used in <a href="/wiki/Digital_puppetry" title="Digital puppetry">digital puppetry</a> systems to drive computer generated characters in real-time.</p>
<p><a href="/wiki/Gait_analysis" title="Gait analysis">Gait analysis</a> is the major application of motion capture in <a href="/wiki/Clinical_medicine" title="Clinical medicine" class="mw-redirect">clinical medicine</a>. <a href="/w/index.php?title=Markerless_motion_capture&amp;action=edit&amp;redlink=1" class="new" title="Markerless motion capture (page does not exist)">Markerless motion capture</a> allows clinicians to evaluate human motion, without burdening patients with body suits or tracking devices. This allows patients to move freely within a defined area, using cameras that map the silhouette of the person and fit 3 to 24 perspectives to a model of the person, to track range of motion, gait, and several other biometric factors, and streams this information live into analytical software. Because this system removes the markers, patients, physicians and analysts are able to collect quantifiable data in real-time with less patient inconvenience, although they tend to have centimeter resolution verses the sub millimeter resolution of most marker based systems.</p>
<p><a name="Methods_and_systems" id="Methods_and_systems"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Motion_capture&amp;action=edit&amp;section=5" title="Edit section: Methods and systems">edit</a>]</span> <span class="mw-headline">Methods and systems</span></h2>
<p>Motion tracking or motion capture started as a photogrammetric analysis tool in biomechanics research in the 1970s and 1980s, and expanded into education, training, sports and recently <a href="/wiki/Computer_animation" title="Computer animation">computer animation</a> for <a href="/wiki/Film" title="Film">cinema</a> and <a href="/wiki/Video_games" title="Video games" class="mw-redirect">video games</a> as the technology matured. A performer wears markers near each joint to identify the motion by the positions or angles between the markers. Acoustic, inertial, <a href="/wiki/LED" title="LED" class="mw-redirect">LED</a>, magnetic or reflective markers, or combinations of any of these, are tracked, optimally at least two times the rate of the desired motion, to submillimeter positions.</p>
<p><a name="Optical_systems" id="Optical_systems"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Motion_capture&amp;action=edit&amp;section=6" title="Edit section: Optical systems">edit</a>]</span> <span class="mw-headline">Optical systems</span></h2>
<p><i>Optical systems</i> utilize data captured from image sensors to <a href="/wiki/Triangulation" title="Triangulation">triangulate</a> the 3D position of a subject between one or more cameras calibrated to provide overlapping projections. Data acquisition is traditionally implemented using special markers attached to an actor; however, more recent systems are able to generate accurate data by tracking surface features identified dynamically for each particular subject. Tracking a large number of performers or expanding the capture area is accomplished by the addition of more cameras. These systems produce data with 3 degrees of freedom for each marker, and rotational information must be inferred from the relative orientation of three or more markers; for instance shoulder, elbow and wrist markers providing the angle of the elbow.</p>
<p><a name="Optical:_Passive_Markers" id="Optical:_Passive_Markers"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Motion_capture&amp;action=edit&amp;section=7" title="Edit section: Optical: Passive Markers">edit</a>]</span> <span class="mw-headline">Optical: Passive Markers</span></h3>
<div class="thumb tright">
<div class="thumbinner" style="width:182px;"><a href="/wiki/File:MotionCapture.jpg" class="image" title="A dancer wearing a suit used in an optical motion capture system"><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/7/73/MotionCapture.jpg/180px-MotionCapture.jpg" width="180" height="178" border="0" class="thumbimage" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="/wiki/File:MotionCapture.jpg" class="internal" title="Enlarge"><img src="/skins-1.5/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
A dancer wearing a suit used in an optical motion capture system</div>
</div>
</div>
<div class="thumb tright">
<div class="thumbinner" style="width:182px;"><a href="/wiki/File:Motion_capture_facial.jpg" class="image" title="Several markers are placed at specific points on an actor's face during facial optical motion capture"><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Motion_capture_facial.jpg/180px-Motion_capture_facial.jpg" width="180" height="120" border="0" class="thumbimage" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="/wiki/File:Motion_capture_facial.jpg" class="internal" title="Enlarge"><img src="/skins-1.5/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
Several markers are placed at specific points on an actor's face during facial optical motion capture</div>
</div>
</div>
<p><i>Passive optical</i> system use markers coated with a <a href="/wiki/Retroreflective" title="Retroreflective" class="mw-redirect">retroreflective</a> material to reflect light back that is generated near the cameras lens. The camera's threshold can be adjusted so only the bright reflective markers will be sampled, ignoring skin and fabric.</p>
<p>The centroid of the marker is estimated as a position within the 2 dimensional image that is captured. The grayscale value of each pixel can be used to provide sub-pixel accuracy by finding the centroid of the <a href="/wiki/Gaussian" title="Gaussian" class="mw-redirect">Gaussian</a>.</p>
<p>An object with markers attached at known positions is used to calibrate the cameras and obtain their positions and the lens distortion of each camera is measured. Providing two calibrated cameras see a marker, a 3 dimensional fix can be obtained. Typically a system will consist of around 6 to 24 cameras. Systems of over three hundred cameras exist to try to reduce marker swap. Extra cameras are required for full coverage around the capture subject and multiple subjects.</p>
<p>Vendors have constraint software to reduce problems from marker swapping since all markers appear identical. Unlike active marker systems and magnetic systems, passive systems do not require the user to wear wires or electronic equipment rather hundreds of rubber balls with reflective tape, which needs to be replaced periodically. The markers are usually attached directly to the skin (as in biomechanics), or they are <a href="/wiki/Velcro" title="Velcro">velcroed</a> to a performer wearing a full body spandex/lycra suit designed specifically for motion capture. This type of system can capture large numbers of markers at frame rates as high as 2000fps. The frame rate for a given system is often traded off between resolution and speed so a 4 megapixel system runs at 370 hertz normally but can reduce the resolution to .3 megapixels and then run at 2000 hertz. Typical systems are $100,000 for 4 megapixel 360 hertz systems, and $50,000 for .3 megapixel 120 hertz systems.</p>
<p><a name="Optical:_Active_marker" id="Optical:_Active_marker"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Motion_capture&amp;action=edit&amp;section=8" title="Edit section: Optical: Active marker">edit</a>]</span> <span class="mw-headline">Optical: Active marker</span></h3>
<p>Active optical systems triangulate positions by illuminating one LED at a time very quickly or multiple LEDs with software to identify them by their relative positions, somewhat akin to celestial navigation. Rather than reflecting light back that is generated externally, the markers themselves are powered to emit their own light. Since Inverse Square law provides 1/4 the power at 2 times the distance, this can increase the distances and volume for capture. ILM used active Markers in Van Helsing to allow capture of the Harpies on very large sets. The power to each marker can be provided sequentially in phase with the capture system providing a unique identification of each marker for a given capture frame at a cost to the resultant frame rate. The ability to identify each marker in this manner is useful in realtime applications. The alternative method of identifying markers is to do it algorithmically requiring extra processing of the data.</p>
<p><a name="Optical:_Time_modulated_active_marker" id="Optical:_Time_modulated_active_marker"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Motion_capture&amp;action=edit&amp;section=9" title="Edit section: Optical: Time modulated active marker">edit</a>]</span> <span class="mw-headline">Optical: Time modulated active marker</span></h3>
<div class="thumb tright">
<div class="thumbinner" style="width:302px;"><a href="/wiki/File:Activemarker2.PNG" class="image" title="A high-resolution active marker system with 3,600 × 3,600 resolution at 480 hertz providing real time submillimeter positions."><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Activemarker2.PNG/300px-Activemarker2.PNG" width="300" height="214" border="0" class="thumbimage" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="/wiki/File:Activemarker2.PNG" class="internal" title="Enlarge"><img src="/skins-1.5/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
A high-resolution active marker system with 3,600 × 3,600 resolution at 480 hertz providing real time submillimeter positions.</div>
</div>
</div>
<p>Active marker systems can further be refined by strobing one marker on at a time, or tracking multiple markers over time and modulating the amplitude or pulse width to provide marker ID. 12 megapixel spatial resolution modulated systems show more subtle movements than 4 megapixel optical systems by having both higher spatial and temporal resolution. Directors can see the actors performance in real time, and watch the results on the mocap driven CG character. The unique marker IDs reduce the turnaround, by eliminating marker swapping and providing much cleaner data than other technologies. LEDs with onboard processing and a radio synchronization allow motion capture outdoors in direct sunlight, while capturing at 480 frames per second due to a high speed electronic shutter. Computer processing of modulated IDs allows less hand cleanup or filtered results for lower operational costs. This higher accuracy and resolution requires more processing than passive technologies, but the additional processing is done at the camera to improve resolution via a subpixel or centroid processing, providing both high resolution and high speed. These motion capture systems are typically under $50,000 for an eight camera, 12 megapixel spatial resolution 480 hertz system with one actor.</p>
<div class="thumb tright">
<div class="thumbinner" style="width:302px;"><a href="/wiki/File:PrakashOutdoorMotionCapture.jpg" class="image" title="IR sensors can compute their location when lit by mobile multi-LED emitters, e.g. in a moving car. With Id per marker, these sensor tags can be worn under clothing and tracked at 500 Hz in broad daylight."><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/e/ec/PrakashOutdoorMotionCapture.jpg/300px-PrakashOutdoorMotionCapture.jpg" width="300" height="106" border="0" class="thumbimage" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="/wiki/File:PrakashOutdoorMotionCapture.jpg" class="internal" title="Enlarge"><img src="/skins-1.5/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
<a href="/wiki/Infrared" title="Infrared">IR</a> sensors can compute their location when lit by mobile multi-LED emitters, e.g. in a moving car. With Id per marker, these sensor tags can be worn under clothing and tracked at 500 Hz in broad daylight.</div>
</div>
</div>
<p><a name="Optical:_Semi-passive_Imperceptible_Marker" id="Optical:_Semi-passive_Imperceptible_Marker"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Motion_capture&amp;action=edit&amp;section=10" title="Edit section: Optical: Semi-passive Imperceptible Marker">edit</a>]</span> <span class="mw-headline">Optical: Semi-passive Imperceptible Marker</span></h3>
<p>One can reverse the traditional approach based on high speed cameras. Systems such as Prakash use inexpensive multi-LED high speed projectors. The specially built multi-LED IR projectors optically encode the space. Instead of retro-reflective or active light emitting diode (LED) markers, the system uses photosensitive marker tags to decode the optical signals. By attaching tags with photo sensors to scene points, the tags can compute not only their own locations of each point, but also their own orientation, incident illumination, and reflectance.</p>
<p>These tracking tags that work in natural lighting conditions and can be imperceptibly embedded in attire or other objects. The system supports an unlimited number of tags in a scene, with each tag uniquely identified to eliminate marker reacquisition issues. Since the system eliminates a high speed camera and the corresponding high-speed image stream, it requires significantly lower data bandwidth. The tags also provide incident illumination data which can be used to match scene lighting when inserting synthetic elements. The technique appears ideal for on-set motion capture or real-time broadcasting of virtual sets but has yet to be proven.</p>
<p><a name="Optical:_Markerless" id="Optical:_Markerless"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Motion_capture&amp;action=edit&amp;section=11" title="Edit section: Optical: Markerless">edit</a>]</span> <span class="mw-headline">Optical: Markerless</span></h3>
<p>Emerging techniques and research in <a href="/wiki/Computer_vision" title="Computer vision">computer vision</a> are leading to the rapid development of the markerless approach to motion capture. Markerless systems such as those developed at Stanford, MIT, and Max Planck Institute, do not require subjects to wear special equipment for tracking. Special computer algorithms are designed to allow the system to analyze multiple streams of optical input and identify human forms, breaking them down into constituent parts for tracking. Applications of this technology extend deeply into popular imagination about the future of computing technology.</p>
<p>One commercially available markerless system designed by <a href="http://www.organicmotion.com" class="external text" title="http://www.organicmotion.com" rel="nofollow">Organic Motion</a> was featured during <a href="/wiki/Intel" title="Intel" class="mw-redirect">Intel</a> CEO <a href="/wiki/Paul_Otellini" title="Paul Otellini">Paul Otellini</a>'s keynote address at the 2008 <a href="/wiki/Consumer_Electronics_Show" title="Consumer Electronics Show">Consumer Electronics Show</a> in Las Vegas. During the demonstration, singer <a href="/wiki/Steven_Harwell" title="Steven Harwell" class="mw-redirect">Steven Harwell</a> of the band <a href="/wiki/Smash_Mouth" title="Smash Mouth">Smash Mouth</a> performed live while tracking data generated in realtime by the markerless system were instantaneously fed into the <a href="/wiki/Unreal_Engine_3" title="Unreal Engine 3" class="mw-redirect">Unreal Engine 3</a>. By using the motion capture system as an input device, the game engine utilized tracking data to animate a virtual Steve located within a garage scene. The demonstration showcases the adaptability of markerless technology in service industries such as patient care wherein a variety of subjects could benefit from motion analysis without the need for extensive user calibrations. These systems work well with large motions, but tend to have difficulties with fingers, faces, wrist rotations and small motions. Some systems require no special suits, while others prefer special colors to identify limbs.</p>
<p><a name="Non-optical_systems" id="Non-optical_systems"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Motion_capture&amp;action=edit&amp;section=12" title="Edit section: Non-optical systems">edit</a>]</span> <span class="mw-headline">Non-optical systems</span></h2>
<p><a name="Inertial_systems" id="Inertial_systems"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Motion_capture&amp;action=edit&amp;section=13" title="Edit section: Inertial systems">edit</a>]</span> <span class="mw-headline">Inertial systems</span></h3>
<p>Inertial Motion Capture technology is based on miniature inertial sensors, biomechanical models and sensor fusion algorithms. It's an easy to use and cost-efficient way for full-body human motion capture. The motion data of the inertial sensors (<a href="/wiki/Inertial_guidance_system" title="Inertial guidance system" class="mw-redirect">inertial guidance system</a>) is transmitted wirelessly to a PC or laptop, where the full body motion is recorded or viewed. Most inertial systems use Gyroscopes to measure rotations. These rotations are translated to a skeleton in the software. Much like optical markers, the more gyro's the more human like the data. No external cameras, emitters or markers are needed for relative motions. Inertial mocap systems capture the full six degrees of freedom body motion of a human in real-time. Benefits of using Inertial systems include; No solving, freedom from studios as most systems are portable, and large capture areas. These systems are similar to the Wii controllers but much more sensitive and having much greater resolution and update rate. They can accurately measure the direction to the ground to within a degree. The popularity of inertial systems is rising amongst independent game developers, mainly because of the quick and easy set up resulting in a fast pipeline. A range of suits are now available from various manufacturers and base price's range from $25,000 to $80,000 USD.</p>
<p><a name="Mechanical_motion" id="Mechanical_motion"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Motion_capture&amp;action=edit&amp;section=14" title="Edit section: Mechanical motion">edit</a>]</span> <span class="mw-headline">Mechanical motion</span></h3>
<p>Mechanical motion capture systems directly track body joint angles and are often referred to as exo-skeleton motion capture systems, due to the way the sensors are attached to the body. A performer attaches the skeletal-like structure to their body and as they move so do the articulated mechanical parts, measuring the performer’s relative motion. Mechanical motion capture systems are real-time, relatively low-cost, free-of-occlusion, and wireless (untethered) systems that have unlimited capture volume. Typically, they are rigid structures of jointed, straight metal or plastic rods linked together with potentiometers that articulate at the joints of the body. These suits tend to be in the $25,000 to $75,000 range plus an external absolution positioning system.</p>
<p><br /></p>
<p><a name="Magnetic_systems" id="Magnetic_systems"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Motion_capture&amp;action=edit&amp;section=15" title="Edit section: Magnetic systems">edit</a>]</span> <span class="mw-headline">Magnetic systems</span></h3>
<p>Magnetic systems calculate position and orientation by the relative magnetic flux of three orthogonal coils on both the transmitter and each receiver. The relative intensity of the voltage or current of the three coils allows these systems to calculate both range and orientation by meticulously mapping the tracking volume. <a href="http://www.jzztechnologies.com" class="external text" title="http://www.jzztechnologies.com" rel="nofollow">JZZ Technologies, Inc</a> uses this hardware in their E-Factor motion capture analysis program. The sensor output is <a href="/wiki/6DOF" title="6DOF" class="mw-redirect">6DOF</a>, which provides useful results obtained with two-thirds the number of markers required in optical systems; one on upper arm and one on lower arm for elbow position and angle. The markers are not occluded by nonmetallic objects but are susceptible to magnetic and electrical interference from metal objects in the environment, like rebar (steel reinforcing bars in concrete) or wiring, which affect the magnetic field, and electrical sources such as monitors, lights, cables and computers. The sensor response is nonlinear, especially toward edges of the capture area. The wiring from the sensors tends to preclude extreme performance movements. The capture volumes for magnetic systems are dramatically smaller than they are for optical systems. With the magnetic systems, there is a distinction between “AC” and “DC” systems: one uses square pulses, the other uses sine wave pulse.</p>
<p><br /></p>
<p><a name="Related_techniques" id="Related_techniques"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Motion_capture&amp;action=edit&amp;section=16" title="Edit section: Related techniques">edit</a>]</span> <span class="mw-headline">Related techniques</span></h2>
<p><a name="Facial_Motion_Capture" id="Facial_Motion_Capture"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Motion_capture&amp;action=edit&amp;section=17" title="Edit section: Facial Motion Capture">edit</a>]</span> <span class="mw-headline">Facial Motion Capture</span></h3>
<p>Most traditional motion capture hardware vendors provide for some type of low resolution facial capture utilizing anywhere from 32 to 300 markers with either an active or passive marker system. All of these solutions are limited by the time it takes to apply the markers, calibrate the positions and process the data. Ultimately the technology also limits their resolution and raw output quality levels.</p>
<p>High Fidelity Facial Motion Capture, also known as Performance Capture, is the next generation of fidelity and is utilized to record the more complex movements in a human face in order to capture higher degrees of emotion. Facial capture is currently arranging itself in several distinct camps. Studio Pendulum's Alter Ego and ArtemDigital's NVisage are utilizing traditional <a href="/wiki/Vicon" title="Vicon">Vicon</a> based motion capture data enhanced with custom software to layer and control blend shapes. Three companies, <a href="/wiki/Image_Metrics" title="Image Metrics">Image Metrics</a>, <a href="/w/index.php?title=Mova&amp;action=edit&amp;redlink=1" class="new" title="Mova (page does not exist)">Mova</a> and <a href="/w/index.php?title=CaptiveMotion&amp;action=edit&amp;redlink=1" class="new" title="CaptiveMotion (page does not exist)">CaptiveMotion</a> have developed proprietary systems for capturing facial performances.</p>
<p><a href="/wiki/Image_Metrics" title="Image Metrics">Image Metrics</a> extends the blend shaped based solution by allowing markerless tracking of HD video captured of an artists performance. <a href="/w/index.php?title=CaptiveMotion%27s_Embody&amp;action=edit&amp;redlink=1" class="new" title="CaptiveMotion's Embody (page does not exist)">CaptiveMotion's Embody</a> and <a href="/w/index.php?title=Mova%27s_Contour&amp;action=edit&amp;redlink=1" class="new" title="Mova's Contour (page does not exist)">Mova's Contour</a> capture the actual topology of an actors face which allows for a greater level of detail without the limits of dealing with a pre-defined blend shape library.</p>
<p><a name="RF_Positioning" id="RF_Positioning"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Motion_capture&amp;action=edit&amp;section=18" title="Edit section: RF Positioning">edit</a>]</span> <span class="mw-headline">RF Positioning</span></h3>
<p>RF (radio frequency) positioning systems are becoming more viable as higher frequency RF devices allow greater precision than older RF technologies. The speed of light is 30 centimeters per nanosecond (billionth of a second), so a 10 gigahertz (billion cycles per second) RF signal enables an accuracy of about 3 centimeters. By measuring amplitude to a quarter wavelength, it is possible to improve the resolution down to about 8 mm. To achieve the resolution of optical systems, frequencies of 50 gigahertz or higher are needed, which are almost as line of sight and as easy to block as optical systems. Multipath and reradiation of the signal are likely to cause additional problems, but these technologies will be ideal for tracking larger volumes with reasonable accuracy, since the required resolution at 100 meter distances isn’t likely to be as high.</p>
<p><a name="Non_Traditional_Systems" id="Non_Traditional_Systems"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Motion_capture&amp;action=edit&amp;section=19" title="Edit section: Non Traditional Systems">edit</a>]</span> <span class="mw-headline">Non Traditional Systems</span></h3>
<p>An alternative approach was developed where the actor is given an unlimited walking area through the use of a rotating sphere, similar to a <a href="/w/index.php?title=File:000_0580.JPG&amp;action=edit&amp;redlink=1" class="new" title="File:000 0580.JPG (page does not exist)">hamster ball</a>, which contains internal sensors recording the angular movements, removing the need for external cameras and other equipment. Even though this technology could potentially lead to much lower costs for mocap, the basic sphere is only capable of recording a single continuous direction. Additional sensors worn on the person would be needed to record anything more.</p>
<p>A studio in the Netherlands is using a 6DOF (Degrees of freedom) motion platform with an integrated omni-directional treadmill with high resolution optical motion capture to achieve the same effect. The captured person can walk in an unlimited area, negotiating different uneven terrains. Applications include medical rehabilitation for balance training, biomechanical research and virtual reality.</p>
<p><a name="See_also" id="See_also"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Motion_capture&amp;action=edit&amp;section=20" title="Edit section: See also">edit</a>]</span> <span class="mw-headline">See also</span></h2>
<div class="noprint tright portal" style="border:solid #aaa 1px;margin:0.5em 0 0.5em 0.5em;">
<table style="background:#f9f9f9; font-size:85%; line-height:110%;">
<tr>
<td><a href="/wiki/File:5-cell.gif" class="image" title="5-cell.gif"><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/d/d8/5-cell.gif" width="28" height="28" border="0" /></a></td>
<td style="padding:0 0.2em;"><i><b><a href="/wiki/Portal:Computer_graphics" title="Portal:Computer graphics">Computer graphics portal</a></b></i></td>
</tr>
</table>
</div>
<ul>
<li><a href="/wiki/Video_games" title="Video games" class="mw-redirect">Video games</a></li>
<li><a href="/wiki/Animation" title="Animation">Animation</a></li>
<li><a href="/wiki/Rotoscope" title="Rotoscope" class="mw-redirect">Rotoscope</a></li>
<li><a href="/wiki/Match_moving" title="Match moving">Match moving</a>, also known as “motion tracking”</li>
<li><a href="/wiki/Gollum" title="Gollum">Gollum</a>, a character in <i><a href="/wiki/The_Lord_of_the_Rings_film_trilogy" title="The Lord of the Rings film trilogy">The Lord of the Rings</a></i> movies who was partially animated with motion capture (the motion capture was used as a reference even when the original data wasn't used.)</li>
<li><a href="/wiki/List_of_motion_and_gesture_file_formats" title="List of motion and gesture file formats">List of motion and gesture file formats</a></li>
<li><a href="/wiki/Hand_Over" title="Hand Over" class="mw-redirect">Hand Over</a></li>
</ul>
<p><a name="External_links" id="External_links"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Motion_capture&amp;action=edit&amp;section=21" title="Edit section: External links">edit</a>]</span> <span class="mw-headline">External links</span></h2>
<ul>
<li><a href="http://www.truebones.com" class="external text" title="http://www.truebones.com" rel="nofollow">Truebones motion capture resources and software</a></li>
<li><a href="http://ftm.ircam.fr/index.php/Gesture_Follower" class="external text" title="http://ftm.ircam.fr/index.php/Gesture_Follower" rel="nofollow">Gesture Follower project at Ircam - Centre Pompidou, Paris</a> MaxMSP Motion tracking system</li>
<li><a href="http://www.xsens.com/en/company-pages/company/human-mocap" class="external text" title="http://www.xsens.com/en/company-pages/company/human-mocap" rel="nofollow">Human motion analysis for Motion Capturing</a> Paper of introduction to the beginning of Mocap technologies.</li>
<li><a href="http://www.jzztechnologies.com" class="external text" title="http://www.jzztechnologies.com" rel="nofollow">JZZ Technologies, Inc</a>- E-Factor motion capture analysis program</li>
<li><a href="http://www.virtualcinematography.org/" class="external text" title="http://www.virtualcinematography.org/" rel="nofollow">VirtualCinematography.org</a>—Several papers on Universal Capture use in Matrix films</li>
<li><a href="http://www.cgw.com/ME2/dirmod.asp?sid=&amp;nm=&amp;type=Publishing&amp;mod=Publications%3A%3AArticle&amp;mid=8F3A7027421841978F18BE895F87F791&amp;tier=4&amp;id=A8B4004315A84A5089255A2E366E2E78" class="external text" title="http://www.cgw.com/ME2/dirmod.asp?sid=&amp;nm=&amp;type=Publishing&amp;mod=Publications%3A%3AArticle&amp;mid=8F3A7027421841978F18BE895F87F791&amp;tier=4&amp;id=A8B4004315A84A5089255A2E366E2E78" rel="nofollow">CGW Article on motion capture</a></li>
<li><a href="http://www.motion-capture-system.com/resources/index.html" class="external text" title="http://www.motion-capture-system.com/resources/index.html" rel="nofollow">Motion Capture Resources</a></li>
<li><a href="http://mocap.cs.cmu.edu" class="external text" title="http://mocap.cs.cmu.edu" rel="nofollow">Free Repository of Motion Capture Data</a></li>
<li><a href="http://www.motioncapturesociety.com" class="external text" title="http://www.motioncapturesociety.com" rel="nofollow">Free Data, membership and information on Motion Capture</a></li>
<li><a href="http://www.motioncapturesociety.com/mcswiki/pmwiki.php?n=Main.MocapRecords" class="external text" title="http://www.motioncapturesociety.com/mcswiki/pmwiki.php?n=Main.MocapRecords" rel="nofollow">The World Records of Motion Capture</a> -- As of 2008-02-09, link has been overrun by spammers. Click on HomePage button on left, then "World Records" link to get to good page.</li>
<li><a href="http://www.mocap.lt/motion-capture/download-mocap-data.html" class="external text" title="http://www.mocap.lt/motion-capture/download-mocap-data.html" rel="nofollow">Free Motion Capture data - Full body and Face MOCAP data</a></li>
<li><a href="http://www.mocapdata.com" class="external text" title="http://www.mocapdata.com" rel="nofollow">MoCapData</a> — Over 4,000 Free Motion Capture data by VICON</li>
<li><a href="http://www.motekentertainment.com" class="external text" title="http://www.motekentertainment.com" rel="nofollow">Motek Entertainment</a> — Thousands of optical motion capture sequences in BVH and FBX formats.</li>
<li><a href="http://www.centroidonline.com" class="external text" title="http://www.centroidonline.com" rel="nofollow">Centroid Online</a> — Hundreds of motion capture sequences in BVH and FBX formats.</li>
<li><a href="http://www.youtube.com/watch?v=vqYursDTOCQ" class="external text" title="http://www.youtube.com/watch?v=vqYursDTOCQ" rel="nofollow">Markerless MoCap for Interaction</a> — Markerless full-body motion capture for human-computer interaction using a single camera.</li>
<li><a href="http://www.motion-capture-system.com/gallery.php" class="external text" title="http://www.motion-capture-system.com/gallery.php" rel="nofollow">Motion Capture Videos</a></li>
<li><a href="http://www.mocapservice.com/" class="external text" title="http://www.mocapservice.com/" rel="nofollow">Mocap Service by EDDADESIGN</a> - Full Body &amp; Facial Mocap Service in Barcelona. VICON Technology</li>
<li><a href="http://www.centroid3d.com/" class="external text" title="http://www.centroid3d.com/" rel="nofollow">Mocap Service by Centroid3D</a> - Full Body &amp; Facial Mocap Service at Pinewood Studios, UK. Motion Analysis Technology</li>
<li><a href="http://www.ndigital.com/lifesciences/researchgrade.php" class="external text" title="http://www.ndigital.com/lifesciences/researchgrade.php" rel="nofollow">Research-Grade Motion Capture Technology</a> - Wireless motion capture systems by Northern Digital</li>
</ul>
<p><br /></p>
<p>Research groups addressing the task of Markerless Motion Capture:</p>
<ul>
<li><a href="http://www.stanford.edu/~stefanoc/Markerless/Markerless.html" class="external text" title="http://www.stanford.edu/~stefanoc/Markerless/Markerless.html" rel="nofollow">Stanford</a></li>
<li><a href="http://www.mpi-inf.mpg.de/~rosenhahn" class="external text" title="http://www.mpi-inf.mpg.de/~rosenhahn" rel="nofollow">MPI Saarbruecken</a></li>
<li><a href="http://www.cs.cmu.edu/~german/research/HumanApp/humanapp.html" class="external text" title="http://www.cs.cmu.edu/~german/research/HumanApp/humanapp.html" rel="nofollow">Carnegie Mellon University</a></li>
<li><a href="http://cvrr.ucsd.edu" class="external text" title="http://cvrr.ucsd.edu" rel="nofollow">University of California, San Diego</a></li>
<li><a href="http://vision.cs.tum.edu/projects/memoman/" class="external text" title="http://vision.cs.tum.edu/projects/memoman/" rel="nofollow">Technische Universität München, Germany</a></li>
</ul>


<!-- 
NewPP limit report
Preprocessor node count: 191/1000000
Post-expand include size: 3779/2048000 bytes
Template argument size: 1232/2048000 bytes
Expensive parser function count: 1/500
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:396968-0!1!0!default!!en!2 and timestamp 20090406202923 -->
<div class="printfooter">
Retrieved from "<a href="http://en.wikipedia.org/wiki/Motion_capture">http://en.wikipedia.org/wiki/Motion_capture</a>"</div>
			<div id='catlinks' class='catlinks'><div id="mw-normal-catlinks"><a href="/wiki/Special:Categories" title="Special:Categories">Categories</a>:&#32;<span dir='ltr'><a href="/wiki/Category:Computer_animation" title="Category:Computer animation">Computer animation</a></span> | <span dir='ltr'><a href="/wiki/Category:3D_computer_graphics" title="Category:3D computer graphics">3D computer graphics</a></span></div><div id="mw-hidden-catlinks" class="mw-hidden-cats-hidden">Hidden categories:&#32;<span dir='ltr'><a href="/wiki/Category:Articles_lacking_sources_from_May_2008" title="Category:Articles lacking sources from May 2008">Articles lacking sources from May 2008</a></span> | <span dir='ltr'><a href="/wiki/Category:All_articles_lacking_sources" title="Category:All articles lacking sources">All articles lacking sources</a></span></div></div>			<!-- end content -->
						<div class="visualClear"></div>
		</div>
	</div>
		</div>
		<div id="column-one">
	<div id="p-cactions" class="portlet">
		<h5>Views</h5>
		<div class="pBody">
			<ul>
	
				 <li id="ca-nstab-main" class="selected"><a href="/wiki/Motion_capture" title="View the content page [c]" accesskey="c">Article</a></li>
				 <li id="ca-talk"><a href="/wiki/Talk:Motion_capture" title="Discussion about the content page [t]" accesskey="t">Discussion</a></li>
				 <li id="ca-edit"><a href="/w/index.php?title=Motion_capture&amp;action=edit" title="You can edit this page. &#10;Please use the preview button before saving. [e]" accesskey="e">Edit this page</a></li>
				 <li id="ca-history"><a href="/w/index.php?title=Motion_capture&amp;action=history" title="Past versions of this page [h]" accesskey="h">History</a></li>			</ul>
		</div>
	</div>
	<div class="portlet" id="p-personal">
		<h5>Personal tools</h5>
		<div class="pBody">
			<ul>
				<li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Motion_capture" title="You are encouraged to log in; however, it is not mandatory. [o]" accesskey="o">Log in / create account</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-logo">
		<a style="background-image: url(http://upload.wikimedia.org/wikipedia/en/b/bc/Wiki.png);" href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
	<div class='generated-sidebar portlet' id='p-navigation'>
		<h5>Navigation</h5>
		<div class='pBody'>
			<ul>
				<li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li>
				<li id="n-contents"><a href="/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li>
				<li id="n-featuredcontent"><a href="/wiki/Portal:Featured_content" title="Featured content — the best of Wikipedia">Featured content</a></li>
				<li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li>
				<li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li>
			</ul>
		</div>
	</div>
	<div id="p-search" class="portlet">
		<h5><label for="searchInput">Search</label></h5>
		<div id="searchBody" class="pBody">
			<form action="/w/index.php" id="searchform"><div>
				<input type='hidden' name="title" value="Special:Search"/>
				<input id="searchInput" name="search" type="text" title="Search Wikipedia [f]" accesskey="f" value="" />
				<input type='submit' name="go" class="searchButton" id="searchGoButton"	value="Go" title="Go to a page with this exact name if one exists" />&nbsp;
				<input type='submit' name="fulltext" class="searchButton" id="mw-searchButton" value="Search" title="Search Wikipedia for this text" />
			</div></form>
		</div>
	</div>
	<div class='generated-sidebar portlet' id='p-interaction'>
		<h5>Interaction</h5>
		<div class='pBody'>
			<ul>
				<li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li>
				<li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li>
				<li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="The list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li>
				<li id="n-contact"><a href="/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact Wikipedia</a></li>
				<li id="n-sitesupport"><a href="http://wikimediafoundation.org/wiki/Donate" title="Support us">Donate to Wikipedia</a></li>
				<li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-tb">
		<h5>Toolbox</h5>
		<div class="pBody">
			<ul>
				<li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Motion_capture" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li>
				<li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Motion_capture" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li>
<li id="t-upload"><a href="/wiki/Wikipedia:Upload" title="Upload files [u]" accesskey="u">Upload file</a></li>
<li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="List of all special pages [q]" accesskey="q">Special pages</a></li>
				<li id="t-print"><a href="/w/index.php?title=Motion_capture&amp;printable=yes" rel="alternate" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>				<li id="t-permalink"><a href="/w/index.php?title=Motion_capture&amp;oldid=282186526" title="Permanent link to this version of the page">Permanent link</a></li><li id="t-cite"><a href="/w/index.php?title=Special:Cite&amp;page=Motion_capture&amp;id=282186526">Cite this page</a></li>			</ul>
		</div>
	</div>
	<div id="p-lang" class="portlet">
		<h5>Languages</h5>
		<div class="pBody">
			<ul>
				<li class="interwiki-da"><a href="http://da.wikipedia.org/wiki/Motion_capture">Dansk</a></li>
				<li class="interwiki-de"><a href="http://de.wikipedia.org/wiki/Motion_Capture">Deutsch</a></li>
				<li class="interwiki-es"><a href="http://es.wikipedia.org/wiki/Captura_de_movimiento">Español</a></li>
				<li class="interwiki-fr"><a href="http://fr.wikipedia.org/wiki/Captation_de_mouvements">Français</a></li>
				<li class="interwiki-ko"><a href="http://ko.wikipedia.org/wiki/%EB%AA%A8%EC%85%98%EC%BA%A1%EC%B2%98">한국어</a></li>
				<li class="interwiki-it"><a href="http://it.wikipedia.org/wiki/Motion_capture">Italiano</a></li>
				<li class="interwiki-nl"><a href="http://nl.wikipedia.org/wiki/Motion_Capturing">Nederlands</a></li>
				<li class="interwiki-ja"><a href="http://ja.wikipedia.org/wiki/%E3%83%A2%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%82%AD%E3%83%A3%E3%83%97%E3%83%81%E3%83%A3">日本語</a></li>
				<li class="interwiki-pl"><a href="http://pl.wikipedia.org/wiki/Motion_capture">Polski</a></li>
				<li class="interwiki-ru"><a href="http://ru.wikipedia.org/wiki/Motion_capture">Русский</a></li>
			</ul>
		</div>
	</div>
		</div><!-- end of the left (by default at least) column -->
			<div class="visualClear"></div>
			<div id="footer">
				<div id="f-poweredbyico"><a href="http://www.mediawiki.org/"><img src="/skins-1.5/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" /></a></div>
				<div id="f-copyrightico"><a href="http://wikimediafoundation.org/"><img src="/images/wikimedia-button.png" border="0" alt="Wikimedia Foundation"/></a></div>
			<ul id="f-list">
					<li id="lastmod"> This page was last modified on 6 April 2009, at 20:29.</li>
					<li id="copyright">All text is available under the terms of the <a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Text_of_the_GNU_Free_Documentation_License" title="Wikipedia:Text of the GNU Free Documentation License">GNU Free Documentation License</a>. (See <b><a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Copyrights" title="Wikipedia:Copyrights">Copyrights</a></b> for details.) <br /> Wikipedia&reg; is a registered trademark of the <a href="http://www.wikimediafoundation.org">Wikimedia Foundation, Inc.</a>, a U.S. registered <a class='internal' href="http://en.wikipedia.org/wiki/501%28c%29#501.28c.29.283.29" title="501(c)(3)">501(c)(3)</a> <a href="http://wikimediafoundation.org/wiki/Deductibility_of_donations">tax-deductible</a> <a class='internal' href="http://en.wikipedia.org/wiki/Non-profit_organization" title="Non-profit organization">nonprofit</a> <a href="http://en.wikipedia.org/wiki/Charitable_organization" title="Charitable organization">charity</a>.<br /></li>
					<li id="privacy"><a href="http://wikimediafoundation.org/wiki/Privacy_policy" title="wikimedia:Privacy policy">Privacy policy</a></li>
					<li id="about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
					<li id="disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
			</ul>
		</div>
</div>

		<script type="text/javascript">if (window.runOnloadHook) runOnloadHook();</script>
<!-- Served by srv223 in 0.045 secs. --></body></html>
