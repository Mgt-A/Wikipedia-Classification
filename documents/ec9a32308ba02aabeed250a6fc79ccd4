<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
		<meta http-equiv="Content-Style-Type" content="text/css" />
		<meta name="generator" content="MediaWiki 1.15alpha" />
		<meta name="keywords" content="Eye tracking,Articles with unsourced statements since January 2009,Articles with unsourced statements since February 2007,Articles with unsourced statements since March 2009,Eye tracker,Advertising,Alfred L. Yarbus,Aluminum,Attention,Automotive,Cerebral palsy" />
		<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Eye_tracking&amp;action=edit" />
		<link rel="edit" title="Edit this page" href="/w/index.php?title=Eye_tracking&amp;action=edit" />
		<link rel="apple-touch-icon" href="http://en.wikipedia.org/apple-touch-icon.png" />
		<link rel="shortcut icon" href="/favicon.ico" />
		<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)" />
		<link rel="copyright" href="http://www.gnu.org/copyleft/fdl.html" />
		<link rel="alternate" type="application/rss+xml" title="Wikipedia RSS Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=rss" />
		<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=atom" />
		<title>Eye tracking - Wikipedia, the free encyclopedia</title>
		<link rel="stylesheet" href="/skins-1.5/common/shared.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/common/commonPrint.css?207xx" type="text/css" media="print" />
		<link rel="stylesheet" href="/skins-1.5/monobook/main.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/chick/main.css?207xx" type="text/css" media="handheld" />
		<!--[if lt IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE50Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE55Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 6]><link rel="stylesheet" href="/skins-1.5/monobook/IE60Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 7]><link rel="stylesheet" href="/skins-1.5/monobook/IE70Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Common.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Print.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="print" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Handheld.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="handheld" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Monobook.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=-&amp;action=raw&amp;maxage=2678400&amp;gen=css" type="text/css" />
		<!--[if lt IE 7]><script type="text/javascript" src="/skins-1.5/common/IEFixes.js?207xx"></script>
		<meta http-equiv="imagetoolbar" content="no" /><![endif]-->

		<script type= "text/javascript">/*<![CDATA[*/
		var skin = "monobook";
		var stylepath = "/skins-1.5";
		var wgArticlePath = "/wiki/$1";
		var wgScriptPath = "/w";
		var wgScript = "/w/index.php";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = "http://en.wikipedia.org";
		var wgCanonicalNamespace = "";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = "Eye_tracking";
		var wgTitle = "Eye tracking";
		var wgAction = "view";
		var wgArticleId = "1543423";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = "en";
		var wgContentLanguage = "en";
		var wgBreakFrames = false;
		var wgCurRevisionId = 282714461;
		var wgVersion = "1.15alpha";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = ["", ""];
		var wgDigitTransformTable = ["", ""];
		var wgMWSuggestTemplate = "http://en.wikipedia.org/w/api.php?action=opensearch\x26search={searchTerms}\x26namespace={namespaces}\x26suggest";
		var wgDBname = "enwiki";
		var wgSearchNamespaces = [0];
		var wgMWSuggestMessages = ["with suggestions", "no suggestions"];
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		/*]]>*/</script>

		<script type="text/javascript" src="/skins-1.5/common/wikibits.js?207xx"><!-- wikibits js --></script>
		<!-- Head Scripts -->
		<script type="text/javascript" src="/skins-1.5/common/ajax.js?207xx"></script>
		<script type="text/javascript" src="/skins-1.5/common/mwsuggest.js?207xx"></script>
<script type="text/javascript">/*<![CDATA[*/
var wgNotice='';var wgNoticeLocal='';
/*]]>*/</script>		<script type="text/javascript" src="http://upload.wikimedia.org/centralnotice/wikipedia/en/centralnotice.js?207xx"></script>
		<script type="text/javascript" src="/w/index.php?title=-&amp;action=raw&amp;gen=js&amp;useskin=monobook"><!-- site js --></script>
	</head>
<body class="mediawiki ltr ns-0 ns-subject page-Eye_tracking skin-monobook">
	<div id="globalWrapper">
		<div id="column-content">
	<div id="content">
		<a name="top" id="top"></a>
		<div id="siteNotice"><script type='text/javascript'>if (wgNotice != '') document.writeln(wgNotice);</script></div>		<h1 id="firstHeading" class="firstHeading">Eye tracking</h1>
		<div id="bodyContent">
			<h3 id="siteSub">From Wikipedia, the free encyclopedia</h3>
			<div id="contentSub"></div>
									<div id="jump-to-nav">Jump to: <a href="#column-one">navigation</a>, <a href="#searchInput">search</a></div>			<!-- start content -->
			<table class="metadata plainlinks ambox ambox-style" style="">
<tr>
<td class="mbox-image">
<div style="width: 52px;"><a href="/wiki/File:Text_document_with_red_question_mark.svg" class="image" title="Text document with red question mark.svg"><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a4/Text_document_with_red_question_mark.svg/40px-Text_document_with_red_question_mark.svg.png" width="40" height="40" border="0" /></a></div>
</td>
<td class="mbox-text" style="">This article includes a <a href="/wiki/Wikipedia:Citing_sources" title="Wikipedia:Citing sources">list of references</a> or <a href="/wiki/Wikipedia:External_links" title="Wikipedia:External links">external links</a>, but <b>its sources remain unclear because it has insufficient <a href="/wiki/Wikipedia:Citing_sources#Adding_the_citation" title="Wikipedia:Citing sources">inline citations</a></b>. Please help to <a href="/wiki/Wikipedia:WikiProject_Fact_and_Reference_Check" title="Wikipedia:WikiProject Fact and Reference Check">improve</a> this article by introducing more precise citations <a href="/wiki/Wikipedia:When_to_cite" title="Wikipedia:When to cite">where appropriate</a>. <small><i>(March 2009)</i></small></td>
</tr>
</table>
<p><b>Eye tracking</b> is the process of measuring either the point of <a href="/wiki/Gaze" title="Gaze">gaze</a> ("where we are looking") or the motion of an <a href="/wiki/Eye" title="Eye">eye</a> relative to the head. An <b>eye tracker</b> is a device for measuring <a href="/wiki/Eye" title="Eye">eye</a> positions and <a href="/wiki/Eye_movements" title="Eye movements" class="mw-redirect">eye movements</a>. Eye trackers are used in research on the <a href="/wiki/Visual_system" title="Visual system">visual system</a>, in <a href="/wiki/Psychology" title="Psychology">psychology</a>, in <a href="/wiki/Cognitive_linguistics" title="Cognitive linguistics">cognitive linguistics</a> and in <a href="/wiki/Product_design" title="Product design">product design</a>. There are a number of methods for measuring eye movements. The most popular variant uses video images from which the eye position is extracted. Other methods use <a href="/wiki/Search_coil" title="Search coil">search coils</a> or are based on the <a href="/wiki/Electrooculography" title="Electrooculography">electrooculogram</a>.</p>
<table id="toc" class="toc" summary="Contents">
<tr>
<td>
<div id="toctitle">
<h2>Contents</h2>
</div>
<ul>
<li class="toclevel-1"><a href="#History"><span class="tocnumber">1</span> <span class="toctext">History</span></a></li>
<li class="toclevel-1"><a href="#Tracker_types"><span class="tocnumber">2</span> <span class="toctext">Tracker types</span></a></li>
<li class="toclevel-1"><a href="#Technologies_and_techniques"><span class="tocnumber">3</span> <span class="toctext">Technologies and techniques</span></a></li>
<li class="toclevel-1"><a href="#Eye_tracking_vs._gaze_tracking"><span class="tocnumber">4</span> <span class="toctext">Eye tracking vs. gaze tracking</span></a></li>
<li class="toclevel-1"><a href="#Eye_tracking_in_practice"><span class="tocnumber">5</span> <span class="toctext">Eye tracking in practice</span></a>
<ul>
<li class="toclevel-2"><a href="#Eye_tracking_while_driving_a_car_in_a_difficult_situation"><span class="tocnumber">5.1</span> <span class="toctext">Eye tracking while driving a car in a difficult situation</span></a></li>
<li class="toclevel-2"><a href="#Eye_tracking_of_younger_and_elderly_people_in_walking"><span class="tocnumber">5.2</span> <span class="toctext">Eye tracking of younger and elderly people in walking</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Choosing_an_eye_tracker"><span class="tocnumber">6</span> <span class="toctext">Choosing an eye tracker</span></a></li>
<li class="toclevel-1"><a href="#Applications"><span class="tocnumber">7</span> <span class="toctext">Applications</span></a>
<ul>
<li class="toclevel-2"><a href="#Commercial_applications"><span class="tocnumber">7.1</span> <span class="toctext">Commercial applications</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Notes"><span class="tocnumber">8</span> <span class="toctext">Notes</span></a></li>
<li class="toclevel-1"><a href="#References"><span class="tocnumber">9</span> <span class="toctext">References</span></a>
<ul>
<li class="toclevel-2"><a href="#Commercial_eye_tracking"><span class="tocnumber">9.1</span> <span class="toctext">Commercial eye tracking</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#See_also"><span class="tocnumber">10</span> <span class="toctext">See also</span></a></li>
</ul>
</td>
</tr>
</table>
<script type="text/javascript">
//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>
</script>
<p><a name="History" id="History"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Eye_tracking&amp;action=edit&amp;section=1" title="Edit section: History">edit</a>]</span> <span class="mw-headline">History</span></h2>
<p>In the 1800s, studies of eye movements were made using direct observations.</p>
<p>In 1879 in Paris, <a href="/wiki/Louis_%C3%89mile_Javal" title="Louis Émile Javal">Louis Émile Javal</a> observed that reading does not involve a smooth sweeping of the eyes along the text, as previously assumed, but a series of short stops (called fixations) and quick <a href="/wiki/Saccade" title="Saccade">saccades</a>.<sup id="cite_ref-0" class="reference"><a href="#cite_note-0" title=""><span>[</span>1<span>]</span></a></sup> This observation raised important questions about reading, which were explored during the 1900s: On which words do the eyes stop? For how long? When does it regress back to already seen words?</p>
<div class="thumb tleft">
<div class="thumbinner" style="width:322px;"><a href="/wiki/File:ReadingFixationsSaccades.jpg" class="image" title="An example of fixations and saccades over text. This is the typical pattern of eye movements during reading. The eyes never move smoothly over still text."><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/b/b9/ReadingFixationsSaccades.jpg/320px-ReadingFixationsSaccades.jpg" width="320" height="240" border="0" class="thumbimage" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="/wiki/File:ReadingFixationsSaccades.jpg" class="internal" title="Enlarge"><img src="/skins-1.5/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
An example of fixations and saccades over text. This is the typical pattern of eye movements during reading. The eyes never move smoothly over still text.</div>
</div>
</div>
<p>Edmund Huey<sup id="cite_ref-1" class="reference"><a href="#cite_note-1" title=""><span>[</span>2<span>]</span></a></sup> built an early eye tracker, using a sort of <a href="/wiki/Contact_lens" title="Contact lens">contact lens</a> with a hole for the <a href="/wiki/Pupil" title="Pupil">pupil</a>. The lens was connected to an <a href="/wiki/Aluminum" title="Aluminum" class="mw-redirect">aluminum</a> pointer that moved in response to the movements of the eye. Huey studied and quantified regressions (only a small proportion of saccades are regressions), and show that some words in a sentence are not fixated.</p>
<p>The first non-intrusive eye trackers were built by Guy Thomas Buswell in Chicago, using beams of light that were reflected on the eye and then recording them on film. Buswell made systematic studies into reading<sup id="cite_ref-2" class="reference"><a href="#cite_note-2" title=""><span>[</span>3<span>]</span></a></sup> and picture viewing<sup id="cite_ref-3" class="reference"><a href="#cite_note-3" title=""><span>[</span>4<span>]</span></a></sup>.</p>
<p>In the 1950s, <a href="/wiki/Alfred_L._Yarbus" title="Alfred L. Yarbus">Alfred L. Yarbus</a><sup id="cite_ref-4" class="reference"><a href="#cite_note-4" title=""><span>[</span>5<span>]</span></a></sup> did important eye tracking research and his 1967 book is one of the most quoted eye tracking publications ever. For example he showed the task given to a subject has a very large influence on the subject's eye movements. He also wrote about the relation between fixations and interest:</p>
<dl>
<dd>"All the records (…) show conclusively that the character of the eye movements is either completely independent of or only very slightly dependent on the material of the picture and how it was made, provided that it is flat or nearly flat." <sup id="cite_ref-5" class="reference"><a href="#cite_note-5" title=""><span>[</span>6<span>]</span></a></sup> The cyclical pattern in the examination of pictures "is dependent not only on what is shown on the picture, but also on the problem facing the observer and the information that he hopes to gain from the picture." <sup id="cite_ref-6" class="reference"><a href="#cite_note-6" title=""><span>[</span>7<span>]</span></a></sup></dd>
</dl>
<div class="thumb tright">
<div class="thumbinner" style="width:322px;"><a href="/wiki/File:Yarbus_The_Visitor.jpg" class="image" title="This study by Yarbus (1967) is often referred to as evidence on how the task given to a person influences his or her eye movements."><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/d/d2/Yarbus_The_Visitor.jpg/320px-Yarbus_The_Visitor.jpg" width="320" height="273" border="0" class="thumbimage" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="/wiki/File:Yarbus_The_Visitor.jpg" class="internal" title="Enlarge"><img src="/skins-1.5/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
This study by Yarbus (1967) is often referred to as evidence on how the task given to a person influences his or her eye movements.</div>
</div>
</div>
<dl>
<dd>"Records of eye movements show that the observer's attention is usually held only by certain elements of the picture. (…) Eye movements reflect the human thought processes; so the observer's thought may be followed to some extent from records of eye movements (the thought accompanying the examination of the particular object). It is easy to determine from these records which elements attract the observer's eye (and, consequently, his thought), in what order, and how often." <sup id="cite_ref-7" class="reference"><a href="#cite_note-7" title=""><span>[</span>8<span>]</span></a></sup></dd>
</dl>
<dl>
<dd>"The observer's attention is frequently drawn to elements which do not give important information but which, in his opinion, may do so. Often an observer will focus his attention on elements that are unusual in the particular circumstances, unfamiliar, incomprehensible, and so on." <sup id="cite_ref-8" class="reference"><a href="#cite_note-8" title=""><span>[</span>9<span>]</span></a></sup></dd>
</dl>
<dl>
<dd>"(…) when changing its points of fixation, the observer's eye repeatedly returns to the same elements of the picture. Additional time spent on perception is not used to examine the secondary elements, but to reexamine the most important elements." <sup id="cite_ref-9" class="reference"><a href="#cite_note-9" title=""><span>[</span>10<span>]</span></a></sup></dd>
</dl>
<div class="thumb tright">
<div class="thumbinner" style="width:322px;"><a href="/wiki/File:Eye_tracking_thru_glass.JPG" class="image" title="This study by Hunziker (1970)[11]on eye tracking in problem solving used simple 8&#160;mm film to track eye movements by filming the subject through a glass plate on which the visual problem was displayed.   To view a slow motion movie of the eye tracking in problem solving click:  http://www.learning-systems.ch/multimedia/eye%20movements%20problem%20solving.swf  for details of the study:  http://www.learning-systems.ch/multimedia/forsch1e.htm"><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/d/de/Eye_tracking_thru_glass.JPG/320px-Eye_tracking_thru_glass.JPG" width="320" height="240" border="0" class="thumbimage" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="/wiki/File:Eye_tracking_thru_glass.JPG" class="internal" title="Enlarge"><img src="/skins-1.5/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
This study by Hunziker (1970)<sup id="cite_ref-10" class="reference"><a href="#cite_note-10" title=""><span>[</span>11<span>]</span></a></sup>on <i>eye tracking in problem solving</i> used simple 8&#160;mm film to track eye movements by filming the subject through a glass plate on which the visual problem was displayed. To view a slow motion movie of the eye tracking in problem solving click: <a href="http://www.learning-systems.ch/multimedia/eye%20movements%20problem%20solving.swf" class="external free" title="http://www.learning-systems.ch/multimedia/eye%20movements%20problem%20solving.swf" rel="nofollow">http://www.learning-systems.ch/multimedia/eye%20movements%20problem%20solving.swf</a> for details of the study: <a href="http://www.learning-systems.ch/multimedia/forsch1e.htm" class="external free" title="http://www.learning-systems.ch/multimedia/forsch1e.htm" rel="nofollow">http://www.learning-systems.ch/multimedia/forsch1e.htm</a></div>
</div>
</div>
<p>In the 1970s, eye tracking research expanded rapidly, particularly reading research. A good overview of the research in this period is given by Rayner.<sup id="cite_ref-11" class="reference"><a href="#cite_note-11" title=""><span>[</span>12<span>]</span></a></sup>.</p>
<p>In 1980, Just and Carpenter <sup id="cite_ref-12" class="reference"><a href="#cite_note-12" title=""><span>[</span>13<span>]</span></a></sup> formulated the influential <i>Strong eye-mind Hypothesis</i>, the hypothesis that "there is no appreciable lag between what is fixated and what is processed". If this hypothesis is correct, then when a subject looks at a word or object, he or she also thinks about (process cognitively), and for exactly as long as the recorded fixation. The hypothesis is too often today taken for granted by beginning eye tracker researchers.</p>
<p>During the 1980s, the eye-mind hypothesis was often questioned in light of covert <a href="/wiki/Attention" title="Attention">attention</a>,<sup id="cite_ref-13" class="reference"><a href="#cite_note-13" title=""><span>[</span>14<span>]</span></a></sup> <sup id="cite_ref-14" class="reference"><a href="#cite_note-14" title=""><span>[</span>15<span>]</span></a></sup> the attention to something that one is not looking at, which people often do. If covert attention is common during eye tracking recordings, the resulting scan path and fixation patterns would often show not where our attention has been, but only where the eye has been looking, and so eye tracking would not indicate cognitive processing.</p>
<p>According to Hoffman, <sup id="cite_ref-15" class="reference"><a href="#cite_note-15" title=""><span>[</span>16<span>]</span></a></sup> current consensus is that visual attention is always slightly (100 to 250 ms) ahead of the eye. But as soon as attention moves to a new position, the eyes will want to follow.<sup id="cite_ref-16" class="reference"><a href="#cite_note-16" title=""><span>[</span>17<span>]</span></a></sup></p>
<p>We still cannot infer specific cognitive processes directly from a fixation on a particular object in a scene.<sup id="cite_ref-17" class="reference"><a href="#cite_note-17" title=""><span>[</span>18<span>]</span></a></sup> For instance, a fixation on a face in a picture may indicate recognition, liking, dislike, puzzlement etc. Therefore eye tracking is often coupled with other methodologies, such as introspective verbal protocols.</p>
<p><a name="Tracker_types" id="Tracker_types"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Eye_tracking&amp;action=edit&amp;section=2" title="Edit section: Tracker types">edit</a>]</span> <span class="mw-headline">Tracker types</span></h2>
<p>Eye trackers measure rotations of the eye in one of several ways, but principally they fall into three categories.</p>
<p>One type uses an attachment to the eye, such as a special contact lens with an embedded mirror or magnetic field sensor, and the movement of the attachment is measured with the assumption that it does not slip significantly as the eye rotates. Measurements with tight fitting contact lenses have provided extremely sensitive recordings of eye movement, and magnetic search coils are the method of choice for researchers studying the dynamics and underlying physiology of eye movements.</p>
<p>The second broad category uses some non-contact, optical method for measuring eye motion. Light, typically infrared, is reflected from the eye and sensed by a video camera or some other specially designed optical sensor. The information is then analyzed to extract eye rotation from changes in reflections. Video based eye trackers typically use the corneal reflection (the first <a href="/wiki/Purkinje_images" title="Purkinje images">Purkinje image</a>) and the center of the pupil as features to track over time. A more sensitive type of eye tracker, the dual-Purkinje eye tracker<sup id="cite_ref-18" class="reference"><a href="#cite_note-18" title=""><span>[</span>19<span>]</span></a></sup>, uses reflections from the front of the cornea (first Purkinje image) and the back of the lens (fourth Purkinje image) as features to track. A still more sensitive method of tracking is to image features from inside the eye, such as the retinal blood vessels, and follow these features as the eye rotates. Optical methods, particularly those based on video recording, are widely used for gaze tracking and are favored for being non-invasive and inexpensive.</p>
<p>The third category uses electrical potentials measured with contact electrodes placed near the eyes. The most common variant of this is the electro-oculogram (EOG) and is based on the fact that the eye has a standing electrical potential, with the cornea being positive relative to the retina. This potential is not constant, however, and its variation causes the EOG to be somewhat unreliable for measuring slow eye movements and fixed gaze positions. The EOG is most useful for measuring the rapid, saccadic eye movements associated with gaze shifts and is the method of choice for measuring REM during sleep.</p>
<p><a name="Technologies_and_techniques" id="Technologies_and_techniques"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Eye_tracking&amp;action=edit&amp;section=3" title="Edit section: Technologies and techniques">edit</a>]</span> <span class="mw-headline">Technologies and techniques</span></h2>
<p>The most widely used current designs are video-based eye trackers. A camera focuses on one or both eyes and records their movement as the viewer looks at some kind of stimulus. Most modern eye-trackers use contrast to locate the center of the pupil and use <a href="/wiki/Infrared" title="Infrared">infrared</a> and <a href="/wiki/Near-infrared" title="Near-infrared" class="mw-redirect">near-infrared</a> non-collimated light to create a <a href="/w/index.php?title=Corneal_reflection&amp;action=edit&amp;redlink=1" class="new" title="Corneal reflection (page does not exist)">corneal reflection</a> (CR). The vector between these two features can be used to compute gaze intersection with a surface after a simple calibration for an individual.</p>
<p>Two general types of eye tracking techniques are used: Bright Pupil and Dark Pupil. Their difference is based on the location of the illumination source with respect to the optics. If the illumination is <a href="/wiki/Coaxial" title="Coaxial">coaxial</a> with the optical path, then the eye acts as a <a href="/wiki/Retroreflector" title="Retroreflector">retroreflector</a> as the light reflects off the <a href="/wiki/Retina" title="Retina">retina</a> creating a bright pupil effect similar to <a href="/wiki/Red-eye_effect" title="Red-eye effect">red eye</a>. If the illumination source is offset from the optical path, then the pupil appears dark because the retroreflection from the retina is directed away from the camera.</p>
<p>Bright Pupil tracking creates greater iris/pupil contrast allowing for more robust eye tracking with all iris pigmentation and greatly reduces interference caused by eyelashes and other obscuring features<sup class="noprint Template-Fact"><span title="This claim needs references to reliable sources&#160;since January 2009" style="white-space: nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed">citation needed</a></i>]</span></sup>. It also allows for tracking in lighting conditions ranging from total darkness to very bright. But bright pupil techniques are not effective for tracking outdoors as extraneous IR sources interfere with monitoring<sup class="noprint Template-Fact"><span title="This claim needs references to reliable sources&#160;since January 2009" style="white-space: nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed">citation needed</a></i>]</span></sup>.</p>
<p>Eye tracking setups vary greatly; some are head-mounted, some require the head to be stable (for example, with a chin rest), and some function remotely and automatically track the head during motion. Most use a sampling rate of at least 30&#160;Hz. Although 50/60&#160;Hz is most common, today many video-based eye trackers run at 240, 350 or even 1000/1250&#160;Hz, which is needed in order to capture the detail of the very rapid eye movements during reading, or during studies of neurology.</p>
<p><a href="/wiki/Eye_movements" title="Eye movements" class="mw-redirect">Eye movements</a> are typically divided into <a href="/wiki/Fixation_(visual)" title="Fixation (visual)">fixations</a> and <a href="/wiki/Saccade" title="Saccade">saccades</a>, when the eye gaze pauses in a certain position, and when it moves to another position, respectively. The resulting series of fixations and saccades is called a <a href="/w/index.php?title=Scanpath&amp;action=edit&amp;redlink=1" class="new" title="Scanpath (page does not exist)">scanpath</a>. Most information from the eye is made available during a fixation, but not during a saccade.<sup class="noprint Template-Fact"><span title="This claim needs references to reliable sources&#160;since February 2007" style="white-space: nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed">citation needed</a></i>]</span></sup> The central one or two degrees of the visual angle (the <a href="/wiki/Fovea" title="Fovea">fovea</a>) provide the bulk of visual information; the input from larger eccentricities (the periphery) is less informative. Hence, the locations of fixations along a scanpath show what information loci on the stimulus were processed during an eye tracking session. On average, fixations last for around 200 ms during the reading of linguistic text, and 350 ms during the viewing of a scene. Preparing a saccade towards a new goal takes around 200 milliseconds.<sup class="noprint Template-Fact"><span title="This claim needs references to reliable sources&#160;since February 2007" style="white-space: nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed">citation needed</a></i>]</span></sup></p>
<p>Scanpaths are useful for analyzing cognitive intent, interest, and salience. Other biological factors (some as simple as gender) may affect the scanpath as well. Eye tracking in HCI typically investigates the scanpath for usability purposes, or as a method of input in <a href="/wiki/Gaze-contingency_paradigm" title="Gaze-contingency paradigm">gaze-contingent displays</a>, also known as <a href="/w/index.php?title=Gaze-based_interfaces&amp;action=edit&amp;redlink=1" class="new" title="Gaze-based interfaces (page does not exist)">gaze-based interfaces</a>.</p>
<p><a name="Eye_tracking_vs._gaze_tracking" id="Eye_tracking_vs._gaze_tracking"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Eye_tracking&amp;action=edit&amp;section=4" title="Edit section: Eye tracking vs. gaze tracking">edit</a>]</span> <span class="mw-headline">Eye tracking vs. gaze tracking</span></h2>
<p>Eye trackers necessarily measure the rotation of the eye with respect to the measuring system. If the measuring system is head mounted, as with EOG, then eye-in-head angles are measured. If the measuring system is table mounted, as with scleral search coils or table mounted camera (“remote”) systems, then gaze angles are measured.</p>
<p>In many applications, the head position is fixed using a bite bar, a forehead support or something similar, so that eye position and gaze are the same. In other cases, the head is free to move, and head movements are measured with systems such as magnetic or video based head trackers.</p>
<p>For head-mounted trackers, head position and direction are added to eye-in-head direction to determine gaze direction. For table-mounted systems, such as search coils, head direction is subtracted from gaze direction to determine eye-in-head position.</p>
<p><a name="Eye_tracking_in_practice" id="Eye_tracking_in_practice"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Eye_tracking&amp;action=edit&amp;section=5" title="Edit section: Eye tracking in practice">edit</a>]</span> <span class="mw-headline">Eye tracking in practice</span></h2>
<p>A great deal of research has gone into studies of the mechanisms and dynamics of eye rotation, but the goal of eye tracking is most often to estimate gaze direction. Users may be interested in what features of an image draw the eye, for example. It is important to realize that the eye tracker does not provide absolute gaze direction, but rather can only measure changes in gaze direction. In order to know precisely what a subject is looking at, some calibration procedure is required in which the subject looks at a point or series of points, while the eye tracker records the value that corresponds to each gaze position. (Even those techniques that track features of the retina cannot provide exact gaze direction because there is no specific anatomical feature that marks the exact point where the visual axis meets the retina, if indeed there is such a single, stable point.) An accurate and reliable calibration is essential for obtaining valid and repeatable eye movement data, and this can be a significant challenge for non-verbal subjects or those who have unstable gaze.</p>
<p>Each method of eye tracking has advantages and disadvantages, and the choice of an eye tracking system depends on considerations of cost and application. There is a trade-off between cost and sensitivity, with the most sensitive systems costing many tens of thousands of dollars and requiring considerable expertise to operate properly. Advances in computer and video technology have led to the development of relatively low cost systems that are useful for many applications and fairly easy to use. Interpretation of the results still requires some level of expertise, however, because a misaligned or poorly calibrated system can produce wildly erroneous data.</p>
<p><a name="Eye_tracking_while_driving_a_car_in_a_difficult_situation" id="Eye_tracking_while_driving_a_car_in_a_difficult_situation"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Eye_tracking&amp;action=edit&amp;section=6" title="Edit section: Eye tracking while driving a car in a difficult situation">edit</a>]</span> <span class="mw-headline">Eye tracking while driving a car in a difficult situation</span></h3>
<div class="thumb tright">
<div class="thumbinner" style="width:536px;"><a href="/wiki/File:Eye_movements_of_drivers.jpg" class="image" title="Explanations see corresponding text to the left."><img alt="" src="http://upload.wikimedia.org/wikipedia/en/2/20/Eye_movements_of_drivers.jpg" width="534" height="532" border="0" class="thumbimage" /></a>
<div class="thumbcaption">Explanations see corresponding text to the left.</div>
</div>
</div>
<p>Eye movements of two groups of drivers have been filmed with a special head camera by a team of the Swiss Federal Institute of Technology: Novice and experienced drivers had their eye-movements recorded while approaching a bend of a narrow road. The series of images has been condensed from the original film frames<sup id="cite_ref-19" class="reference"><a href="#cite_note-19" title=""><span>[</span>20<span>]</span></a></sup> to show 2 eye fixations per image for better comprehension.</p>
<p>Each of these stills correspond approximately to 0.5 seconds in realtime.</p>
<p>The series of images shows an example of eye fixations #9 to #14 of a typical novice and an experienced driver.</p>
<p>Comparison of the top images shows that the experienced driver checks the curve and even has <a href="/wiki/Fixation" title="Fixation">fixation</a> number 9 left to look aside while the novice driver needs to check the road and estimate his distance to the parked car.</p>
<p>In the middle images the experienced driver is now fully concentrating on the location where an oncoming car could be seen. The novice driver concentrates his view on the parked car.</p>
<p>In the bottom image the novice is busy estimating the distance between the left wall and the parked car, while the experienced driver can use his <a href="/wiki/Peripheral_vision" title="Peripheral vision">peripheral vision</a> for that and still concentrates his view on the dangerous point of the curve: If a car appears there he has to give way, i. e. stop to the right instead of passing the parked car.<sup id="cite_ref-20" class="reference"><a href="#cite_note-20" title=""><span>[</span>21<span>]</span></a></sup></p>
<p><a name="Eye_tracking_of_younger_and_elderly_people_in_walking" id="Eye_tracking_of_younger_and_elderly_people_in_walking"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Eye_tracking&amp;action=edit&amp;section=7" title="Edit section: Eye tracking of younger and elderly people in walking">edit</a>]</span> <span class="mw-headline">Eye tracking of younger and elderly people in walking</span></h3>
<p>Elderly subjects depend more on <a href="/wiki/Fovea" title="Fovea">foveal</a> vision than younger subjects during walking. Their walking speed is decreased by a limited <a href="/wiki/Visual_field" title="Visual field">visual field</a>, probably caused by a deteriorated <a href="/wiki/Peripheral" title="Peripheral">peripheral</a> vision.</p>
<p>Younger subjects make use of both their central and peripheral vision while walking. Their peripheral vision allows faster control over the process of walking.<sup id="cite_ref-21" class="reference"><a href="#cite_note-21" title=""><span>[</span>22<span>]</span></a></sup></p>
<p><a name="Choosing_an_eye_tracker" id="Choosing_an_eye_tracker"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Eye_tracking&amp;action=edit&amp;section=8" title="Edit section: Choosing an eye tracker">edit</a>]</span> <span class="mw-headline">Choosing an eye tracker</span></h2>
<p>One difficulty in evaluating an eye tracking system is that the eye is never still, and it can be difficult to distinguish the tiny, but rapid and somewhat chaotic movements associated with fixation from noise sources in the eye tracking mechanism itself. One useful evaluation technique is to record from the two eyes simultaneously and compare the vertical rotation records. The two eyes of a normal subject are very tightly coordinated and vertical gaze directions typically agree to within +/- 2 minutes of arc (RMS of vertical position difference) during steady fixation. A properly functioning and sensitive eye tracking system will show this level of agreement between the two eyes, and any differences much larger than this can usually be attributed to measurement error.</p>
<p><a name="Applications" id="Applications"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Eye_tracking&amp;action=edit&amp;section=9" title="Edit section: Applications">edit</a>]</span> <span class="mw-headline">Applications</span></h2>
<p>A wide variety of disciplines use eye tracking techniques, including <a href="/wiki/Cognitive_science" title="Cognitive science">cognitive science</a>, <a href="/wiki/Psychology" title="Psychology">psychology</a> (notably <a href="/wiki/Psycholinguistics" title="Psycholinguistics">psycholinguistics</a>, the visual world paradigm), <a href="/wiki/Human-computer_interaction" title="Human-computer interaction" class="mw-redirect">human-computer interaction</a> (HCI), <a href="/wiki/Marketing_research" title="Marketing research">marketing research</a> and medical research (neurological diagnosis). Specific applications include the tracking eye movement in <a href="/wiki/Eye_movement_in_language_reading" title="Eye movement in language reading">language reading</a>, <a href="/wiki/Eye_movement_in_music_reading" title="Eye movement in music reading">music reading</a>, the perception of advertising, and the playing of sport.<sup id="cite_ref-22" class="reference"><a href="#cite_note-22" title=""><span>[</span>23<span>]</span></a></sup> Uses include:</p>
<ul>
<li>Cognitive Studies</li>
<li>Medical Research</li>
<li>Human Factors</li>
<li>Computer Usability</li>
<li>Translation Process Research</li>
<li>Vehicle Simulators</li>
<li>In-vehicle Research</li>
<li>Training Simulators</li>
<li>Virtual Reality</li>
<li>Adult Research</li>
<li>Infant Research</li>
<li>Adolescent Research</li>
<li>Geriatric Research</li>
<li>Primate Research</li>
<li>Sports Training</li>
<li>fMRI / MEG / EEG</li>
<li>Commercial eye tracking (web usability, advertising, marketing, automotive, etc)</li>
<li>Finding good clues</li>
<li>Communication systems for disabled</li>
<li>Improved image and video communications</li>
</ul>
<p><a name="Commercial_applications" id="Commercial_applications"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Eye_tracking&amp;action=edit&amp;section=10" title="Edit section: Commercial applications">edit</a>]</span> <span class="mw-headline">Commercial applications</span></h3>
<p>In recent years, the increased sophistication and accessibility of eye tracking technologies have generated a great deal of interest in the commercial sector. Applications include <a href="/wiki/Web_usability" title="Web usability">web usability</a>, <a href="/wiki/Advertising" title="Advertising">advertising</a>, <a href="/wiki/Sponsor_(commercial)" title="Sponsor (commercial)">sponsorship</a>, package design and <a href="/wiki/Automotive" title="Automotive" class="mw-redirect">automotive</a> engineering. In general, commercial eye tracking studies function by presenting a target stimulus to a sample of consumers while an <a href="/wiki/Eye_tracker" title="Eye tracker" class="mw-redirect">eye tracker</a> is used to record the activity of the eye. Examples of target stimuli may include websites, television programs, sporting events, films, commercials, magazines, newspapers, packages, shelf Displays, consumer systems (ATMs, checkout systems, kiosks), and software. The resulting data can be statistically analyzed and graphically rendered to provide evidence of specific visual patterns. By examining fixations, <a href="/wiki/Saccades" title="Saccades" class="mw-redirect">saccades</a>, pupil dilation, blinks and a variety of other behaviors researchers can determine a great deal about the effectiveness of a given medium or product. While some companies complete this type of research internally, there are many private companies that offer eye tracking services and analysis.</p>
<p>The most prominent field of commercial eye tracking research is <a href="/wiki/Web_usability" title="Web usability">web usability</a>. While traditional usability techniques are often quite powerful in providing information on clicking and scrolling patterns, eye tracking offers the ability to analyze user interaction between the clicks. This provides valuable insight into which features are the most eye-catching, which features cause confusion and which ones are ignored altogether. Specifically, eye tracking can be used to assess search efficiency, branding, online advertisements, navigation usability, overall design and many other site components. Analyses may target a <a href="/wiki/Prototype" title="Prototype">prototype</a> or competitor site in addition to the main client site.</p>
<p>Eye tracking is commonly used in a variety of different <a href="/wiki/Advertising" title="Advertising">advertising</a> media. Commercials, print ads, online ads and sponsored programs are all conducive to analysis with current eye tracking technology. Analyses focus on visibility of a target product or logo in the context of a magazine, newspaper, website, or televised event. This allows researchers to assess in great detail how often a sample of consumers fixates on the target logo, product or ad. In this way, an advertiser can quantify the success of a given campaign in terms of actual visual attention.</p>
<p>Eye tracking provides package designers with the opportunity to examine the visual behavior of a consumer while interacting with a target package. This may be used to analyze distinctiveness, attractiveness and the tendency of the package to be chosen for purchase. Eye tracking is often utilized while the target product is in the <a href="/wiki/Prototype" title="Prototype">prototype</a> stage. Prototypes are tested against each other and competitors to examine which specific elements are associated with high visibility and appeal.</p>
<p>One of the most promising applications of eye tracking research is in the field of <a href="/wiki/Automotive" title="Automotive" class="mw-redirect">automotive</a> design. Research is currently underway to integrate eye tracking cameras into automobiles. The goal of this endeavor is to provide the vehicle with the capacity to assess in real-time the visual behavior of the driver. The <a href="/wiki/National_Highway_Traffic_Safety_Administration" title="National Highway Traffic Safety Administration">National Highway Traffic Safety Administration</a> (NHTSA) estimates that drowsiness is the primary causal factor in 100,000 police-reported accidents per year. Another NHTSA study suggests that 80% of collisions occur within three seconds of a distraction. By equipping automobiles with the ability to monitor drowsiness, inattention, and <a href="/w/index.php?title=Cognitive_engagement&amp;action=edit&amp;redlink=1" class="new" title="Cognitive engagement (page does not exist)">cognitive engagement</a> driving safety could be dramatically enhanced. <a href="/wiki/Lexus" title="Lexus">Lexus</a> claims to have equipped its <a href="/wiki/Lexus_LS" title="Lexus LS">LS 460</a> with the first driver monitor system in 2006, providing a warning if the driver takes his or her eye off the road.<sup id="cite_ref-preventative_23-0" class="reference"><a href="#cite_note-preventative-23" title=""><span>[</span>24<span>]</span></a></sup></p>
<p>Since 2005, eye tracking is used in communication systems for disabled persons: allowing the user to speak, send e-mail, browse the Internet and perform other such activities, using only their eyes. Eye control works even when the user has involuntary movements as a result of <a href="/wiki/Cerebral_palsy" title="Cerebral palsy">Cerebral palsy</a> or other disabilities, and for those who have glasses or other physical interference which would limit the effectiveness of older eye control systems.<sup class="noprint Template-Fact"><span title="This claim needs references to reliable sources&#160;since March 2009" style="white-space: nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed">citation needed</a></i>]</span></sup></p>
<p>Eye tracking has also seen minute use in autofocus still camera equipment, where users can focus on a subject simply by looking at it through the viewfinder.<sup class="noprint Template-Fact"><span title="This claim needs references to reliable sources&#160;since March 2009" style="white-space: nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed">citation needed</a></i>]</span></sup></p>
<p><a name="Notes" id="Notes"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Eye_tracking&amp;action=edit&amp;section=11" title="Edit section: Notes">edit</a>]</span> <span class="mw-headline">Notes</span></h2>
<div class="references-small">
<ol class="references">
<li id="cite_note-0"><b><a href="#cite_ref-0" title="">^</a></b> Reported in Huey 1908/1968.</li>
<li id="cite_note-1"><b><a href="#cite_ref-1" title="">^</a></b> <cite style="font-style:normal" class="book" id="CITEREFHuey">Huey, Edmund. <i>The Psychology and Pedagogy of Reading (Reprint)</i>. MIT Press 1968 (originally published 1908).</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Psychology+and+Pedagogy+of+Reading+%28Reprint%29&amp;rft.aulast=Huey&amp;rft.aufirst=Edmund&amp;rft.au=Huey%2C+Edmund&amp;rft.pub=MIT+Press+1968+%28originally+published+1908%29&amp;rfr_id=info:sid/en.wikipedia.org:Eye_tracking"><span style="display: none;">&#160;</span></span></li>
<li id="cite_note-2"><b><a href="#cite_ref-2" title="">^</a></b> Buswell (1922, 1937)</li>
<li id="cite_note-3"><b><a href="#cite_ref-3" title="">^</a></b> (1935)</li>
<li id="cite_note-4"><b><a href="#cite_ref-4" title="">^</a></b> Yarbus (1967)</li>
<li id="cite_note-5"><b><a href="#cite_ref-5" title="">^</a></b> (Yarbus 1967: 190)</li>
<li id="cite_note-6"><b><a href="#cite_ref-6" title="">^</a></b> (Yarbus 1967:194)</li>
<li id="cite_note-7"><b><a href="#cite_ref-7" title="">^</a></b> (Yarbus 1967:190).</li>
<li id="cite_note-8"><b><a href="#cite_ref-8" title="">^</a></b> (Yarbus 1967:191).</li>
<li id="cite_note-9"><b><a href="#cite_ref-9" title="">^</a></b> (Yarbus 1967:193).</li>
<li id="cite_note-10"><b><a href="#cite_ref-10" title="">^</a></b> Hunziker, H. W. (1970). Visuelle Informationsaufnahme und Intelligenz: Eine Untersuchung über die Augenfixationen beim Problemlösen. Schweizerische Zeitschrift für Psychologie und ihre Anwendungen, 1970, 29, Nr 1/2 (english abstract: <a href="http://www.learning-systems.ch/multimedia/forsch1e.htm" class="external free" title="http://www.learning-systems.ch/multimedia/forsch1e.htm" rel="nofollow">http://www.learning-systems.ch/multimedia/forsch1e.htm</a> )</li>
<li id="cite_note-11"><b><a href="#cite_ref-11" title="">^</a></b> Rayner (1978)</li>
<li id="cite_note-12"><b><a href="#cite_ref-12" title="">^</a></b> Just and Carpenter (1980)</li>
<li id="cite_note-13"><b><a href="#cite_ref-13" title="">^</a></b> Posner (1980)</li>
<li id="cite_note-14"><b><a href="#cite_ref-14" title="">^</a></b> Wright &amp; Ward (2008)</li>
<li id="cite_note-15"><b><a href="#cite_ref-15" title="">^</a></b> Hoffman 1998</li>
<li id="cite_note-16"><b><a href="#cite_ref-16" title="">^</a></b> Deubel and Schneider 1996 <a href="http://www.sciencedirect.com/science?_ob=ArticleURL&amp;_udi=B6T0W-3VXNHBP-10&amp;_user=952938&amp;_coverDate=06%2F30%2F1996&amp;_rdoc=1&amp;_fmt=&amp;_orig=search&amp;_sort=d&amp;view=c&amp;_acct=C000049220&amp;_version=1&amp;_urlVersion=0&amp;_userid=952938&amp;md5=4f7fbf4f015fde59aa9a39b30154e7f3" class="external autonumber" title="http://www.sciencedirect.com/science?_ob=ArticleURL&amp;_udi=B6T0W-3VXNHBP-10&amp;_user=952938&amp;_coverDate=06%2F30%2F1996&amp;_rdoc=1&amp;_fmt=&amp;_orig=search&amp;_sort=d&amp;view=c&amp;_acct=C000049220&amp;_version=1&amp;_urlVersion=0&amp;_userid=952938&amp;md5=4f7fbf4f015fde59aa9a39b30154e7f3" rel="nofollow">[1]</a></li>
<li id="cite_note-17"><b><a href="#cite_ref-17" title="">^</a></b> Holsanova 2007</li>
<li id="cite_note-18"><b><a href="#cite_ref-18" title="">^</a></b> <cite style="font-style:normal" class="" id="CITEREFCraneSteele.2C_C.M.">Crane, H.D.; Steele, C.M.. "Generation-V dual-Purkinje-image eyetracker". <i>Applied Optics</i> <b>24</b>: 527-537.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Generation-V+dual-Purkinje-image+eyetracker&amp;rft.jtitle=Applied+Optics&amp;rft.aulast=Crane&amp;rft.aufirst=H.D.&amp;rft.au=Crane%2C+H.D.&amp;rft.au=Steele%2C+C.M.&amp;rft.volume=24&amp;rft.pages=527-537&amp;rfr_id=info:sid/en.wikipedia.org:Eye_tracking"><span style="display: none;">&#160;</span></span></li>
<li id="cite_note-19"><b><a href="#cite_ref-19" title="">^</a></b> Cohen, A. S. (1983). Informationsaufnahme beim Befahren von Kurven, Psychologie für die Praxis 2/83, Bulletin der Schweizerischen Stiftung für Angewandte Psychologie</li>
<li id="cite_note-20"><b><a href="#cite_ref-20" title="">^</a></b> Pictures from: Hans-Werner Hunziker, (2006) Im Auge des Lesers: foveale und periphere Wahrnehmung - vom Buchstabieren zur Lesefreude [In the eye of the reader: foveal and peripheral perception - from letter recognition to the joy of reading] Transmedia Stäubli Verlag Zürich 2006 <a href="/wiki/Special:BookSources/9783726600686" class="internal">ISBN 978-3-7266-0068-6</a></li>
<li id="cite_note-21"><b><a href="#cite_ref-21" title="">^</a></b> Itoh N, Fukuda T. (2002) Comparative study of eye movements in extent of central and peripheral vision and use by young and elderly walkers.Percept Mot Skills. 2002 Jun;94(3 Pt 2):1283-91</li>
<li id="cite_note-22"><b><a href="#cite_ref-22" title="">^</a></b> See, e.g., <a href="http://www.sol.lu.se/humlab/research/humlabResearch.html?fileName=et_sv.html&amp;language=EN" class="external text" title="http://www.sol.lu.se/humlab/research/humlabResearch.html?fileName=et_sv.html&amp;language=EN" rel="nofollow">newspaper reading studies</a>.</li>
<li id="cite_note-preventative-23"><b><a href="#cite_ref-preventative_23-0" title="">^</a></b> <cite style="font-style:normal" class="web"><a href="http://www.newcarnet.co.uk/Lexus_news.html?id=5787" class="external text" title="http://www.newcarnet.co.uk/Lexus_news.html?id=5787" rel="nofollow">"LS460 achieves a world-first in preventative safety"</a> (HTML). NewCarNet.co.uk. 2006-08-30<span class="printonly">. <a href="http://www.newcarnet.co.uk/Lexus_news.html?id=5787" class="external free" title="http://www.newcarnet.co.uk/Lexus_news.html?id=5787" rel="nofollow">http://www.newcarnet.co.uk/Lexus_news.html?id=5787</a></span><span class="reference-accessdate">. Retrieved on 2007-04-08</span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=LS460+achieves+a+world-first+in+preventative+safety&amp;rft.atitle=&amp;rft.date=2006-08-30&amp;rft.pub=NewCarNet.co.uk&amp;rft_id=http%3A%2F%2Fwww.newcarnet.co.uk%2FLexus_news.html%3Fid%3D5787&amp;rfr_id=info:sid/en.wikipedia.org:Eye_tracking"><span style="display: none;">&#160;</span></span></li>
</ol>
</div>
<p><a name="References" id="References"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Eye_tracking&amp;action=edit&amp;section=12" title="Edit section: References">edit</a>]</span> <span class="mw-headline">References</span></h2>
<ul>
<li>Adler FH &amp; Fliegelman (1934). Influence of fixation on the visual acuity. Arch. Ophthalmology 12, 475.</li>
<li>Buswell, G.T. (1922). Fundamental reading habits: A study of their development. Chicago, IL: University of Chicago Press.</li>
<li>Buswell G.T. (1935). How People Look at Pictures. Chicago: Univ. Chicago Press 137–55. Hillsdale, NJ: Erlbaum</li>
<li>Buswell, G.T. (1937). How adults read. Chicago, IL: University of Chicago Press.</li>
<li>Carpenter, Roger H.S.; Movements of the Eyes (2nd ed.). Pion Ltd, London, 1988. <a href="/wiki/Special:BookSources/0850861098" class="internal">ISBN 0-85086-109-8</a>.</li>
<li>Cornsweet TN, Crane HD. (1973) Accurate two-dimensional eye tracker using first and fourth Purkinje images. J Opt Soc Am. 63, 921-8.</li>
<li>Cornsweet TN. (1958). New technique for the measurement of small eye movements. JOSA 48, 808-811.</li>
<li>Deubel, H. &amp; Schneider, W.X. (1996) Saccade target selection and object recognition: Evidence for a common attentional mechanism. Vision Research, 36, 1827-1837.</li>
<li>Duchowski, A. T., "A Breadth-First Survey of Eye Tracking Applications", Behavior Research Methods, Instruments, &amp; Computers (BRMIC), 34(4), November 2002, pp.455-470.</li>
<li>Eizenman M, Hallett PE, Frecker RC. (1985). Power spectra for ocular drift and tremor. Vision Res. 25, 1635-40</li>
<li>Ferguson RD (1998). Servo tracking system utilizing phase-sensitive detection of reflectance variations. US Patent # 5,767,941</li>
<li>Hammer DX, Ferguson RD, Magill JC, White MA, Elsner AE, Webb RH. (2003) Compact scanning laser ophthalmoscope with high-speed retinal tracker. Appl Opt. 42, 4621-32.</li>
<li>Hoffman, J. E. (1998). Visual attention and eye movements. In H. Pashler (ed.), Attention (pp. 119-154). Hove, UK: Psychology Press.</li>
<li>Holsanova, J. (forthcoming) Picture viewing and picture descriptions, Benjamins.</li>
<li>Huey, E.B. (1968). The psychology and pedagogy of reading. Cambridge, MA: MIT Press. (Originally published 1908)</li>
<li>Jacob, R. J. K. &amp; Karn, K. S. (2003). Eye Tracking in Human-Computer Interaction and Usability Research: Ready to Deliver the Promises. In R. Radach, J. Hyona, &amp; H. Deubel (eds.), The mind's eye: cognitive and applied aspects of eye movement research (pp.573-605). Boston: North-Holland/Elsevier.</li>
<li>Just MA, Carpenter PA (1980) A theory of reading: from eye fixation to comprehension. Psychol Rev 87:329–354</li>
<li>Liechty,J, Pieters, R, &amp; Wedel, M. (2003). The Representation of Local and Global Exploration Modes in Eye Movements through Bayesian Hidden Markov Models. Psychometrika, 68 (4), 519-542.</li>
<li>Mulligan, JB, (1997). Recovery of Motion Parameters from Distortions in Scanned Images. Proceedings of the NASA Image Registration Workshop (IRW97), NASA Goddard Space Flight Center, MD</li>
<li>Ott D &amp; Daunicht WJ (1992). Eye movement measurement with the scanning laser ophthalmoscope. Clin. Vision Sci. 7, 551-556.</li>
<li>Posner, M. I. (1980) Orienting of attention. Quarterly Journal of Experimental Psychology 32: 3-25.</li>
<li>Rayner, K. (1978). Eye movements in reading and information processing. Psychological Bulletin, 85, 618-660</li>
<li>Rayner, K. (1998) Eye movements in reading and information processing: 20 years of research. Psychological Bulletin, 124, 372-422.</li>
<li>Riggs LA, Armington JC &amp; Ratliff F. (1954) Motions of the retinal image during fixation. JOSA 44, 315-321.</li>
<li>Riggs, L. A. &amp; Niehl, E. W. (1960). Eye movements recorded during convergence and divergence. J Opt Soc Am 50:913-920.</li>
<li>Robinson, D. A. A method of measuring eye movement using a scleral search coil in a magnetic field. IEEE Trans. Biomed. Eng., vol. BME-l0, pp. 137-145, 1963</li>
<li>Wright, R.D., &amp; Ward, L.M. (2008). Orienting of Attention. New York. Oxford University Press.</li>
<li>Yarbus, A. L. Eye Movements and Vision. Plenum. New York. 1967 (Originally published in Russian 1962)</li>
</ul>
<p><a name="Commercial_eye_tracking" id="Commercial_eye_tracking"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Eye_tracking&amp;action=edit&amp;section=13" title="Edit section: Commercial eye tracking">edit</a>]</span> <span class="mw-headline">Commercial eye tracking</span></h3>
<ul>
<li>Bojko, A. (2006). Using Eye Tracking to Compare Web Page Designs: A Case Study. Journal of Usability Studies, Vol.1, No. 3. <a href="http://www.upassoc.org/upa_publications/jus/2006_may/bojko_eye_tracking.html" class="external autonumber" title="http://www.upassoc.org/upa_publications/jus/2006_may/bojko_eye_tracking.html" rel="nofollow">[2]</a></li>
<li>Bojko, A. &amp; Stephenson, A. (2005). It's All in the Eye of the User: How eye tracking can help answer usability questions. User Experience, Vol. 4, No. 1.</li>
<li>Chandon, Pierre, J. Wesley Hutchinson, and Scott H. Young (2001), Measuring Value of Point-of-Purchase Marketing with Commercial Eye-Tracking Data. <a href="http://ged.insead.edu/fichiersti/inseadwp2001/2001-19.pdf" class="external autonumber" title="http://ged.insead.edu/fichiersti/inseadwp2001/2001-19.pdf" rel="nofollow">[3]</a></li>
<li>Duchowski, A. T., (2002) A Breadth-First Survey of Eye Tracking Applications, 'Behavior Research Methods, Instruments, &amp; Computers (BRMIC),' 34(4), November 2002, pp.455-470.</li>
<li>National Highway Traffic Safety Administration. (n.d.) Retrieved July 9, 2006, from <a href="http://www-nrd.nhtsa.dot.gov/departments/nrd-13/newDriverDistraction.html" class="external autonumber" title="http://www-nrd.nhtsa.dot.gov/departments/nrd-13/newDriverDistraction.html" rel="nofollow">[4]</a></li>
<li>Pieters, R., Wedel, M. &amp; Zhang, J. (2007). Optimal Feature Advertising Under Competitive Clutter, Management Science, 2007, 51 (11) 1815-1828.</li>
<li>Pieters, R., &amp; Wedel, M. (2007). Goal Control of Visual Attention to Advertising: The Yarbus Implication, Journal of Consumer Research, 2007, 34 (August), 224-233.</li>
<li>Pieters, R. &amp; Wedel, M. (2004). Attention Capture and Transfer by elements of Advertisements. Journal of Marketing, 68 (2), 2004, 36-50.</li>
<li>Thomas RECORDING GmbH, high-speed Eye Tracking Systems for neuro-scientific purposes <a href="http://www.thomasrecording.com/en/cms/front_content.php?idcatart=63&amp;lang=1&amp;client=1" class="external autonumber" title="http://www.thomasrecording.com/en/cms/front_content.php?idcatart=63&amp;lang=1&amp;client=1" rel="nofollow">[5]</a></li>
<li>Weatherhead, James. (2005) Eye on the Future, 'British Computer Society, ITNOW Future of Computing,' 47 (6), pp. 32-33 <a href="http://itnow.oxfordjournals.org/cgi/reprint/47/6/32" class="external autonumber" title="http://itnow.oxfordjournals.org/cgi/reprint/47/6/32" rel="nofollow">[6]</a></li>
<li>Wedel, M. &amp; Pieters, R. (2000). Eye fixations on advertisements and memory for brands: a model and findings. Marketing Science, 19 (4), 2000, 297-312.</li>
<li>Wittenstein, Jerran. (2006). EyeTracking sees gold in its technology. [Electronic Version]. San Diego Source, The Daily Transcript, April, 3rd, 2006. <a href="http://www.sddt.com/news/article.cfm?SourceCode=20060403czh" class="external autonumber" title="http://www.sddt.com/news/article.cfm?SourceCode=20060403czh" rel="nofollow">[7]</a></li>
</ul>
<p><a name="See_also" id="See_also"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Eye_tracking&amp;action=edit&amp;section=14" title="Edit section: See also">edit</a>]</span> <span class="mw-headline">See also</span></h2>
<ul>
<li><a href="/wiki/Eye_movement" title="Eye movement">Eye movement</a></li>
<li><a href="/wiki/Eye_movement_in_language_reading" title="Eye movement in language reading">Eye movement in language reading</a></li>
<li><a href="/wiki/Eye_movement_in_music_reading" title="Eye movement in music reading">Eye movement in music reading</a></li>
<li><a href="/wiki/Fovea" title="Fovea">Fovea</a></li>
<li><a href="/wiki/Gaze-contingency_paradigm" title="Gaze-contingency paradigm">Gaze-contingency paradigm</a></li>
<li><a href="/wiki/Peripheral_vision" title="Peripheral vision">Peripheral vision</a></li>
<li><a href="/wiki/Foveated_imaging" title="Foveated imaging">Foveated imaging</a></li>
<li><a href="/wiki/Eye_Tracking_Device" title="Eye Tracking Device">Eye Tracking Device</a></li>
<li><a href="/wiki/Smart_Eye" title="Smart Eye">Smart Eye</a></li>
</ul>


<!-- 
NewPP limit report
Preprocessor node count: 2143/1000000
Post-expand include size: 17530/2048000 bytes
Template argument size: 5843/2048000 bytes
Expensive parser function count: 6/500
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:1543423-0!1!0!default!!en!2 and timestamp 20090415120951 -->
<div class="printfooter">
Retrieved from "<a href="http://en.wikipedia.org/wiki/Eye_tracking">http://en.wikipedia.org/wiki/Eye_tracking</a>"</div>
			<div id='catlinks' class='catlinks'><div id="mw-normal-catlinks"><a href="/wiki/Special:Categories" title="Special:Categories">Categories</a>:&#32;<span dir='ltr'><a href="/wiki/Category:Eye" title="Category:Eye">Eye</a></span> | <span dir='ltr'><a href="/wiki/Category:Cognitive_science" title="Category:Cognitive science">Cognitive science</a></span> | <span dir='ltr'><a href="/wiki/Category:Multimodal_interaction" title="Category:Multimodal interaction">Multimodal interaction</a></span> | <span dir='ltr'><a href="/wiki/Category:Vision" title="Category:Vision">Vision</a></span> | <span dir='ltr'><a href="/wiki/Category:Usability" title="Category:Usability">Usability</a></span> | <span dir='ltr'><a href="/wiki/Category:Web_design" title="Category:Web design">Web design</a></span></div><div id="mw-hidden-catlinks" class="mw-hidden-cats-hidden">Hidden categories:&#32;<span dir='ltr'><a href="/wiki/Category:Articles_lacking_in-text_citations_from_March_2009" title="Category:Articles lacking in-text citations from March 2009">Articles lacking in-text citations from March 2009</a></span> | <span dir='ltr'><a href="/wiki/Category:All_articles_with_unsourced_statements" title="Category:All articles with unsourced statements">All articles with unsourced statements</a></span> | <span dir='ltr'><a href="/wiki/Category:Articles_with_unsourced_statements_since_January_2009" title="Category:Articles with unsourced statements since January 2009">Articles with unsourced statements since January 2009</a></span> | <span dir='ltr'><a href="/wiki/Category:Articles_with_unsourced_statements_since_February_2007" title="Category:Articles with unsourced statements since February 2007">Articles with unsourced statements since February 2007</a></span> | <span dir='ltr'><a href="/wiki/Category:Articles_with_unsourced_statements_since_March_2009" title="Category:Articles with unsourced statements since March 2009">Articles with unsourced statements since March 2009</a></span></div></div>			<!-- end content -->
						<div class="visualClear"></div>
		</div>
	</div>
		</div>
		<div id="column-one">
	<div id="p-cactions" class="portlet">
		<h5>Views</h5>
		<div class="pBody">
			<ul>
	
				 <li id="ca-nstab-main" class="selected"><a href="/wiki/Eye_tracking" title="View the content page [c]" accesskey="c">Article</a></li>
				 <li id="ca-talk"><a href="/wiki/Talk:Eye_tracking" title="Discussion about the content page [t]" accesskey="t">Discussion</a></li>
				 <li id="ca-edit"><a href="/w/index.php?title=Eye_tracking&amp;action=edit" title="You can edit this page. &#10;Please use the preview button before saving. [e]" accesskey="e">Edit this page</a></li>
				 <li id="ca-history"><a href="/w/index.php?title=Eye_tracking&amp;action=history" title="Past versions of this page [h]" accesskey="h">History</a></li>			</ul>
		</div>
	</div>
	<div class="portlet" id="p-personal">
		<h5>Personal tools</h5>
		<div class="pBody">
			<ul>
				<li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Eye_tracking" title="You are encouraged to log in; however, it is not mandatory. [o]" accesskey="o">Log in / create account</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-logo">
		<a style="background-image: url(http://upload.wikimedia.org/wikipedia/en/b/bc/Wiki.png);" href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
	<div class='generated-sidebar portlet' id='p-navigation'>
		<h5>Navigation</h5>
		<div class='pBody'>
			<ul>
				<li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li>
				<li id="n-contents"><a href="/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li>
				<li id="n-featuredcontent"><a href="/wiki/Portal:Featured_content" title="Featured content — the best of Wikipedia">Featured content</a></li>
				<li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li>
				<li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li>
			</ul>
		</div>
	</div>
	<div id="p-search" class="portlet">
		<h5><label for="searchInput">Search</label></h5>
		<div id="searchBody" class="pBody">
			<form action="/w/index.php" id="searchform"><div>
				<input type='hidden' name="title" value="Special:Search"/>
				<input id="searchInput" name="search" type="text" title="Search Wikipedia [f]" accesskey="f" value="" />
				<input type='submit' name="go" class="searchButton" id="searchGoButton"	value="Go" title="Go to a page with this exact name if one exists" />&nbsp;
				<input type='submit' name="fulltext" class="searchButton" id="mw-searchButton" value="Search" title="Search Wikipedia for this text" />
			</div></form>
		</div>
	</div>
	<div class='generated-sidebar portlet' id='p-interaction'>
		<h5>Interaction</h5>
		<div class='pBody'>
			<ul>
				<li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li>
				<li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li>
				<li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="The list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li>
				<li id="n-contact"><a href="/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact Wikipedia</a></li>
				<li id="n-sitesupport"><a href="http://wikimediafoundation.org/wiki/Donate" title="Support us">Donate to Wikipedia</a></li>
				<li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-tb">
		<h5>Toolbox</h5>
		<div class="pBody">
			<ul>
				<li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Eye_tracking" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li>
				<li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Eye_tracking" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li>
<li id="t-upload"><a href="/wiki/Wikipedia:Upload" title="Upload files [u]" accesskey="u">Upload file</a></li>
<li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="List of all special pages [q]" accesskey="q">Special pages</a></li>
				<li id="t-print"><a href="/w/index.php?title=Eye_tracking&amp;printable=yes" rel="alternate" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>				<li id="t-permalink"><a href="/w/index.php?title=Eye_tracking&amp;oldid=282714461" title="Permanent link to this version of the page">Permanent link</a></li><li id="t-cite"><a href="/w/index.php?title=Special:Cite&amp;page=Eye_tracking&amp;id=282714461">Cite this page</a></li>			</ul>
		</div>
	</div>
	<div id="p-lang" class="portlet">
		<h5>Languages</h5>
		<div class="pBody">
			<ul>
				<li class="interwiki-de"><a href="http://de.wikipedia.org/wiki/Blickbewegungsregistrierung">Deutsch</a></li>
				<li class="interwiki-fr"><a href="http://fr.wikipedia.org/wiki/Oculom%C3%A9trie">Français</a></li>
				<li class="interwiki-pl"><a href="http://pl.wikipedia.org/wiki/Okulografia">Polski</a></li>
				<li class="interwiki-es"><a href="http://es.wikipedia.org/wiki/Eye_tracking">Español</a></li>
			</ul>
		</div>
	</div>
		</div><!-- end of the left (by default at least) column -->
			<div class="visualClear"></div>
			<div id="footer">
				<div id="f-poweredbyico"><a href="http://www.mediawiki.org/"><img src="/skins-1.5/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" /></a></div>
				<div id="f-copyrightico"><a href="http://wikimediafoundation.org/"><img src="/images/wikimedia-button.png" border="0" alt="Wikimedia Foundation"/></a></div>
			<ul id="f-list">
					<li id="lastmod"> This page was last modified on 9 April 2009, at 06:11 (UTC).</li>
					<li id="copyright">All text is available under the terms of the <a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Text_of_the_GNU_Free_Documentation_License" title="Wikipedia:Text of the GNU Free Documentation License">GNU Free Documentation License</a>. (See <b><a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Copyrights" title="Wikipedia:Copyrights">Copyrights</a></b> for details.) <br /> Wikipedia&reg; is a registered trademark of the <a href="http://www.wikimediafoundation.org">Wikimedia Foundation, Inc.</a>, a U.S. registered <a class='internal' href="http://en.wikipedia.org/wiki/501%28c%29#501.28c.29.283.29" title="501(c)(3)">501(c)(3)</a> <a href="http://wikimediafoundation.org/wiki/Deductibility_of_donations">tax-deductible</a> <a class='internal' href="http://en.wikipedia.org/wiki/Non-profit_organization" title="Non-profit organization">nonprofit</a> <a href="http://en.wikipedia.org/wiki/Charitable_organization" title="Charitable organization">charity</a>.<br /></li>
					<li id="privacy"><a href="http://wikimediafoundation.org/wiki/Privacy_policy" title="wikimedia:Privacy policy">Privacy policy</a></li>
					<li id="about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
					<li id="disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
			</ul>
		</div>
</div>

		<script type="text/javascript">if (window.runOnloadHook) runOnloadHook();</script>
<!-- Served by srv39 in 0.104 secs. --></body></html>
