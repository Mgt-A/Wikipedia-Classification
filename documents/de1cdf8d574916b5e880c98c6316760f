<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
		<meta http-equiv="Content-Style-Type" content="text/css" />
		<meta name="generator" content="MediaWiki 1.15alpha" />
		<meta name="keywords" content="Variance,Theory of probability distributions,Statistics,Algorithms for calculating variance,Alternative hypothesis,An inequality on location and scale parameters,Analysis of covariance,Analysis of variance,Arithmetic mean,Autocorrelation,Autocovariance" />
		<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Variance&amp;action=edit" />
		<link rel="edit" title="Edit this page" href="/w/index.php?title=Variance&amp;action=edit" />
		<link rel="apple-touch-icon" href="http://en.wikipedia.org/apple-touch-icon.png" />
		<link rel="shortcut icon" href="/favicon.ico" />
		<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)" />
		<link rel="copyright" href="http://www.gnu.org/copyleft/fdl.html" />
		<link rel="alternate" type="application/rss+xml" title="Wikipedia RSS Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=rss" />
		<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=atom" />
		<title>Variance - Wikipedia, the free encyclopedia</title>
		<link rel="stylesheet" href="/skins-1.5/common/shared.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/common/commonPrint.css?207xx" type="text/css" media="print" />
		<link rel="stylesheet" href="/skins-1.5/monobook/main.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/chick/main.css?207xx" type="text/css" media="handheld" />
		<!--[if lt IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE50Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE55Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 6]><link rel="stylesheet" href="/skins-1.5/monobook/IE60Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 7]><link rel="stylesheet" href="/skins-1.5/monobook/IE70Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Common.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Print.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="print" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Handheld.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="handheld" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Monobook.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=-&amp;action=raw&amp;maxage=2678400&amp;gen=css" type="text/css" />
		<!--[if lt IE 7]><script type="text/javascript" src="/skins-1.5/common/IEFixes.js?207xx"></script>
		<meta http-equiv="imagetoolbar" content="no" /><![endif]-->

		<script type= "text/javascript">/*<![CDATA[*/
		var skin = "monobook";
		var stylepath = "/skins-1.5";
		var wgArticlePath = "/wiki/$1";
		var wgScriptPath = "/w";
		var wgScript = "/w/index.php";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = "http://en.wikipedia.org";
		var wgCanonicalNamespace = "";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = "Variance";
		var wgTitle = "Variance";
		var wgAction = "view";
		var wgArticleId = "32344";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = "en";
		var wgContentLanguage = "en";
		var wgBreakFrames = false;
		var wgCurRevisionId = 282377803;
		var wgVersion = "1.15alpha";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = ["", ""];
		var wgDigitTransformTable = ["", ""];
		var wgMWSuggestTemplate = "http://en.wikipedia.org/w/api.php?action=opensearch\x26search={searchTerms}\x26namespace={namespaces}\x26suggest";
		var wgDBname = "enwiki";
		var wgSearchNamespaces = [0];
		var wgMWSuggestMessages = ["with suggestions", "no suggestions"];
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		/*]]>*/</script>

		<script type="text/javascript" src="/skins-1.5/common/wikibits.js?207xx"><!-- wikibits js --></script>
		<!-- Head Scripts -->
		<script type="text/javascript" src="/skins-1.5/common/ajax.js?207xx"></script>
		<script type="text/javascript" src="/skins-1.5/common/mwsuggest.js?207xx"></script>
<script type="text/javascript">/*<![CDATA[*/
var wgNotice='';var wgNoticeLocal='';
/*]]>*/</script>		<script type="text/javascript" src="http://upload.wikimedia.org/centralnotice/wikipedia/en/centralnotice.js?207xx"></script>
		<script type="text/javascript" src="/w/index.php?title=-&amp;action=raw&amp;gen=js&amp;useskin=monobook"><!-- site js --></script>
	</head>
<body class="mediawiki ltr ns-0 ns-subject page-Variance skin-monobook">
	<div id="globalWrapper">
		<div id="column-content">
	<div id="content">
		<a name="top" id="top"></a>
		<div id="siteNotice"><script type='text/javascript'>if (wgNotice != '') document.writeln(wgNotice);</script></div>		<h1 id="firstHeading" class="firstHeading">Variance</h1>
		<div id="bodyContent">
			<h3 id="siteSub">From Wikipedia, the free encyclopedia</h3>
			<div id="contentSub"></div>
									<div id="jump-to-nav">Jump to: <a href="#column-one">navigation</a>, <a href="#searchInput">search</a></div>			<!-- start content -->
			<div class="dablink">This article is about mathematics.  For the administrative exception to land use regulations, see <a href="/wiki/Variance_(land_use)" title="Variance (land use)">variance (land use)</a>.</div>
<p>In <a href="/wiki/Probability_theory" title="Probability theory">probability theory</a> and <a href="/wiki/Statistics" title="Statistics">statistics</a>, the <b>variance</b> of a <a href="/wiki/Random_variable" title="Random variable">random variable</a>, <a href="/wiki/Probability_distribution" title="Probability distribution">probability distribution</a>, or <a href="/wiki/Sample_(statistics)" title="Sample (statistics)">sample</a> is a measure of <a href="/wiki/Statistical_dispersion" title="Statistical dispersion">statistical dispersion</a>, averaging the squared distance of its possible values from the <a href="/wiki/Expected_value" title="Expected value">expected value</a> (mean). Whereas the mean is a way to describe the location of a distribution, the variance is a way to capture its scale or degree of being spread out. The <a href="/wiki/Units_of_measurement" title="Units of measurement">unit</a> of variance is the square of the unit of the original variable. The positive <a href="/wiki/Square_root" title="Square root">square root</a> of the variance, called the <a href="/wiki/Standard_deviation" title="Standard deviation">standard deviation</a>, has the same units as the original variable and can be easier to interpret for this reason.</p>
<p>The variance of a <a href="/wiki/Real_number" title="Real number">real</a>-valued random variable is its second <a href="/wiki/Central_moment" title="Central moment">central moment</a>, and it also happens to be its second <a href="/wiki/Cumulant" title="Cumulant">cumulant</a>. Just as some distributions do not have a mean, some do not have a variance. The mean exists whenever the variance exists, but not vice versa.</p>
<table id="toc" class="toc" summary="Contents">
<tr>
<td>
<div id="toctitle">
<h2>Contents</h2>
</div>
<ul>
<li class="toclevel-1"><a href="#Definition"><span class="tocnumber">1</span> <span class="toctext">Definition</span></a>
<ul>
<li class="toclevel-2"><a href="#Continuous_case"><span class="tocnumber">1.1</span> <span class="toctext">Continuous case</span></a></li>
<li class="toclevel-2"><a href="#Discrete_case"><span class="tocnumber">1.2</span> <span class="toctext">Discrete case</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Examples"><span class="tocnumber">2</span> <span class="toctext">Examples</span></a>
<ul>
<li class="toclevel-2"><a href="#Exponential_distribution"><span class="tocnumber">2.1</span> <span class="toctext">Exponential distribution</span></a></li>
<li class="toclevel-2"><a href="#Fair_die"><span class="tocnumber">2.2</span> <span class="toctext">Fair die</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Properties"><span class="tocnumber">3</span> <span class="toctext">Properties</span></a></li>
<li class="toclevel-1"><a href="#Properties.2C_formal"><span class="tocnumber">4</span> <span class="toctext">Properties, formal</span></a>
<ul>
<li class="toclevel-2"><a href="#Variance_of_the_sum_of_uncorrelated_variables_.28Bienaym.C3.A9_formula.29"><span class="tocnumber">4.1</span> <span class="toctext">Variance of the sum of uncorrelated variables (Bienaym√© formula)</span></a></li>
<li class="toclevel-2"><a href="#Variance_of_the_sum_of_correlated_variables"><span class="tocnumber">4.2</span> <span class="toctext">Variance of the sum of correlated variables</span></a></li>
<li class="toclevel-2"><a href="#Variance_of_a_weighted_sum_of_variables"><span class="tocnumber">4.3</span> <span class="toctext">Variance of a weighted sum of variables</span></a></li>
<li class="toclevel-2"><a href="#Decomposition_of_variance"><span class="tocnumber">4.4</span> <span class="toctext">Decomposition of variance</span></a></li>
<li class="toclevel-2"><a href="#Computational_formula_for_variance"><span class="tocnumber">4.5</span> <span class="toctext">Computational formula for variance</span></a></li>
<li class="toclevel-2"><a href="#Characteristic_property"><span class="tocnumber">4.6</span> <span class="toctext">Characteristic property</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Approximating_the_variance_of_a_function"><span class="tocnumber">5</span> <span class="toctext">Approximating the variance of a function</span></a></li>
<li class="toclevel-1"><a href="#Population_variance_and_sample_variance"><span class="tocnumber">6</span> <span class="toctext">Population variance and sample variance</span></a>
<ul>
<li class="toclevel-2"><a href="#Distribution_of_the_sample_variance"><span class="tocnumber">6.1</span> <span class="toctext">Distribution of the sample variance</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Generalizations"><span class="tocnumber">7</span> <span class="toctext">Generalizations</span></a></li>
<li class="toclevel-1"><a href="#History"><span class="tocnumber">8</span> <span class="toctext">History</span></a></li>
<li class="toclevel-1"><a href="#Moment_of_inertia"><span class="tocnumber">9</span> <span class="toctext">Moment of inertia</span></a></li>
<li class="toclevel-1"><a href="#See_also"><span class="tocnumber">10</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1"><a href="#References"><span class="tocnumber">11</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1"><a href="#External_links"><span class="tocnumber">12</span> <span class="toctext">External links</span></a></li>
</ul>
</td>
</tr>
</table>
<script type="text/javascript">
//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>
</script>
<p><a name="Definition" id="Definition"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Variance&amp;action=edit&amp;section=1" title="Edit section: Definition">edit</a>]</span> <span class="mw-headline">Definition</span></h2>
<p>If a random variable <i>X</i> has <a href="/wiki/Expected_value" title="Expected value">expected value</a> (mean) Œº = E(<i>X</i>), then the variance Var(<i>X</i>) of <i>X</i> is given by:</p>
<dl>
<dd><img class="tex" alt="\operatorname{Var}(X) = \operatorname{E}[ ( X - \mu ) ^ 2 ].\," src="http://upload.wikimedia.org/math/f/3/4/f3467b0e7debc2862ad426a63a6838b0.png" /></dd>
</dl>
<p>This definition encompasses random variables that are <a href="/wiki/Discrete_random_variable" title="Discrete random variable" class="mw-redirect">discrete</a>, <a href="/wiki/Continuous_random_variable" title="Continuous random variable" class="mw-redirect">continuous</a>, or neither. Of all the points about which squared deviations could have been calculated, the mean produces the minimum value for the averaged sum of squared deviations.</p>
<p>The variance of random variable <i>X</i> is typically designated as Var(<i>X</i>), <img class="tex" alt="\scriptstyle\sigma_X^2" src="http://upload.wikimedia.org/math/8/6/e/86e72a3c7f3cff712ed39727d5543bb6.png" />, or simply œÉ<sup>2</sup>. If a distribution does not have an expected value, as is the case for the <a href="/wiki/Cauchy_distribution" title="Cauchy distribution">Cauchy distribution</a>, it does not have a variance either. Many other distributions for which the expected value does exist do not have a finite variance because the relevant integral diverges. An example is a <a href="/wiki/Pareto_distribution" title="Pareto distribution">Pareto distribution</a> whose <a href="/wiki/Pareto_index" title="Pareto index">Pareto index</a> <i>k</i> satisfies <span style="white-space:nowrap;">1 &lt; <i>k</i> ‚â§ 2</span>.</p>
<p><a name="Continuous_case" id="Continuous_case"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Variance&amp;action=edit&amp;section=2" title="Edit section: Continuous case">edit</a>]</span> <span class="mw-headline">Continuous case</span></h3>
<p>If the random variable <i>X</i> is <a href="/wiki/Continuous_distribution" title="Continuous distribution" class="mw-redirect">continuous</a> with <a href="/wiki/Probability_density_function" title="Probability density function">probability density function</a> <i>p</i>(<i>x</i>),</p>
<dl>
<dd><img class="tex" alt="\operatorname{Var}(X) =\int (x-\mu)^2 \, p(x) \, dx\,," src="http://upload.wikimedia.org/math/4/e/4/4e4677e38933482a60e0f322e598c7cd.png" /></dd>
</dl>
<p>where</p>
<dl>
<dd><img class="tex" alt="\mu = \int x \, p(x) \, dx\,," src="http://upload.wikimedia.org/math/5/2/b/52bc687e1475806a8abb8b8252f220cf.png" /></dd>
</dl>
<p>and where the integrals are <a href="/wiki/Definite_integral" title="Definite integral" class="mw-redirect">definite integrals</a> taken for <i>x</i> ranging over the range of <i>X</i>.</p>
<p><a name="Discrete_case" id="Discrete_case"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Variance&amp;action=edit&amp;section=3" title="Edit section: Discrete case">edit</a>]</span> <span class="mw-headline">Discrete case</span></h3>
<p>If the random variable <i>X</i> is <a href="/wiki/Discrete_probability_distribution" title="Discrete probability distribution">discrete</a> with <a href="/wiki/Probability_mass_function" title="Probability mass function">probability mass function</a> <i>x</i><sub>1</sub>&#160;‚Ü¶&#160;<i>p</i><sub>1</sub>,&#160;...,&#160;<i>x</i><sub><i>n</i></sub>&#160;‚Ü¶&#160;<i>p</i><sub><i>n</i></sub>,</p>
<dl>
<dd><img class="tex" alt="\operatorname{Var}(X) = \sum_{i=1}^n p_i (x_i - \mu)^2\,." src="http://upload.wikimedia.org/math/f/d/6/fd6e2e6f32a0542d13daecc6d1d41e3b.png" /></dd>
</dl>
<p>(When such a discrete <a href="/wiki/Weighted_variance" title="Weighted variance" class="mw-redirect">weighted variance</a> is specified by weights whose sum is not&#160;1, then one divides by the sum of the weights.) That is, it is the expected value of the <a href="/wiki/Squared_deviations" title="Squared deviations">square of the deviation</a> of <i>X</i> from its own mean. In plain language, it can be expressed as "The average of the square of the distance of each data point from the mean". It is thus the <i>mean squared deviation</i>.</p>
<p><a name="Examples" id="Examples"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Variance&amp;action=edit&amp;section=4" title="Edit section: Examples">edit</a>]</span> <span class="mw-headline">Examples</span></h2>
<p><a name="Exponential_distribution" id="Exponential_distribution"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Variance&amp;action=edit&amp;section=5" title="Edit section: Exponential distribution">edit</a>]</span> <span class="mw-headline">Exponential distribution</span></h3>
<p>The <a href="/wiki/Exponential_distribution" title="Exponential distribution">exponential distribution</a> with parameter Œª is a continuous distribution whose support is the semi-infinite interval [0,‚àû). Its <a href="/wiki/Probability_density_function" title="Probability density function">probability density function</a> is given by:</p>
<dl>
<dd><img class="tex" alt="f(x) = \lambda e^{-\lambda x},\," src="http://upload.wikimedia.org/math/d/6/6/d6611d12f9544313de83e2808512de5b.png" /></dd>
</dl>
<p>and it has expected value Œº = Œª<sup>‚àí1</sup>. Therefore the variance is equal to:</p>
<dl>
<dd><img class="tex" alt="\int_0^\infty f(x) (x - \mu)^2\,dx = \int_0^\infty \lambda e^{-\lambda x} (x - \lambda^{-1})^2\,dx = \lambda^{-2}.\," src="http://upload.wikimedia.org/math/b/c/1/bc1f5d0048371fa3586bfca8caf666a9.png" /></dd>
</dl>
<p>So for an exponentially distributed random variable œÉ<sup>2</sup> = Œº<sup>2</sup>.</p>
<p><a name="Fair_die" id="Fair_die"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Variance&amp;action=edit&amp;section=6" title="Edit section: Fair die">edit</a>]</span> <span class="mw-headline">Fair die</span></h3>
<p>A six-sided <a href="/wiki/Fair_die" title="Fair die" class="mw-redirect">fair die</a> can be modelled with a discrete random variable with outcomes 1 through 6, each with equal probability <sup>1</sup>/<sub>6</sub>. The expected value is (1+2+3+4+5+6)/6 = 3.5. Therefore the variance can be computed to be:</p>
<dl>
<dd><img class="tex" alt="\sum_{i=1}^6 \tfrac{1}{6} (i - 3.5)^2 = \tfrac{1}{6}\left((-2.5)^2{+}(-1.5)^2{+}(-0.5)^2{+}0.5^2{+}1.5^2{+}2.5^2\right) = \tfrac{1}{6} \cdot 17.50 = \tfrac{35}{12} = 2.92\,." src="http://upload.wikimedia.org/math/7/f/1/7f12e7aa0e95baecf54f2b8b098f5539.png" /></dd>
</dl>
<p><a name="Properties" id="Properties"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Variance&amp;action=edit&amp;section=7" title="Edit section: Properties">edit</a>]</span> <span class="mw-headline">Properties</span></h2>
<p>Variance is non-negative because the squares are positive or zero. The variance of a constant random variable is zero, and the variance of a variable in a <a href="/wiki/Data_set" title="Data set">data set</a> is 0 if and only if all entries have the same value.</p>
<p>Variance is <a href="/wiki/Invariant" title="Invariant">invariant</a> with respect to changes in a <a href="/wiki/Location_parameter" title="Location parameter">location parameter</a>. That is, if a constant is added to all values of the variable, the variance is unchanged. If all values are scaled by a constant, the variance is scaled by the square of that constant. These two properties can be expressed in the following formula:</p>
<dl>
<dd><img class="tex" alt="\operatorname{Var}(aX+b)=a^2\operatorname{Var}(X)." src="http://upload.wikimedia.org/math/5/4/3/54382d7f9ba942bb3d32327f514a3d5b.png" /></dd>
</dl>
<p>The variance of a finite sum of <b>uncorrelated</b> random variables is equal to the sum of their variances. This stems from the identity:</p>
<dl>
<dd><img class="tex" alt="\operatorname{Var}(X+Y)=\operatorname{Var}(X)+\operatorname{Var}(Y)+2\operatorname{cov}(X,Y)," src="http://upload.wikimedia.org/math/e/1/8/e18e47c53b1ed8036bb06b436134b459.png" /></dd>
</dl>
<p>and that for uncorrelated variables <a href="/wiki/Covariance" title="Covariance">covariance</a> is zero.</p>
<p>In general, for the sum of <span class="texhtml"><i>N</i></span> variables: <img class="tex" alt="Y = \sum_{i=1}^{N} X_i" src="http://upload.wikimedia.org/math/e/6/f/e6f9310d43b24af72cfcfae41b65b80d.png" />, we have:</p>
<dl>
<dd><img class="tex" alt="\operatorname{Var}(Y)=\sum_{i=1}^{N}\operatorname{Var}(X_i)+2\sum_{i&lt;j}\operatorname{cov}(X_i,X_j)." src="http://upload.wikimedia.org/math/1/1/8/118dda8c6a1f5133f73fa9efe573c4f1.png" /></dd>
</dl>
<ol>
<li>Suppose that the observations can be partitioned into <b>subgroups</b> according to some second variable. Then the variance of the total group is equal to the mean of the variances of the subgroups plus the variance of the means of the subgroups. This property is known as <a href="/wiki/Variance_decomposition" title="Variance decomposition" class="mw-redirect">variance decomposition</a> or the <a href="/wiki/Law_of_total_variance" title="Law of total variance">law of total variance</a> and plays an important role in the <a href="/wiki/Analysis_of_variance" title="Analysis of variance">analysis of variance</a>. For example, suppose that a group consists of a subgroup of men and an equally large subgroup of women. Suppose that the men have a mean body length of 180 and that the variance of their lengths is 100. Suppose that the women have a mean length of 160 and that the variance of their lengths is 50. Then the mean of the variances is (100 + 50) / 2 = 75; the variance of the means is the variance of 180, 160 which is 100. Then, for the total group of men and women combined, the variance of the body lengths will be 75 + 100 = 175. Note that this uses N for the denominator instead of N - 1.
<p>In a more general case, if the subgroups have unequal sizes, then they must be weighted proportionally to their size in the computations of the means and variances. The formula is also valid with more than two groups, and even if the grouping variable is continuous.<a href="http://www.groupsrv.com/science/post-1990611.html" class="external autonumber" title="http://www.groupsrv.com/science/post-1990611.html" rel="nofollow">[2]</a></p>
<p>This formula implies that the variance of the total group cannot be smaller than the mean of the variances of the subgroups. Note, however, that the total variance is not necessarily larger than the variances of the subgroups. In the above example, when the subgroups are analyzed separately, the variance is influenced only by the man-man differences and the woman-woman differences. If the two groups are combined, however, then the men-women differences enter into the variance also.</p>
</li>
<li>Many <a href="/wiki/Computational_formulas_for_the_variance" title="Computational formulas for the variance" class="mw-redirect">computational formulas for the variance</a> are based on this equality: <b>The variance is equal to the mean of the squares minus the square of the mean.</b> For example, if we consider the numbers 1, 2, 3, 4 then the mean of the squares is (1 √ó 1 + 2 √ó 2 + 3 √ó 3 + 4 √ó 4) / 4 = 7.5. The mean is 2.5, so the square of the mean is 6.25. Therefore the variance is 7.5&#160;‚àí&#160;6.25 = 1.25, which is indeed the same result obtained earlier with the definition formulas. Many pocket calculators use an algorithm that is based on this formula and that allows them to compute the variance while the data are entered, without storing all values in memory. The algorithm is to adjust only three variables when a new data value is entered: The number of data entered so far (<i>n</i>), the sum of the values so far (<i>S</i>), and the sum of the squared values so far (<i>SS</i>). For example, if the data are 1, 2, 3, 4, then after entering the first value, the algorithm would have <i>n</i> = 1, <i>S</i> = 1 and <i>SS</i> = 1. After entering the second value (2), it would have <i>n</i> = 2, <i>S</i> = 3 and <i>SS</i> = 5. When all data are entered, it would have <i>n</i> = 4, <i>S</i> = 10 and <i>SS</i> = 30. Next, the mean is computed as <i>M</i> = <i>S</i> / <i>n</i>, and finally the variance is computed as <i>SS</i> / <i>n</i>&#160;‚àí&#160;<i>M</i> √ó <i>M</i>. In this example the outcome would be 30 / 4 - 2.5 √ó 2.5 = 7.5&#160;‚àí&#160;6.25 = 1.25. If the unbiased sample estimate is to be computed, the outcome will be multiplied by <i>n</i> / (<i>n</i>&#160;‚àí&#160;1), which yields 1.667 in this example.</li>
</ol>
<p><a name="Properties.2C_formal" id="Properties.2C_formal"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Variance&amp;action=edit&amp;section=8" title="Edit section: Properties, formal">edit</a>]</span> <span class="mw-headline">Properties, formal</span></h2>
<p><a name="Variance_of_the_sum_of_uncorrelated_variables_.28Bienaym.C3.A9_formula.29" id="Variance_of_the_sum_of_uncorrelated_variables_.28Bienaym.C3.A9_formula.29"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Variance&amp;action=edit&amp;section=9" title="Edit section: Variance of the sum of uncorrelated variables (Bienaym√© formula)">edit</a>]</span> <span class="mw-headline">Variance of the sum of uncorrelated variables (Bienaym√© formula)</span></h3>
<p>One reason for the use of the variance in preference to other measures of dispersion is that the variance of the sum (or the difference) of <a href="/wiki/Uncorrelated" title="Uncorrelated">uncorrelated</a> random variables is the sum of their variances:</p>
<dl>
<dd><img class="tex" alt="\operatorname{Var}\Big(\sum_{i=1}^n X_i\Big) = \sum_{i=1}^n \operatorname{Var}(X_i)." src="http://upload.wikimedia.org/math/c/8/b/c8b1ce1bb5b2b3385472ae9ec15387d0.png" /></dd>
</dl>
<p>This statement is called the <a href="/wiki/Ir%C3%A9n%C3%A9e-Jules_Bienaym%C3%A9" title="Ir√©n√©e-Jules Bienaym√©">Bienaym√©</a> formula.<sup id="cite_ref-0" class="reference"><a href="#cite_note-0" title=""><span>[</span>1<span>]</span></a></sup> and was discovered in 1853. It is often made with the stronger condition that the variables are <a href="/wiki/Statistical_independence" title="Statistical independence" class="mw-redirect">independent</a>, but uncorrelatedness suffices. So if the variables have the same variance œÉ<sup>2</sup>, then, since division by <i>n</i> is a linear transformation, this formula immediately implies that the variance of their mean is</p>
<dl>
<dd><img class="tex" alt="\operatorname{Var}(\overline{X}) = \operatorname{Var}\left(\frac{1}{n}\sum_{i=1}^n X_i\right) = \frac{1}{n^2} \sum_{i=1}^n \operatorname{Var}\left(X_i\right) = \frac {1}{n^2} n \sigma^2 = \frac {\sigma^2} {n}." src="http://upload.wikimedia.org/math/a/e/9/ae93cdb760ad3c8393949b9cd264d864.png" /></dd>
</dl>
<p>That is, the variance of the mean decreases with <i>n</i>. This fact is used in the definition of the <a href="/wiki/Standard_error_(statistics)" title="Standard error (statistics)">standard error</a> of the sample mean, which is used in the <a href="/wiki/Central_limit_theorem" title="Central limit theorem">central limit theorem</a>.</p>
<p><a name="Variance_of_the_sum_of_correlated_variables" id="Variance_of_the_sum_of_correlated_variables"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Variance&amp;action=edit&amp;section=10" title="Edit section: Variance of the sum of correlated variables">edit</a>]</span> <span class="mw-headline">Variance of the sum of correlated variables</span></h3>
<p>In general, if the variables are <a href="/wiki/Correlated" title="Correlated" class="mw-redirect">correlated</a>, then the variance of their sum is the sum of their <a href="/wiki/Covariance" title="Covariance">covariances</a>:</p>
<dl>
<dd><img class="tex" alt="\operatorname{Var}\left(\sum_{i=1}^n X_i\right) = \sum_{i=1}^n \sum_{j=1}^n \operatorname{Cov}(X_i, X_j)." src="http://upload.wikimedia.org/math/8/9/2/892e47900d33a00f604d4f790c2d515c.png" /></dd>
</dl>
<p>(Note: This by definition includes the variance of each variable, since Cov(<i>X</i>,<i>X</i>)=Var(<i>X</i>).)</p>
<p>Here Cov is the covariance, which is zero for independent random variables (if it exists). The formula states that the variance of a sum is equal to the sum of all elements in the covariance matrix of the components. This formula is used in the theory of <a href="/wiki/Cronbach%27s_alpha" title="Cronbach's alpha">Cronbach's alpha</a> in <a href="/wiki/Classical_test_theory" title="Classical test theory">classical test theory</a>.</p>
<p>So if the variables have equal variance œÉ<sup>2</sup> and the average correlation of distinct variables is œÅ, then the variance of their mean is</p>
<dl>
<dd><img class="tex" alt="\operatorname{Var}(\overline{X}) = \frac {\sigma^2} {n} + \frac {n-1} {n} \rho \sigma^2." src="http://upload.wikimedia.org/math/e/9/5/e957a59f5008c402b96b507e814fc18a.png" /></dd>
</dl>
<p>This implies that the variance of the mean increases with the average of the correlations. Moreover, if the variables have unit variance, for example if they are standardized, then this simplifies to</p>
<dl>
<dd><img class="tex" alt="\operatorname{Var}(\overline{X}) = \frac {1} {n} + \frac {n-1} {n} \rho." src="http://upload.wikimedia.org/math/e/2/b/e2bd5ae63ec6c354f4c2b2e5c2a85a2f.png" /></dd>
</dl>
<p>This formula is used in the <a href="/wiki/Spearman-Brown_prediction_formula" title="Spearman-Brown prediction formula">Spearman-Brown prediction formula</a> of classical test theory. This converges to œÅ if <i>n</i> goes to infinity, provided that the average correlation remains constant or converges too. So for the variance of the mean of standardized variables with equal correlations or converging average correlation we have</p>
<dl>
<dd><img class="tex" alt=" \lim_{n \to \infty} \operatorname{Var}(\overline{X}) = \rho." src="http://upload.wikimedia.org/math/0/2/3/023c64e7a3042665f2af872271bb01ff.png" /></dd>
</dl>
<p>Therefore, the variance of the mean of a large number of standardized variables is approximately equal to their average correlation. This makes clear that the sample mean of correlated variables does generally not converge to the population mean, even though the <a href="/wiki/Law_of_large_numbers" title="Law of large numbers">Law of large numbers</a> states that the sample mean will converge for independent variables.</p>
<p><a name="Variance_of_a_weighted_sum_of_variables" id="Variance_of_a_weighted_sum_of_variables"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Variance&amp;action=edit&amp;section=11" title="Edit section: Variance of a weighted sum of variables">edit</a>]</span> <span class="mw-headline">Variance of a weighted sum of variables</span></h3>
<p>Properties 6 and 8, along with this property from the <a href="/wiki/Covariance" title="Covariance">covariance</a> page: Cov(<i>aX</i>,&#160;<i>bY</i>) = <i>ab</i>&#160;Cov(<i>X</i>,&#160;<i>Y</i>) jointly imply that</p>
<dl>
<dd><img class="tex" alt="\operatorname{Var}(aX+bY) =a^2 \operatorname{Var}(X) + b^2 \operatorname{Var}(Y) + 2ab\, \operatorname{Cov}(X, Y)." src="http://upload.wikimedia.org/math/d/7/b/d7bb1ae1819636046e58b14d7a970f6b.png" /></dd>
</dl>
<p>This implies that in a weighted sum of variables, the variable with the largest weight will have a disproportionally large weight in the variance of the total. For example, if <i>X</i> and <i>Y</i> are uncorrelated and the weight of <i>X</i> is two times the weight of <i>Y</i>, then the weight of the variance of <i>X</i> will be four times the weight of the variance of <i>Y</i>.</p>
<p><a name="Decomposition_of_variance" id="Decomposition_of_variance"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Variance&amp;action=edit&amp;section=12" title="Edit section: Decomposition of variance">edit</a>]</span> <span class="mw-headline">Decomposition of variance</span></h3>
<p>The general formula for variance decomposition or the <a href="/wiki/Law_of_total_variance" title="Law of total variance">law of total variance</a> is: If <i>X</i> and <i>Y</i> are two random variables and the variance of <i>X</i> exists, then</p>
<dl>
<dd><img class="tex" alt="\operatorname{Var}(X) = \operatorname{Var}(\operatorname{E}(X|Y))+ \operatorname{E}(\operatorname{Var}(X|Y))." src="http://upload.wikimedia.org/math/d/5/5/d55da673246f1897b03dbb861d6fae16.png" /></dd>
</dl>
<p>Here, E(<i>X</i>|<i>Y</i>) is the <a href="/wiki/Conditional_expectation" title="Conditional expectation">conditional expectation</a> of <i>X</i> given <i>Y</i>, and Var(<i>X</i>|<i>Y</i>) is the conditional variance of <i>X</i> given <i>Y</i>. (A more intuitive explanation is that given a particular value of <i>Y</i>, then <i>X</i> follows a distribution with mean E(<i>X</i>|<i>Y</i>) and variance Var(<i>X</i>|<i>Y</i>). The above formula tells how to find Var(<i>X</i>) based on the distributions of these two quantities when <i>Y</i> is allowed to vary.) This formula is often applied in <a href="/wiki/Analysis_of_variance" title="Analysis of variance">analysis of variance</a>, where the corresponding formula is</p>
<dl>
<dd><span class="texhtml"><i>S</i><i>S</i><sub>Total</sub> = <i>S</i><i>S</i><sub>Between</sub> + <i>S</i><i>S</i><sub>Within</sub>.</span></dd>
</dl>
<p>It is also used in <a href="/wiki/Linear_regression" title="Linear regression">linear regression</a> analysis, where the corresponding formula is</p>
<dl>
<dd><span class="texhtml"><i>S</i><i>S</i><sub>Total</sub> = <i>S</i><i>S</i><sub>Regression</sub> + <i>S</i><i>S</i><sub>Residual</sub>.</span></dd>
</dl>
<p>This can also be derived from the additivity of variances (property 8), since the total (observed) score is the sum of the predicted score and the error score, where the latter two are uncorrelated.</p>
<p><a name="Computational_formula_for_variance" id="Computational_formula_for_variance"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Variance&amp;action=edit&amp;section=13" title="Edit section: Computational formula for variance">edit</a>]</span> <span class="mw-headline">Computational formula for variance</span></h3>
<div class="rellink noprint relarticle mainarticle">Main article: <a href="/wiki/Computational_formula_for_the_variance" title="Computational formula for the variance">computational formula for the variance</a></div>
<p>The <b>computational formula for the variance</b> follows in a straightforward manner from the linearity of expected values and the above definition:</p>
<dl>
<dd><img class="tex" alt="{}\operatorname{Var}(X)= \operatorname{E}(X^2 - 2\,X\,\operatorname{E}(X) + (\operatorname{E}(X))^2)," src="http://upload.wikimedia.org/math/4/a/f/4af7ef8f7a749dd94efd6c16cc9797f2.png" /></dd>
</dl>
<dl>
<dd><img class="tex" alt="{}=\operatorname{E}(X^2) - 2(\operatorname{E}(X))^2 + (\operatorname{E}(X))^2," src="http://upload.wikimedia.org/math/6/5/3/65307119f457ae2ad27583ec95fd69b5.png" /></dd>
</dl>
<dl>
<dd><img class="tex" alt="{}=\operatorname{E}(X^2) - (\operatorname{E}(X))^2." src="http://upload.wikimedia.org/math/d/c/0/dc0cadcf39b33a4f49270ffb9a1d1779.png" /></dd>
</dl>
<p>This is often used to calculate the variance in practice, although it suffers from <a href="/wiki/Catastrophic_cancellation" title="Catastrophic cancellation" class="mw-redirect">catastrophic cancellation</a> if the two components of the equation are similar in magnitude.</p>
<p><a name="Characteristic_property" id="Characteristic_property"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Variance&amp;action=edit&amp;section=14" title="Edit section: Characteristic property">edit</a>]</span> <span class="mw-headline">Characteristic property</span></h3>
<p>The second <a href="/wiki/Moment_(mathematics)" title="Moment (mathematics)">moment</a> of a random variable attains the minimum value when taken around the first moment (i.e., mean) of the random variable, i.e. <img class="tex" alt="\mathrm{argmin}_m\,\mathrm{E}((X - m)^2) = \mathrm{E}(X)\," src="http://upload.wikimedia.org/math/f/6/5/f65e526bfc2ac649fcd687bb26110b15.png" />. Conversely, if a continuous function <img class="tex" alt="\varphi" src="http://upload.wikimedia.org/math/3/5/3/3538eb9c84efdcbd130c4c953781cfdb.png" /> satisfies <img class="tex" alt="\mathrm{argmin}_m\,\mathrm{E}(\varphi(X - m)) = \mathrm{E}(X)\," src="http://upload.wikimedia.org/math/0/1/0/0107c05ca3b995e46bb5e709cce69997.png" /> for all random variables <i>X</i>, then it is necessarily of the form <img class="tex" alt="\varphi(x) = a x^2 + b" src="http://upload.wikimedia.org/math/3/9/1/391fd3bb2a3d93165d47ea5e2a862544.png" />, where <span style="white-space:nowrap;"><i>a</i> &gt; 0</span>. This also holds in the multidimensional case.<sup id="cite_ref-1" class="reference"><a href="#cite_note-1" title=""><span>[</span>2<span>]</span></a></sup></p>
<p><a name="Approximating_the_variance_of_a_function" id="Approximating_the_variance_of_a_function"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Variance&amp;action=edit&amp;section=15" title="Edit section: Approximating the variance of a function">edit</a>]</span> <span class="mw-headline">Approximating the variance of a function</span></h2>
<p>The <a href="/wiki/Delta_method" title="Delta method">delta method</a> uses second-order <a href="/wiki/Taylor_expansion" title="Taylor expansion" class="mw-redirect">Taylor expansions</a> to approximate the variance of a function of one or more random variables. For example, the approximate variance of a function of one variable is given by</p>
<dl>
<dd>
<dl>
<dd><img class="tex" alt="\operatorname{Var}\left[f(X)\right]\approx \left(f'(\operatorname{E}\left[X\right])\right)^2\operatorname{Var}\left[X\right]" src="http://upload.wikimedia.org/math/4/4/e/44ecd91c9c06fdc2b377d515533ad30e.png" /></dd>
</dl>
</dd>
</dl>
<p>provided that <i>f</i> is twice differentiable and that the mean and variance of <i>X</i> are finite.</p>
<p><a name="Population_variance_and_sample_variance" id="Population_variance_and_sample_variance"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Variance&amp;action=edit&amp;section=16" title="Edit section: Population variance and sample variance">edit</a>]</span> <span class="mw-headline">Population variance and sample variance</span></h2>
<p>In general, the population variance of a <i>finite</i> <a href="/wiki/Statistical_population" title="Statistical population">population</a> of size <i>N</i> is given by</p>
<dl>
<dd><img class="tex" alt="{}\sigma^2 = \frac 1N \sum_{i=1}^N  \left(x_i - \overline{x} \right)^2 \," src="http://upload.wikimedia.org/math/9/c/5/9c5bfb79744673c1b2433e9cdf159001.png" /></dd>
</dl>
<p>or if the population is an abstract population with probability distribution Pr:</p>
<dl>
<dd><img class="tex" alt="{}\sigma^2 = \sum_{i=1}^N  \left(x_i - \overline{x} \right)^2 \, \Pr(x_i)," src="http://upload.wikimedia.org/math/d/2/f/d2f2533ae12b3b42c7d2ca67d5d0f402.png" /></dd>
</dl>
<p>where <img class="tex" alt="\overline{x}" src="http://upload.wikimedia.org/math/3/4/f/34fd2436571a41ac9080dd4e238e72a5.png" /> is the population mean. This is merely a special case of the general definition of variance introduced above, but restricted to finite populations.</p>
<p>In many practical situations, the true variance of a population is not known <i>a priori</i> and must be computed somehow. When dealing with infinite populations, this is generally impossible.</p>
<p>A common task is to estimate the variance of a population from a <a href="/wiki/Sampling_(statistics)" title="Sampling (statistics)">sample</a>. We take a <a href="/wiki/Statistical_sample" title="Statistical sample" class="mw-redirect">sample with replacement</a> <img class="tex" alt="(y_1,\dots,y_n)" src="http://upload.wikimedia.org/math/b/5/b/b5bad4963ad68a5e27c42255095e51fd.png" /> of <i>n</i> values from the population, and estimate the variance on the basis of this sample. There are several good estimators. Two of them are well known:</p>
<dl>
<dd><img class="tex" alt="s_n^2 = \frac 1n \sum_{i=1}^n \left(y_i - \overline{y} \right)^ 2 = \left(\frac{1}{n} \sum_{i=1}^{n}y_i^2\right) - \overline{y}^2," src="http://upload.wikimedia.org/math/6/a/d/6ad02bc5a6ac0482207e30f84225956c.png" /></dd>
</dl>
<p>and</p>
<dl>
<dd><img class="tex" alt="s^2 = \frac{1}{n-1} \sum_{i=1}^n\left(y_i - \overline{y} \right)^ 2 = \frac{1}{n-1}\sum_{i=1}^n y_i^2 - \frac{n}{n-1} \overline{y}^2," src="http://upload.wikimedia.org/math/2/f/d/2fd62988ca4dca5e3d31512c1c645dde.png" /></dd>
</dl>
<p>Both are referred to as <i><b>sample variance</b></i>.</p>
<p>The two estimators only differ slightly as we see, and for larger values of the <a href="/wiki/Sample_size" title="Sample size">sample size</a> <i>n</i> the difference is negligible. While the first one may be seen as the variance of the sample considered as a population, the second one is an <a href="/wiki/Unbiased_estimator" title="Unbiased estimator" class="mw-redirect">unbiased estimator</a> of the population variance, meaning that its expected value <span class="texhtml"><i>E</i>[<i>s</i><sup>2</sup>]</span> is equal to the true variance of the sampled random variable.</p>
<dl>
<dd><img class="tex" alt="
\begin{align}
\operatorname{E}[s^2] &amp; = \operatorname{E}\left[\frac{1}{n-1} \sum_{i=1}^n Y_i^2 ~ - ~ \frac{n}{n-1} \overline{Y}^2 \right] \\
&amp; = \frac{1}{n-1}\left( \sum \operatorname{E}[Y_i^2] ~ - ~ n \operatorname{E}[\overline{Y}^2] \right) \\
&amp; = \frac{1}{n-1}\left(    n \operatorname{E}[Y_1^2] ~ - ~ n \operatorname{E}[\overline{Y}^2] \right) \\
&amp; = \frac{n}{n-1}\left( \operatorname{Var}(Y_1) + \operatorname{E}[Y_1]^2 ~ - ~ \operatorname{Var}(\overline{Y}) - \operatorname{E}[\overline{Y}]^2 \right) \\
&amp; = \frac{n}{n-1}\left( \operatorname{Var}(Y_1) + \mu^2 ~ - ~ \frac{1}{n}\operatorname{Var}(Y_1) - \mu^2 \right) \\
&amp; = \frac{n}{n-1}\left( \frac{n-1}{n} ~ \operatorname{Var}(Y_1) \right) \\
&amp; = \operatorname{Var}(Y_1) \\
&amp; = \sigma^2
\end{align}
" src="http://upload.wikimedia.org/math/1/4/d/14d405be16bb3eb29ef046c9544c96e1.png" /></dd>
</dl>
<p>While,</p>
<dl>
<dd><img class="tex" alt="E[s_n^2] = \frac{n-1}{n} \sigma^2" src="http://upload.wikimedia.org/math/8/d/7/8d70d0f4b102b1b1c50ee60bd7bcad11.png" /></dd>
</dl>
<p>Common sense would suggest to apply the population formula to the sample as well. The reason that it is biased is that the sample mean is generally somewhat closer to the observations in the sample than the population mean is to these observations. This is so because the sample mean is by definition in the middle of the sample, while the population mean may even lie outside the sample. So the deviations to the sample mean will often be smaller than the deviations to the population mean, and so, if the same formula is applied to both, then this variance estimate will on average be somewhat smaller in the sample than in the population.</p>
<p>One common source of confusion is that the term <i>sample variance</i> may refer to either the unbiased estimator <span class="texhtml"><i>s</i><sup>2</sup></span> of the population variance, or to the variance <img class="tex" alt="s_n^2" src="http://upload.wikimedia.org/math/6/4/f/64f85cdb1f243dcbdccf5fabd357fed7.png" /> of the sample viewed as a finite population. Both can be used to estimate the true population variance. Apart from theoretical considerations, it doesn't really matter which one is used, as for small sample sizes both are inaccurate and for large values of <i>n</i> they are practically the same. Naively computing the variance by dividing by <i>n</i> instead of <i>n</i>-1 systematically underestimates the population variance. Moreover, in practical applications most people report the standard deviation rather than the sample variance, and the standard deviation that is obtained from the unbiased <i>n</i>-1 version of the sample variance has a slight negative bias (though for normally distributed samples a theoretically interesting but rarely used <a href="/wiki/Unbiased_estimation_of_standard_deviation" title="Unbiased estimation of standard deviation">slight correction</a> exists to eliminate this bias). Nevertheless, in applied statistics it is a convention to use the <i>n</i>-1 version if the variance or the standard deviation is computed from a sample. The definition of standard test-statistics, such as <a href="/wiki/Student%27s_t-test" title="Student's t-test">Student's t-test</a>, are often expressed in terms of estimated standard deviations where it is assumed that this convention is followed.</p>
<p>In practice, for large <span class="texhtml"><i>n</i></span>, the distinction is often a minor one. In the course of statistical measurements, sample sizes so small as to warrant the use of the unbiased variance virtually never occur. In this context Press et al.<sup id="cite_ref-2" class="reference"><a href="#cite_note-2" title=""><span>[</span>3<span>]</span></a></sup> commented that <i>if the difference between</i> n <i>and</i> n<i>‚àí1 ever matters to you, then you are probably up to no good anyway - e.g., trying to substantiate a questionable hypothesis with marginal data.</i></p>
<p><a name="Distribution_of_the_sample_variance" id="Distribution_of_the_sample_variance"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Variance&amp;action=edit&amp;section=17" title="Edit section: Distribution of the sample variance">edit</a>]</span> <span class="mw-headline">Distribution of the sample variance</span></h3>
<p>Being a function of <a href="/wiki/Random_variable" title="Random variable">random variables</a>, the sample variance is itself a random variable, and it is natural to study its distribution. In the case that <span class="texhtml"><i>y</i><sub><i>i</i></sub></span> are independent observations from a <a href="/wiki/Normal_distribution" title="Normal distribution">normal distribution</a>, <a href="/wiki/Cochran%27s_theorem" title="Cochran's theorem">Cochran's theorem</a> shows that <span class="texhtml"><i>s</i><sup>2</sup></span> follows a scaled <a href="/wiki/Chi-square_distribution" title="Chi-square distribution">chi-square distribution</a>:</p>
<dl>
<dd><img class="tex" alt="
(n-1)\frac{s^2}{\sigma^2}\sim\chi^2_{n-1}.
" src="http://upload.wikimedia.org/math/0/0/b/00b82e7430ab174113ba05e186d16b1b.png" /></dd>
</dl>
<p>As a direct consequence, it follows that <img class="tex" alt=" \operatorname{E}(s^2)=\sigma^2." src="http://upload.wikimedia.org/math/d/e/d/ded06c5d1658e67d56ad88ab68d37e6a.png" /></p>
<p>However, even in the absence of the Normal assumption, it is still possible to prove that <span class="texhtml"><i>s</i><sup>2</sup></span> is unbiased for <span class="texhtml">œÉ<sup>2</sup></span>.</p>
<p><a name="Generalizations" id="Generalizations"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Variance&amp;action=edit&amp;section=18" title="Edit section: Generalizations">edit</a>]</span> <span class="mw-headline">Generalizations</span></h2>
<div class="thumb tright">
<div class="thumbinner" style="width:302px;"><a href="/wiki/File:SampleBiasCoefficient.png" class="image" title="Unbiased estimate for expected error in the mean of A for a sample of M data points with sample bias coefficient œÅ. The log-log slope -¬Ω line for œÅ=0 is the unbiased standard error."><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b4/SampleBiasCoefficient.png/300px-SampleBiasCoefficient.png" width="300" height="310" border="0" class="thumbimage" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="/wiki/File:SampleBiasCoefficient.png" class="internal" title="Enlarge"><img src="/skins-1.5/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
Unbiased estimate for expected error in the mean of A for a sample of M data points with sample bias coefficient œÅ. The log-log slope -¬Ω line for œÅ=0 is the unbiased standard error.</div>
</div>
</div>
<p>If <span class="texhtml"><i>X</i></span> is a <a href="/wiki/Vector_space" title="Vector space">vector</a>-valued random variable, with values in <img class="tex" alt="\mathbb{R}^n" src="http://upload.wikimedia.org/math/3/0/c/30c28f76ef7517dbd19df4d4c683dbe6.png" />, and thought of as a column vector, then the natural generalization of variance is <img class="tex" alt="\operatorname{E}((X - \mu)(X - \mu)^\operatorname{T})" src="http://upload.wikimedia.org/math/7/d/c/7dcecb870e27d818008a8723baa8ccb3.png" />, where <img class="tex" alt="\mu = \operatorname{E}(X)" src="http://upload.wikimedia.org/math/8/e/4/8e416b9f006891be0dc8a977506ce3a2.png" /> and <img class="tex" alt="X^\operatorname{T}" src="http://upload.wikimedia.org/math/7/7/e/77ec6c9df3c47c2b4dd853d1c419499d.png" /> is the transpose of <span class="texhtml"><i>X</i></span>, and so is a row vector. This variance is a <a href="/wiki/Positive_definite_matrix" title="Positive definite matrix" class="mw-redirect">positive semi-definite square matrix</a>, commonly referred to as the <a href="/wiki/Covariance_matrix" title="Covariance matrix">covariance matrix</a>.</p>
<p>If <span class="texhtml"><i>X</i></span> is a <a href="/wiki/Complex_number" title="Complex number">complex</a>-valued random variable, with values in <img class="tex" alt="\mathbb{C}" src="http://upload.wikimedia.org/math/f/0/b/f0b01fe0a1eec87c634584ac0694fb71.png" />, then its variance is <img class="tex" alt="\operatorname{E}((X - \mu)(X - \mu)^*)" src="http://upload.wikimedia.org/math/c/a/3/ca3dfab1a1eec926bbffb4c0e554481e.png" />, where <span class="texhtml"><i>X</i> <sup>*</sup></span> is the <a href="/wiki/Complex_conjugate" title="Complex conjugate">complex conjugate</a> of <span class="texhtml"><i>X</i></span>. This variance is also a positive semi-definite square matrix.</p>
<p>If one's (real) random variables are defined on an n-dimensional <a href="/wiki/Continuum_(mathematics)" title="Continuum (mathematics)">continuum</a> <b>x</b>, the <a href="/wiki/Cross-covariance" title="Cross-covariance" class="mw-redirect">cross-covariance</a> of variables A[<b>x</b>] and B[<b>x</b>] as a function of n-dimensional vector displacement (or lag) <b>Œîx</b> may be defined as œÉ<sub>AB</sub>[<b>Œîx</b>] ‚â° „Äà(A[<b>x</b>+<b>Œîx</b>]-Œº<sub>A</sub>)(B[<b>x</b>]-Œº<sub>B</sub>)„Äâ<sub><b>x</b></sub>. Here the population (as distinct from sample) average over <b>x</b> is denoted by angle brackets „Äà „Äâ<sub><b>x</b></sub> or the Greek letter Œº.</p>
<p>This quantity, called a second-moment <a href="http://knowledgetoday.org/wiki/index.php/Correlation" class="external text" title="http://knowledgetoday.org/wiki/index.php/Correlation" rel="nofollow">correlation measure</a> because it's a generalization of the second-moment statistic <i>variance</i>, is sometimes put into dimensionless form by normalizing with the population standard deviations of A and B (e.g. œÉ<sub>A</sub>‚â°Sqrt[œÉ<sub>AA</sub>[0]]). This results in a <a href="/wiki/Correlation_coefficient" title="Correlation coefficient" class="mw-redirect">correlation coefficient</a> œÅ<sub>AB</sub>[<b>Œîx</b>] ‚â° œÉ<sub>AB</sub>[<b>Œîx</b>]/(œÉ<sub>A</sub>œÉ<sub>B</sub>) that takes on values between plus and minus one. When A is the same as B, the foregoing expressions yield values for <a href="/wiki/Autocovariance" title="Autocovariance">autocovariance</a>, a quantity also known in <a href="/wiki/Scattering_theory" title="Scattering theory">scattering theory</a> as the pair-correlation (or <a href="/wiki/Patterson_function" title="Patterson function">Patterson</a>) function.</p>
<p>If one defines <i>sample bias coefficient</i> œÅ as an average of the <a href="/wiki/Autocorrelation" title="Autocorrelation">autocorrelation</a>-coefficient œÅ<sub>AA</sub>[<b>Œîx</b>] over all point pairs in a set of M sample points<sup id="cite_ref-3" class="reference"><a href="#cite_note-3" title=""><span>[</span>4<span>]</span></a></sup>, an unbiased estimate for <i>expected error in the mean</i> of A is the square root of: sample variance (taken as a population) times (1+(M-1)œÅ)/((M-1)(1-œÅ)). When œÅ is much greater than 1/(M-1), this reduces to the square root of: sample variance (taken as a population) times œÅ/(1-œÅ). When |œÅ| is much less than 1/(M-1) this yields the more familiar expression for <a href="/wiki/Standard_error_(statistics)" title="Standard error (statistics)">standard error</a>, namely the square root of: sample variance (taken as a population) over (M-1).</p>
<p><a name="History" id="History"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Variance&amp;action=edit&amp;section=19" title="Edit section: History">edit</a>]</span> <span class="mw-headline">History</span></h2>
<p>The term <i>variance</i> was first introduced by <a href="/wiki/Ronald_Fisher" title="Ronald Fisher">Ronald Fisher</a> in his 1918 paper <i><a href="/wiki/The_Correlation_Between_Relatives_on_the_Supposition_of_Mendelian_Inheritance" title="The Correlation Between Relatives on the Supposition of Mendelian Inheritance">The Correlation Between Relatives on the Supposition of Mendelian Inheritance</a></i><sup id="cite_ref-4" class="reference"><a href="#cite_note-4" title=""><span>[</span>5<span>]</span></a></sup>:</p>
<blockquote>
<p>The great body of available statistics show us that the deviations of a <a href="/wiki/Biometry" title="Biometry" class="mw-redirect">human measurement</a> from its mean follow very closely the <a href="/wiki/Normal_distribution" title="Normal distribution">Normal Law of Errors</a>, and, therefore, that the variability may be uniformly measured by the <a href="/wiki/Standard_deviation" title="Standard deviation">standard deviation</a> corresponding to the <a href="/wiki/Square_root" title="Square root">square root</a> of the <a href="/wiki/Mean_square_error" title="Mean square error" class="mw-redirect">mean square error</a>. When there are two independent causes of variability capable of producing in an otherwise uniform population distributions with standard deviations <span class="texhtml">Œ∏<sub>1</sub></span> and <span class="texhtml">Œ∏<sub>2</sub></span>, it is found that the distribution, when both causes act together, has a standard deviation <img class="tex" alt="\sqrt{\theta_1^2 + \theta_2^2}" src="http://upload.wikimedia.org/math/0/7/6/076d5bdde9bb431e2236a1f236ae81d7.png" />. It is therefore desirable in analysing the causes of variability to deal with the square of the standard deviation as the measure of variability. We shall term this quantity the Variance...</p>
</blockquote>
<p><a name="Moment_of_inertia" id="Moment_of_inertia"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Variance&amp;action=edit&amp;section=20" title="Edit section: Moment of inertia">edit</a>]</span> <span class="mw-headline">Moment of inertia</span></h2>
<p>The variance of a probability distribution is analogous to the <a href="/wiki/Moment_of_inertia" title="Moment of inertia">moment of inertia</a> in <a href="/wiki/Classical_mechanics" title="Classical mechanics">classical mechanics</a> of a corresponding mass distribution along a line, with respect to rotation about its center of mass. It is because of this analogy that such things as the variance are called <i><a href="/wiki/Moment_(mathematics)" title="Moment (mathematics)">moments</a></i> of <a href="/wiki/Probability_distribution" title="Probability distribution">probability distributions</a>. The covariance matrix is related to the <a href="/wiki/Moment_of_inertia_tensor" title="Moment of inertia tensor" class="mw-redirect">moment of inertia tensor</a> for multivariate distributions. The moment of inertia of a cloud of <i>n</i> points with a covariance matrix of <span class="texhtml">Œ£</span> is given by</p>
<dl>
<dd><img class="tex" alt="I=n (\mathbf{1}_{3\times 3} \operatorname{tr}(\Sigma)  - \Sigma)." src="http://upload.wikimedia.org/math/3/4/2/34231dbc6685e567ef481108753046f0.png" /></dd>
</dl>
<p>This difference between moment of inertia in physics and in statistics is clear for points that are gathered along a line. Suppose many points are close to the <i>x</i> and distributed along it. The covariance matrix might look like</p>
<dl>
<dd><img class="tex" alt="\Sigma=\begin{bmatrix}10 &amp; 0 &amp; 0\\0 &amp; 0.1 &amp; 0 \\ 0 &amp; 0 &amp; 0.1\end{bmatrix}." src="http://upload.wikimedia.org/math/3/9/1/391a56d2c7702f9eaea9eb7dc362d056.png" /></dd>
</dl>
<p>That is, there is the most variance in the <i>x</i> direction. However, physicists would consider this to have a low moment <i>about</i> the <i>x</i> axis so the moment-of-inertia tensor is</p>
<dl>
<dd><img class="tex" alt="I=n\begin{bmatrix}0.2 &amp; 0 &amp; 0\\0 &amp; 10.1 &amp; 0 \\ 0 &amp; 0 &amp; 10.1\end{bmatrix}." src="http://upload.wikimedia.org/math/8/e/f/8ef105f4f15467193cfe87076f9a602b.png" /></dd>
</dl>
<p><a name="See_also" id="See_also"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Variance&amp;action=edit&amp;section=21" title="Edit section: See also">edit</a>]</span> <span class="mw-headline">See also</span></h2>
<div class="noprint tright portal" style="border:solid #aaa 1px;margin:0.5em 0 0.5em 0.5em;">
<table style="background:#f9f9f9; font-size:85%; line-height:110%;">
<tr>
<td><a href="/wiki/File:Fisher_iris_versicolor_sepalwidth.svg" class="image" title="Fisher iris versicolor sepalwidth.svg"><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Fisher_iris_versicolor_sepalwidth.svg/42px-Fisher_iris_versicolor_sepalwidth.svg.png" width="42" height="28" border="0" /></a></td>
<td style="padding:0 0.2em;"><i><b><a href="/wiki/Portal:Statistics" title="Portal:Statistics">Statistics portal</a></b></i></td>
</tr>
</table>
</div>
<div class="infobox sisterproject">
<div style="float: left;">
<div class="floatnone"><a href="/wiki/File:Wiktionary-logo-en.svg" class="image" title="Wiktionary-logo-en.svg"><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Wiktionary-logo-en.svg/50px-Wiktionary-logo-en.svg.png" width="50" height="54" border="0" /></a></div>
</div>
<div style="margin-left: 60px;">Look up <i><b><a href="http://en.wiktionary.org/wiki/variance" class="extiw" title="wiktionary:variance">variance</a></b></i> in <a href="/wiki/Wiktionary" title="Wiktionary">Wiktionary</a>, the free dictionary.</div>
</div>
<div style="-moz-column-count:2; column-count:2;">
<ul>
<li><a href="/wiki/Algorithms_for_calculating_variance" title="Algorithms for calculating variance">Algorithms for calculating variance</a></li>
<li><a href="/wiki/An_inequality_on_location_and_scale_parameters" title="An inequality on location and scale parameters">An inequality on location and scale parameters</a></li>
<li><a href="/wiki/Covariance" title="Covariance">Covariance</a></li>
<li><a href="/wiki/Chebyshev%27s_inequality" title="Chebyshev's inequality">Chebyshev's inequality</a></li>
<li><a href="/wiki/Estimation_of_covariance_matrices" title="Estimation of covariance matrices">Estimation of covariance matrices</a></li>
<li><a href="/wiki/Explained_variance" title="Explained variance" class="mw-redirect">Explained variance</a> &amp; <a href="/wiki/Unexplained_variance" title="Unexplained variance" class="mw-redirect">unexplained variance</a></li>
<li><a href="/wiki/Kurtosis" title="Kurtosis">Kurtosis</a></li>
<li><a href="/wiki/Mean_absolute_error" title="Mean absolute error">Mean absolute error</a></li>
<li><a href="/wiki/Qualitative_variation" title="Qualitative variation">Qualitative variation</a></li>
<li><a href="/wiki/Sample_mean_and_covariance" title="Sample mean and covariance" class="mw-redirect">Sample mean and covariance</a></li>
<li><a href="/wiki/Semivariance" title="Semivariance">Semivariance</a></li>
<li><a href="/wiki/Skewness" title="Skewness">Skewness</a></li>
<li><a href="/wiki/Standard_deviation" title="Standard deviation">Standard deviation</a></li>
<li><a href="/wiki/True_variance" title="True variance">True variance</a></li>
<li><a href="/wiki/Weighted_variance" title="Weighted variance" class="mw-redirect">Weighted variance</a></li>
</ul>
</div>
<p><a name="References" id="References"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Variance&amp;action=edit&amp;section=22" title="Edit section: References">edit</a>]</span> <span class="mw-headline">References</span></h2>
<div class="references-small">
<ol class="references">
<li id="cite_note-0"><b><a href="#cite_ref-0" title="">^</a></b> Michel Loeve, "Probability Theory", <i>Graduate Texts in Mathematics</i>, Volume 45, 4th edition, Springer-Verlag, 1977, p.&#160;12.</li>
<li id="cite_note-1"><b><a href="#cite_ref-1" title="">^</a></b> A. Kagan and L. A. Shepp, "Why the variance?", <i>Statistics and Probability Letters</i>, Volume 38, Number 4, 1998, pp.&#160;329‚Äì333. (online <a href="http://dx.doi.org/10.1016/S0167-7152(98)00041-8" class="external autonumber" title="http://dx.doi.org/10.1016/S0167-7152(98)00041-8" rel="nofollow">[1]</a>)</li>
<li id="cite_note-2"><b><a href="#cite_ref-2" title="">^</a></b> Press, W. H., Teukolsky, S. A., Vetterling, W. T. &amp; Flannery, B. P. (1986) <i><a href="/wiki/Numerical_Recipes" title="Numerical Recipes">Numerical recipes: The art of scientific computing</a></i>. Cambridge: Cambridge University Press. (<a href="http://nr.com/" class="external text" title="http://nr.com/" rel="nofollow">online</a>)</li>
<li id="cite_note-3"><b><a href="#cite_ref-3" title="">^</a></b> P. Fraundorf (1980) "Microcharacterization of interplanetary dust collected in the earth's stratosphere" (Ph.D. Dissertation in Physics, Washington University, Saint Louis MO), <a href="http://arxiv.org/abs/cond-mat/0403013" class="external text" title="http://arxiv.org/abs/cond-mat/0403013" rel="nofollow">Appendix E</a></li>
<li id="cite_note-4"><b><a href="#cite_ref-4" title="">^</a></b> Ronald Fisher (1918) <a href="http://www.library.adelaide.edu.au/digitised/fisher/9.pdf" class="external text" title="http://www.library.adelaide.edu.au/digitised/fisher/9.pdf" rel="nofollow">The correlation between relatives on the supposition of Mendelian Inheritance</a></li>
</ol>
</div>
<p><a name="External_links" id="External_links"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Variance&amp;action=edit&amp;section=23" title="Edit section: External links">edit</a>]</span> <span class="mw-headline">External links</span></h2>
<ul>
<li><a href="http://www.stats4students.com/Essentials/Measures-Of-Spread/Overview_3.php" class="external text" title="http://www.stats4students.com/Essentials/Measures-Of-Spread/Overview_3.php" rel="nofollow">A Guide to Understanding &amp; Calculating Variance</a></li>
<li><a href="http://www.library.adelaide.edu.au/digitised/fisher/9.pdf" class="external text" title="http://www.library.adelaide.edu.au/digitised/fisher/9.pdf" rel="nofollow">Fisher's original paper</a> (pdf format)</li>
<li><a href="http://www.celiagreen.com/charlesmccreery/statistics/anova.pdf" class="external text" title="http://www.celiagreen.com/charlesmccreery/statistics/anova.pdf" rel="nofollow">A tutorial on Analysis of Variance devised for first-year Oxford University students</a></li>
</ul>
<table class="navbox" cellspacing="0" style=";">
<tr>
<td style="padding:2px;">
<table cellspacing="0" class="nowraplinks collapsible autocollapse" style="width:100%;background:transparent;color:inherit;;">
<tr>
<th style=";" colspan="3" class="navbox-title">
<div style="float:left; width:6em;text-align:left;">
<div class="noprint plainlinksneverexpand navbar" style="background:none; padding:0; font-weight:normal;;;border:none;; font-size:xx-small;"><a href="/wiki/Template:Theory_of_probability_distributions" title="Template:Theory of probability distributions"><span title="View this template" style=";;border:none;">v</span></a>&#160;<span style="font-size:80%;">‚Ä¢</span>&#160;<a href="/wiki/Template_talk:Theory_of_probability_distributions" title="Template talk:Theory of probability distributions"><span title="Discussion about this template" style=";;border:none;">d</span></a>&#160;<span style="font-size:80%;">‚Ä¢</span>&#160;<a href="http://en.wikipedia.org/w/index.php?title=Template:Theory_of_probability_distributions&amp;action=edit" class="external text" title="http://en.wikipedia.org/w/index.php?title=Template:Theory_of_probability_distributions&amp;action=edit" rel="nofollow"><span title="Edit this template" style=";;border:none;;">e</span></a></div>
</div>
<span style="font-size:110%;">Theory of <a href="/wiki/Probability_distribution" title="Probability distribution">probability distributions</a></span></th>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<td colspan="2" style="width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/Probability_mass_function" title="Probability mass function">probability mass function</a> (pmf)<span style="font-weight:bold;">&#160;¬∑</span> <a href="/wiki/Probability_density_function" title="Probability density function">probability density function</a> (pdf)<span style="font-weight:bold;">&#160;¬∑</span> <a href="/wiki/Cumulative_distribution_function" title="Cumulative distribution function">cumulative distribution function</a> (cdf)<span style="font-weight:bold;">&#160;¬∑</span> <a href="/wiki/Quantile_function" title="Quantile function">quantile function</a></div>
</td>
<td style="width:0%;padding:0px 0px 0px 2px;" rowspan="5"><a href="/wiki/File:Loglogisticpdf_no-labels.svg" class="image" title="Loglogisticpdf no-labels.svg"><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8f/Loglogisticpdf_no-labels.svg/90px-Loglogisticpdf_no-labels.svg.png" width="90" height="68" border="0" /></a></td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td colspan="2" style="width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"><a href="/wiki/Raw_moment" title="Raw moment" class="mw-redirect">raw moment</a><span style="font-weight:bold;">&#160;¬∑</span> <a href="/wiki/Central_moment" title="Central moment">central moment</a><span style="font-weight:bold;">&#160;¬∑</span> <a href="/wiki/Expected_value" title="Expected value">mean</a><span style="font-weight:bold;">&#160;¬∑</span> <strong class="selflink">variance</strong><span style="font-weight:bold;">&#160;¬∑</span> <a href="/wiki/Standard_deviation" title="Standard deviation">standard deviation</a><span style="font-weight:bold;">&#160;¬∑</span> <a href="/wiki/Skewness" title="Skewness">skewness</a><span style="font-weight:bold;">&#160;¬∑</span> <a href="/wiki/Kurtosis" title="Kurtosis">kurtosis</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td colspan="2" style="width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/Moment-generating_function" title="Moment-generating function">moment-generating function</a> (mgf)<span style="font-weight:bold;">&#160;¬∑</span> <a href="/wiki/Characteristic_function_(probability_theory)" title="Characteristic function (probability theory)">characteristic function</a><span style="font-weight:bold;">&#160;¬∑</span> <a href="/wiki/Probability-generating_function" title="Probability-generating function">probability-generating function</a> (pgf)<span style="font-weight:bold;">&#160;¬∑</span> <a href="/wiki/Cumulant" title="Cumulant">cumulant</a></div>
</td>
</tr>
</table>
</td>
</tr>
</table>
<table class="navbox" cellspacing="0" style=";">
<tr>
<td style="padding:2px;">
<table cellspacing="0" class="nowraplinks collapsible autocollapse" style="width:100%;background:transparent;color:inherit;;">
<tr>
<th style=";" colspan="2" class="navbox-title">
<div style="float:left; width:6em;text-align:left;">
<div class="noprint plainlinksneverexpand navbar" style="background:none; padding:0; font-weight:normal;;;border:none;; font-size:xx-small;"><a href="/wiki/Template:Statistics" title="Template:Statistics"><span title="View this template" style=";;border:none;">v</span></a>&#160;<span style="font-size:80%;">‚Ä¢</span>&#160;<a href="/wiki/Template_talk:Statistics" title="Template talk:Statistics"><span title="Discussion about this template" style=";;border:none;">d</span></a>&#160;<span style="font-size:80%;">‚Ä¢</span>&#160;<a href="http://en.wikipedia.org/w/index.php?title=Template:Statistics&amp;action=edit" class="external text" title="http://en.wikipedia.org/w/index.php?title=Template:Statistics&amp;action=edit" rel="nofollow"><span title="Edit this template" style=";;border:none;;">e</span></a></div>
</div>
<span style="font-size:110%;"><a href="/wiki/Statistics" title="Statistics">Statistics</a></span></th>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/Design_of_experiments" title="Design of experiments">Design of experiments</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/Statistical_population" title="Statistical population">Population</a>&#160;‚Ä¢ <a href="/wiki/Sampling_(statistics)" title="Sampling (statistics)">Sampling</a>&#160;‚Ä¢ <a href="/wiki/Stratified_sampling" title="Stratified sampling">Stratified sampling</a>&#160;‚Ä¢ <a href="/wiki/Replication_(statistics)" title="Replication (statistics)">Replication</a>&#160;‚Ä¢ <a href="/wiki/Blocking_(statistics)" title="Blocking (statistics)">Blocking</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/Sample_size" title="Sample size">Sample size estimation</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"><a href="/wiki/Null_hypothesis" title="Null hypothesis">Null hypothesis</a>&#160;‚Ä¢ <a href="/wiki/Alternative_hypothesis" title="Alternative hypothesis">Alternative hypothesis</a>&#160;‚Ä¢ <a href="/wiki/Type_I_and_Type_II_errors" title="Type I and Type II errors" class="mw-redirect">Type I and Type II errors</a>&#160;‚Ä¢ <a href="/wiki/Statistical_power" title="Statistical power">Statistical power</a>&#160;‚Ä¢ <a href="/wiki/Effect_size" title="Effect size">Effect size</a>&#160;‚Ä¢ <a href="/wiki/Standard_error_(statistics)" title="Standard error (statistics)">Standard error</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/Descriptive_statistics" title="Descriptive statistics">Descriptive statistics</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"></div>
<table cellspacing="0" class="nowraplinks navbox-subgroup" style="width:100%;;;;">
<tr>
<td class="navbox-group" style=";padding-left:0em;padding-right:0em;;">
<div style="padding:0em 0.75em;"><a href="/wiki/Continuous_probability_distribution" title="Continuous probability distribution">Continuous data</a></div>
</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"></div>
<table cellspacing="0" class="nowraplinks navbox-subgroup" style="width:100%;;;;">
<tr>
<td class="navbox-group" style=";padding-left:0em;padding-right:0em;;">
<div style="padding:0em 0.75em;"><a href="/wiki/Location_parameter" title="Location parameter">Location</a></div>
</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/Mean" title="Mean">Mean</a> (<a href="/wiki/Arithmetic_mean" title="Arithmetic mean">Arithmetic</a>, <a href="/wiki/Geometric_mean" title="Geometric mean">Geometric</a>, <a href="/wiki/Harmonic_mean" title="Harmonic mean">Harmonic</a>)&#160;‚Ä¢ <a href="/wiki/Median" title="Median">Median</a>&#160;‚Ä¢ <a href="/wiki/Mode_(statistics)" title="Mode (statistics)">Mode</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";padding-left:0em;padding-right:0em;;">
<div style="padding:0em 0.75em;"><a href="/wiki/Statistical_dispersion" title="Statistical dispersion">Dispersion</a></div>
</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"><a href="/wiki/Range_(statistics)" title="Range (statistics)">Range</a>&#160;‚Ä¢ <a href="/wiki/Standard_deviation" title="Standard deviation">Standard deviation</a>&#160;‚Ä¢ <a href="/wiki/Coefficient_of_variation" title="Coefficient of variation">Coefficient of variation</a>&#160;‚Ä¢ <a href="/wiki/Percentile" title="Percentile">Percentile</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";padding-left:0em;padding-right:0em;;">
<div style="padding:0em 0.75em;"><a href="/wiki/Moment_(mathematics)" title="Moment (mathematics)">Moments</a></div>
</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><strong class="selflink">Variance</strong>&#160;‚Ä¢ <a href="/wiki/Semivariance" title="Semivariance">Semivariance</a>&#160;‚Ä¢ <a href="/wiki/Skewness" title="Skewness">Skewness</a>&#160;‚Ä¢ <a href="/wiki/Kurtosis" title="Kurtosis">Kurtosis</a></div>
</td>
</tr>
</table>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";padding-left:0em;padding-right:0em;;">
<div style="padding:0em 0.75em;"><a href="/wiki/Discrete_probability_distribution" title="Discrete probability distribution">Categorical data</a></div>
</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"><a href="/wiki/Frequency_(statistics)" title="Frequency (statistics)">Frequency</a>&#160;‚Ä¢ <a href="/wiki/Contingency_table" title="Contingency table">Contingency table</a></div>
</td>
</tr>
</table>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/Statistical_inference" title="Statistical inference">Inferential statistics</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"><a href="/wiki/Bayesian_inference" title="Bayesian inference">Bayesian inference</a>&#160;‚Ä¢ <a href="/wiki/Frequentist_inference" title="Frequentist inference" class="mw-redirect">Frequentist inference</a>&#160;‚Ä¢ <a href="/wiki/Statistical_hypothesis_testing" title="Statistical hypothesis testing">Hypothesis testing</a>&#160;‚Ä¢ <a href="/wiki/Statistical_significance" title="Statistical significance">Significance</a>&#160;‚Ä¢ <a href="/wiki/P-value" title="P-value">P-value</a>&#160;‚Ä¢ <a href="/wiki/Interval_estimation" title="Interval estimation">Interval estimation</a>&#160;‚Ä¢ <a href="/wiki/Confidence_interval" title="Confidence interval">Confidence interval</a>&#160;‚Ä¢ <a href="/wiki/Meta-analysis" title="Meta-analysis">Meta-analysis</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;">General estimation</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/Bayesian_estimator" title="Bayesian estimator" class="mw-redirect">Bayesian estimator</a>&#160;‚Ä¢ <a href="/wiki/Maximum_likelihood" title="Maximum likelihood">Maximum likelihood</a>&#160;‚Ä¢ <a href="/wiki/Method_of_moments_(statistics)" title="Method of moments (statistics)">Method of moments</a>&#160;‚Ä¢ <a href="/wiki/Minimum_distance_estimation" title="Minimum distance estimation">Minimum distance</a>&#160;‚Ä¢ <a href="/wiki/Maximum_spacing_estimation" title="Maximum spacing estimation">Maximum spacing</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;">Specific tests</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"><a href="/wiki/Z-test" title="Z-test">Z-test (normal)</a>&#160;‚Ä¢ <a href="/wiki/Student%27s_t-test" title="Student's t-test">Student's t-test</a>&#160;‚Ä¢ <a href="/wiki/Chi-square_test" title="Chi-square test">Chi-square test</a>&#160;‚Ä¢ <a href="/wiki/F-test" title="F-test">F-test</a>&#160;‚Ä¢ <a href="/wiki/Sensitivity_and_specificity" title="Sensitivity and specificity">Sensitivity and specificity</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/Survival_analysis" title="Survival analysis">Survival analysis</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/Survival_function" title="Survival function">Survival function</a>&#160;‚Ä¢ <a href="/wiki/Kaplan-Meier_estimator" title="Kaplan-Meier estimator">Kaplan-Meier</a>&#160;‚Ä¢ <a href="/wiki/Logrank_test" title="Logrank test">Logrank test</a>&#160;‚Ä¢ <a href="/wiki/Failure_rate" title="Failure rate">Failure rate</a>&#160;‚Ä¢ <a href="/wiki/Proportional_hazards_models" title="Proportional hazards models">Proportional hazards models</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/Correlation" title="Correlation">Correlation</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"><a href="/wiki/Pearson_product-moment_correlation_coefficient" title="Pearson product-moment correlation coefficient">Pearson product-moment correlation coefficient</a>&#160;‚Ä¢ <a href="/wiki/Rank_correlation" title="Rank correlation">Rank correlation</a> (<a href="/wiki/Spearman%27s_rank_correlation_coefficient" title="Spearman's rank correlation coefficient">Spearman's rho</a>, <a href="/wiki/Kendall_tau_rank_correlation_coefficient" title="Kendall tau rank correlation coefficient">Kendall's tau</a>)&#160;‚Ä¢ <a href="/wiki/Confounding_variable" title="Confounding variable" class="mw-redirect">Confounding variable</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/Linear_model" title="Linear model">Linear models</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/General_linear_model" title="General linear model">General linear model</a>&#160;‚Ä¢ <a href="/wiki/Generalized_linear_model" title="Generalized linear model">Generalized linear model</a>&#160;‚Ä¢ <a href="/wiki/Analysis_of_variance" title="Analysis of variance">Analysis of variance</a>&#160;‚Ä¢ <a href="/wiki/Analysis_of_covariance" title="Analysis of covariance">Analysis of covariance</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/Regression_analysis" title="Regression analysis">Regression analysis</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"><a href="/wiki/Linear_regression" title="Linear regression">Linear regression</a>&#160;‚Ä¢ <a href="/wiki/Nonlinear_regression" title="Nonlinear regression">Nonlinear regression</a>&#160;‚Ä¢ <a href="/wiki/Nonparametric_regression" title="Nonparametric regression">Nonparametric regression</a>&#160;‚Ä¢ <a href="/wiki/Semiparametric_regression" title="Semiparametric regression">Semiparametric regression</a>&#160;‚Ä¢ <a href="/wiki/Logistic_regression" title="Logistic regression">Logistic regression</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/Statistical_graphics" title="Statistical graphics">Statistical graphics</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/Bar_chart" title="Bar chart">Bar chart</a>&#160;‚Ä¢ <a href="/wiki/Biplot" title="Biplot">Biplot</a>&#160;‚Ä¢ <a href="/wiki/Box_plot" title="Box plot">Box plot</a>&#160;‚Ä¢ <a href="/wiki/Control_chart" title="Control chart">Control chart</a>&#160;‚Ä¢ <a href="/wiki/Forest_plot" title="Forest plot">Forest plot</a>&#160;‚Ä¢ <a href="/wiki/Histogram" title="Histogram">Histogram</a>&#160;‚Ä¢ <a href="/wiki/Q-Q_plot" title="Q-Q plot">Q-Q plot</a>&#160;‚Ä¢ <a href="/wiki/Run_chart" title="Run chart">Run chart</a>&#160;‚Ä¢ <a href="/wiki/Scatter_plot" title="Scatter plot">Scatter plot</a>&#160;‚Ä¢ <a href="/wiki/Stemplot" title="Stemplot">Stemplot</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/History_of_statistics" title="History of statistics">History</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"><a href="/wiki/History_of_statistics" title="History of statistics">History of statistics</a>&#160;‚Ä¢ <a href="/wiki/Founders_of_statistics" title="Founders of statistics">Founders of statistics</a>&#160;‚Ä¢ <a href="/wiki/Timeline_of_probability_and_statistics" title="Timeline of probability and statistics">Timeline of probability and statistics</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;">Publications</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/List_of_scientific_journals_in_statistics" title="List of scientific journals in statistics">Journals in statistics</a>&#160;‚Ä¢ <a href="/wiki/List_of_important_publications_in_statistics" title="List of important publications in statistics">Important publications</a></div>
</td>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<td class="navbox-abovebelow" style=";" colspan="2"><b><a href="/wiki/Category:Statistics" title="Category:Statistics">Category</a></b>&#160;‚Ä¢ <b><a href="/wiki/Portal:Statistics" title="Portal:Statistics">Portal</a></b>&#160;‚Ä¢ <b><a href="/wiki/Topic_outline_of_statistics" title="Topic outline of statistics">Topic outline</a></b>&#160;‚Ä¢ <b><a href="/wiki/List_of_statistics_topics" title="List of statistics topics">List of topics</a></b></td>
</tr>
</table>
</td>
</tr>
</table>


<!-- 
NewPP limit report
Preprocessor node count: 2278/1000000
Post-expand include size: 59760/2048000 bytes
Template argument size: 29119/2048000 bytes
Expensive parser function count: 0/500
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:32344-0!1!0!default!!en!2 and timestamp 20090407171843 -->
<div class="printfooter">
Retrieved from "<a href="http://en.wikipedia.org/wiki/Variance">http://en.wikipedia.org/wiki/Variance</a>"</div>
			<div id='catlinks' class='catlinks'><div id="mw-normal-catlinks"><a href="/wiki/Special:Categories" title="Special:Categories">Categories</a>:&#32;<span dir='ltr'><a href="/wiki/Category:Probability_theory" title="Category:Probability theory">Probability theory</a></span> | <span dir='ltr'><a href="/wiki/Category:Statistical_deviation_and_dispersion" title="Category:Statistical deviation and dispersion">Statistical deviation and dispersion</a></span> | <span dir='ltr'><a href="/wiki/Category:Articles_containing_proofs" title="Category:Articles containing proofs">Articles containing proofs</a></span> | <span dir='ltr'><a href="/wiki/Category:Data_analysis" title="Category:Data analysis">Data analysis</a></span></div><div id="mw-hidden-catlinks" class="mw-hidden-cats-hidden">Hidden categories:&#32;<span dir='ltr'><a href="/wiki/Category:Statistics_articles_linked_to_the_portal" title="Category:Statistics articles linked to the portal">Statistics articles linked to the portal</a></span> | <span dir='ltr'><a href="/wiki/Category:Statistics_articles_with_navigational_template" title="Category:Statistics articles with navigational template">Statistics articles with navigational template</a></span></div></div>			<!-- end content -->
						<div class="visualClear"></div>
		</div>
	</div>
		</div>
		<div id="column-one">
	<div id="p-cactions" class="portlet">
		<h5>Views</h5>
		<div class="pBody">
			<ul>
	
				 <li id="ca-nstab-main" class="selected"><a href="/wiki/Variance" title="View the content page [c]" accesskey="c">Article</a></li>
				 <li id="ca-talk"><a href="/wiki/Talk:Variance" title="Discussion about the content page [t]" accesskey="t">Discussion</a></li>
				 <li id="ca-edit"><a href="/w/index.php?title=Variance&amp;action=edit" title="You can edit this page. &#10;Please use the preview button before saving. [e]" accesskey="e">Edit this page</a></li>
				 <li id="ca-history"><a href="/w/index.php?title=Variance&amp;action=history" title="Past versions of this page [h]" accesskey="h">History</a></li>			</ul>
		</div>
	</div>
	<div class="portlet" id="p-personal">
		<h5>Personal tools</h5>
		<div class="pBody">
			<ul>
				<li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Variance" title="You are encouraged to log in; however, it is not mandatory. [o]" accesskey="o">Log in / create account</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-logo">
		<a style="background-image: url(http://upload.wikimedia.org/wikipedia/en/b/bc/Wiki.png);" href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
	<div class='generated-sidebar portlet' id='p-navigation'>
		<h5>Navigation</h5>
		<div class='pBody'>
			<ul>
				<li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li>
				<li id="n-contents"><a href="/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li>
				<li id="n-featuredcontent"><a href="/wiki/Portal:Featured_content" title="Featured content ‚Äî the best of Wikipedia">Featured content</a></li>
				<li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li>
				<li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li>
			</ul>
		</div>
	</div>
	<div id="p-search" class="portlet">
		<h5><label for="searchInput">Search</label></h5>
		<div id="searchBody" class="pBody">
			<form action="/w/index.php" id="searchform"><div>
				<input type='hidden' name="title" value="Special:Search"/>
				<input id="searchInput" name="search" type="text" title="Search Wikipedia [f]" accesskey="f" value="" />
				<input type='submit' name="go" class="searchButton" id="searchGoButton"	value="Go" title="Go to a page with this exact name if one exists" />&nbsp;
				<input type='submit' name="fulltext" class="searchButton" id="mw-searchButton" value="Search" title="Search Wikipedia for this text" />
			</div></form>
		</div>
	</div>
	<div class='generated-sidebar portlet' id='p-interaction'>
		<h5>Interaction</h5>
		<div class='pBody'>
			<ul>
				<li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li>
				<li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li>
				<li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="The list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li>
				<li id="n-contact"><a href="/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact Wikipedia</a></li>
				<li id="n-sitesupport"><a href="http://wikimediafoundation.org/wiki/Donate" title="Support us">Donate to Wikipedia</a></li>
				<li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-tb">
		<h5>Toolbox</h5>
		<div class="pBody">
			<ul>
				<li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Variance" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li>
				<li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Variance" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li>
<li id="t-upload"><a href="/wiki/Wikipedia:Upload" title="Upload files [u]" accesskey="u">Upload file</a></li>
<li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="List of all special pages [q]" accesskey="q">Special pages</a></li>
				<li id="t-print"><a href="/w/index.php?title=Variance&amp;printable=yes" rel="alternate" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>				<li id="t-permalink"><a href="/w/index.php?title=Variance&amp;oldid=282377803" title="Permanent link to this version of the page">Permanent link</a></li><li id="t-cite"><a href="/w/index.php?title=Special:Cite&amp;page=Variance&amp;id=282377803">Cite this page</a></li>			</ul>
		</div>
	</div>
	<div id="p-lang" class="portlet">
		<h5>Languages</h5>
		<div class="pBody">
			<ul>
				<li class="interwiki-ar"><a href="http://ar.wikipedia.org/wiki/%D8%AA%D8%A8%D8%A7%D9%8A%D9%86">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a></li>
				<li class="interwiki-ca"><a href="http://ca.wikipedia.org/wiki/Vari%C3%A0ncia">Catal√†</a></li>
				<li class="interwiki-cs"><a href="http://cs.wikipedia.org/wiki/Rozptyl_(statistika)">ƒåesky</a></li>
				<li class="interwiki-da"><a href="http://da.wikipedia.org/wiki/Varians">Dansk</a></li>
				<li class="interwiki-de"><a href="http://de.wikipedia.org/wiki/Varianz">Deutsch</a></li>
				<li class="interwiki-et"><a href="http://et.wikipedia.org/wiki/Dispersioon">Eesti</a></li>
				<li class="interwiki-el"><a href="http://el.wikipedia.org/wiki/%CE%94%CE%B9%CE%B1%CE%BA%CF%8D%CE%BC%CE%B1%CE%BD%CF%83%CE%B7">ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨</a></li>
				<li class="interwiki-es"><a href="http://es.wikipedia.org/wiki/Varianza">Espa√±ol</a></li>
				<li class="interwiki-eo"><a href="http://eo.wikipedia.org/wiki/Varianco">Esperanto</a></li>
				<li class="interwiki-eu"><a href="http://eu.wikipedia.org/wiki/Bariantza">Euskara</a></li>
				<li class="interwiki-fa"><a href="http://fa.wikipedia.org/wiki/%D9%88%D8%A7%D8%B1%DB%8C%D8%A7%D9%86%D8%B3">ŸÅÿßÿ±ÿ≥€å</a></li>
				<li class="interwiki-fr"><a href="http://fr.wikipedia.org/wiki/Variance_(statistiques_et_probabilit%C3%A9s)">Fran√ßais</a></li>
				<li class="interwiki-gl"><a href="http://gl.wikipedia.org/wiki/Varianza">Galego</a></li>
				<li class="interwiki-ko"><a href="http://ko.wikipedia.org/wiki/%EB%B6%84%EC%82%B0">ÌïúÍµ≠Ïñ¥</a></li>
				<li class="interwiki-id"><a href="http://id.wikipedia.org/wiki/Varians">Bahasa Indonesia</a></li>
				<li class="interwiki-is"><a href="http://is.wikipedia.org/wiki/Dreifni">√çslenska</a></li>
				<li class="interwiki-it"><a href="http://it.wikipedia.org/wiki/Varianza">Italiano</a></li>
				<li class="interwiki-he"><a href="http://he.wikipedia.org/wiki/%D7%A9%D7%95%D7%A0%D7%95%D7%AA">◊¢◊ë◊®◊ô◊™</a></li>
				<li class="interwiki-lt"><a href="http://lt.wikipedia.org/wiki/Dispersija">Lietuvi≈≥</a></li>
				<li class="interwiki-nl"><a href="http://nl.wikipedia.org/wiki/Variantie">Nederlands</a></li>
				<li class="interwiki-ja"><a href="http://ja.wikipedia.org/wiki/%E5%88%86%E6%95%A3">Êó•Êú¨Ë™û</a></li>
				<li class="interwiki-mk"><a href="http://mk.wikipedia.org/wiki/%D0%92%D0%B0%D1%80%D0%B8%D1%98%D0%B0%D0%BD%D1%81%D0%B0">–ú–∞–∫–µ–¥–æ–Ω—Å–∫–∏</a></li>
				<li class="interwiki-no"><a href="http://no.wikipedia.org/wiki/Varians">‚Ä™Norsk (bokm√•l)‚Ä¨</a></li>
				<li class="interwiki-pl"><a href="http://pl.wikipedia.org/wiki/Wariancja">Polski</a></li>
				<li class="interwiki-pt"><a href="http://pt.wikipedia.org/wiki/Vari%C3%A2ncia">Portugu√™s</a></li>
				<li class="interwiki-ru"><a href="http://ru.wikipedia.org/wiki/%D0%94%D0%B8%D1%81%D0%BF%D0%B5%D1%80%D1%81%D0%B8%D1%8F_%D1%81%D0%BB%D1%83%D1%87%D0%B0%D0%B9%D0%BD%D0%BE%D0%B9_%D0%B2%D0%B5%D0%BB%D0%B8%D1%87%D0%B8%D0%BD%D1%8B">–†—É—Å—Å–∫–∏–π</a></li>
				<li class="interwiki-simple"><a href="http://simple.wikipedia.org/wiki/Variance">Simple English</a></li>
				<li class="interwiki-sk"><a href="http://sk.wikipedia.org/wiki/Rozptyl_(%C5%A1tatistika)">Slovenƒçina</a></li>
				<li class="interwiki-sl"><a href="http://sl.wikipedia.org/wiki/Varianca">Sloven≈°ƒçina</a></li>
				<li class="interwiki-su"><a href="http://su.wikipedia.org/wiki/Varian">Basa Sunda</a></li>
				<li class="interwiki-fi"><a href="http://fi.wikipedia.org/wiki/Varianssi">Suomi</a></li>
				<li class="interwiki-sv"><a href="http://sv.wikipedia.org/wiki/Varians">Svenska</a></li>
				<li class="interwiki-vi"><a href="http://vi.wikipedia.org/wiki/Ph%C6%B0%C6%A1ng_sai">Ti·∫øng Vi·ªát</a></li>
				<li class="interwiki-tr"><a href="http://tr.wikipedia.org/wiki/Varyans">T√ºrk√ße</a></li>
				<li class="interwiki-uk"><a href="http://uk.wikipedia.org/wiki/%D0%94%D0%B8%D1%81%D0%BF%D0%B5%D1%80%D1%81%D1%96%D1%8F_%D0%B2%D0%B8%D0%BF%D0%B0%D0%B4%D0%BA%D0%BE%D0%B2%D0%BE%D1%97_%D0%B2%D0%B5%D0%BB%D0%B8%D1%87%D0%B8%D0%BD%D0%B8">–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞</a></li>
				<li class="interwiki-ur"><a href="http://ur.wikipedia.org/wiki/%D8%AA%D9%81%D8%A7%D9%88%D8%AA">ÿßÿ±ÿØŸà</a></li>
				<li class="interwiki-zh"><a href="http://zh.wikipedia.org/wiki/%E6%96%B9%E5%B7%AE">‰∏≠Êñá</a></li>
			</ul>
		</div>
	</div>
		</div><!-- end of the left (by default at least) column -->
			<div class="visualClear"></div>
			<div id="footer">
				<div id="f-poweredbyico"><a href="http://www.mediawiki.org/"><img src="/skins-1.5/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" /></a></div>
				<div id="f-copyrightico"><a href="http://wikimediafoundation.org/"><img src="/images/wikimedia-button.png" border="0" alt="Wikimedia Foundation"/></a></div>
			<ul id="f-list">
					<li id="lastmod"> This page was last modified on 7 April 2009, at 17:18 (UTC).</li>
					<li id="copyright">All text is available under the terms of the <a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Text_of_the_GNU_Free_Documentation_License" title="Wikipedia:Text of the GNU Free Documentation License">GNU Free Documentation License</a>. (See <b><a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Copyrights" title="Wikipedia:Copyrights">Copyrights</a></b> for details.) <br /> Wikipedia&reg; is a registered trademark of the <a href="http://www.wikimediafoundation.org">Wikimedia Foundation, Inc.</a>, a U.S. registered <a class='internal' href="http://en.wikipedia.org/wiki/501%28c%29#501.28c.29.283.29" title="501(c)(3)">501(c)(3)</a> <a href="http://wikimediafoundation.org/wiki/Deductibility_of_donations">tax-deductible</a> <a class='internal' href="http://en.wikipedia.org/wiki/Non-profit_organization" title="Non-profit organization">nonprofit</a> <a href="http://en.wikipedia.org/wiki/Charitable_organization" title="Charitable organization">charity</a>.<br /></li>
					<li id="privacy"><a href="http://wikimediafoundation.org/wiki/Privacy_policy" title="wikimedia:Privacy policy">Privacy policy</a></li>
					<li id="about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
					<li id="disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
			</ul>
		</div>
</div>

		<script type="text/javascript">if (window.runOnloadHook) runOnloadHook();</script>
<!-- Served by srv144 in 0.054 secs. --></body></html>
