<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
		<meta http-equiv="Content-Style-Type" content="text/css" />
		<meta name="generator" content="MediaWiki 1.15alpha" />
		<meta name="keywords" content="Latent semantic analysis,Articles with disputed statements from December 2008,Articles with unsourced statements since April 2008,Semantics,1988,2005,Abstract interpretation,Abstract semantic graph,Action semantics,Algebraic semantics,Axiomatic semantics" />
		<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Latent_semantic_analysis&amp;action=edit" />
		<link rel="edit" title="Edit this page" href="/w/index.php?title=Latent_semantic_analysis&amp;action=edit" />
		<link rel="apple-touch-icon" href="http://en.wikipedia.org/apple-touch-icon.png" />
		<link rel="shortcut icon" href="/favicon.ico" />
		<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)" />
		<link rel="copyright" href="http://www.gnu.org/copyleft/fdl.html" />
		<link rel="alternate" type="application/rss+xml" title="Wikipedia RSS Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=rss" />
		<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=atom" />
		<title>Latent semantic analysis - Wikipedia, the free encyclopedia</title>
		<link rel="stylesheet" href="/skins-1.5/common/shared.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/common/commonPrint.css?207xx" type="text/css" media="print" />
		<link rel="stylesheet" href="/skins-1.5/monobook/main.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/chick/main.css?207xx" type="text/css" media="handheld" />
		<!--[if lt IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE50Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE55Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 6]><link rel="stylesheet" href="/skins-1.5/monobook/IE60Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 7]><link rel="stylesheet" href="/skins-1.5/monobook/IE70Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Common.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Print.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="print" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Handheld.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="handheld" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Monobook.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=-&amp;action=raw&amp;maxage=2678400&amp;gen=css" type="text/css" />
		<!--[if lt IE 7]><script type="text/javascript" src="/skins-1.5/common/IEFixes.js?207xx"></script>
		<meta http-equiv="imagetoolbar" content="no" /><![endif]-->

		<script type= "text/javascript">/*<![CDATA[*/
		var skin = "monobook";
		var stylepath = "/skins-1.5";
		var wgArticlePath = "/wiki/$1";
		var wgScriptPath = "/w";
		var wgScript = "/w/index.php";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = "http://en.wikipedia.org";
		var wgCanonicalNamespace = "";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = "Latent_semantic_analysis";
		var wgTitle = "Latent semantic analysis";
		var wgAction = "view";
		var wgArticleId = "689427";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = "en";
		var wgContentLanguage = "en";
		var wgBreakFrames = false;
		var wgCurRevisionId = 282432233;
		var wgVersion = "1.15alpha";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = ["", ""];
		var wgDigitTransformTable = ["", ""];
		var wgMWSuggestTemplate = "http://en.wikipedia.org/w/api.php?action=opensearch\x26search={searchTerms}\x26namespace={namespaces}\x26suggest";
		var wgDBname = "enwiki";
		var wgSearchNamespaces = [0];
		var wgMWSuggestMessages = ["with suggestions", "no suggestions"];
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		/*]]>*/</script>

		<script type="text/javascript" src="/skins-1.5/common/wikibits.js?207xx"><!-- wikibits js --></script>
		<!-- Head Scripts -->
		<script type="text/javascript" src="/skins-1.5/common/ajax.js?207xx"></script>
		<script type="text/javascript" src="/skins-1.5/common/mwsuggest.js?207xx"></script>
<script type="text/javascript">/*<![CDATA[*/
var wgNotice='';var wgNoticeLocal='';
/*]]>*/</script>		<script type="text/javascript" src="http://upload.wikimedia.org/centralnotice/wikipedia/en/centralnotice.js?207xx"></script>
		<script type="text/javascript" src="/w/index.php?title=-&amp;action=raw&amp;gen=js&amp;useskin=monobook"><!-- site js --></script>
	</head>
<body class="mediawiki ltr ns-0 ns-subject page-Latent_semantic_analysis skin-monobook">
	<div id="globalWrapper">
		<div id="column-content">
	<div id="content">
		<a name="top" id="top"></a>
		<div id="siteNotice"><script type='text/javascript'>if (wgNotice != '') document.writeln(wgNotice);</script></div>		<h1 id="firstHeading" class="firstHeading">Latent semantic analysis</h1>
		<div id="bodyContent">
			<h3 id="siteSub">From Wikipedia, the free encyclopedia</h3>
			<div id="contentSub"></div>
									<div id="jump-to-nav">Jump to: <a href="#column-one">navigation</a>, <a href="#searchInput">search</a></div>			<!-- start content -->
			<table cellpadding="1" style="float: right; border: 1px solid #8888aa; background: #f7f8ff; padding: 5px; font-size: 90%; margin: 0px 0px 15px 15px; clear:right;">
<tr>
<td style="background: #ccf; text-align: center;"><b><a href="/wiki/Semantics" title="Semantics">Semantics</a></b></td>
</tr>
<tr>
<td><a href="/wiki/Language" title="Language">Language</a> • <a href="/wiki/Linguistics" title="Linguistics">Linguistics</a></td>
</tr>
<tr>
<td style="border-bottom: 1px solid #ccc"></td>
</tr>
<tr>
<td style="padding-left: 1.0em;"><a href="/wiki/Formal_semantics" title="Formal semantics">Formal semantics</a></td>
</tr>
<tr>
<td style="padding-left: 1.0em;"><a href="/wiki/Lexis_(linguistics)" title="Lexis (linguistics)">Lexis</a></td>
</tr>
<tr>
<td style="padding-left: 2.0em;"><a href="/wiki/Lexical_semantics" title="Lexical semantics">Lexical semantics</a></td>
</tr>
<tr>
<td style="padding-left: 2.0em;"><a href="/wiki/Statistical_semantics" title="Statistical semantics">Statistical semantics</a></td>
</tr>
<tr>
<td style="padding-left: 2.0em;"><a href="/wiki/Structural_semantics" title="Structural semantics">Structural semantics</a></td>
</tr>
<tr>
<td style="padding-left: 2.0em;"><a href="/wiki/Prototype_Theory" title="Prototype Theory" class="mw-redirect">Prototype semantics</a></td>
</tr>
<tr>
<td><a href="/wiki/Lexicology" title="Lexicology">Lexicology</a></td>
</tr>
<tr>
<td><a href="/wiki/Semantic_analysis_(linguistics)" title="Semantic analysis (linguistics)">Semantic analysis</a></td>
</tr>
<tr>
<td style="border-bottom: 1px solid #ccc"></td>
</tr>
<tr>
<td><strong class="selflink">Latent semantic analysis</strong></td>
</tr>
<tr>
<td><a href="/wiki/Theory_of_descriptions" title="Theory of descriptions">Theory of descriptions</a></td>
</tr>
<tr>
<td><a href="/wiki/Force_Dynamics" title="Force Dynamics">Force Dynamics</a></td>
</tr>
<tr>
<td><a href="/wiki/Unsolved_problems_in_linguistics" title="Unsolved problems in linguistics">Unsolved problems</a></td>
</tr>
<tr>
<td style="border-bottom: 1px solid #ccc"></td>
</tr>
<tr>
<td><a href="/wiki/Semantic_matching" title="Semantic matching">Semantic matching</a></td>
</tr>
<tr>
<td><a href="/wiki/Semantic_analysis_(machine_learning)" title="Semantic analysis (machine learning)">Analysis (machine)</a></td>
</tr>
<tr>
<td><a href="/wiki/Abstract_semantic_graph" title="Abstract semantic graph">Abstract semantic graph</a></td>
</tr>
<tr>
<td><a href="/wiki/Semantic_Web" title="Semantic Web">Semantic Web</a></td>
</tr>
<tr>
<td><a href="/wiki/Semantic_wiki" title="Semantic wiki">Semantic wiki</a></td>
</tr>
<tr>
<td><a href="/wiki/Semantic_File_System" title="Semantic File System">Semantic File System</a></td>
</tr>
<tr>
<td><a href="/wiki/Abstract_interpretation" title="Abstract interpretation">Abstract interpretation</a></td>
</tr>
<tr>
<td><a href="/wiki/Formal_semantics_of_programming_languages" title="Formal semantics of programming languages">Formal semantics of<br />
&#160;programming languages</a></td>
</tr>
<tr>
<td>&#160; <a href="/wiki/Denotational_semantics" title="Denotational semantics">Denotational semantics</a></td>
</tr>
<tr>
<td>&#160; <a href="/wiki/Axiomatic_semantics" title="Axiomatic semantics">Axiomatic semantics</a></td>
</tr>
<tr>
<td>&#160; <a href="/wiki/Operational_semantics" title="Operational semantics">Operational semantics</a></td>
</tr>
<tr>
<td>&#160; <a href="/wiki/Action_semantics" title="Action semantics">Action semantics</a></td>
</tr>
<tr>
<td>&#160; <a href="/wiki/Algebraic_semantics" title="Algebraic semantics">Algebraic semantics</a></td>
</tr>
<tr>
<td>&#160; <a href="/wiki/Categorical_semantics" title="Categorical semantics" class="mw-redirect">Categorical semantics</a></td>
</tr>
<tr>
<td>&#160; <a href="/wiki/Concurrency_semantics" title="Concurrency semantics">Concurrency semantics</a></td>
</tr>
<tr>
<td>&#160; <a href="/wiki/Game_semantics" title="Game semantics">Game semantics</a></td>
</tr>
<tr>
<td>&#160; <a href="/wiki/Predicate_transformer_semantics" title="Predicate transformer semantics">Predicate transformer..</a></td>
</tr>
<tr>
<td>
<div class="noprint plainlinksneverexpand navbar" style="background:none; padding:0; font-weight:normal;; font-size:xx-small; text-align:center;">This box: <a href="/wiki/Template:Semantics" title="Template:Semantics"><span title="View this template" style="">view</span></a>&#160;<span style="font-size:80%;">•</span>&#160;<a href="/w/index.php?title=Template_talk:Semantics&amp;action=edit&amp;redlink=1" class="new" title="Template talk:Semantics (page does not exist)"><span title="Discussion about this template" style="">talk</span></a>&#160;<span style="font-size:80%;">•</span>&#160;<a href="http://en.wikipedia.org/w/index.php?title=Template:Semantics&amp;action=edit" class="external text" title="http://en.wikipedia.org/w/index.php?title=Template:Semantics&amp;action=edit" rel="nofollow"><span title="Edit this template" style=";">edit</span></a></div>
</td>
</tr>
</table>
<p><b>Latent semantic analysis (LSA)</b> is a technique in <a href="/wiki/Natural_language_processing" title="Natural language processing">natural language processing</a>, in particular in <a href="/wiki/Vectorial_semantics" title="Vectorial semantics" class="mw-redirect">vectorial semantics</a>, of analyzing relationships between a set of documents and the terms they contain by producing a set of concepts related to the documents and terms.</p>
<p>LSA was patented in <a href="/wiki/1988" title="1988">1988</a> (<a href="http://patft.uspto.gov/netacgi/nph-Parser?patentnumber=4839853" class="external text" title="http://patft.uspto.gov/netacgi/nph-Parser?patentnumber=4839853" rel="nofollow">US Patent 4,839,853</a>) by <a href="/wiki/Scott_Deerwester" title="Scott Deerwester">Scott Deerwester</a>, <a href="/wiki/Susan_Dumais" title="Susan Dumais">Susan Dumais</a>, <a href="/wiki/George_Furnas" title="George Furnas">George Furnas</a>, <a href="/wiki/Richard_Harshman" title="Richard Harshman">Richard Harshman</a>, <a href="/wiki/Thomas_Landauer" title="Thomas Landauer">Thomas Landauer</a>, <a href="/w/index.php?title=Karen_Lochbaum&amp;action=edit&amp;redlink=1" class="new" title="Karen Lochbaum (page does not exist)">Karen Lochbaum</a> and <a href="/w/index.php?title=Lynn_Streeter&amp;action=edit&amp;redlink=1" class="new" title="Lynn Streeter (page does not exist)">Lynn Streeter</a>. In the context of its application to <a href="/wiki/Information_retrieval" title="Information retrieval">information retrieval</a>, it is sometimes called <b>latent semantic indexing (LSI)</b>.</p>
<table id="toc" class="toc" summary="Contents">
<tr>
<td>
<div id="toctitle">
<h2>Contents</h2>
</div>
<ul>
<li class="toclevel-1"><a href="#Occurrence_matrix"><span class="tocnumber">1</span> <span class="toctext">Occurrence matrix</span></a></li>
<li class="toclevel-1"><a href="#Applications"><span class="tocnumber">2</span> <span class="toctext">Applications</span></a></li>
<li class="toclevel-1"><a href="#Rank_lowering"><span class="tocnumber">3</span> <span class="toctext">Rank lowering</span></a></li>
<li class="toclevel-1"><a href="#Derivation"><span class="tocnumber">4</span> <span class="toctext">Derivation</span></a></li>
<li class="toclevel-1"><a href="#Implementation"><span class="tocnumber">5</span> <span class="toctext">Implementation</span></a></li>
<li class="toclevel-1"><a href="#Limitations"><span class="tocnumber">6</span> <span class="toctext">Limitations</span></a></li>
<li class="toclevel-1"><a href="#Commercial_Applications"><span class="tocnumber">7</span> <span class="toctext">Commercial Applications</span></a></li>
<li class="toclevel-1"><a href="#See_also"><span class="tocnumber">8</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1"><a href="#External_links"><span class="tocnumber">9</span> <span class="toctext">External links</span></a></li>
<li class="toclevel-1"><a href="#References"><span class="tocnumber">10</span> <span class="toctext">References</span></a></li>
</ul>
</td>
</tr>
</table>
<script type="text/javascript">
//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>
</script>
<p><a name="Occurrence_matrix" id="Occurrence_matrix"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Latent_semantic_analysis&amp;action=edit&amp;section=1" title="Edit section: Occurrence matrix">edit</a>]</span> <span class="mw-headline">Occurrence matrix</span></h2>
<p>LSA can use a <a href="/wiki/Term-document_matrix" title="Term-document matrix" class="mw-redirect">term-document matrix</a> which describes the occurrences of terms in documents; it is a <a href="/wiki/Sparse_matrix" title="Sparse matrix">sparse matrix</a> whose rows correspond to <a href="/wiki/Terminology" title="Terminology">terms</a> and whose columns correspond to documents. The terms are typically not <a href="/wiki/Stemming" title="Stemming">stemmed</a> because LSA can intrinsically identify the relationship between words and their stem forms. A typical example of the weighting of the elements of the matrix is <a href="/wiki/Tf-idf" title="Tf-idf" class="mw-redirect">tf-idf</a> (term frequency–inverse document frequency): the element of the matrix is proportional to the number of times the terms appear in each document, where rare terms are upweighted to reflect their relative importance.</p>
<p>This matrix is also common to standard semantic models, though it is not necessarily explicitly expressed as a matrix, since the mathematical properties of matrices are not always used.</p>
<p>LSA transforms the occurrence matrix into a relation between the terms and some <i>concepts</i>, and a relation between those concepts and the documents.<sup class="noprint Inline-Template"><span title="The material in the vicinity of this tag may not be factual or accurate&#160;from December 2008" style="white-space: nowrap;">[<i><a href="/wiki/Wikipedia:Disputed_statement" title="Wikipedia:Disputed statement">dubious</a> <span class="metadata">– <a href="/wiki/Talk:Latent_semantic_analysis#better_explanation_required" title="Talk:Latent semantic analysis">discuss</a></span></i>]</span></sup>Thus the terms and documents are now indirectly related through the concepts.</p>
<p><a name="Applications" id="Applications"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Latent_semantic_analysis&amp;action=edit&amp;section=2" title="Edit section: Applications">edit</a>]</span> <span class="mw-headline">Applications</span></h2>
<p>The new concept space typically can be used to:</p>
<ul>
<li>Compare the documents in the concept space (<a href="/wiki/Data_clustering" title="Data clustering" class="mw-redirect">data clustering</a>, <a href="/wiki/Document_classification" title="Document classification">document classification</a>).</li>
<li>Find similar documents across languages, after analyzing a base set of translated documents (<a href="/w/index.php?title=Cross_language_retrieval&amp;action=edit&amp;redlink=1" class="new" title="Cross language retrieval (page does not exist)">cross language retrieval</a>).</li>
<li>Find relations between terms (<a href="/wiki/Synonymy" title="Synonymy" class="mw-redirect">synonymy</a> and <a href="/wiki/Polysemy" title="Polysemy">polysemy</a>).</li>
<li>Given a query of terms, translate it into the concept space, and find matching documents (<a href="/wiki/Information_retrieval" title="Information retrieval">information retrieval</a>).</li>
</ul>
<p>Synonymy and polysemy are fundamental problems in <a href="/wiki/Natural_language_processing" title="Natural language processing">natural language processing</a>:</p>
<ul>
<li>Synonymy is the phenomenon where different words describe the same idea. Thus, a query in a search engine may fail to retrieve a relevant document that does not contain the words which appeared in the query. For example, a search for "doctors" may not return a document containing the word "physicians", even though the words have the same meaning.</li>
<li>Polysemy is the phenomenon where the same word has multiple meanings. So a search may retrieve irrelevant documents containing the desired words in the wrong meaning. For example, a botanist and a computer scientist looking for the word "tree" probably desire different sets of documents.</li>
</ul>
<p><a name="Rank_lowering" id="Rank_lowering"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Latent_semantic_analysis&amp;action=edit&amp;section=3" title="Edit section: Rank lowering">edit</a>]</span> <span class="mw-headline">Rank lowering</span></h2>
<p>After the construction of the occurrence matrix, LSA finds a low-<a href="/wiki/Rank_(matrix_theory)" title="Rank (matrix theory)" class="mw-redirect">rank</a> approximation to the <a href="/wiki/Term-document_matrix" title="Term-document matrix" class="mw-redirect">term-document matrix</a>. There could be various reasons for these approximations:</p>
<ul>
<li>The original term-document matrix is presumed too large for the computing resources; in this case, the approximated low rank matrix is interpreted as an <i>approximation</i> (a "least and necessary evil").</li>
<li>The original term-document matrix is presumed <i>noisy</i>: for example, anecdotal instances of terms are to be eliminated. From this point of view, the approximated matrix is interpreted as a <i>de-noisified matrix</i> (a better matrix than the original).</li>
<li>The original term-document matrix is presumed overly <a href="/wiki/Sparse_matrix" title="Sparse matrix">sparse</a> relative to the "true" term-document matrix. That is, the original matrix lists only the words actually <i>in</i> each document, whereas we might be interested in all words <i>related to</i> each document--generally a much larger set due to <a href="/wiki/Synonymy" title="Synonymy" class="mw-redirect">synonymy</a>.</li>
</ul>
<p>The consequence of the rank lowering is that some dimensions are combined and depend on more than one term:</p>
<dl>
<dd>
<dl>
<dd>{(car), (truck), (flower)} --&gt; {(1.3452 * car + 0.2828 * truck), (flower)}</dd>
</dl>
</dd>
</dl>
<p>This mitigates the problem of identifying synonymy, as the rank lowering is expected to merge the dimensions associated with terms that have similar meanings. It also mitigates the problem with polysemy, since components of polysemous words that point in the "right" direction are added to the components of words that share a similar meaning. Conversely, components that point in other directions tend to either simply cancel out, or, at worst, to be smaller than components in the directions corresponding to the intended sense.</p>
<p><a name="Derivation" id="Derivation"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Latent_semantic_analysis&amp;action=edit&amp;section=4" title="Edit section: Derivation">edit</a>]</span> <span class="mw-headline">Derivation</span></h2>
<p>Let <span class="texhtml"><i>X</i></span> be a matrix where element <span class="texhtml">(<i>i</i>,<i>j</i>)</span> describes the occurrence of term <span class="texhtml"><i>i</i></span> in document <span class="texhtml"><i>j</i></span> (this can be, for example, the frequency). <span class="texhtml"><i>X</i></span> will look like this:</p>
<dl>
<dd><img class="tex" alt="
\begin{matrix} 
 &amp; \textbf{d}_j \\
 &amp; \downarrow \\
\textbf{t}_i^T \rightarrow &amp;
\begin{bmatrix} 
x_{1,1} &amp; \dots &amp; x_{1,n} \\
\vdots &amp; \ddots &amp; \vdots \\
x_{m,1} &amp; \dots &amp; x_{m,n} \\
\end{bmatrix}
\end{matrix}
" src="http://upload.wikimedia.org/math/f/c/a/fcaae85b8640dadbcb8355e9d45221e9.png" /></dd>
</dl>
<p>Now a row in this matrix will be a vector corresponding to a term, giving its relation to each document:</p>
<dl>
<dd><img class="tex" alt="\textbf{t}_i^T = \begin{bmatrix} x_{i,1} &amp; \dots &amp; x_{i,n} \end{bmatrix}" src="http://upload.wikimedia.org/math/b/5/f/b5f302f00ad00bdb2f15cf6f823d5d01.png" /></dd>
</dl>
<p>Likewise, a column in this matrix will be a vector corresponding to a document, giving its relation to each term:</p>
<dl>
<dd><img class="tex" alt="\textbf{d}_j = \begin{bmatrix} x_{1,j} \\ \vdots \\ x_{m,j} \end{bmatrix}" src="http://upload.wikimedia.org/math/3/b/b/3bbf23e335aebf14efbae3bef7ae1cae.png" /></dd>
</dl>
<p>Now the <a href="/wiki/Dot_product" title="Dot product">dot product</a> <img class="tex" alt="\textbf{t}_i^T \textbf{t}_p" src="http://upload.wikimedia.org/math/c/f/0/cf0066bb27a4e826ddd825d55aaeef02.png" /> between two term vectors gives the <a href="/wiki/Correlation" title="Correlation">correlation</a> between the terms over the documents. The <a href="/wiki/Matrix_product" title="Matrix product" class="mw-redirect">matrix product</a> <span class="texhtml"><i>X</i><i>X</i><sup><i>T</i></sup></span> contains all these dot products. Element <span class="texhtml">(<i>i</i>,<i>p</i>)</span> (which is equal to element <span class="texhtml">(<i>p</i>,<i>i</i>)</span>) contains the dot product <img class="tex" alt="\textbf{t}_i^T \textbf{t}_p" src="http://upload.wikimedia.org/math/c/f/0/cf0066bb27a4e826ddd825d55aaeef02.png" /> (<img class="tex" alt=" = \textbf{t}_p^T \textbf{t}_i" src="http://upload.wikimedia.org/math/6/5/1/6516f880ab8f1bc61bf81d5aa84a3809.png" />). Likewise, the matrix <span class="texhtml"><i>X</i><sup><i>T</i></sup><i>X</i></span> contains the dot products between all the document vectors, giving their correlation over the terms: <img class="tex" alt="\textbf{d}_j^T \textbf{d}_q = \textbf{d}_q^T \textbf{d}_j" src="http://upload.wikimedia.org/math/9/6/e/96e47cd32ac14159eb76ee663a385f22.png" />.</p>
<p>Now assume that there exists a decomposition of <span class="texhtml"><i>X</i></span> such that <span class="texhtml"><i>U</i></span> and <span class="texhtml"><i>V</i></span> are <a href="/wiki/Orthonormal_matrix" title="Orthonormal matrix" class="mw-redirect">orthonormal matrices</a> and <span class="texhtml">Σ</span> is a <a href="/wiki/Diagonal_matrix" title="Diagonal matrix">diagonal matrix</a>. This is called a <a href="/wiki/Singular_value_decomposition" title="Singular value decomposition">singular value decomposition</a> (SVD):</p>
<dl>
<dd><span class="texhtml"><i>X</i> = <i>U</i>Σ<i>V</i><sup><i>T</i></sup></span></dd>
</dl>
<p>The matrix products giving us the term and document correlations then become</p>
<dl>
<dd><img class="tex" alt="
\begin{matrix}
X X^T &amp;=&amp; (U \Sigma V^T) (U \Sigma V^T)^T = (U \Sigma V^T) (V^{T^T} \Sigma^T U^T) = U \Sigma V^T V \Sigma^T U^T = U \Sigma \Sigma^T U^T \\
X^T X &amp;=&amp; (U \Sigma V^T)^T (U \Sigma V^T) = (V^{T^T} \Sigma^T U^T) (U \Sigma V^T) = V \Sigma U^T U \Sigma V^T = V \Sigma^T \Sigma V^T
\end{matrix}
" src="http://upload.wikimedia.org/math/b/4/b/b4bad025bf0e321cc366a0e4ce117739.png" /></dd>
</dl>
<p>Since <span class="texhtml">ΣΣ<sup><i>T</i></sup></span> and <span class="texhtml">Σ<sup><i>T</i></sup>Σ</span> are diagonal we see that <span class="texhtml"><i>U</i></span> must contain the <a href="/wiki/Eigenvector" title="Eigenvector" class="mw-redirect">eigenvectors</a> of <span class="texhtml"><i>X</i><i>X</i><sup><i>T</i></sup></span>, while <span class="texhtml"><i>V</i></span> must be the eigenvectors of <span class="texhtml"><i>X</i><sup><i>T</i></sup><i>X</i></span>. Both products have the same non-zero eigenvalues, given by the non-zero entries of <span class="texhtml">ΣΣ<sup><i>T</i></sup></span>, or equally, by the non-zero entries of <span class="texhtml">Σ<sup><i>T</i></sup>Σ</span>. Now the decomposition looks like this:</p>
<dl>
<dd><img class="tex" alt="
\begin{matrix} 
 &amp; X &amp; &amp; &amp; U &amp; &amp; \Sigma &amp; &amp; V^T \\
 &amp; (\textbf{d}_j) &amp; &amp; &amp; &amp; &amp; &amp; &amp; (\hat \textbf{d}_j) \\
 &amp; \downarrow &amp; &amp; &amp; &amp; &amp; &amp; &amp; \downarrow \\
(\textbf{t}_i^T) \rightarrow 
&amp;
\begin{bmatrix} 
x_{1,1} &amp; \dots &amp; x_{1,n} \\
\\
\vdots &amp; \ddots &amp; \vdots \\
\\
x_{m,1} &amp; \dots &amp; x_{m,n} \\
\end{bmatrix}
&amp;
=
&amp;
(\hat \textbf{t}_i^T) \rightarrow
&amp;
\begin{bmatrix} 
\begin{bmatrix} \, \\ \, \\ \textbf{u}_1 \\ \, \\ \,\end{bmatrix} 
\dots
\begin{bmatrix} \, \\ \, \\ \textbf{u}_l \\ \, \\ \, \end{bmatrix}
\end{bmatrix}
&amp;
\cdot
&amp;
\begin{bmatrix} 
\sigma_1 &amp; \dots &amp; 0 \\
\vdots &amp; \ddots &amp; \vdots \\
0 &amp; \dots &amp; \sigma_l \\
\end{bmatrix}
&amp;
\cdot
&amp;
\begin{bmatrix} 
\begin{bmatrix} &amp; &amp; \textbf{v}_1 &amp; &amp; \end{bmatrix} \\
\vdots \\
\begin{bmatrix} &amp; &amp; \textbf{v}_l &amp; &amp; \end{bmatrix}
\end{bmatrix}
\end{matrix}
" src="http://upload.wikimedia.org/math/3/5/d/35d7c396038e96b3fadc325f8fe43f86.png" /></dd>
</dl>
<p>The values <img class="tex" alt="\sigma_1, \dots, \sigma_l" src="http://upload.wikimedia.org/math/5/d/d/5ddddd012aa2958cd6b3d740ded1f745.png" /> are called the singular values, and <img class="tex" alt="u_1, \dots, u_l" src="http://upload.wikimedia.org/math/4/9/4/494e1410634c33c9eca795ff81ecc5df.png" /> and <img class="tex" alt="v_1, \dots, v_l" src="http://upload.wikimedia.org/math/7/b/2/7b2992af726baddf5d5b4a9ccbcb8e20.png" /> the left and right singular vectors. Notice how the only part of <span class="texhtml"><i>U</i></span> that contributes to <img class="tex" alt="\textbf{t}_i" src="http://upload.wikimedia.org/math/b/8/2/b82b6244e2903f28317115bf713b2b9e.png" /> is the <span class="texhtml"><i>i</i>'th</span> row. Let this row vector be called <img class="tex" alt="\hat \textrm{t}_i" src="http://upload.wikimedia.org/math/e/e/1/ee12701b0688c5b66cf859493a0bfba9.png" />. Likewise, the only part of <span class="texhtml"><i>V</i><sup><i>T</i></sup></span> that contributes to <img class="tex" alt="\textbf{d}_j" src="http://upload.wikimedia.org/math/f/6/c/f6c8c71b8375333a65c5aeabb05225c3.png" /> is the <span class="texhtml"><i>j</i>'th</span> column, <img class="tex" alt="\hat \textrm{d}_j" src="http://upload.wikimedia.org/math/5/4/6/5464229e5909d4e84ec38caf8bf670df.png" />. These are <i>not</i> the eigenvectors, but <i>depend</i> on <i>all</i> the eigenvectors.</p>
<p>It turns out that when you select the <span class="texhtml"><i>k</i></span> largest singular values, and their corresponding singular vectors from <span class="texhtml"><i>U</i></span> and <span class="texhtml"><i>V</i></span>, you get the rank <span class="texhtml"><i>k</i></span> approximation to X with the smallest error (<a href="/wiki/Frobenius_norm" title="Frobenius norm" class="mw-redirect">Frobenius norm</a>). The amazing thing about this approximation is that not only does it have a minimal error, but it translates the term and document vectors into a concept space. The vector <img class="tex" alt="\hat \textbf{t}_i" src="http://upload.wikimedia.org/math/8/7/2/872d5d1f5be6fbfdab6cfafcf6ebba48.png" /> then has <span class="texhtml"><i>k</i></span> entries, each giving the occurrence of term <span class="texhtml"><i>i</i></span> in one of the <span class="texhtml"><i>k</i></span> concepts. Likewise, the vector <img class="tex" alt="\hat \textbf{d}_j" src="http://upload.wikimedia.org/math/e/6/f/e6ff78113a6a49650b0980306a7d1ef8.png" /> gives the relation between document <span class="texhtml"><i>j</i></span> and each concept. We write this approximation as</p>
<dl>
<dd><img class="tex" alt="X_k = U_k \Sigma_k V_k^T" src="http://upload.wikimedia.org/math/f/4/0/f40a9d1951a5b232095e07e720c40b60.png" /></dd>
</dl>
<p>You can now do the following:</p>
<ul>
<li>See how related documents <span class="texhtml"><i>j</i></span> and <span class="texhtml"><i>q</i></span> are in the concept space by comparing the vectors <img class="tex" alt="\hat \textbf{d}_j" src="http://upload.wikimedia.org/math/e/6/f/e6ff78113a6a49650b0980306a7d1ef8.png" /> and <img class="tex" alt="\hat \textbf{d}_q" src="http://upload.wikimedia.org/math/f/5/d/f5d56b66997a9b16d02558b013bc5ccb.png" /> (typically by <a href="/wiki/Vector_space_model" title="Vector space model">cosine similarity</a>). This gives you a clustering of the documents.</li>
<li>Comparing terms <span class="texhtml"><i>i</i></span> and <span class="texhtml"><i>p</i></span> by comparing the vectors <img class="tex" alt="\hat \textbf{t}_i" src="http://upload.wikimedia.org/math/8/7/2/872d5d1f5be6fbfdab6cfafcf6ebba48.png" /> and <img class="tex" alt="\hat \textbf{t}_p" src="http://upload.wikimedia.org/math/a/1/4/a149b9013eb50936867cd2565884b73b.png" />, giving you a clustering of the terms in the concept space.</li>
<li>Given a query, view this as a mini document, and compare it to your documents in the concept space.</li>
</ul>
<p>To do the latter, you must first translate your query into the concept space. It is then intuitive that you must use the same transformation that you use on your documents:</p>
<dl>
<dd><img class="tex" alt="\textbf{d}_j = U_k \Sigma_k \hat \textbf{d}_j" src="http://upload.wikimedia.org/math/2/e/5/2e528567ac2c5aa98db5be0cd014b05d.png" /></dd>
</dl>
<dl>
<dd><img class="tex" alt="\hat \textbf{d}_j = \Sigma_k^{-1} U_k^T \textbf{d}_j" src="http://upload.wikimedia.org/math/6/3/c/63c0ab445518a57b4e55b65028fb2d71.png" /></dd>
</dl>
<p>This means that if you have a query vector <span class="texhtml"><i>q</i></span>, you must do the translation <img class="tex" alt="\hat \textbf{q} = \Sigma_k^{-1} U_k^T \textbf{q}" src="http://upload.wikimedia.org/math/8/a/5/8a5a90cb4d9c997c5d00abcb34aa9060.png" /> before you compare it with the document vectors in the concept space. You can do the same for pseudo term vectors:</p>
<dl>
<dd><img class="tex" alt="\textbf{t}_i^T = \hat \textbf{t}_i^T \Sigma_k V_k^T" src="http://upload.wikimedia.org/math/2/2/0/220f384b452c05de16d8f53595cf0628.png" /></dd>
</dl>
<dl>
<dd><img class="tex" alt="\hat \textbf{t}_i^T = \textbf{t}_i^T V_k^{-T} \Sigma_k^{-1} = \textbf{t}_i^T V_k \Sigma_k^{-1}" src="http://upload.wikimedia.org/math/a/3/3/a335e202d92476ee2947175c8677d420.png" /></dd>
</dl>
<dl>
<dd><img class="tex" alt="\hat \textbf{t}_i = \Sigma_k^{-1}  V_k^T \textbf{t}_i" src="http://upload.wikimedia.org/math/3/1/f/31f2b2d969b10a2b021f8dd7cd6d390e.png" /></dd>
</dl>
<p><a name="Implementation" id="Implementation"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Latent_semantic_analysis&amp;action=edit&amp;section=5" title="Edit section: Implementation">edit</a>]</span> <span class="mw-headline">Implementation</span></h2>
<p>The <a href="/wiki/Singular_Value_Decomposition" title="Singular Value Decomposition" class="mw-redirect">SVD</a> is typically computed using large matrix methods (for example, <a href="/wiki/Lanczos_method" title="Lanczos method" class="mw-redirect">Lanczos methods</a>) but may also be computed incrementally and with greatly reduced resources via a <a href="/wiki/Neural_network" title="Neural network">neural network</a>-like approach, which does not require the large, full-rank matrix to be held in memory (<a href="http://www.dcs.shef.ac.uk/~genevieve/gorrell_webb.pdf" class="external text" title="http://www.dcs.shef.ac.uk/~genevieve/gorrell_webb.pdf" rel="nofollow">Gorrell and Webb, 2005</a>).</p>
<p>A fast, incremental, low-memory, large-matrix SVD algorithm has recently been developed (<a href="http://www.merl.com/publications/TR2006-059/" class="external text" title="http://www.merl.com/publications/TR2006-059/" rel="nofollow">Brand, 2006</a>). Unlike Gorrell and Webb's (2005) stochastic approximation, Brand's (2006) algorithm provides an exact solution.</p>
<p><a name="Limitations" id="Limitations"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Latent_semantic_analysis&amp;action=edit&amp;section=6" title="Edit section: Limitations">edit</a>]</span> <span class="mw-headline">Limitations</span></h2>
<p>LSA has two drawbacks:</p>
<ul>
<li>The resulting dimensions might be difficult to interpret. For instance, in</li>
</ul>
<dl>
<dd>
<dl>
<dd>{(car), (truck), (flower)} --&gt; {(1.3452 * car + 0.2828 * truck), (flower)}</dd>
</dl>
</dd>
<dd>the (1.3452 * car + 0.2828 * truck) component could be interpreted as "vehicle". However, it is very likely that cases close to
<dl>
<dd>{(car), (bottle), (flower)} --&gt; {(1.3452 * car + 0.2828 * bottle), (flower)}</dd>
</dl>
</dd>
<dd>will occur. This leads to results which can be justified on the mathematical level, but have no interpretable meaning in natural language.</dd>
</dl>
<ul>
<li>The <a href="/wiki/Probabilistic_model" title="Probabilistic model" class="mw-redirect">probabilistic model</a> of LSA does not match observed data: LSA assumes that words and documents form a joint <a href="/wiki/Normal_distribution" title="Normal distribution">Gaussian</a> model (<a href="/wiki/Ergodic_hypothesis" title="Ergodic hypothesis">ergodic hypothesis</a>), while a <a href="/wiki/Poisson_distribution" title="Poisson distribution">Poisson distribution</a> has been observed. Thus, a newer alternative is <a href="/wiki/Probabilistic_latent_semantic_analysis" title="Probabilistic latent semantic analysis">probabilistic latent semantic analysis</a>, based on a <a href="/wiki/Multinomial_distribution" title="Multinomial distribution">multinomial</a> model, which is reported to give better results than standard LSA<sup class="noprint Template-Fact"><span title="This claim needs references to reliable sources&#160;since April 2008" style="white-space: nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed">citation needed</a></i>]</span></sup>.</li>
</ul>
<p><a name="Commercial_Applications" id="Commercial_Applications"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Latent_semantic_analysis&amp;action=edit&amp;section=7" title="Edit section: Commercial Applications">edit</a>]</span> <span class="mw-headline">Commercial Applications</span></h2>
<p>LSA has been used to assist in performing <a href="/wiki/Prior_art" title="Prior art">prior art</a> searches for <a href="/wiki/Patents" title="Patents" class="mw-redirect">patents</a>.<sup id="cite_ref-0" class="reference"><a href="#cite_note-0" title=""><span>[</span>1<span>]</span></a></sup></p>
<p><a name="See_also" id="See_also"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Latent_semantic_analysis&amp;action=edit&amp;section=8" title="Edit section: See also">edit</a>]</span> <span class="mw-headline">See also</span></h2>
<ul>
<li>An example of the application of <a href="http://blog.targetwoman.com/latent-semantic-analysis/" class="external autonumber" title="http://blog.targetwoman.com/latent-semantic-analysis/" rel="nofollow">[1]</a> Latent Semantic Analysis in Natural language Processing</li>
<li><a href="/wiki/Compound_term_processing" title="Compound term processing">Compound term processing</a></li>
<li><a href="/wiki/Latent_Dirichlet_allocation" title="Latent Dirichlet allocation">Latent Dirichlet allocation</a></li>
<li><a href="/wiki/Latent_semantic_mapping" title="Latent semantic mapping">Latent semantic mapping</a></li>
<li><a href="/wiki/Latent_Semantic_Structure_Indexing" title="Latent Semantic Structure Indexing">Latent Semantic Structure Indexing</a></li>
<li><a href="/wiki/Principal_components_analysis" title="Principal components analysis" class="mw-redirect">Principal components analysis</a></li>
<li><a href="/wiki/Probabilistic_latent_semantic_analysis" title="Probabilistic latent semantic analysis">Probabilistic latent semantic analysis</a></li>
<li><a href="/wiki/Spamdexing" title="Spamdexing">Spamdexing</a></li>
<li><a href="/wiki/Vectorial_semantics" title="Vectorial semantics" class="mw-redirect">Vectorial semantics</a></li>
</ul>
<p><a name="External_links" id="External_links"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Latent_semantic_analysis&amp;action=edit&amp;section=9" title="Edit section: External links">edit</a>]</span> <span class="mw-headline">External links</span></h2>
<ul>
<li><a href="http://www.scholarpedia.org/article/Latent_semantic_analysis" class="external text" title="http://www.scholarpedia.org/article/Latent_semantic_analysis" rel="nofollow">Latent Semantic Analysis</a>, a scholarpedia article on LSA written by Tom Landauer, one of the creators of LSA.</li>
<li><a href="http://www.seobook.com/lsi/lsa_definition.htm" class="external text" title="http://www.seobook.com/lsi/lsa_definition.htm" rel="nofollow">Latent Semantic Indexing</a>, a non mathematical introduction and explanation of LSI</li>
<li><a href="http://www.thebirdstheword.com/" class="external text" title="http://www.thebirdstheword.com/" rel="nofollow">TheBirdsTheWord - Beta LSI Tool</a>, A tool that emulates Google's semantic dictionary used to aide its ranking algorithm</li>
<li><a href="http://knowledgesearch.org/" class="external text" title="http://knowledgesearch.org/" rel="nofollow">The Semantic Indexing Project</a>, an open source program for latent semantic indexing</li>
<li><a href="http://senseclusters.sourceforge.net" class="external text" title="http://senseclusters.sourceforge.net" rel="nofollow">SenseClusters</a>, an open source package for Latent Semantic Analysis and other methods for clustering similar contexts</li>
</ul>
<p><a name="References" id="References"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Latent_semantic_analysis&amp;action=edit&amp;section=10" title="Edit section: References">edit</a>]</span> <span class="mw-headline">References</span></h2>
<div class="references-small">
<ol class="references">
<li id="cite_note-0"><b><a href="#cite_ref-0" title="">^</a></b> <a href="http://www.liebertonline.com/doi/abs/10.1089/blr.2007.9896" class="external text" title="http://www.liebertonline.com/doi/abs/10.1089/blr.2007.9896" rel="nofollow">Gerry Elman, "Automated Patent Examination Support - A proposal", Biotechnology Law Report, October 2007</a></li>
</ol>
</div>
<ul>
<li><cite style="font-style:normal" class="web"><a href="http://lsa.colorado.edu/" class="external text" title="http://lsa.colorado.edu/" rel="nofollow">"The Latent Semantic Indexing home page"</a><span class="printonly">. <a href="http://lsa.colorado.edu/" class="external free" title="http://lsa.colorado.edu/" rel="nofollow">http://lsa.colorado.edu/</a></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=The+Latent+Semantic+Indexing+home+page&amp;rft.atitle=&amp;rft_id=http%3A%2F%2Flsa.colorado.edu%2F&amp;rfr_id=info:sid/en.wikipedia.org:Latent_semantic_analysis"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal" class="" id="CITEREFMatthew_Brand2006">Matthew Brand (2006). "<a href="http://www.merl.com/publications/TR2006-059/" class="external text" title="http://www.merl.com/publications/TR2006-059/" rel="nofollow">Fast Low-Rank Modifications of the Thin Singular Value Decomposition</a>". <i>Linear Algebra and Its Applications</i> <b>415</b>: 20–30. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<span class="neverexpand"><a href="http://dx.doi.org/10.1016%2Fj.laa.2005.07.021" class="external text" title="http://dx.doi.org/10.1016%2Fj.laa.2005.07.021" rel="nofollow">10.1016/j.laa.2005.07.021</a></span><span class="printonly">. <a href="http://www.merl.com/publications/TR2006-059/" class="external free" title="http://www.merl.com/publications/TR2006-059/" rel="nofollow">http://www.merl.com/publications/TR2006-059/</a></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Fast+Low-Rank+Modifications+of+the+Thin+Singular+Value+Decomposition&amp;rft.jtitle=Linear+Algebra+and+Its+Applications&amp;rft.aulast=Matthew+Brand&amp;rft.au=Matthew+Brand&amp;rft.date=2006&amp;rft.volume=415&amp;rft.pages=20%E2%80%9330&amp;rft_id=info:doi/10.1016%2Fj.laa.2005.07.021&amp;rft_id=http%3A%2F%2Fwww.merl.com%2Fpublications%2FTR2006-059%2F&amp;rfr_id=info:sid/en.wikipedia.org:Latent_semantic_analysis"><span style="display: none;">&#160;</span></span> -- a <a href="http://www.eecs.umich.edu/~wingated/resources.html" class="external text" title="http://www.eecs.umich.edu/~wingated/resources.html" rel="nofollow">MATLAB implementation of Brand's algorithm</a> is available</li>
<li><cite style="font-style:normal" class="" id="CITEREF.5B.5BThomas_Landauer.5D.5D.2C_P._W._Foltz.2C_.26_D._Laham1998"><a href="/wiki/Thomas_Landauer" title="Thomas Landauer">Thomas Landauer</a>, P. W. Foltz, &amp; D. Laham (1998). "<a href="http://lsa.colorado.edu/papers/dp1.LSAintro.pdf" class="external text" title="http://lsa.colorado.edu/papers/dp1.LSAintro.pdf" rel="nofollow">Introduction to Latent Semantic Analysis</a>" (PDF). <i>Discourse Processes</i> <b>25</b>: 259–284<span class="printonly">. <a href="http://lsa.colorado.edu/papers/dp1.LSAintro.pdf" class="external free" title="http://lsa.colorado.edu/papers/dp1.LSAintro.pdf" rel="nofollow">http://lsa.colorado.edu/papers/dp1.LSAintro.pdf</a></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Introduction+to+Latent+Semantic+Analysis&amp;rft.jtitle=Discourse+Processes&amp;rft.aulast=%5B%5BThomas+Landauer%5D%5D%2C+P.+W.+Foltz%2C+%26+D.+Laham&amp;rft.au=%5B%5BThomas+Landauer%5D%5D%2C+P.+W.+Foltz%2C+%26+D.+Laham&amp;rft.date=1998&amp;rft.volume=25&amp;rft.pages=259%E2%80%93284&amp;rft_id=http%3A%2F%2Flsa.colorado.edu%2Fpapers%2Fdp1.LSAintro.pdf&amp;rfr_id=info:sid/en.wikipedia.org:Latent_semantic_analysis"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal" class="" id="CITEREF.5B.5BScott_Deerwester.7CS._Deerwester.5D.5D.2C_.5B.5BSusan_Dumais.5D.5D.2C_.5B.5BGeorge_Furnas.7CG._W._Furnas.5D.5D.2C_.5B.5BThomas_Landauer.7CT._K._Landauer.5D.5D.2C_.5B.5BRichard_Harshman.7CR._Harshman.5D.5D1990"><a href="/wiki/Scott_Deerwester" title="Scott Deerwester">S. Deerwester</a>, <a href="/wiki/Susan_Dumais" title="Susan Dumais">Susan Dumais</a>, <a href="/wiki/George_Furnas" title="George Furnas">G. W. Furnas</a>, <a href="/wiki/Thomas_Landauer" title="Thomas Landauer">T. K. Landauer</a>, <a href="/wiki/Richard_Harshman" title="Richard Harshman">R. Harshman</a> (1990). "<a href="http://lsi.research.telcordia.com/lsi/papers/JASIS90.pdf" class="external text" title="http://lsi.research.telcordia.com/lsi/papers/JASIS90.pdf" rel="nofollow">Indexing by Latent Semantic Analysis</a>" (PDF). <i>Journal of the American Society for Information Science</i> <b>41</b> (6): 391–407. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<span class="neverexpand"><a href="http://dx.doi.org/10.1002%2F%28SICI%291097-4571%28199009%2941%3A6%3C391%3A%3AAID-ASI1%3E3.0.CO%3B2-9" class="external text" title="http://dx.doi.org/10.1002%2F%28SICI%291097-4571%28199009%2941%3A6%3C391%3A%3AAID-ASI1%3E3.0.CO%3B2-9" rel="nofollow">10.1002/(SICI)1097-4571(199009)41:6&lt;391::AID-ASI1&gt;3.0.CO;2-9</a></span><span class="printonly">. <a href="http://lsi.research.telcordia.com/lsi/papers/JASIS90.pdf" class="external free" title="http://lsi.research.telcordia.com/lsi/papers/JASIS90.pdf" rel="nofollow">http://lsi.research.telcordia.com/lsi/papers/JASIS90.pdf</a></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Indexing+by+Latent+Semantic+Analysis&amp;rft.jtitle=Journal+of+the+American+Society+for+Information+Science&amp;rft.aulast=%5B%5BScott+Deerwester%7CS.+Deerwester%5D%5D%2C+%5B%5BSusan+Dumais%5D%5D%2C+%5B%5BGeorge+Furnas%7CG.+W.+Furnas%5D%5D%2C+%5B%5BThomas+Landauer%7CT.+K.+Landauer%5D%5D%2C+%5B%5BRichard+Harshman%7CR.+Harshman%5D%5D&amp;rft.au=%5B%5BScott+Deerwester%7CS.+Deerwester%5D%5D%2C+%5B%5BSusan+Dumais%5D%5D%2C+%5B%5BGeorge+Furnas%7CG.+W.+Furnas%5D%5D%2C+%5B%5BThomas+Landauer%7CT.+K.+Landauer%5D%5D%2C+%5B%5BRichard+Harshman%7CR.+Harshman%5D%5D&amp;rft.date=1990&amp;rft.volume=41&amp;rft.issue=6&amp;rft.pages=391%E2%80%93407&amp;rft_id=info:doi/10.1002%2F%28SICI%291097-4571%28199009%2941%3A6%3C391%3A%3AAID-ASI1%3E3.0.CO%3B2-9&amp;rft_id=http%3A%2F%2Flsi.research.telcordia.com%2Flsi%2Fpapers%2FJASIS90.pdf&amp;rfr_id=info:sid/en.wikipedia.org:Latent_semantic_analysis"><span style="display: none;">&#160;</span></span> Original article where the model was first exposed.</li>
<li><cite style="font-style:normal" class="" id="CITEREFMichael_Berry.2C_.5B.5BSusan_Dumais.7CS.T._Dumais.5D.5D.2C_G.W._O.27Brien1995">Michael Berry, <a href="/wiki/Susan_Dumais" title="Susan Dumais">S.T. Dumais</a>, G.W. O'Brien (1995). <i><a href="http://citeseer.ist.psu.edu/berry95using.html" class="external text" title="http://citeseer.ist.psu.edu/berry95using.html" rel="nofollow">Using Linear Algebra for Intelligent Information Retrieval</a></i><span class="printonly">. <a href="http://citeseer.ist.psu.edu/berry95using.html" class="external free" title="http://citeseer.ist.psu.edu/berry95using.html" rel="nofollow">http://citeseer.ist.psu.edu/berry95using.html</a></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Using+Linear+Algebra+for+Intelligent+Information+Retrieval&amp;rft.aulast=Michael+Berry%2C+%5B%5BSusan+Dumais%7CS.T.+Dumais%5D%5D%2C+G.W.+O%27Brien&amp;rft.au=Michael+Berry%2C+%5B%5BSusan+Dumais%7CS.T.+Dumais%5D%5D%2C+G.W.+O%27Brien&amp;rft.date=1995&amp;rft_id=http%3A%2F%2Fciteseer.ist.psu.edu%2Fberry95using.html&amp;rfr_id=info:sid/en.wikipedia.org:Latent_semantic_analysis"><span style="display: none;">&#160;</span></span> <a href="http://lsirwww.epfl.ch/courses/dis/2003ws/papers/ut-cs-94-270.pdf" class="external text" title="http://lsirwww.epfl.ch/courses/dis/2003ws/papers/ut-cs-94-270.pdf" rel="nofollow">PDF</a>. Illustration of the application of LSA to document retrieval.</li>
<li><cite style="font-style:normal" class="web"><a href="http://iv.slis.indiana.edu/sw/lsa.html" class="external text" title="http://iv.slis.indiana.edu/sw/lsa.html" rel="nofollow">"Latent Semantic Analysis"</a>. InfoVis<span class="printonly">. <a href="http://iv.slis.indiana.edu/sw/lsa.html" class="external free" title="http://iv.slis.indiana.edu/sw/lsa.html" rel="nofollow">http://iv.slis.indiana.edu/sw/lsa.html</a></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=Latent+Semantic+Analysis&amp;rft.atitle=&amp;rft.pub=InfoVis&amp;rft_id=http%3A%2F%2Fiv.slis.indiana.edu%2Fsw%2Flsa.html&amp;rfr_id=info:sid/en.wikipedia.org:Latent_semantic_analysis"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal">T. Hofmann (1999). "<a href="http://www.cs.brown.edu/people/th/papers/Hofmann-UAI99.pdf" class="external text" title="http://www.cs.brown.edu/people/th/papers/Hofmann-UAI99.pdf" rel="nofollow">Probabilistic Latent Semantic Analysis</a>" (PDF). <i>Uncertainty in Artificial Intelligence</i>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.btitle=Uncertainty+in+Artificial+Intelligence&amp;rft.atitle=Probabilistic+Latent+Semantic+Analysis&amp;rft.au=T.+Hofmann&amp;rft.date=1999&amp;rft_id=http%3A%2F%2Fwww.cs.brown.edu%2Fpeople%2Fth%2Fpapers%2FHofmann-UAI99.pdf"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal">G. Gorrell and B. Webb (2005). "<a href="http://www.dcs.shef.ac.uk/~genevieve/gorrell_webb.pdf" class="external text" title="http://www.dcs.shef.ac.uk/~genevieve/gorrell_webb.pdf" rel="nofollow">Generalized Hebbian Algorithm for Latent Semantic Analysis</a>" (PDF). <i>Interspeech</i>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.btitle=Interspeech&amp;rft.atitle=Generalized+Hebbian+Algorithm+for+Latent+Semantic+Analysis&amp;rft.au=G.+Gorrell+and+B.+Webb&amp;rft.date=2005&amp;rft_id=http%3A%2F%2Fwww.dcs.shef.ac.uk%2F%7Egenevieve%2Fgorrell_webb.pdf"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal" class="web" id="CITEREFFridolin_Wild">Fridolin Wild (<span class="mw-formatted-date" title="2005-11-23"><span class="mw-formatted-date" title="11-23"><a href="/wiki/November_23" title="November 23">November 23</a></span>, <a href="/wiki/2005" title="2005">2005</a></span>). <a href="http://cran.at.r-project.org/web/packages/lsa/index.html" class="external text" title="http://cran.at.r-project.org/web/packages/lsa/index.html" rel="nofollow">"An Open Source LSA Package for R"</a>. CRAN<span class="printonly">. <a href="http://cran.at.r-project.org/web/packages/lsa/index.html" class="external free" title="http://cran.at.r-project.org/web/packages/lsa/index.html" rel="nofollow">http://cran.at.r-project.org/web/packages/lsa/index.html</a></span><span class="reference-accessdate">. Retrieved on 2006-11-20</span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=An+Open+Source+LSA+Package+for+R&amp;rft.atitle=&amp;rft.aulast=Fridolin+Wild&amp;rft.au=Fridolin+Wild&amp;rft.date=%5B%5BNovember+23%5D%5D+%5B%5B2005%5D%5D&amp;rft.pub=CRAN&amp;rft_id=http%3A%2F%2Fcran.at.r-project.org%2Fweb%2Fpackages%2Flsa%2Findex.html&amp;rfr_id=info:sid/en.wikipedia.org:Latent_semantic_analysis"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal" class="web" id="CITEREF.5B.5BThomas_Landauer.5D.5D"><a href="/wiki/Thomas_Landauer" title="Thomas Landauer">Thomas Landauer</a>. <a href="http://www.welchco.com/02/14/01/60/96/02/2901.HTM" class="external text" title="http://www.welchco.com/02/14/01/60/96/02/2901.HTM" rel="nofollow">"A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge"</a><span class="printonly">. <a href="http://www.welchco.com/02/14/01/60/96/02/2901.HTM" class="external free" title="http://www.welchco.com/02/14/01/60/96/02/2901.HTM" rel="nofollow">http://www.welchco.com/02/14/01/60/96/02/2901.HTM</a></span><span class="reference-accessdate">. Retrieved on 2007-07-02</span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=A+Solution+to+Plato%27s+Problem%3A+The+Latent+Semantic+Analysis+Theory+of+Acquisition%2C+Induction%2C+and+Representation+of+Knowledge&amp;rft.atitle=&amp;rft.aulast=%5B%5BThomas+Landauer%5D%5D&amp;rft.au=%5B%5BThomas+Landauer%5D%5D&amp;rft_id=http%3A%2F%2Fwww.welchco.com%2F02%2F14%2F01%2F60%2F96%2F02%2F2901.HTM&amp;rfr_id=info:sid/en.wikipedia.org:Latent_semantic_analysis"><span style="display: none;">&#160;</span></span></li>
<li><cite style="font-style:normal" class="web" id="CITEREFDimitrios_Zeimpekis_and_E._Gallopoulos2005">Dimitrios Zeimpekis and E. Gallopoulos (September 11, 2005). <a href="http://scgroup.hpclab.ceid.upatras.gr/scgroup/Projects/TMG/" class="external text" title="http://scgroup.hpclab.ceid.upatras.gr/scgroup/Projects/TMG/" rel="nofollow">"A MATLAB Toolbox for generating term-document matrices from text collections"</a><span class="printonly">. <a href="http://scgroup.hpclab.ceid.upatras.gr/scgroup/Projects/TMG/" class="external free" title="http://scgroup.hpclab.ceid.upatras.gr/scgroup/Projects/TMG/" rel="nofollow">http://scgroup.hpclab.ceid.upatras.gr/scgroup/Projects/TMG/</a></span><span class="reference-accessdate">. Retrieved on 2006-11-20</span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=A+MATLAB+Toolbox+for+generating+term-document+matrices+from+text+collections&amp;rft.atitle=&amp;rft.aulast=Dimitrios+Zeimpekis+and+E.+Gallopoulos&amp;rft.au=Dimitrios+Zeimpekis+and+E.+Gallopoulos&amp;rft.date=September+11%2C+2005&amp;rft_id=http%3A%2F%2Fscgroup.hpclab.ceid.upatras.gr%2Fscgroup%2FProjects%2FTMG%2F&amp;rfr_id=info:sid/en.wikipedia.org:Latent_semantic_analysis"><span style="display: none;">&#160;</span></span></li>
</ul>


<!-- 
NewPP limit report
Preprocessor node count: 4684/1000000
Post-expand include size: 45040/2048000 bytes
Template argument size: 16383/2048000 bytes
Expensive parser function count: 2/500
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:689427-0!1!0!default!!en!2 and timestamp 20090407220743 -->
<div class="printfooter">
Retrieved from "<a href="http://en.wikipedia.org/wiki/Latent_semantic_analysis">http://en.wikipedia.org/wiki/Latent_semantic_analysis</a>"</div>
			<div id='catlinks' class='catlinks'><div id="mw-normal-catlinks"><a href="/wiki/Special:Categories" title="Special:Categories">Categories</a>:&#32;<span dir='ltr'><a href="/wiki/Category:Information_retrieval" title="Category:Information retrieval">Information retrieval</a></span> | <span dir='ltr'><a href="/wiki/Category:Natural_language_processing" title="Category:Natural language processing">Natural language processing</a></span> | <span dir='ltr'><a href="/wiki/Category:Latent_variable_models" title="Category:Latent variable models">Latent variable models</a></span></div><div id="mw-hidden-catlinks" class="mw-hidden-cats-hidden">Hidden categories:&#32;<span dir='ltr'><a href="/wiki/Category:All_pages_needing_cleanup" title="Category:All pages needing cleanup">All pages needing cleanup</a></span> | <span dir='ltr'><a href="/wiki/Category:Articles_with_disputed_statements_from_December_2008" title="Category:Articles with disputed statements from December 2008">Articles with disputed statements from December 2008</a></span> | <span dir='ltr'><a href="/wiki/Category:All_articles_with_unsourced_statements" title="Category:All articles with unsourced statements">All articles with unsourced statements</a></span> | <span dir='ltr'><a href="/wiki/Category:Articles_with_unsourced_statements_since_April_2008" title="Category:Articles with unsourced statements since April 2008">Articles with unsourced statements since April 2008</a></span></div></div>			<!-- end content -->
						<div class="visualClear"></div>
		</div>
	</div>
		</div>
		<div id="column-one">
	<div id="p-cactions" class="portlet">
		<h5>Views</h5>
		<div class="pBody">
			<ul>
	
				 <li id="ca-nstab-main" class="selected"><a href="/wiki/Latent_semantic_analysis" title="View the content page [c]" accesskey="c">Article</a></li>
				 <li id="ca-talk"><a href="/wiki/Talk:Latent_semantic_analysis" title="Discussion about the content page [t]" accesskey="t">Discussion</a></li>
				 <li id="ca-edit"><a href="/w/index.php?title=Latent_semantic_analysis&amp;action=edit" title="You can edit this page. &#10;Please use the preview button before saving. [e]" accesskey="e">Edit this page</a></li>
				 <li id="ca-history"><a href="/w/index.php?title=Latent_semantic_analysis&amp;action=history" title="Past versions of this page [h]" accesskey="h">History</a></li>			</ul>
		</div>
	</div>
	<div class="portlet" id="p-personal">
		<h5>Personal tools</h5>
		<div class="pBody">
			<ul>
				<li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Latent_semantic_analysis" title="You are encouraged to log in; however, it is not mandatory. [o]" accesskey="o">Log in / create account</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-logo">
		<a style="background-image: url(http://upload.wikimedia.org/wikipedia/en/b/bc/Wiki.png);" href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
	<div class='generated-sidebar portlet' id='p-navigation'>
		<h5>Navigation</h5>
		<div class='pBody'>
			<ul>
				<li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li>
				<li id="n-contents"><a href="/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li>
				<li id="n-featuredcontent"><a href="/wiki/Portal:Featured_content" title="Featured content — the best of Wikipedia">Featured content</a></li>
				<li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li>
				<li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li>
			</ul>
		</div>
	</div>
	<div id="p-search" class="portlet">
		<h5><label for="searchInput">Search</label></h5>
		<div id="searchBody" class="pBody">
			<form action="/w/index.php" id="searchform"><div>
				<input type='hidden' name="title" value="Special:Search"/>
				<input id="searchInput" name="search" type="text" title="Search Wikipedia [f]" accesskey="f" value="" />
				<input type='submit' name="go" class="searchButton" id="searchGoButton"	value="Go" title="Go to a page with this exact name if one exists" />&nbsp;
				<input type='submit' name="fulltext" class="searchButton" id="mw-searchButton" value="Search" title="Search Wikipedia for this text" />
			</div></form>
		</div>
	</div>
	<div class='generated-sidebar portlet' id='p-interaction'>
		<h5>Interaction</h5>
		<div class='pBody'>
			<ul>
				<li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li>
				<li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li>
				<li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="The list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li>
				<li id="n-contact"><a href="/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact Wikipedia</a></li>
				<li id="n-sitesupport"><a href="http://wikimediafoundation.org/wiki/Donate" title="Support us">Donate to Wikipedia</a></li>
				<li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-tb">
		<h5>Toolbox</h5>
		<div class="pBody">
			<ul>
				<li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Latent_semantic_analysis" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li>
				<li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Latent_semantic_analysis" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li>
<li id="t-upload"><a href="/wiki/Wikipedia:Upload" title="Upload files [u]" accesskey="u">Upload file</a></li>
<li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="List of all special pages [q]" accesskey="q">Special pages</a></li>
				<li id="t-print"><a href="/w/index.php?title=Latent_semantic_analysis&amp;printable=yes" rel="alternate" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>				<li id="t-permalink"><a href="/w/index.php?title=Latent_semantic_analysis&amp;oldid=282432233" title="Permanent link to this version of the page">Permanent link</a></li><li id="t-cite"><a href="/w/index.php?title=Special:Cite&amp;page=Latent_semantic_analysis&amp;id=282432233">Cite this page</a></li>			</ul>
		</div>
	</div>
	<div id="p-lang" class="portlet">
		<h5>Languages</h5>
		<div class="pBody">
			<ul>
				<li class="interwiki-de"><a href="http://de.wikipedia.org/wiki/Latent_Semantic_Indexing">Deutsch</a></li>
				<li class="interwiki-fr"><a href="http://fr.wikipedia.org/wiki/Analyse_s%C3%A9mantique_latente">Français</a></li>
				<li class="interwiki-ja"><a href="http://ja.wikipedia.org/wiki/%E6%BD%9C%E5%9C%A8%E6%84%8F%E5%91%B3%E8%A7%A3%E6%9E%90">日本語</a></li>
				<li class="interwiki-ru"><a href="http://ru.wikipedia.org/wiki/%D0%9B%D0%B0%D1%82%D0%B5%D0%BD%D1%82%D0%BD%D0%BE-%D1%81%D0%B5%D0%BC%D0%B0%D0%BD%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7">Русский</a></li>
				<li class="interwiki-zh"><a href="http://zh.wikipedia.org/wiki/%E6%BD%9C%E5%9C%A8%E8%AF%AD%E4%B9%89%E5%AD%A6">中文</a></li>
			</ul>
		</div>
	</div>
		</div><!-- end of the left (by default at least) column -->
			<div class="visualClear"></div>
			<div id="footer">
				<div id="f-poweredbyico"><a href="http://www.mediawiki.org/"><img src="/skins-1.5/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" /></a></div>
				<div id="f-copyrightico"><a href="http://wikimediafoundation.org/"><img src="/images/wikimedia-button.png" border="0" alt="Wikimedia Foundation"/></a></div>
			<ul id="f-list">
					<li id="lastmod"> This page was last modified on 7 April 2009, at 22:07 (UTC).</li>
					<li id="copyright">All text is available under the terms of the <a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Text_of_the_GNU_Free_Documentation_License" title="Wikipedia:Text of the GNU Free Documentation License">GNU Free Documentation License</a>. (See <b><a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Copyrights" title="Wikipedia:Copyrights">Copyrights</a></b> for details.) <br /> Wikipedia&reg; is a registered trademark of the <a href="http://www.wikimediafoundation.org">Wikimedia Foundation, Inc.</a>, a U.S. registered <a class='internal' href="http://en.wikipedia.org/wiki/501%28c%29#501.28c.29.283.29" title="501(c)(3)">501(c)(3)</a> <a href="http://wikimediafoundation.org/wiki/Deductibility_of_donations">tax-deductible</a> <a class='internal' href="http://en.wikipedia.org/wiki/Non-profit_organization" title="Non-profit organization">nonprofit</a> <a href="http://en.wikipedia.org/wiki/Charitable_organization" title="Charitable organization">charity</a>.<br /></li>
					<li id="privacy"><a href="http://wikimediafoundation.org/wiki/Privacy_policy" title="wikimedia:Privacy policy">Privacy policy</a></li>
					<li id="about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
					<li id="disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
			</ul>
		</div>
</div>

		<script type="text/javascript">if (window.runOnloadHook) runOnloadHook();</script>
<!-- Served by srv206 in 0.042 secs. --></body></html>
